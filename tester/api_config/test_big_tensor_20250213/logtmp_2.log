test begin: paddle.broadcast_to(Tensor([1073741824, 1, 4],"bool"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([1073741824, 1, 4],"bool"), list[2,2,4,], ) 
 The expanded size of the tensor (2) must match the existing size (1073741824) at non-singleton dimension 0.  Target sizes: [2, 2, 4].  Tensor sizes: [1073741824, 1, 4]

W0205 15:42:35.730765 162659 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:42:35.731854 162659 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1073741824, 1, 4],"float32"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([1073741824, 1, 4],"float32"), list[2,2,4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 43081 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:43:48.137796 162946 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:43:48.138908 162946 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1073741824, 1, 4],"int32"), tuple(5,1,4,), )
[torch error] paddle.broadcast_to(Tensor([1073741824, 1, 4],"int32"), tuple(5,1,4,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 100750 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:44:57.332720 163557 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:44:57.333683 163557 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1073741824, 4],"bool"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([1073741824, 4],"bool"), list[2,2,4,], ) 
 The expanded size of the tensor (2) must match the existing size (1073741824) at non-singleton dimension 1.  Target sizes: [2, 2, 4].  Tensor sizes: [1073741824, 4]

W0205 15:46:02.458865   413 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:46:02.460245   413 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1073741825, 2],"int64"), list[4,2,], )
[torch error] paddle.broadcast_to(Tensor([1073741825, 2],"int64"), list[4,2,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 37610 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:46:47.354876   725 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:46:47.355899   725 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1073741825, 2],"int64"), tuple(2,2,), )
[torch error] paddle.broadcast_to(Tensor([1073741825, 2],"int64"), tuple(2,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 73851 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:47:30.572840   984 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:47:30.573972   984 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1073741825, 2],"int64"), tuple(3,2,), )
[torch error] paddle.broadcast_to(Tensor([1073741825, 2],"int64"), tuple(3,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 101613 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:48:14.255420  1163 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:48:14.256474  1163 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([111, 222, 87148],"float64"), list[111,222,333,], )
[torch error] paddle.broadcast_to(Tensor([111, 222, 87148],"float64"), list[111,222,333,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 145142 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:49:03.035374  1418 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:49:03.036425  1418 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([111, 58099, 333],"float64"), list[111,222,333,], )
[torch error] paddle.broadcast_to(Tensor([111, 58099, 333],"float64"), list[111,222,333,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 10933 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:49:49.546252  1606 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:49:49.547410  1606 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([128, 16777217],"int64"), tuple(128,1,), )
[torch error] paddle.broadcast_to(Tensor([128, 16777217],"int64"), tuple(128,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 47252 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:50:34.335464  1858 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:50:34.336460  1858 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([128, 33554432],"float32"), tuple(128,8,), )
[torch error] paddle.broadcast_to(Tensor([128, 33554432],"float32"), tuple(128,8,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 72444 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:51:41.902724  2031 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:51:41.903795  2031 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1431655765, 3],"bool"), list[3,3,], )
[torch error] paddle.broadcast_to(Tensor([1431655765, 3],"bool"), list[3,3,], ) 
 The expanded size of the tensor (3) must match the existing size (1431655765) at non-singleton dimension 0.  Target sizes: [3, 3].  Tensor sizes: [1431655765, 3]

W0205 15:52:51.790359  2335 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:52:51.791666  2335 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1431655765, 3],"float32"), tuple(1,3,), )
[torch error] paddle.broadcast_to(Tensor([1431655765, 3],"float32"), tuple(1,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 18573 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:54:01.815896  2708 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:54:01.817008  2708 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1431655765, 3],"float32"), tuple(2,3,), )
[torch error] paddle.broadcast_to(Tensor([1431655765, 3],"float32"), tuple(2,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 68824 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:55:16.368919  2992 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:55:16.369997  2992 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1431655765, 3],"float32"), tuple(3,3,), )
[torch error] paddle.broadcast_to(Tensor([1431655765, 3],"float32"), tuple(3,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 130937 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:56:27.185879  3390 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:56:27.186997  3390 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1431655765, 3],"float32"), tuple(4,3,), )
[torch error] paddle.broadcast_to(Tensor([1431655765, 3],"float32"), tuple(4,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 19466 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:57:36.296391  3714 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:57:36.297374  3714 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1431655765, 3],"float32"), tuple(8,3,), )
[torch error] paddle.broadcast_to(Tensor([1431655765, 3],"float32"), tuple(8,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 64075 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:58:45.507431  4000 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:58:45.508430  4000 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1431655765, 3],"int32"), tuple(1,3,), )
[torch error] paddle.broadcast_to(Tensor([1431655765, 3],"int32"), tuple(1,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 125812 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:59:54.903080  4404 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:59:54.904170  4404 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1619, 1327104],"int64"), tuple(64,1327104,), )
[torch error] paddle.broadcast_to(Tensor([1619, 1327104],"int64"), tuple(64,1327104,), ) 
 CUDA out of memory. Tried to allocate 16.01 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 15923 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:00:38.410400  4703 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:00:38.411485  4703 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([171798692, 5, 5],"float16"), tuple(5,5,5,), )
[torch error] paddle.broadcast_to(Tensor([171798692, 5, 5],"float16"), tuple(5,5,5,), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 40662 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:02:01.573381  4881 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:02:01.574486  4881 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([171798692, 5, 5],"float32"), tuple(5,5,5,), )
[torch error] paddle.broadcast_to(Tensor([171798692, 5, 5],"float32"), tuple(5,5,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 105001 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:03:10.761241  5274 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:03:10.762488  5274 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([171798692, 5, 5],"int32"), tuple(1,5,5,), )
[torch error] paddle.broadcast_to(Tensor([171798692, 5, 5],"int32"), tuple(1,5,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 162207 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:04:19.577498  5564 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:04:19.578646  5564 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([178956971, 12],"float64"), tuple(5,12,), )
[torch error] paddle.broadcast_to(Tensor([178956971, 12],"float64"), tuple(5,12,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 45410 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:05:06.606065  5939 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:05:06.607041  5939 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([178956971, 3, 4],"float64"), tuple(2,3,4,), )
[torch error] paddle.broadcast_to(Tensor([178956971, 3, 4],"float64"), tuple(2,3,4,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 72995 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:05:52.870405  6104 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:05:52.871510  6104 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([178956971, 3, 4],"float64"), tuple(5,3,4,), )
[torch error] paddle.broadcast_to(Tensor([178956971, 3, 4],"float64"), tuple(5,3,4,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 118890 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:06:38.116674  6349 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:06:38.117794  6349 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 1, 2147483648],"bool"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2, 1, 2147483648],"bool"), list[2,2,4,], ) 
 The expanded size of the tensor (4) must match the existing size (2147483648) at non-singleton dimension 2.  Target sizes: [2, 2, 4].  Tensor sizes: [2, 1, 2147483648]

W0205 16:07:44.646742  6514 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:07:44.647867  6514 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 1, 2147483648],"float32"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2, 1, 2147483648],"float32"), list[2,2,4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 37570 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:08:54.534931  6899 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:08:54.535915  6899 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 1073741825],"float64"), tuple(2,3,), )
[torch error] paddle.broadcast_to(Tensor([2, 1073741825],"float64"), tuple(2,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 92822 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:09:41.915558  7191 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:09:41.916544  7191 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 1073741825],"int64"), tuple(2,2,), )
[torch error] paddle.broadcast_to(Tensor([2, 1073741825],"int64"), tuple(2,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 126882 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:10:24.283015  7361 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:10:24.284091  7361 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 2, 1073741824],"bool"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2, 2, 1073741824],"bool"), list[2,2,4,], ) 
 The expanded size of the tensor (4) must match the existing size (1073741824) at non-singleton dimension 2.  Target sizes: [2, 2, 4].  Tensor sizes: [2, 2, 1073741824]

W0205 16:11:31.663275  7658 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:11:31.664331  7658 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 2, 1073741824],"float32"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2, 2, 1073741824],"float32"), list[2,2,4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 43333 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:12:40.801303  8015 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:12:40.802345  8015 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 2, 1073741824],"float32"), list[3,2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2, 2, 1073741824],"float32"), list[3,2,2,4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 100638 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:13:56.351629  8348 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:13:56.352705  8348 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 2147483648, 1],"bool"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2, 2147483648, 1],"bool"), list[2,2,4,], ) 
 The expanded size of the tensor (2) must match the existing size (2147483648) at non-singleton dimension 1.  Target sizes: [2, 2, 4].  Tensor sizes: [2, 2147483648, 1]

W0205 16:15:03.927713  8761 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:15:03.928929  8761 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 2147483648, 1],"float32"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2, 2147483648, 1],"float32"), list[2,2,4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 36984 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:16:22.120932  9128 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:16:22.121904  9128 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 2147483648, 1],"float32"), list[3,2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2, 2147483648, 1],"float32"), list[3,2,2,4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 103726 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:17:38.715241  9500 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:17:38.716295  9500 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 2147483648],"bool"), list[1,2,2,], )
[torch error] paddle.broadcast_to(Tensor([2, 2147483648],"bool"), list[1,2,2,], ) 
 The expanded size of the tensor (2) must match the existing size (2147483648) at non-singleton dimension 2.  Target sizes: [1, 2, 2].  Tensor sizes: [2, 2147483648]

W0205 16:18:43.299172  9803 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:18:43.300326  9803 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 2147483648],"bool"), list[2,2,], )
[torch error] paddle.broadcast_to(Tensor([2, 2147483648],"bool"), list[2,2,], ) 
 The expanded size of the tensor (2) must match the existing size (2147483648) at non-singleton dimension 1.  Target sizes: [2, 2].  Tensor sizes: [2, 2147483648]

W0205 16:19:47.696623 10170 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:19:47.697798 10170 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 2147483648],"bool"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2, 2147483648],"bool"), list[2,2,4,], ) 
 The expanded size of the tensor (4) must match the existing size (2147483648) at non-singleton dimension 2.  Target sizes: [2, 2, 4].  Tensor sizes: [2, 2147483648]

W0205 16:20:51.026293 10455 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:20:51.027555 10455 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 2147483648],"float32"), tuple(2,2,), )
[torch error] paddle.broadcast_to(Tensor([2, 2147483648],"float32"), tuple(2,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 139420 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:22:04.289706 10728 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:22:04.290663 10728 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 2147483648],"float32"), tuple(2,3,), )
[torch error] paddle.broadcast_to(Tensor([2, 2147483648],"float32"), tuple(2,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 27338 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:23:17.336679 11039 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:23:17.337646 11039 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 2147483648],"int32"), tuple(2,1,), )
[torch error] paddle.broadcast_to(Tensor([2, 2147483648],"int32"), tuple(2,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 86879 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:24:30.789546 11417 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:24:30.790537 11417 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 268435457, 4],"float64"), tuple(2,3,4,), )
[torch error] paddle.broadcast_to(Tensor([2, 268435457, 4],"float64"), tuple(2,3,4,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 132023 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:25:14.988101 11711 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:25:14.989132 11711 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 3, 357913942],"float64"), tuple(2,3,4,), )
[torch error] paddle.broadcast_to(Tensor([2, 3, 357913942],"float64"), tuple(2,3,4,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 10715 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:26:00.111035 11963 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:26:00.112278 11963 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 536870912, 4],"bool"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2, 536870912, 4],"bool"), list[2,2,4,], ) 
 The expanded size of the tensor (2) must match the existing size (536870912) at non-singleton dimension 1.  Target sizes: [2, 2, 4].  Tensor sizes: [2, 536870912, 4]

W0205 16:27:18.326876 12135 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:27:18.328258 12135 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 536870912, 4],"float32"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2, 536870912, 4],"float32"), list[2,2,4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 109686 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:28:31.996317 12521 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:28:31.997277 12521 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2, 536870912, 4],"float32"), list[3,2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2, 536870912, 4],"float32"), list[3,2,2,4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 157628 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:29:38.306813 12805 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:29:38.307926 12805 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([21053762, 17, 1, 6],"float64"), list[5,17,0,6,], )
[torch error] paddle.broadcast_to(Tensor([21053762, 17, 1, 6],"float64"), list[5,17,0,6,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 42352 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:30:22.583910 13089 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:30:22.585000 13089 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([21053762, 17, 6],"float64"), list[0,5,17,6,], )
[torch error] paddle.broadcast_to(Tensor([21053762, 17, 6],"float64"), list[0,5,17,6,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 79956 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:31:07.249131 13340 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:31:07.250528 13340 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([21053762, 17, 6],"float64"), list[5,17,6,], )
[torch error] paddle.broadcast_to(Tensor([21053762, 17, 6],"float64"), list[5,17,6,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 108483 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:31:58.058101 13527 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:31:58.059219 13527 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483648, 2, 1],"bool"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2147483648, 2, 1],"bool"), list[2,2,4,], ) 
 The expanded size of the tensor (2) must match the existing size (2147483648) at non-singleton dimension 0.  Target sizes: [2, 2, 4].  Tensor sizes: [2147483648, 2, 1]

W0205 16:33:01.575467 13780 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:33:01.576766 13780 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483648, 2, 1],"float32"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2147483648, 2, 1],"float32"), list[2,2,4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 32463 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:34:08.993425 14044 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:34:08.994390 14044 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483648, 2, 1],"float32"), list[3,2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([2147483648, 2, 1],"float32"), list[3,2,2,4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 84583 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:35:22.836134 14342 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:35:22.837178 14342 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483648, 2],"bool"), list[1,2,2,], )
[torch error] paddle.broadcast_to(Tensor([2147483648, 2],"bool"), list[1,2,2,], ) 
 The expanded size of the tensor (2) must match the existing size (2147483648) at non-singleton dimension 1.  Target sizes: [1, 2, 2].  Tensor sizes: [2147483648, 2]

W0205 16:36:27.027078 14723 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:36:27.028239 14723 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483648, 2],"bool"), list[2,2,], )
[torch error] paddle.broadcast_to(Tensor([2147483648, 2],"bool"), list[2,2,], ) 
 The expanded size of the tensor (2) must match the existing size (2147483648) at non-singleton dimension 0.  Target sizes: [2, 2].  Tensor sizes: [2147483648, 2]

W0205 16:37:31.552395 15011 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:37:31.553869 15011 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483648, 2],"float32"), list[4,2,], )
[torch error] paddle.broadcast_to(Tensor([2147483648, 2],"float32"), list[4,2,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 68044 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:38:44.916024 15323 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:38:44.917150 15323 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483648, 2],"float32"), tuple(2,2,), )
[torch error] paddle.broadcast_to(Tensor([2147483648, 2],"float32"), tuple(2,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 131408 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:39:55.790879 15700 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:39:55.791954 15700 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483648, 2],"float32"), tuple(4,2,), )
[torch error] paddle.broadcast_to(Tensor([2147483648, 2],"float32"), tuple(4,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 20271 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:41:09.138432 15992 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:41:09.139395 15992 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483648, 2],"float32"), tuple(5,2,), )
[torch error] paddle.broadcast_to(Tensor([2147483648, 2],"float32"), tuple(5,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 75413 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:42:15.945092 16295 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:42:15.957020 16295 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(1,3,), )
[torch error] paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(1,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 132511 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:43:02.582135 16657 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:43:02.583194 16657 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(128,1,), )
[torch error] paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(128,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 160019 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:43:45.706403 16829 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:43:45.707929 16829 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(28,1,), )
[torch error] paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(28,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 30154 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:44:29.616600 17085 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:44:29.617743 17085 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(30,1,), )
[torch error] paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(30,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 57540 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:45:25.696849 17250 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:45:25.698057 17250 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(38,1,), )
[torch error] paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(38,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 101797 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:46:08.625672 17516 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:46:08.627171 17516 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(4,1,), )
[torch error] paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(4,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 138105 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:46:51.684782 17688 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:46:51.685894 17688 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(5,1,), )
[torch error] paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(5,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 8626 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:47:47.736660 17923 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:47:47.737788 17923 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(8,1,), )
[torch error] paddle.broadcast_to(Tensor([2147483649, 1],"int64"), tuple(8,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 49626 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:48:33.397239 18194 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:48:33.398268 18194 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649],"float64"), list[1,1,2048,2048,], )
[torch error] paddle.broadcast_to(Tensor([2147483649],"float64"), list[1,1,2048,2048,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 81701 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:49:22.980175 18369 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:49:22.981297 18369 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649],"float64"), list[10,10,5,], )
[torch error] paddle.broadcast_to(Tensor([2147483649],"float64"), list[10,10,5,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 125910 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:50:10.029578 18628 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:50:10.030892 18628 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649],"float64"), list[100,100,], )
[torch error] paddle.broadcast_to(Tensor([2147483649],"float64"), list[100,100,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 4218 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:51:00.329927 18801 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:51:00.330878 18801 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649],"float64"), list[4,], )
[torch error] paddle.broadcast_to(Tensor([2147483649],"float64"), list[4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 35794 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:51:48.824342 19059 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:51:48.825362 19059 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649],"float64"), shape=tuple(1,), )
[torch error] paddle.broadcast_to(Tensor([2147483649],"float64"), shape=tuple(1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 70239 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:52:38.778383 19319 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:52:38.779336 19319 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649],"float64"), shape=tuple(5000,1,), )
[torch error] paddle.broadcast_to(Tensor([2147483649],"float64"), shape=tuple(5000,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 106889 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:53:28.600531 19497 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:53:28.601543 19497 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649],"float64"), tuple(168,), )
[torch error] paddle.broadcast_to(Tensor([2147483649],"float64"), tuple(168,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 144565 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:54:17.973692 19757 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:54:17.974785 19757 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649],"int64"), list[1,], )
[torch error] paddle.broadcast_to(Tensor([2147483649],"int64"), list[1,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 24015 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:55:01.498900 20016 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:55:01.500005 20016 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649],"int64"), list[2,100,], )
[torch error] paddle.broadcast_to(Tensor([2147483649],"int64"), list[2,100,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 52461 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:55:47.436514 20181 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:55:47.437500 20181 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649],"int64"), list[3,10,], )
[torch error] paddle.broadcast_to(Tensor([2147483649],"int64"), list[3,10,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 91552 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:56:34.153254 20434 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:56:34.154227 20434 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649],"int64"), list[3,4,], )
[torch error] paddle.broadcast_to(Tensor([2147483649],"int64"), list[3,4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 124553 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:57:18.343701 20625 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:57:18.344822 20625 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649],"int64"), list[3,4,2,], )
[torch error] paddle.broadcast_to(Tensor([2147483649],"int64"), list[3,4,2,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 4240 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:58:01.600718 20893 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:58:01.601833 20893 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([2147483649],"int64"), list[5,4,], )
[torch error] paddle.broadcast_to(Tensor([2147483649],"int64"), list[5,4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 36174 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:58:45.116390 21046 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:58:45.117544 21046 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([214748365, 1, 10],"float64"), tuple(10,1,10,), )
[torch error] paddle.broadcast_to(Tensor([214748365, 1, 10],"float64"), tuple(10,1,10,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 72691 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:59:30.884291 21299 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:59:30.885337 21299 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([214748365, 1, 10],"int64"), tuple(10,1,10,), )
[torch error] paddle.broadcast_to(Tensor([214748365, 1, 10],"int64"), tuple(10,1,10,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 102421 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:00:14.257418 21457 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:00:14.258863 21457 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([214748365, 20],"int32"), list[10,20,], )
[torch error] paddle.broadcast_to(Tensor([214748365, 20],"int32"), list[10,20,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 145657 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:01:23.081774 21706 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:01:23.082778 21706 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([21474837, 100],"float64"), list[100,100,], )
[torch error] paddle.broadcast_to(Tensor([21474837, 100],"float64"), list[100,100,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28872 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:02:10.717674 21983 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:02:10.718724 21983 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([222, 9673350],"float64"), list[111,222,333,], )
[torch error] paddle.broadcast_to(Tensor([222, 9673350],"float64"), list[111,222,333,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 70602 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:02:59.724614 22155 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:02:59.791499 22155 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([28, 153391690],"float32"), tuple(28,5,), )
[torch error] paddle.broadcast_to(Tensor([28, 153391690],"float32"), tuple(28,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 101689 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:04:08.494244 22407 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:04:08.495208 22407 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([28, 76695845],"int64"), tuple(28,1,), )
[torch error] paddle.broadcast_to(Tensor([28, 76695845],"int64"), tuple(28,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 154916 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:04:55.826488 22706 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:04:55.827454 22706 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([29050, 222, 333],"float64"), list[111,222,333,], )
[torch error] paddle.broadcast_to(Tensor([29050, 222, 333],"float64"), list[111,222,333,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 27560 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:05:48.000715 22960 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:05:48.001820 22960 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([3, 1431655765],"bool"), list[3,40,], )
[torch error] paddle.broadcast_to(Tensor([3, 1431655765],"bool"), list[3,40,], ) 
 The expanded size of the tensor (40) must match the existing size (1431655765) at non-singleton dimension 1.  Target sizes: [3, 40].  Tensor sizes: [3, 1431655765]

W0205 17:06:52.770503 23209 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:06:52.771631 23209 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([3, 1431655765],"float32"), tuple(3,3,), )
[torch error] paddle.broadcast_to(Tensor([3, 1431655765],"float32"), tuple(3,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 120726 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:08:16.449808 23473 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:08:16.450887 23473 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([3, 1431655765],"float32"), tuple(3,5,), )
[torch error] paddle.broadcast_to(Tensor([3, 1431655765],"float32"), tuple(3,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 26872 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:09:30.671978 23872 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:09:30.672960 23872 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([3, 2, 715827883],"float32"), tuple(3,2,5,), )
[torch error] paddle.broadcast_to(Tensor([3, 2, 715827883],"float32"), tuple(3,2,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 73412 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:10:43.646135 24165 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:10:43.647094 24165 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([3, 286331153, 5],"float32"), tuple(3,2,5,), )
[torch error] paddle.broadcast_to(Tensor([3, 286331153, 5],"float32"), tuple(3,2,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 135915 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:11:51.940502 24537 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:11:51.941637 24537 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([3, 715827883],"float64"), tuple(3,5,), )
[torch error] paddle.broadcast_to(Tensor([3, 715827883],"float64"), tuple(3,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 23419 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:12:42.488143 24837 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:12:42.489226 24837 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([3, 715827883],"int64"), tuple(3,2,), )
[torch error] paddle.broadcast_to(Tensor([3, 715827883],"int64"), tuple(3,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 64130 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:13:26.045979 25096 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:13:26.047140 25096 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([30, 143165577],"bool"), list[30,3,], )
[torch error] paddle.broadcast_to(Tensor([30, 143165577],"bool"), list[30,3,], ) 
 The expanded size of the tensor (3) must match the existing size (143165577) at non-singleton dimension 1.  Target sizes: [30, 3].  Tensor sizes: [30, 143165577]

W0205 17:14:31.157291 25274 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:14:31.158432 25274 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([30, 143165577],"float32"), tuple(30,5,), )
[torch error] paddle.broadcast_to(Tensor([30, 143165577],"float32"), tuple(30,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 144267 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:15:38.030268 25556 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:15:38.031456 25556 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([30, 71582789],"int64"), tuple(30,1,), )
[torch error] paddle.broadcast_to(Tensor([30, 71582789],"int64"), tuple(30,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 34529 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:16:21.514631 25824 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:16:21.515726 25824 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([300, 14316558],"float16"), list[300,40,], )
[torch error] paddle.broadcast_to(Tensor([300, 14316558],"float16"), list[300,40,], ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 75470 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:17:49.184993 26101 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:17:49.185968 26101 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([306783379, 7],"float64"), tuple(4,7,), )
[torch error] paddle.broadcast_to(Tensor([306783379, 7],"float64"), tuple(4,7,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 139291 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:18:41.897302 26609 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:18:41.898283 26609 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([3237, 1327104],"float32"), tuple(64,1327104,), )
[torch error] paddle.broadcast_to(Tensor([3237, 1327104],"float32"), tuple(64,1327104,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 20787 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:19:49.189822 26846 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:19:49.190972 26846 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([357913942, 1, 6],"float64"), list[4,5,6,], )
[torch error] paddle.broadcast_to(Tensor([357913942, 1, 6],"float64"), list[4,5,6,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 66728 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:20:34.142697 27215 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:20:34.143715 27215 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([357913942, 3, 2],"int64"), tuple(4,3,2,), )
[torch error] paddle.broadcast_to(Tensor([357913942, 3, 2],"int64"), tuple(4,3,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 97368 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:21:19.871651 27382 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:21:19.872704 27382 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([357913942, 3, 4],"int32"), tuple(1,3,4,), )
[torch error] paddle.broadcast_to(Tensor([357913942, 3, 4],"int32"), tuple(1,3,4,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 139857 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:22:28.082166 27633 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:22:28.083263 27633 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([357913942, 6, 1],"int64"), tuple(5,6,1,), )
[torch error] paddle.broadcast_to(Tensor([357913942, 6, 1],"int64"), tuple(5,6,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 21722 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:23:11.011111 27934 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:23:11.012743 27934 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([38, 113025456],"float32"), tuple(38,5,), )
[torch error] paddle.broadcast_to(Tensor([38, 113025456],"float32"), tuple(38,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 62459 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:24:24.680116 28100 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:24:24.681106 28100 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([38, 56512728],"int64"), tuple(38,1,), )
[torch error] paddle.broadcast_to(Tensor([38, 56512728],"int64"), tuple(38,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 111255 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:25:08.390576 28465 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:25:08.392056 28465 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4, 1, 1073741824],"int32"), tuple(4,1,6,), )
[torch error] paddle.broadcast_to(Tensor([4, 1, 1073741824],"int32"), tuple(4,1,6,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 143555 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:26:15.577010 28644 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:26:15.578058 28644 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4, 1073741824, 1],"int32"), tuple(4,7,1,), )
[torch error] paddle.broadcast_to(Tensor([4, 1073741824, 1],"int32"), tuple(4,7,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 41971 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:27:22.515908 29062 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:27:22.517014 29062 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4, 1073741824],"float32"), list[4,2,], )
[torch error] paddle.broadcast_to(Tensor([4, 1073741824],"float32"), list[4,2,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 88758 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:28:33.114440 29387 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:28:33.115438 29387 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4, 1073741824],"float32"), tuple(4,2,), )
[torch error] paddle.broadcast_to(Tensor([4, 1073741824],"float32"), tuple(4,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 137988 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:29:41.731472 29672 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:29:41.732481 29672 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4, 1073741824],"float32"), tuple(4,3,), )
[torch error] paddle.broadcast_to(Tensor([4, 1073741824],"float32"), tuple(4,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 34944 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:30:54.568748 29957 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:30:54.569868 29957 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4, 1073741824],"float32"), tuple(4,7,), )
[torch error] paddle.broadcast_to(Tensor([4, 1073741824],"float32"), tuple(4,7,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 89790 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:32:01.515996 30345 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:32:01.517030 30345 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4, 1073741824],"int32"), tuple(4,1,), )
[torch error] paddle.broadcast_to(Tensor([4, 1073741824],"int32"), tuple(4,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 139169 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:33:14.736023 30636 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:33:14.737092 30636 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4, 178956971, 6],"int32"), tuple(4,1,6,), )
[torch error] paddle.broadcast_to(Tensor([4, 178956971, 6],"int32"), tuple(4,1,6,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 45291 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:34:22.736505 31023 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:34:22.738246 31023 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4, 3, 357913942],"float32"), tuple(4,3,2,), )
[torch error] paddle.broadcast_to(Tensor([4, 3, 357913942],"float32"), tuple(4,3,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 98347 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:35:30.707716 31298 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:35:30.709230 31298 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4, 536870912, 2],"float32"), tuple(4,3,2,), )
[torch error] paddle.broadcast_to(Tensor([4, 536870912, 2],"float32"), tuple(4,3,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 150416 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:36:38.289757 31599 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:36:38.290858 31599 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4, 536870913],"float64"), tuple(4,42,), )
[torch error] paddle.broadcast_to(Tensor([4, 536870913],"float64"), tuple(4,42,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 53798 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:37:31.317997 31885 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:37:31.319077 31885 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4, 536870913],"float64"), tuple(4,7,), )
[torch error] paddle.broadcast_to(Tensor([4, 536870913],"float64"), tuple(4,7,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 100293 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:38:21.777827 32145 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:38:21.778856 32145 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4, 536870913],"int64"), list[4,2,], )
[torch error] paddle.broadcast_to(Tensor([4, 536870913],"int64"), list[4,2,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 152914 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:39:09.380137 32391 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:39:09.381155 32391 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4, 536870913],"int64"), tuple(4,1,), )
[torch error] paddle.broadcast_to(Tensor([4, 536870913],"int64"), tuple(4,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 33283 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:39:55.128471 32589 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:39:55.130009 32589 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4, 7, 153391690],"int32"), tuple(4,7,1,), )
[torch error] paddle.broadcast_to(Tensor([4, 7, 153391690],"int32"), tuple(4,7,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 64782 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:41:09.931205 32830 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:41:09.932192 32830 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4, 7, 76695845],"float64"), tuple(4,7,6,), )
[torch error] paddle.broadcast_to(Tensor([4, 7, 76695845],"float64"), tuple(4,7,6,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 137553 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:41:56.610038 33137 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:41:56.611359 33137 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4, 89478486, 6],"float64"), tuple(4,7,6,), )
[torch error] paddle.broadcast_to(Tensor([4, 89478486, 6],"float64"), tuple(4,7,6,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 5238 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:42:46.463493 33389 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:42:46.464566 33389 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295, 1, 1, 1],"int32"), tuple(10,10,1,10,), )
[torch error] paddle.broadcast_to(Tensor([4294967295, 1, 1, 1],"int32"), tuple(10,10,1,10,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 45125 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:43:53.296077 33663 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:43:53.297190 33663 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295, 1, 1],"float32"), list[10,20,1,], )
[torch error] paddle.broadcast_to(Tensor([4294967295, 1, 1],"float32"), list[10,20,1,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 97828 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:45:06.116827 33966 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:45:06.117820 33966 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295, 1],"bool"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([4294967295, 1],"bool"), list[2,2,4,], ) 
 The expanded size of the tensor (2) must match the existing size (4294967295) at non-singleton dimension 1.  Target sizes: [2, 2, 4].  Tensor sizes: [4294967295, 1]

W0205 17:46:11.789971 34245 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:46:11.818095 34245 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295, 1],"bool"), list[3,40,], )
[torch error] paddle.broadcast_to(Tensor([4294967295, 1],"bool"), list[3,40,], ) 
 The expanded size of the tensor (3) must match the existing size (4294967295) at non-singleton dimension 0.  Target sizes: [3, 40].  Tensor sizes: [4294967295, 1]

W0205 17:47:16.754324 34540 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:47:16.755559 34540 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295, 1],"bool"), list[30,3,], )
[torch error] paddle.broadcast_to(Tensor([4294967295, 1],"bool"), list[30,3,], ) 
 The expanded size of the tensor (30) must match the existing size (4294967295) at non-singleton dimension 0.  Target sizes: [30, 3].  Tensor sizes: [4294967295, 1]

W0205 17:48:26.589109 34900 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:48:26.590148 34900 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295, 1],"float16"), list[300,40,], )
[torch error] paddle.broadcast_to(Tensor([4294967295, 1],"float16"), list[300,40,], ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 11018 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:49:52.412127 35191 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:49:52.421433 35191 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295, 1],"int32"), tuple(2,1,), )
[torch error] paddle.broadcast_to(Tensor([4294967295, 1],"int32"), tuple(2,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 79785 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:51:09.412878 35594 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:51:09.414023 35594 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295, 1],"int32"), tuple(4,1,), )
[torch error] paddle.broadcast_to(Tensor([4294967295, 1],"int32"), tuple(4,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 154214 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:52:20.540971 35892 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:52:20.542111 35892 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295, 1],"int32"), tuple(5,1,), )
[torch error] paddle.broadcast_to(Tensor([4294967295, 1],"int32"), tuple(5,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 44025 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:53:29.666886 36251 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:53:29.667992 36251 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295, 1],"int32"), tuple(7,1,), )
[torch error] paddle.broadcast_to(Tensor([4294967295, 1],"int32"), tuple(7,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 95574 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:54:37.090982 36549 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:54:37.091926 36549 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295],"bool"), list[300,40,], )
[torch error] paddle.broadcast_to(Tensor([4294967295],"bool"), list[300,40,], ) 
 The expanded size of the tensor (40) must match the existing size (4294967295) at non-singleton dimension 1.  Target sizes: [300, 40].  Tensor sizes: [4294967295]

W0205 17:55:46.045284 36829 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:55:46.046833 36829 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295],"bool"), list[4,3,], )
[torch error] paddle.broadcast_to(Tensor([4294967295],"bool"), list[4,3,], ) 
 The expanded size of the tensor (3) must match the existing size (4294967295) at non-singleton dimension 1.  Target sizes: [4, 3].  Tensor sizes: [4294967295]

W0205 17:56:58.846299 37208 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:56:58.847443 37208 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295],"float16"), list[168,], )
[torch error] paddle.broadcast_to(Tensor([4294967295],"float16"), list[168,], ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 111877 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:58:28.797128 37513 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:58:28.798138 37513 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295],"float16"), list[3,40,], )
[torch error] paddle.broadcast_to(Tensor([4294967295],"float16"), list[3,40,], ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 16312 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:59:56.559737 37912 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:59:56.560890 37912 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295],"float16"), list[300,40,], )
[torch error] paddle.broadcast_to(Tensor([4294967295],"float16"), list[300,40,], ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 82616 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:01:22.396920 38297 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:01:22.398061 38297 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295],"float16"), list[6,8,9,18,], )
[torch error] paddle.broadcast_to(Tensor([4294967295],"float16"), list[6,8,9,18,], ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 152010 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:02:50.960443 38703 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:02:50.961525 38703 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295],"float32"), list[1,1,], )
[torch error] paddle.broadcast_to(Tensor([4294967295],"float32"), list[1,1,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 56116 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:04:03.088035 39102 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:04:03.089176 39102 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295],"float32"), list[120,84,], )
[torch error] paddle.broadcast_to(Tensor([4294967295],"float32"), list[120,84,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 113390 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:05:10.159407 39440 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:05:10.160477 39440 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295],"float32"), list[128,1,], )
[torch error] paddle.broadcast_to(Tensor([4294967295],"float32"), list[128,1,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 10222 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:06:19.111467 39746 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:06:19.112542 39746 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295],"float32"), list[150,16,], )
[torch error] paddle.broadcast_to(Tensor([4294967295],"float32"), list[150,16,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 63140 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:07:25.749177 40118 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:07:25.750458 40118 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295],"float32"), list[168,], )
[torch error] paddle.broadcast_to(Tensor([4294967295],"float32"), list[168,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 111749 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:08:33.363363 40403 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:08:33.364305 40403 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295],"float32"), list[3,3,], )
[torch error] paddle.broadcast_to(Tensor([4294967295],"float32"), list[3,3,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 162813 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:09:42.748555 40682 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:09:42.749675 40682 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295],"float32"), list[3,40,], )
[torch error] paddle.broadcast_to(Tensor([4294967295],"float32"), list[3,40,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 65597 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:10:49.970959 41467 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:10:49.971978 41467 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295],"float32"), list[300,120,], )
[torch error] paddle.broadcast_to(Tensor([4294967295],"float32"), list[300,120,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 118790 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:12:01.157467 42062 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:12:01.158550 42062 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295],"float32"), list[300,40,], )
[torch error] paddle.broadcast_to(Tensor([4294967295],"float32"), list[300,40,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 18523 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:13:14.907037 42731 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:13:14.908134 42731 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295],"float32"), list[400,120,], )
[torch error] paddle.broadcast_to(Tensor([4294967295],"float32"), list[400,120,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 87243 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:14:23.208700 43428 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:14:23.209928 43428 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295],"float32"), list[50,3,], )
[torch error] paddle.broadcast_to(Tensor([4294967295],"float32"), list[50,3,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 139447 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:15:30.944326 44026 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:15:30.945390 44026 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295],"float32"), list[6,8,9,18,], )
[torch error] paddle.broadcast_to(Tensor([4294967295],"float32"), list[6,8,9,18,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28484 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:16:39.589529 44415 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:16:39.590649 44415 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295],"float32"), list[84,10,], )
[torch error] paddle.broadcast_to(Tensor([4294967295],"float32"), list[84,10,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 99194 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:17:51.902642 44733 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:17:51.903683 44733 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295],"float32"), list[9,6,], )
[torch error] paddle.broadcast_to(Tensor([4294967295],"float32"), list[9,6,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 158103 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:19:03.455801 45047 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:19:03.456879 45047 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295],"float32"), shape=tuple(2,), )
[torch error] paddle.broadcast_to(Tensor([4294967295],"float32"), shape=tuple(2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 58103 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:20:10.754240 45452 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:20:10.755349 45452 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295],"float32"), shape=tuple(5000,2,), )
[torch error] paddle.broadcast_to(Tensor([4294967295],"float32"), shape=tuple(5000,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 124215 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:21:24.699048 45746 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:21:24.700043 45746 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295],"float32"), tuple(1,), )
[torch error] paddle.broadcast_to(Tensor([4294967295],"float32"), tuple(1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 15268 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:22:40.319200 46060 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:22:40.320155 46060 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295],"float32"), tuple(3,), )
[torch error] paddle.broadcast_to(Tensor([4294967295],"float32"), tuple(3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 82102 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:23:48.397601 46463 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:23:48.398563 46463 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295],"float32"), tuple(6,), )
[torch error] paddle.broadcast_to(Tensor([4294967295],"float32"), tuple(6,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 134138 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:24:58.111435 46769 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:24:58.112465 46769 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295],"float32"), tuple(8,), )
[torch error] paddle.broadcast_to(Tensor([4294967295],"float32"), tuple(8,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 29336 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:26:07.839427 47056 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:26:07.840411 47056 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295],"int32"), list[6,], )
[torch error] paddle.broadcast_to(Tensor([4294967295],"int32"), list[6,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 89863 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:27:14.337620 47454 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:27:14.338753 47454 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([4294967295],"int32"), tuple(1,), )
[torch error] paddle.broadcast_to(Tensor([4294967295],"int32"), tuple(1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 156113 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:28:25.277719 47755 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:28:25.278811 47755 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([429496730, 1, 10],"float16"), tuple(10,1,10,), )
[torch error] paddle.broadcast_to(Tensor([429496730, 1, 10],"float16"), tuple(10,1,10,), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 48411 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:29:56.478911 48070 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:29:56.479888 48070 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([429496730, 1, 10],"float32"), tuple(10,1,10,), )
[torch error] paddle.broadcast_to(Tensor([429496730, 1, 10],"float32"), tuple(10,1,10,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 123163 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:31:03.250211 48473 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:31:03.251317 48473 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([429496730, 1, 10],"int32"), tuple(10,1,10,), )
[torch error] paddle.broadcast_to(Tensor([429496730, 1, 10],"int32"), tuple(10,1,10,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 15835 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:32:11.654892 48861 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:32:11.656028 48861 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([429496730, 2, 5],"float32"), tuple(3,2,5,), )
[torch error] paddle.broadcast_to(Tensor([429496730, 2, 5],"float32"), tuple(3,2,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 82330 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:33:22.473721 49152 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:33:22.474865 49152 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([429496730, 5, 1],"float64"), list[4,5,6,], )
[torch error] paddle.broadcast_to(Tensor([429496730, 5, 1],"float64"), list[4,5,6,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 135572 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:34:09.375917 49448 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:34:09.377046 49448 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([429496730, 5],"float64"), tuple(3,5,), )
[torch error] paddle.broadcast_to(Tensor([429496730, 5],"float64"), tuple(3,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 20599 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:34:59.305938 49730 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:34:59.310711 49730 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([5, 1, 858993459],"int32"), tuple(5,1,4,), )
[torch error] paddle.broadcast_to(Tensor([5, 1, 858993459],"int32"), tuple(5,1,4,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 52071 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:36:08.380908 49998 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:36:08.381995 49998 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([5, 107374183, 4],"float64"), tuple(5,3,4,), )
[torch error] paddle.broadcast_to(Tensor([5, 107374183, 4],"float64"), tuple(5,3,4,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 115951 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:36:57.939167 50278 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:36:57.940162 50278 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([5, 122713352, 7],"float32"), tuple(5,6,7,), )
[torch error] paddle.broadcast_to(Tensor([5, 122713352, 7],"float32"), tuple(5,6,7,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 155669 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:38:11.838574 50474 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:38:11.839725 50474 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([5, 17, 1, 25264514],"float64"), list[5,17,0,6,], )
[torch error] paddle.broadcast_to(Tensor([5, 17, 1, 25264514],"float64"), list[5,17,0,6,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 62589 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:39:02.128048 50872 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:39:02.129163 50872 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([5, 17, 25264514],"float64"), list[0,5,17,6,], )
[torch error] paddle.broadcast_to(Tensor([5, 17, 25264514],"float64"), list[0,5,17,6,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 97776 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:39:49.863423 51140 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:39:49.864527 51140 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([5, 17, 25264514],"float64"), list[5,17,6,], )
[torch error] paddle.broadcast_to(Tensor([5, 17, 25264514],"float64"), list[5,17,6,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 134397 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:40:38.202380 51308 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:40:38.203397 51308 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([5, 17, 4210753, 6],"float64"), list[5,17,0,6,], )
[torch error] paddle.broadcast_to(Tensor([5, 17, 4210753, 6],"float64"), list[5,17,0,6,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 5083 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:41:23.600440 51569 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:41:23.601675 51569 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([5, 171798692, 5],"float16"), tuple(5,5,5,), )
[torch error] paddle.broadcast_to(Tensor([5, 171798692, 5],"float16"), tuple(5,5,5,), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 46682 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:42:52.803745 51733 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:42:52.804754 51733 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([5, 171798692, 5],"float32"), tuple(5,5,5,), )
[torch error] paddle.broadcast_to(Tensor([5, 171798692, 5],"float32"), tuple(5,5,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 110628 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:44:03.816915 52149 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:44:03.817956 52149 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([5, 214748365, 4],"int32"), tuple(5,1,4,), )
[torch error] paddle.broadcast_to(Tensor([5, 214748365, 4],"int32"), tuple(5,1,4,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 3412 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:45:09.862149 52528 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:45:09.863274 52528 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([5, 3, 143165577],"float64"), tuple(5,3,4,), )
[torch error] paddle.broadcast_to(Tensor([5, 3, 143165577],"float64"), tuple(5,3,4,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 55438 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:46:00.442502 52808 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:46:00.443606 52808 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([5, 429496730, 1],"int64"), tuple(5,6,1,), )
[torch error] paddle.broadcast_to(Tensor([5, 429496730, 1],"int64"), tuple(5,6,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 97068 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:46:47.894896 53076 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:46:47.895888 53076 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([5, 429496730],"float64"), tuple(5,12,), )
[torch error] paddle.broadcast_to(Tensor([5, 429496730],"float64"), tuple(5,12,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 135893 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:47:38.347750 53239 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:47:38.348749 53239 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([5, 429496730],"int64"), tuple(5,1,), )
[torch error] paddle.broadcast_to(Tensor([5, 429496730],"int64"), tuple(5,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 4585 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:48:24.151185 53492 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:48:24.152536 53492 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([5, 5, 171798692],"float16"), tuple(5,5,5,), )
[torch error] paddle.broadcast_to(Tensor([5, 5, 171798692],"float16"), tuple(5,5,5,), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 48705 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:49:52.110405 53690 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:49:52.111541 53690 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([5, 5, 171798692],"float32"), tuple(5,5,5,), )
[torch error] paddle.broadcast_to(Tensor([5, 5, 171798692],"float32"), tuple(5,5,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 117607 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:51:03.408023 54090 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:51:03.409018 54090 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([5, 5, 171798692],"int32"), tuple(5,5,1,), )
[torch error] paddle.broadcast_to(Tensor([5, 5, 171798692],"int32"), tuple(5,5,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 10360 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:52:11.306242 54469 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:52:11.307199 54469 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([5, 5, 85899346],"float64"), tuple(5,5,5,), )
[torch error] paddle.broadcast_to(Tensor([5, 5, 85899346],"float64"), tuple(5,5,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 69737 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:53:00.680464 54770 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:53:00.681402 54770 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([5, 6, 143165577],"float32"), tuple(5,6,7,), )
[torch error] paddle.broadcast_to(Tensor([5, 6, 143165577],"float32"), tuple(5,6,7,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 99712 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:54:08.386117 55032 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:54:08.387214 55032 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([5, 6, 71582789],"int64"), tuple(5,6,1,), )
[torch error] paddle.broadcast_to(Tensor([5, 6, 71582789],"int64"), tuple(5,6,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 150482 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:54:55.352967 55322 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:54:55.354111 55322 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([5, 71582789, 1, 6],"float64"), list[5,17,0,6,], )
[torch error] paddle.broadcast_to(Tensor([5, 71582789, 1, 6],"float64"), list[5,17,0,6,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 19597 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:55:41.184796 55504 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:55:41.185904 55504 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([5, 71582789, 6],"float64"), list[0,5,17,6,], )
[torch error] paddle.broadcast_to(Tensor([5, 71582789, 6],"float64"), list[0,5,17,6,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 64569 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:56:32.175684 55772 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:56:32.176872 55772 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([5, 71582789, 6],"float64"), list[5,17,6,], )
[torch error] paddle.broadcast_to(Tensor([5, 71582789, 6],"float64"), list[5,17,6,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 98532 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:57:16.943626 56040 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:57:16.944636 56040 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([5, 858993459, 1],"int32"), tuple(5,5,1,), )
[torch error] paddle.broadcast_to(Tensor([5, 858993459, 1],"int32"), tuple(5,5,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 141175 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:58:31.347448 56210 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:58:31.348449 56210 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([5, 858993459],"float32"), tuple(5,2,), )
[torch error] paddle.broadcast_to(Tensor([5, 858993459],"float32"), tuple(5,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 27958 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:59:43.768986 56595 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:59:43.769969 56595 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([5, 858993459],"int32"), tuple(5,1,), )
[torch error] paddle.broadcast_to(Tensor([5, 858993459],"int32"), tuple(5,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 87836 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:00:50.787724 56914 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:00:50.789332 56914 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([5, 85899346, 5],"float64"), tuple(5,5,5,), )
[torch error] paddle.broadcast_to(Tensor([5, 85899346, 5],"float64"), tuple(5,5,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 135108 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:01:35.994643 57202 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:01:35.995724 57202 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([51130564, 42],"float64"), tuple(4,42,), )
[torch error] paddle.broadcast_to(Tensor([51130564, 42],"float64"), tuple(4,42,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 1629 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:02:26.475227 57471 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:02:26.476295 57471 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([51130564, 7, 6],"float64"), tuple(4,7,6,), )
[torch error] paddle.broadcast_to(Tensor([51130564, 7, 6],"float64"), tuple(4,7,6,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 45020 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:03:17.023450 57635 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:03:17.024569 57635 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([536870912, 2, 4],"float32"), list[3,2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([536870912, 2, 4],"float32"), list[3,2,2,4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 88294 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:04:25.105782 57902 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:04:25.106779 57902 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([536870912, 8],"float32"), tuple(128,8,), )
[torch error] paddle.broadcast_to(Tensor([536870912, 8],"float32"), tuple(128,8,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 136600 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:05:32.308998 58190 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:05:32.310056 58190 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([613566757, 7, 1],"int32"), tuple(4,7,1,), )
[torch error] paddle.broadcast_to(Tensor([613566757, 7, 1],"int32"), tuple(4,7,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 26499 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:06:43.771636 58561 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:06:43.772565 58561 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([613566757, 7],"float32"), tuple(4,7,), )
[torch error] paddle.broadcast_to(Tensor([613566757, 7],"float32"), tuple(4,7,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 90773 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:07:51.741384 58868 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:07:51.742445 58868 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([64, 33554433],"int64"), tuple(64,1327104,), )
[torch error] paddle.broadcast_to(Tensor([64, 33554433],"int64"), tuple(64,1327104,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 138027 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:08:37.985188 59156 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:08:37.986266 59156 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([64, 67108864],"float32"), tuple(64,1327104,), )
[torch error] paddle.broadcast_to(Tensor([64, 67108864],"float32"), tuple(64,1327104,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 8271 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:09:50.904949 59402 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:09:50.906062 59402 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([6448900, 333],"float64"), list[111,222,333,], )
[torch error] paddle.broadcast_to(Tensor([6448900, 333],"float64"), list[111,222,333,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 65939 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:10:39.391439 59725 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:10:39.392599 59725 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([7, 306783379],"float64"), tuple(7,24,), )
[torch error] paddle.broadcast_to(Tensor([7, 306783379],"float64"), tuple(7,24,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 99303 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:11:29.009526 59991 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:11:29.010731 59991 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([7, 613566757],"int32"), tuple(7,1,), )
[torch error] paddle.broadcast_to(Tensor([7, 613566757],"int32"), tuple(7,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 143733 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:12:42.278415 60155 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:12:42.279400 60155 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([715827883, 1, 3],"int64"), tuple(3,2,3,), )
[torch error] paddle.broadcast_to(Tensor([715827883, 1, 3],"int64"), tuple(3,2,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 39927 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:13:29.816776 60539 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:13:29.817734 60539 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([715827883, 1, 6],"bool"), list[4,5,6,], )
[torch error] paddle.broadcast_to(Tensor([715827883, 1, 6],"bool"), list[4,5,6,], ) 
 The expanded size of the tensor (4) must match the existing size (715827883) at non-singleton dimension 0.  Target sizes: [4, 5, 6].  Tensor sizes: [715827883, 1, 6]

W0205 19:14:33.361892 60803 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:14:33.363302 60803 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([715827883, 1, 6],"int32"), tuple(4,1,6,), )
[torch error] paddle.broadcast_to(Tensor([715827883, 1, 6],"int32"), tuple(4,1,6,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 118296 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:15:40.252070 61097 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:15:40.253077 61097 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([715827883, 3, 2],"float32"), tuple(4,3,2,), )
[torch error] paddle.broadcast_to(Tensor([715827883, 3, 2],"float32"), tuple(4,3,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 16964 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:16:54.180725 61406 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:16:54.181847 61406 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([715827883, 3],"float64"), tuple(2,3,), )
[torch error] paddle.broadcast_to(Tensor([715827883, 3],"float64"), tuple(2,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 68062 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:17:38.763388 61714 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:17:38.764395 61714 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([715827883, 3],"int64"), tuple(1,3,), )
[torch error] paddle.broadcast_to(Tensor([715827883, 3],"int64"), tuple(1,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 99647 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:18:21.219620 61974 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:18:21.220710 61974 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([715827883, 3],"int64"), tuple(3,3,), )
[torch error] paddle.broadcast_to(Tensor([715827883, 3],"int64"), tuple(3,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 142056 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:19:04.719343 62145 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:19:04.720381 62145 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([71582789, 5, 6],"float64"), list[4,5,6,], )
[torch error] paddle.broadcast_to(Tensor([71582789, 5, 6],"float64"), list[4,5,6,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 8186 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:19:55.600903 62400 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:19:55.601882 62400 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([8, 268435457],"int64"), tuple(8,1,), )
[torch error] paddle.broadcast_to(Tensor([8, 268435457],"int64"), tuple(8,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 43227 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:20:42.216842 62582 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:20:42.217780 62582 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([8, 536870912],"float32"), tuple(8,3,), )
[torch error] paddle.broadcast_to(Tensor([8, 536870912],"float32"), tuple(8,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 86294 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:21:49.485118 62860 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:21:49.486322 62860 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([858993459, 5, 1],"int32"), tuple(5,5,1,), )
[torch error] paddle.broadcast_to(Tensor([858993459, 5, 1],"int32"), tuple(5,5,1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 137757 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:22:57.253752 63139 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:22:57.254890 63139 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([858993459, 5],"float32"), tuple(28,5,), )
[torch error] paddle.broadcast_to(Tensor([858993459, 5],"float32"), tuple(28,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 22750 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:24:09.924759 63433 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:24:09.925768 63433 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([858993459, 5],"float32"), tuple(3,5,), )
[torch error] paddle.broadcast_to(Tensor([858993459, 5],"float32"), tuple(3,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 88413 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:25:17.619747 63815 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:25:17.620790 63815 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([858993459, 5],"float32"), tuple(30,5,), )
[torch error] paddle.broadcast_to(Tensor([858993459, 5],"float32"), tuple(30,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 136470 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:26:23.701464 64110 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:26:23.702513 64110 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([858993459, 5],"float32"), tuple(38,5,), )
[torch error] paddle.broadcast_to(Tensor([858993459, 5],"float32"), tuple(38,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 26531 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:27:37.383963 64403 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:27:37.385057 64403 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([85899346, 5, 5],"float64"), tuple(5,5,5,), )
[torch error] paddle.broadcast_to(Tensor([85899346, 5, 5],"float64"), tuple(5,5,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 74103 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:28:25.435205 64781 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:28:25.436350 64781 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([89478486, 24],"float64"), tuple(7,24,), )
[torch error] paddle.broadcast_to(Tensor([89478486, 24],"float64"), tuple(7,24,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 120657 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:29:17.439095 64968 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:29:17.440045 64968 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bucketize(Tensor([2, 1073741825],"float64"), Tensor([4],"float64"), )
[torch error] paddle.bucketize(Tensor([2, 1073741825],"float64"), Tensor([4],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 162961 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:30:06.858312 65243 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:30:06.859295 65243 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bucketize(Tensor([2, 1073741825],"float64"), Tensor([4],"float64"), out_int32=True, )
[torch error] paddle.bucketize(Tensor([2, 1073741825],"float64"), Tensor([4],"float64"), out_int32=True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 29836 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:30:51.813710 65497 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:30:51.814738 65497 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bucketize(Tensor([2, 1073741825],"float64"), Tensor([4],"float64"), right=True, )
[torch error] paddle.bucketize(Tensor([2, 1073741825],"float64"), Tensor([4],"float64"), right=True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 63845 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:31:36.653291 65675 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:31:36.654491 65675 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bucketize(Tensor([2, 4],"float64"), Tensor([2147483649],"float64"), )
[torch error] paddle.bucketize(Tensor([2, 4],"float64"), Tensor([2147483649],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 93689 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:32:23.763666 65921 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:32:23.764737 65921 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bucketize(Tensor([2, 4],"float64"), Tensor([2147483649],"float64"), out_int32=True, )
[torch error] paddle.bucketize(Tensor([2, 4],"float64"), Tensor([2147483649],"float64"), out_int32=True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 137668 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:33:13.365331 66104 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:33:13.366266 66104 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bucketize(Tensor([2, 4],"float64"), Tensor([2147483649],"float64"), right=True, )
[torch error] paddle.bucketize(Tensor([2, 4],"float64"), Tensor([2147483649],"float64"), right=True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 17304 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:34:01.515422 66367 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:34:01.516547 66367 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bucketize(Tensor([536870913, 4],"float64"), Tensor([4],"float64"), )
[torch error] paddle.bucketize(Tensor([536870913, 4],"float64"), Tensor([4],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 46268 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:34:51.834702 66624 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:34:51.835960 66624 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bucketize(Tensor([536870913, 4],"float64"), Tensor([4],"float64"), out_int32=True, )
[torch error] paddle.bucketize(Tensor([536870913, 4],"float64"), Tensor([4],"float64"), out_int32=True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 81969 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:35:36.677932 66793 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:35:36.678952 66793 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bucketize(Tensor([536870913, 4],"float64"), Tensor([4],"float64"), right=True, )
[torch error] paddle.bucketize(Tensor([536870913, 4],"float64"), Tensor([4],"float64"), right=True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 114337 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:36:21.013666 67059 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:36:21.014797 67059 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ceil(Tensor([1, 2147483649],"float64"), )
[torch error] paddle.ceil(Tensor([1, 2147483649],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 161757 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:37:05.599128 67232 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:37:05.600219 67232 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ceil(Tensor([1, 3, 715827883],"float64"), )
[torch error] paddle.ceil(Tensor([1, 3, 715827883],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 33771 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:37:56.482033 67482 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:37:56.483120 67482 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ceil(Tensor([1, 536870913, 4],"float64"), )
[torch error] paddle.ceil(Tensor([1, 536870913, 4],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 76800 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:38:53.973624 67671 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:38:53.974651 67671 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ceil(Tensor([1048576, 32, 128],"float32"), )
[torch error] paddle.ceil(Tensor([1048576, 32, 128],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 125091 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:40:00.233227 67937 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:40:00.234288 67937 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ceil(Tensor([1431655765, 3],"float32"), )
[torch error] paddle.ceil(Tensor([1431655765, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 11382 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:41:06.543202 68328 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:41:06.544246 68328 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ceil(Tensor([178956971, 3, 4],"float64"), )
[torch error] paddle.ceil(Tensor([178956971, 3, 4],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 63667 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:41:51.663159 68634 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:41:51.664234 68634 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ceil(Tensor([2, 2147483648],"float32"), )
[torch error] paddle.ceil(Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 98632 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:43:06.178154 68811 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:43:06.194957 68811 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ceil(Tensor([2147483649, 1],"float64"), )
[torch error] paddle.ceil(Tensor([2147483649, 1],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 154400 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:43:55.435724 69201 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:43:55.436844 69201 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ceil(Tensor([2147483649],"float64"), )
[torch error] paddle.ceil(Tensor([2147483649],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 26969 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:44:44.740828 69384 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:44:44.741860 69384 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ceil(Tensor([306783379, 7, 1],"float64"), )
[torch error] paddle.ceil(Tensor([306783379, 7, 1],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 69530 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:45:30.501546 69651 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:45:30.502641 69651 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ceil(Tensor([32, 1048576, 128],"float32"), )
[torch error] paddle.ceil(Tensor([32, 1048576, 128],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 100915 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:46:43.055560 69903 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:46:43.056517 69903 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ceil(Tensor([32, 32, 4194304],"float32"), )
[torch error] paddle.ceil(Tensor([32, 32, 4194304],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 3357 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:47:49.416699 70204 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:47:49.417769 70204 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ceil(Tensor([357913942, 1, 6],"float64"), )
[torch error] paddle.ceil(Tensor([357913942, 1, 6],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 49136 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:48:38.475873 70504 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:48:38.477021 70504 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ceil(Tensor([4, 1, 536870913],"float64"), )
[torch error] paddle.ceil(Tensor([4, 1, 536870913],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 86191 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:49:28.062237 70760 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:49:28.063314 70760 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ceil(Tensor([4, 1073741824],"float32"), )
[torch error] paddle.ceil(Tensor([4, 1073741824],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 125974 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:50:34.731820 70931 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:50:34.732817 70931 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ceil(Tensor([4, 536870913, 1],"float64"), )
[torch error] paddle.ceil(Tensor([4, 536870913, 1],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 9539 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:51:19.817534 71313 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:51:19.818713 71313 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ceil(Tensor([4, 536870913],"float64"), )
[torch error] paddle.ceil(Tensor([4, 536870913],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 51737 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:52:08.173218 71476 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:52:08.174230 71476 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ceil(Tensor([4, 7, 76695845],"float64"), )
[torch error] paddle.ceil(Tensor([4, 7, 76695845],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 83323 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:52:57.413386 71732 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:52:57.414484 71732 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ceil(Tensor([4, 89478486, 6],"float64"), )
[torch error] paddle.ceil(Tensor([4, 89478486, 6],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 119514 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:53:47.450258 71917 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:53:47.451211 71917 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ceil(Tensor([4294967295, 1],"float32"), )
[torch error] paddle.ceil(Tensor([4294967295, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 1597 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:55:01.955924 72191 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:55:01.956884 72191 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ceil(Tensor([4294967295],"float32"), )
[torch error] paddle.ceil(Tensor([4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 55136 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:56:28.507445 72581 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:56:28.508414 72581 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ceil(Tensor([5, 1, 429496730],"float64"), )
[torch error] paddle.ceil(Tensor([5, 1, 429496730],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 128154 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:57:14.053963 72920 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:57:14.055104 72920 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ceil(Tensor([5, 107374183, 4],"float64"), )
[torch error] paddle.ceil(Tensor([5, 107374183, 4],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 7514 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:58:03.069118 73174 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:58:03.070210 73174 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ceil(Tensor([5, 429496730],"float64"), )
[torch error] paddle.ceil(Tensor([5, 429496730],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 35143 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:58:50.187700 73427 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:58:50.188663 73427 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ceil(Tensor([536870913, 1, 4],"float64"), )
[torch error] paddle.ceil(Tensor([536870913, 1, 4],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 72776 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:59:35.024549 73617 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:59:35.025714 73617 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ceil(Tensor([7, 306783379],"float64"), )
[torch error] paddle.ceil(Tensor([7, 306783379],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 103153 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:00:21.783023 73878 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:00:21.784312 73878 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.ceil(Tensor([715827883, 3],"float64"), )
[torch error] paddle.ceil(Tensor([715827883, 3],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 146357 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:01:06.447232 74060 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:01:06.448287 74060 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.chunk(Tensor([1, 1, 1, 4294967295],"float16"), 2, axis=-1, )
[torch error] paddle.chunk(Tensor([1, 1, 1, 4294967295],"float16"), 2, axis=-1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 12770 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:02:28.307976 74323 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:02:28.309377 74323 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.chunk(Tensor([1, 1, 64, 67108864],"float16"), 2, axis=-1, )
[torch error] paddle.chunk(Tensor([1, 1, 64, 67108864],"float16"), 2, axis=-1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Including non-PyTorch memory, this process has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:03:55.758641 74657 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:03:55.759619 74657 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.chunk(Tensor([1, 1, 67108864, 64],"float16"), 2, axis=-1, )
[torch error] paddle.chunk(Tensor([1, 1, 67108864, 64],"float16"), 2, axis=-1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 138640 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:05:22.899246 75086 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:05:22.900399 75086 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.chunk(Tensor([1, 1048576, 64, 64],"float16"), 2, axis=-1, )
[torch error] paddle.chunk(Tensor([1, 1048576, 64, 64],"float16"), 2, axis=-1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 47027 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:06:44.605234 75511 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:06:44.606598 75511 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.chunk(Tensor([1, 67108864, 1, 64],"float16"), 2, axis=-1, )
[torch error] paddle.chunk(Tensor([1, 67108864, 1, 64],"float16"), 2, axis=-1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 115962 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:08:06.128749 75927 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:08:06.129797 75927 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.chunk(Tensor([1048576, 1, 64, 64],"float16"), 2, axis=-1, )
[torch error] paddle.chunk(Tensor([1048576, 1, 64, 64],"float16"), 2, axis=-1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 9113 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:09:35.597450 76342 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:09:35.598448 76342 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.chunk(Tensor([119304648, 6, 6],"bool"), chunks=3, axis=1, )
[paddle error] paddle.chunk(Tensor([119304648, 6, 6],"bool"), chunks=3, axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 77.387634GB memory has been allocated and available memory is only 1.797241GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 20:10:53.674095 76800 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:10:53.675027 76800 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.chunk(Tensor([119304648, 6, 6],"int32"), chunks=3, axis=1, )
[torch error] paddle.chunk(Tensor([119304648, 6, 6],"int32"), chunks=3, axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 139759 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:12:04.944252 77108 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:12:04.945223 77108 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.chunk(Tensor([119304648, 6, 6],"int32"), chunks=3, axis=Tensor([1],"int32"), )
[torch error] paddle.chunk(Tensor([119304648, 6, 6],"int32"), chunks=3, axis=Tensor([1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 33420 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:13:11.149106 77497 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:13:11.150166 77497 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.chunk(Tensor([4, 178956971, 6],"bool"), chunks=3, axis=1, )
[paddle error] paddle.chunk(Tensor([4, 178956971, 6],"bool"), chunks=3, axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 77.387634GB memory has been allocated and available memory is only 1.797241GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 20:14:36.753850 77790 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:14:36.754691 77790 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.chunk(Tensor([4, 178956971, 6],"int32"), chunks=3, axis=1, )
[torch error] paddle.chunk(Tensor([4, 178956971, 6],"int32"), chunks=3, axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 142492 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:15:48.113101 78198 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:15:48.114070 78198 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.chunk(Tensor([4, 178956971, 6],"int32"), chunks=3, axis=Tensor([1],"int32"), )
[torch error] paddle.chunk(Tensor([4, 178956971, 6],"int32"), chunks=3, axis=Tensor([1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 40799 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:16:53.773931 78502 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:16:53.775058 78502 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.chunk(Tensor([4, 6, 178956971],"bool"), chunks=3, axis=1, )
[paddle error] paddle.chunk(Tensor([4, 6, 178956971],"bool"), chunks=3, axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 77.387634GB memory has been allocated and available memory is only 1.797241GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 20:18:11.675951 78801 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:18:11.677073 78801 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.chunk(Tensor([4, 6, 178956971],"int32"), chunks=3, axis=1, )
[torch error] paddle.chunk(Tensor([4, 6, 178956971],"int32"), chunks=3, axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 153144 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:19:25.454419 79177 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:19:25.455551 79177 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.chunk(Tensor([4, 6, 178956971],"int32"), chunks=3, axis=Tensor([1],"int32"), )
[torch error] paddle.chunk(Tensor([4, 6, 178956971],"int32"), chunks=3, axis=Tensor([1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 42093 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:20:35.673775 79475 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:20:35.674926 79475 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.chunk(Tensor([4, 6, 6],"int32"), chunks=3, axis=Tensor([4294967295],"int32"), )
[torch error] paddle.chunk(Tensor([4, 6, 6],"int32"), chunks=3, axis=Tensor([4294967295],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 88228 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:21:42.268421 79863 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:21:42.269378 79863 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.chunk(Tensor([67108864, 1, 1, 64],"float16"), 2, axis=-1, )
[torch error] paddle.chunk(Tensor([67108864, 1, 1, 64],"float16"), 2, axis=-1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 146719 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:23:05.516144 80162 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:23:05.517107 80162 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([1, 1048576, 4096],"float32"), 0, 1, )
[torch error] paddle.clip(Tensor([1, 1048576, 4096],"float32"), 0, 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 38165 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:24:16.428844 80564 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:24:16.429790 80564 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([1, 2, 2147483648],"float32"), min=-1.0, max=1.0, )
[torch error] paddle.clip(Tensor([1, 2, 2147483648],"float32"), min=-1.0, max=1.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 97745 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:25:23.232955 80858 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:25:23.234010 80858 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([1, 2147483648, 2],"float32"), min=-1.0, max=1.0, )
[torch error] paddle.clip(Tensor([1, 2147483648, 2],"float32"), min=-1.0, max=1.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 148501 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:26:31.089087 81157 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:26:31.090037 81157 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([1, 300, 14316558],"float32"), 0, 1, )
[torch error] paddle.clip(Tensor([1, 300, 14316558],"float32"), 0, 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 35551 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:27:38.128693 81534 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:27:38.134538 81534 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([1, 4294967295],"float32"), min=1.1754943508222875e-38, )
[torch error] paddle.clip(Tensor([1, 4294967295],"float32"), min=1.1754943508222875e-38, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 83959 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:28:47.225121 81844 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:28:47.226118 81844 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([10, 2, 214748365],"float32"), min=1e-06, )
[torch error] paddle.clip(Tensor([10, 2, 214748365],"float32"), min=1e-06, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 141413 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:29:55.662557 82158 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:29:55.663642 82158 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([10, 214748365],"float64"), min=1e-06, )
[torch error] paddle.clip(Tensor([10, 214748365],"float64"), min=1e-06, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 23833 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:30:42.542402 82470 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:30:42.543440 82470 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([10, 429496730, 1],"float32"), min=1e-06, )
[torch error] paddle.clip(Tensor([10, 429496730, 1],"float32"), min=1e-06, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 65393 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:31:49.787418 82724 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:31:49.788609 82724 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([10, 429496730],"float32"), min=1e-06, )
[torch error] paddle.clip(Tensor([10, 429496730],"float32"), min=1e-06, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 110353 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:32:56.831969 83048 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:32:56.833082 83048 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([1048576, 4096],"float16"), -126, 126, )
[torch error] paddle.clip(Tensor([1048576, 4096],"float16"), -126, 126, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 156118 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:34:18.694603 83343 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:34:18.695643 83343 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([1073741824, 2, 2],"float32"), min=-1.0, max=1.0, )
[torch error] paddle.clip(Tensor([1073741824, 2, 2],"float32"), min=-1.0, max=1.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 61320 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:35:24.929553 83760 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:35:24.930688 83760 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([1073741824, 4],"float32"), -1, 1, )
[torch error] paddle.clip(Tensor([1073741824, 4],"float32"), -1, 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 106817 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:36:38.428030 84066 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:36:38.429014 84066 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([1073741825, 2],"float64"), min=0.0, )
[torch error] paddle.clip(Tensor([1073741825, 2],"float64"), min=0.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 162338 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:37:25.830981 84445 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:37:25.832080 84445 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([1073741825, 2],"float64"), min=1e-06, )
[torch error] paddle.clip(Tensor([1073741825, 2],"float64"), min=1e-06, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 38160 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:38:15.620793 84627 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:38:15.621774 84627 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([128, 33554432],"float32"), -8, 7, )
[torch error] paddle.clip(Tensor([128, 33554432],"float32"), -8, 7, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 82221 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:39:29.407059 84894 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:39:29.408154 84894 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([153391690, 28],"float32"), 0.0, 1.0, )
[torch error] paddle.clip(Tensor([153391690, 28],"float32"), 0.0, 1.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 129385 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:40:37.068022 85213 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:40:37.069422 85213 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([16, 134217729],"float64"), -127, 127, )
[torch error] paddle.clip(Tensor([16, 134217729],"float64"), -127, 127, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 11852 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:41:26.958626 85615 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:41:26.964915 85615 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([16, 268435456],"float16"), -127, 127, )
[torch error] paddle.clip(Tensor([16, 268435456],"float16"), -127, 127, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 60002 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:42:50.816310 85803 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:42:50.817260 85803 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([16777216, 256],"float16"), -127, 127, )
[torch error] paddle.clip(Tensor([16777216, 256],"float16"), -127, 127, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 120745 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:44:19.659044 86218 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:44:19.660037 86218 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([2, 1073741824, 2],"float32"), min=-1.0, max=1.0, )
[torch error] paddle.clip(Tensor([2, 1073741824, 2],"float32"), min=-1.0, max=1.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 27984 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:45:26.055325 86650 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:45:26.056424 86650 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([2, 2, 1073741824],"float32"), min=-1.0, max=1.0, )
[torch error] paddle.clip(Tensor([2, 2, 1073741824],"float32"), min=-1.0, max=1.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 74095 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:46:31.928270 86943 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:46:31.929682 86943 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([2, 2147483648],"float16"), -126, 126, )
[torch error] paddle.clip(Tensor([2, 2147483648],"float16"), -126, 126, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 127681 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:48:01.400462 87326 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:48:01.401499 87326 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([2, 2147483648],"float32"), min=1.1754943508222875e-38, )
[torch error] paddle.clip(Tensor([2, 2147483648],"float32"), min=1.1754943508222875e-38, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 27843 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:49:15.382102 87748 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:49:15.383198 87748 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([2, 268435456, 8],"float32"), 0.0, 1.0, )
[torch error] paddle.clip(Tensor([2, 268435456, 8],"float32"), 0.0, 1.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 98034 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:50:21.934211 88054 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:50:21.935256 88054 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([2, 8, 268435456],"float32"), 0.0, 1.0, )
[torch error] paddle.clip(Tensor([2, 8, 268435456],"float32"), 0.0, 1.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 145029 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:51:27.595247 88353 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:51:27.596326 88353 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([2147483648, 2, 1],"float32"), min=1e-06, )
[torch error] paddle.clip(Tensor([2147483648, 2, 1],"float32"), min=1e-06, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 27080 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:52:37.684238 88632 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:52:37.685292 88632 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([2147483648, 2],"float32"), min=1.1754943508222875e-38, )
[torch error] paddle.clip(Tensor([2147483648, 2],"float32"), min=1.1754943508222875e-38, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 74354 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:53:51.389396 89036 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:53:51.390484 89036 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([2147483648, 2],"float32"), min=1e-06, )
[torch error] paddle.clip(Tensor([2147483648, 2],"float32"), min=1e-06, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 135794 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:54:56.110201 89346 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:54:56.111280 89346 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([2147483649],"float64"), min=0, )
[torch error] paddle.clip(Tensor([2147483649],"float64"), min=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 17982 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:55:47.008056 89638 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:55:47.009055 89638 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([2147483649],"float64"), min=0.0, )
[torch error] paddle.clip(Tensor([2147483649],"float64"), min=0.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 64830 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:56:35.361214 89926 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:56:35.362218 89926 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([2147483649],"int64"), min=0, )
[torch error] paddle.clip(Tensor([2147483649],"int64"), min=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 98892 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:57:21.862960 90187 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:57:21.864081 90187 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([28, 153391690],"float32"), 0.0, 1.0, )
[torch error] paddle.clip(Tensor([28, 153391690],"float32"), 0.0, 1.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 145685 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:58:36.599344 90376 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:58:36.600317 90376 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([32, 134217728],"float16"), -127, 127, )
[torch error] paddle.clip(Tensor([32, 134217728],"float16"), -127, 127, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 32358 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:00:01.001645 90779 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:00:01.002805 90779 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([33554432, 128],"float32"), -8, 7, )
[torch error] paddle.clip(Tensor([33554432, 128],"float32"), -8, 7, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 95942 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:01:08.791493 91177 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:01:08.792624 91177 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([3496, 300, 4096],"float32"), 0, 1, )
[torch error] paddle.clip(Tensor([3496, 300, 4096],"float32"), 0, 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 139567 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:02:24.933203 91485 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:02:24.934172 91485 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([4, 1073741824],"float32"), -1, 1, )
[torch error] paddle.clip(Tensor([4, 1073741824],"float32"), -1, 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 2704 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:03:34.878746 91794 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:03:34.879703 91794 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([4, 536870913],"float64"), -1, 1, )
[torch error] paddle.clip(Tensor([4, 536870913],"float64"), -1, 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 26440 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:04:22.606706 92190 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:04:22.607702 92190 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([4294967295],"float32"), min=0, )
[torch error] paddle.clip(Tensor([4294967295],"float32"), min=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 45751 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:05:32.221244 92374 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:05:32.222353 92374 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([4294967295],"float32"), min=1.1754943508222875e-38, )
[torch error] paddle.clip(Tensor([4294967295],"float32"), min=1.1754943508222875e-38, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 70642 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:06:45.439806 92770 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:06:45.440915 92770 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([429496730, 5],"float64"), -1, 1, )
[torch error] paddle.clip(Tensor([429496730, 5],"float64"), -1, 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 100416 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:07:30.887264 93113 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:07:30.888357 93113 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([5, 429496730],"float64"), -1, 1, )
[torch error] paddle.clip(Tensor([5, 429496730],"float64"), -1, 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 118523 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:08:20.936064 93365 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:08:20.937095 93365 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([5, 429496730],"float64"), min=0.0, )
[torch error] paddle.clip(Tensor([5, 429496730],"float64"), min=0.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 139452 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:09:08.460764 93564 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:09:08.461795 93564 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([5, 858993459],"float32"), -1, 1, )
[torch error] paddle.clip(Tensor([5, 858993459],"float32"), -1, 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 158372 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:10:16.677525 93841 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:10:16.678692 93841 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([536870912, 8],"float32"), 0.0, 1.0, )
[torch error] paddle.clip(Tensor([536870912, 8],"float32"), 0.0, 1.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 19203 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:11:30.733117 94176 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:11:30.734156 94176 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([536870913, 4],"float64"), -1, 1, )
[torch error] paddle.clip(Tensor([536870913, 4],"float64"), -1, 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 49854 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:12:21.033427 94587 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:12:21.034380 94587 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([67108864, 8, 8],"float32"), 0.0, 1.0, )
[torch error] paddle.clip(Tensor([67108864, 8, 8],"float32"), 0.0, 1.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 73825 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:13:34.889909 94790 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:13:34.890890 94790 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([8, 536870912],"float32"), 0.0, 1.0, )
[torch error] paddle.clip(Tensor([8, 536870912],"float32"), 0.0, 1.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 107963 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:14:41.781664 95180 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:14:41.782749 95180 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([8388609, 256],"float64"), -127, 127, )
[torch error] paddle.clip(Tensor([8388609, 256],"float64"), -127, 127, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 136471 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:15:30.261516 95494 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:15:30.262559 95494 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(Tensor([858993459, 5],"float32"), -1, 1, )
[torch error] paddle.clip(Tensor([858993459, 5],"float32"), -1, 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 159661 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:16:43.054265 95761 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:16:43.055279 95761 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(x=Tensor([10, 429496730],"float32"), min=-0.1, max=0.8, )
[torch error] paddle.clip(x=Tensor([10, 429496730],"float32"), min=-0.1, max=0.8, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 32672 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:17:49.702638 96081 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:17:49.703917 96081 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(x=Tensor([10, 429496730],"float32"), min=-0.6, max=0.6, )
[torch error] paddle.clip(x=Tensor([10, 429496730],"float32"), min=-0.6, max=0.6, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 58947 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:18:57.146291 96401 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:18:57.147801 96401 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(x=Tensor([16, 268435456],"float32"), min=-1.0, max=1.0, )
[torch error] paddle.clip(x=Tensor([16, 268435456],"float32"), min=-1.0, max=1.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 88288 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:20:04.112838 96707 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:20:04.120237 96707 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(x=Tensor([268435456, 16],"float32"), min=-1.0, max=1.0, )
[torch error] paddle.clip(x=Tensor([268435456, 16],"float32"), min=-1.0, max=1.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 120059 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:21:12.465366 97074 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:21:12.466338 97074 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(x=Tensor([33554432, 8, 16],"float32"), min=0.0, max=0.0, )
[torch error] paddle.clip(x=Tensor([33554432, 8, 16],"float32"), min=0.0, max=0.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 152979 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:22:25.633119 97394 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:22:25.634205 97394 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(x=Tensor([4, 67108864, 16],"float32"), min=0.0, max=0.0, )
[torch error] paddle.clip(x=Tensor([4, 67108864, 16],"float32"), min=0.0, max=0.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 18300 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:23:36.146119 97716 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:23:36.147254 97716 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(x=Tensor([4, 8, 134217728],"float32"), min=0.0, max=0.0, )
[torch error] paddle.clip(x=Tensor([4, 8, 134217728],"float32"), min=0.0, max=0.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 45437 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:24:52.786042 98112 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:24:52.787012 98112 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(x=Tensor([4294967295],"float32"), min=-0.1, max=0.1, )
[torch error] paddle.clip(x=Tensor([4294967295],"float32"), min=-0.1, max=0.1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 75810 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:26:01.630923 98449 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:26:01.631935 98449 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(x=Tensor([4294967295],"float32"), min=0.1, max=0.2, )
[torch error] paddle.clip(x=Tensor([4294967295],"float32"), min=0.1, max=0.2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 107650 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:27:09.606724 98836 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:27:09.607757 98836 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(x=Tensor([429496730, 10],"float32"), min=-0.1, max=0.8, )
[torch error] paddle.clip(x=Tensor([429496730, 10],"float32"), min=-0.1, max=0.8, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 146689 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:28:23.036186 99144 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:28:23.037315 99144 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(x=Tensor([429496730, 10],"float32"), min=-0.6, max=0.6, )
[torch error] paddle.clip(x=Tensor([429496730, 10],"float32"), min=-0.6, max=0.6, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 15886 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:29:36.243849 99463 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:29:36.244828 99463 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(x=Tensor([5, 858993459],"float32"), min=0.1, max=0.2, )
[torch error] paddle.clip(x=Tensor([5, 858993459],"float32"), min=0.1, max=0.2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 47448 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:30:44.042452 99875 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:30:44.043843 99875 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clip(x=Tensor([858993459, 5],"float32"), min=0.1, max=0.2, )
[torch error] paddle.clip(x=Tensor([858993459, 5],"float32"), min=0.1, max=0.2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 75906 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:31:50.891274 100182 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:31:50.892666 100182 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 100, 42949673],"float32"), )
[torch error] paddle.clone(Tensor([1, 100, 42949673],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 103215 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:32:58.354734 100475 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:32:58.355867 100475 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 10000, 429497],"float32"), )
[torch error] paddle.clone(Tensor([1, 10000, 429497],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 130432 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:34:07.272393 100755 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:34:07.273571 100755 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 1024, 48, 87382],"float32"), )
[torch error] paddle.clone(Tensor([1, 1024, 48, 87382],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 162671 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:35:13.377996 101137 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:35:13.378960 101137 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 1024, 58255, 72],"float32"), )
[torch error] paddle.clone(Tensor([1, 1024, 58255, 72],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 30784 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:36:20.720363 101430 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:36:20.721638 101430 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 103884, 152, 272],"float32"), )
[torch error] paddle.clone(Tensor([1, 103884, 152, 272],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 68201 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:37:28.111153 101736 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:37:28.112135 101736 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 1048576, 64, 64],"float32"), )
[torch error] paddle.clone(Tensor([1, 1048576, 64, 64],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 100829 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:38:35.264155 102022 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:38:35.265268 102022 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 10728, 544, 736],"float32"), )
[torch error] paddle.clone(Tensor([1, 10728, 544, 736],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 130612 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:39:42.429034 102411 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:39:42.430436 102411 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 1073741824, 4],"float32"), )
[torch error] paddle.clone(Tensor([1, 1073741824, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 157482 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:40:49.447103 102706 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:40:49.448220 102706 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 12, 1, 357913942],"float32"), )
[torch error] paddle.clone(Tensor([1, 12, 1, 357913942],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 20555 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:42:03.259593 102998 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:42:03.260607 102998 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 12, 11, 32537632],"float32"), )
[torch error] paddle.clone(Tensor([1, 12, 11, 32537632],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 49653 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:43:22.700985 103403 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:43:22.701995 103403 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 12, 11184811, 32],"float32"), )
[torch error] paddle.clone(Tensor([1, 12, 11184811, 32],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 88678 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:44:30.303649 103716 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:44:30.304665 103716 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 12, 1398102, 256],"float32"), )
[torch error] paddle.clone(Tensor([1, 12, 1398102, 256],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 114248 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:45:43.080925 104097 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:45:43.082124 104097 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 12, 168, 2130441],"float32"), )
[torch error] paddle.clone(Tensor([1, 12, 168, 2130441],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 150988 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:46:50.525863 104389 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:46:50.526914 104389 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 12, 21, 17043522],"float32"), )
[torch error] paddle.clone(Tensor([1, 12, 21, 17043522],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 10957 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:48:02.543004 104689 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:48:02.544036 104689 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 12, 22369622, 16],"float32"), )
[torch error] paddle.clone(Tensor([1, 12, 22369622, 16],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 33410 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:49:10.106474 105074 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:49:10.107622 105074 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 12, 2796203, 128],"float32"), )
[torch error] paddle.clone(Tensor([1, 12, 2796203, 128],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 61240 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:50:23.534404 105380 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:50:23.535544 105380 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 12, 42, 8521761],"float32"), )
[torch error] paddle.clone(Tensor([1, 12, 42, 8521761],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 90854 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:51:33.923831 105719 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:51:33.924939 105719 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 12, 5592406, 64],"float32"), )
[torch error] paddle.clone(Tensor([1, 12, 5592406, 64],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 113118 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:52:45.908394 106107 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:52:45.909488 106107 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 12, 84, 4260881],"float32"), )
[torch error] paddle.clone(Tensor([1, 12, 84, 4260881],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 137172 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:53:56.054421 106420 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:53:56.055553 106420 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 1242757, 48, 72],"float32"), )
[torch error] paddle.clone(Tensor([1, 1242757, 48, 72],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 158505 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:55:03.830690 106720 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:55:03.831625 106720 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 128, 123362, 272],"float32"), )
[torch error] paddle.clone(Tensor([1, 128, 123362, 272],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 17576 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:56:16.063148 107126 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:56:16.064280 107126 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 128, 152, 220753],"float32"), )
[torch error] paddle.clone(Tensor([1, 128, 152, 220753],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 51483 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:57:23.402132 107426 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:57:23.403084 107426 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 144, 21, 1420294],"float32"), )
[torch error] paddle.clone(Tensor([1, 144, 21, 1420294],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 77885 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:58:32.943765 107719 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:58:32.944851 107719 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 144, 932068, 32],"float32"), )
[torch error] paddle.clone(Tensor([1, 144, 932068, 32],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 102204 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:59:45.609400 108128 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:59:45.610476 108128 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 15, 4473925, 64],"float32"), )
[torch error] paddle.clone(Tensor([1, 15, 4473925, 64],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 126550 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:00:57.559764 108441 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:00:57.560829 108441 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 15, 64, 4473925],"float32"), )
[torch error] paddle.clone(Tensor([1, 15, 64, 4473925],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 153587 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:02:03.392161 108728 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:02:03.393245 108728 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 1597831, 42, 64],"float32"), )
[torch error] paddle.clone(Tensor([1, 1597831, 42, 64],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 11939 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:03:11.377542 109118 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:03:11.378687 109118 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 16777216, 256],"float32"), )
[torch error] paddle.clone(Tensor([1, 16777216, 256],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 35976 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:04:23.735296 109425 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:04:23.736251 109425 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 1717987, 50, 50],"float32"), )
[torch error] paddle.clone(Tensor([1, 1717987, 50, 50],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 65666 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:05:40.479920 109758 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:05:40.481019 109758 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 171888, 24988],"float32"), )
[torch error] paddle.clone(Tensor([1, 171888, 24988],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 94183 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:06:54.701923 110163 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:06:54.702915 110163 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 18, 168, 1420294],"float32"), )
[torch error] paddle.clone(Tensor([1, 18, 168, 1420294],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 120715 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:08:09.936818 110484 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:08:09.937826 110484 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 18, 932068, 256],"float32"), )
[torch error] paddle.clone(Tensor([1, 18, 932068, 256],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 144739 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:09:23.986397 110896 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:09:23.987355 110896 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 192, 32, 699051],"float32"), )
[torch error] paddle.clone(Tensor([1, 192, 32, 699051],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 14408 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:10:37.428216 111232 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:10:37.429175 111232 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 192, 349526, 64],"float32"), )
[torch error] paddle.clone(Tensor([1, 192, 349526, 64],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 36954 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:11:44.062471 111659 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:11:44.063799 111659 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 192, 44, 508401],"float32"), )
[torch error] paddle.clone(Tensor([1, 192, 44, 508401],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 62089 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:12:57.725772 111967 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:12:57.726734 111967 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 192, 508401, 44],"float32"), )
[torch error] paddle.clone(Tensor([1, 192, 508401, 44],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 84292 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:14:11.249611 112281 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:14:11.250694 112281 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 192, 64, 349526],"float32"), )
[torch error] paddle.clone(Tensor([1, 192, 64, 349526],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 108576 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:15:25.781570 112685 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:15:25.782689 112685 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 192, 699051, 32],"float32"), )
[torch error] paddle.clone(Tensor([1, 192, 699051, 32],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 141201 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:16:39.590346 113015 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:16:39.591337 113015 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 2048, 24, 87382],"float32"), )
[torch error] paddle.clone(Tensor([1, 2048, 24, 87382],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 11401 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:17:46.960405 113427 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:17:46.961496 113427 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 2048, 58255, 36],"float32"), )
[torch error] paddle.clone(Tensor([1, 2048, 58255, 36],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 34368 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:19:00.390439 113736 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:19:00.391408 113736 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 2147483648, 2],"float32"), )
[torch error] paddle.clone(Tensor([1, 2147483648, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 58644 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:20:10.012524 114139 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:20:10.013533 114139 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 2147483649],"int64"), )
[torch error] paddle.clone(Tensor([1, 2147483649],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 82739 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:20:57.874655 114432 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:20:57.875733 114432 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 21504, 199729],"float32"), )
[torch error] paddle.clone(Tensor([1, 21504, 199729],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 100232 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:22:07.054029 114622 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:22:07.055131 114622 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 2218475, 44, 44],"float32"), )
[torch error] paddle.clone(Tensor([1, 2218475, 44, 44],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 123132 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:23:15.096040 115035 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:23:15.097183 115035 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 24403224, 11, 16],"float32"), )
[torch error] paddle.clone(Tensor([1, 24403224, 11, 16],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 147784 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:24:27.855362 115356 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:24:27.856467 115356 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 2500, 1717987],"float32"), )
[torch error] paddle.clone(Tensor([1, 2500, 1717987],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 13513 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:25:42.702636 115668 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:25:42.703673 115668 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 2541, 1690267],"float32"), )
[torch error] paddle.clone(Tensor([1, 2541, 1690267],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 42194 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:26:52.988760 116053 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:26:52.989773 116053 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 256, 116509, 144],"float32"), )
[torch error] paddle.clone(Tensor([1, 256, 116509, 144],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 65830 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:28:05.556747 116370 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:28:05.557868 116370 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 256, 131072, 128],"float32"), )
[torch error] paddle.clone(Tensor([1, 256, 131072, 128],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 88658 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:29:20.082432 116764 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:29:20.083428 116764 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 256, 168, 99865],"float32"), )
[torch error] paddle.clone(Tensor([1, 256, 168, 99865],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 121741 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:30:28.587091 117070 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:30:28.588058 117070 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 256, 192, 87382],"float32"), )
[torch error] paddle.clone(Tensor([1, 256, 192, 87382],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 145794 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:31:36.246896 117378 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:31:36.250991 117378 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 256, 21, 798916],"float32"), )
[torch error] paddle.clone(Tensor([1, 256, 21, 798916],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 5121 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:32:43.552805 117783 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:32:43.553913 117783 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 256, 233017, 72],"float32"), )
[torch error] paddle.clone(Tensor([1, 256, 233017, 72],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 32177 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:33:55.217346 118085 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:33:55.218362 118085 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 256, 24, 699051],"float32"), )
[torch error] paddle.clone(Tensor([1, 256, 24, 699051],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 54566 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:35:08.816203 118398 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:35:08.817210 118398 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 256, 262144, 64],"float32"), )
[torch error] paddle.clone(Tensor([1, 256, 262144, 64],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 77860 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:36:22.687490 118810 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:36:22.688576 118810 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 256, 42, 399458],"float32"), )
[torch error] paddle.clone(Tensor([1, 256, 42, 399458],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 114527 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:37:35.482554 119123 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:37:35.483686 119123 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 256, 466034, 36],"float32"), )
[torch error] paddle.clone(Tensor([1, 256, 466034, 36],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 139203 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:38:42.390679 119398 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:38:42.391835 119398 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 256, 48, 349526],"float32"), )
[torch error] paddle.clone(Tensor([1, 256, 48, 349526],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 163153 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:39:55.776818 119614 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:39:55.777926 119614 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 256, 524288, 32],"float32"), )
[torch error] paddle.clone(Tensor([1, 256, 524288, 32],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 23089 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:41:03.089277 119830 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:41:03.090276 119830 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 256, 58255, 288],"float32"), )
[torch error] paddle.clone(Tensor([1, 256, 58255, 288],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 46196 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:42:15.851323 120117 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:42:15.852398 120117 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 256, 65536, 256],"float32"), )
[torch error] paddle.clone(Tensor([1, 256, 65536, 256],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 70896 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:43:29.227056 120334 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:43:29.228042 120334 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 256, 84, 199729],"float32"), )
[torch error] paddle.clone(Tensor([1, 256, 84, 199729],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 101048 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:44:42.027819 120551 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:44:42.028918 120551 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 256, 96, 174763],"float32"), )
[torch error] paddle.clone(Tensor([1, 256, 96, 174763],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 125263 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:45:52.725531 120841 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:45:52.726634 120841 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 262144, 128, 128],"float32"), )
[torch error] paddle.clone(Tensor([1, 262144, 128, 128],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 150636 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:47:02.537709 121070 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:47:02.538808 121070 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 286331153, 15],"float32"), )
[torch error] paddle.clone(Tensor([1, 286331153, 15],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 12163 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:48:14.252245 121372 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:48:14.253353 121372 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 3, 11, 130150525],"float32"), )
[torch error] paddle.clone(Tensor([1, 3, 11, 130150525],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 37775 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:49:21.568243 121602 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:49:21.569689 121602 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 3, 11184811, 128],"float32"), )
[torch error] paddle.clone(Tensor([1, 3, 11184811, 128],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 70542 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:50:34.838167 121819 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:50:34.839296 121819 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 3, 14913081, 96, 1],"float32"), )
[torch error] paddle.clone(Tensor([1, 3, 14913081, 96, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 95733 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:51:48.333034 122099 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:51:48.334002 122099 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 3, 168, 8521761],"float32"), )
[torch error] paddle.clone(Tensor([1, 3, 168, 8521761],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 119764 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:52:58.099184 122324 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:52:58.100288 122324 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 3, 1945185, 736],"float32"), )
[torch error] paddle.clone(Tensor([1, 3, 1945185, 736],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 141713 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:54:07.270653 122541 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:54:07.271867 122541 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 3, 21, 68174085],"float32"), )
[torch error] paddle.clone(Tensor([1, 3, 21, 68174085],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 162276 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:55:20.503691 122844 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:55:20.504798 122844 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 3, 22369622, 64],"float32"), )
[torch error] paddle.clone(Tensor([1, 3, 22369622, 64],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28596 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:56:28.417629 123061 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:56:28.418592 123061 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 3, 42, 34087043],"float32"), )
[torch error] paddle.clone(Tensor([1, 3, 42, 34087043],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 60297 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:57:42.308008 123291 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:57:42.309013 123291 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 3, 44739243, 32],"float32"), )
[torch error] paddle.clone(Tensor([1, 3, 44739243, 32],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 84551 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:58:51.061012 123580 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:58:51.062088 123580 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 3, 544, 2631721],"float32"), )
[torch error] paddle.clone(Tensor([1, 3, 544, 2631721],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 108484 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:00:03.432128 123782 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:00:03.433167 123782 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 3, 5592406, 256],"float32"), )
[torch error] paddle.clone(Tensor([1, 3, 5592406, 256],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 131127 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:01:17.048779 124086 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:01:17.049762 124086 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 3, 84, 17043522],"float32"), )
[torch error] paddle.clone(Tensor([1, 3, 84, 17043522],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 156441 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:02:23.989359 124316 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:02:23.990413 124316 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 3, 89478486, 16],"float32"), )
[torch error] paddle.clone(Tensor([1, 3, 89478486, 16],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 20266 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:03:31.023669 124534 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:03:31.024788 124534 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 3, 96, 14913081, 1],"float32"), )
[torch error] paddle.clone(Tensor([1, 3, 96, 14913081, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 43280 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:04:41.888931 124821 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:04:41.889891 124821 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 3, 96, 96, 155345],"float32"), )
[torch error] paddle.clone(Tensor([1, 3, 96, 96, 155345],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 71167 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:05:53.089834 125052 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:05:53.090898 125052 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 310690, 96, 144],"float32"), )
[torch error] paddle.clone(Tensor([1, 310690, 96, 144],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 98193 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:07:00.820490 125270 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:07:00.821520 125270 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 36, 84, 1420294],"float32"), )
[torch error] paddle.clone(Tensor([1, 36, 84, 1420294],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 122996 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:08:11.395359 125570 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:08:11.396394 125570 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 36, 932068, 128],"float32"), )
[torch error] paddle.clone(Tensor([1, 36, 932068, 128],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 145751 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:09:17.728557 125774 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:09:17.730085 125774 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 384, 32, 349526],"float32"), )
[torch error] paddle.clone(Tensor([1, 384, 32, 349526],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 7960 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:10:30.707186 125990 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:10:30.717988 125990 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 384, 349526, 32],"float32"), )
[torch error] paddle.clone(Tensor([1, 384, 349526, 32],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 37425 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:11:43.844396 126294 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:11:43.845502 126294 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 399458, 84, 128],"float32"), )
[torch error] paddle.clone(Tensor([1, 399458, 84, 128],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 62297 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:12:57.204977 126524 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:12:57.205946 126524 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 4, 16777216, 64],"float32"), )
[torch error] paddle.clone(Tensor([1, 4, 16777216, 64],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 85460 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:14:10.581141 126744 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:14:10.582108 126744 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 4, 64, 16777216],"float32"), )
[torch error] paddle.clone(Tensor([1, 4, 64, 16777216],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 110676 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:15:24.601953 127032 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:15:24.602919 127032 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 4194304, 32, 32],"float32"), )
[torch error] paddle.clone(Tensor([1, 4194304, 32, 32],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 143708 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:16:38.447108 127262 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:16:38.448155 127262 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 4294967295, 1],"float32"), )
[torch error] paddle.clone(Tensor([1, 4294967295, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 11967 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:17:56.871328 127567 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:17:56.872476 127567 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 4294967295],"bool"), )
[torch error] paddle.clone(Tensor([1, 4294967295],"bool"), ) 
 CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 37282 has 4.99 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:19:08.683459 127785 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:19:08.684523 127785 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 4294967295],"float32"), )
[torch error] paddle.clone(Tensor([1, 4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 63482 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:20:22.338100 128101 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:20:22.339154 128101 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 4294967295],"int32"), )
[torch error] paddle.clone(Tensor([1, 4294967295],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 96891 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:21:34.413059 128322 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:21:34.414134 128322 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 466034, 96, 96, 1],"float32"), )
[torch error] paddle.clone(Tensor([1, 466034, 96, 96, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 126936 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:22:41.010576 128611 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:22:41.011685 128611 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 47197443, 91],"float32"), )
[torch error] paddle.clone(Tensor([1, 47197443, 91],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 149559 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:23:54.649646 128827 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:23:54.650748 128827 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 4971027, 24, 36],"float32"), )
[torch error] paddle.clone(Tensor([1, 4971027, 24, 36],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 11332 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:25:02.420981 129059 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:25:02.422115 129059 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 5, 17179870, 50],"float32"), )
[torch error] paddle.clone(Tensor([1, 5, 17179870, 50],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 32963 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:26:10.968173 129362 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:26:10.969213 129362 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 5, 50, 17179870],"float32"), )
[torch error] paddle.clone(Tensor([1, 5, 50, 17179870],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 62349 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:27:23.843397 129578 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:27:23.844360 129578 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 512, 58255, 144],"float32"), )
[torch error] paddle.clone(Tensor([1, 512, 58255, 144],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 95207 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:28:37.028824 129809 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:28:37.029910 129809 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 512, 96, 87382],"float32"), )
[torch error] paddle.clone(Tensor([1, 512, 96, 87382],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 123435 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:29:52.506829 130097 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:29:52.507831 130097 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 53687092, 80],"float32"), )
[torch error] paddle.clone(Tensor([1, 53687092, 80],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 149072 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:31:06.673533 130315 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:31:06.674659 130315 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 625, 6871948],"float32"), )
[torch error] paddle.clone(Tensor([1, 625, 6871948],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 10397 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:32:14.613670 130618 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:32:14.614779 130618 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 63161284, 68],"float32"), )
[torch error] paddle.clone(Tensor([1, 63161284, 68],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 34492 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:33:24.165467 130848 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:33:24.166527 130848 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 6391321, 21, 32],"float32"), )
[torch error] paddle.clone(Tensor([1, 6391321, 21, 32],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 65727 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:34:39.128352 131065 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:34:39.139135 131065 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 67108864, 1, 64],"float32"), )
[torch error] paddle.clone(Tensor([1, 67108864, 1, 64],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 92098 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:35:46.643419 131366 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:35:46.644537 131366 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 72, 42, 1420294],"float32"), )
[torch error] paddle.clone(Tensor([1, 72, 42, 1420294],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 119323 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:36:55.128115 131584 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:36:55.129093 131584 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 72, 932068, 64],"float32"), )
[torch error] paddle.clone(Tensor([1, 72, 932068, 64],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 155853 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:38:08.494323 131793 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:38:08.495321 131793 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 77673, 192, 288],"float32"), )
[torch error] paddle.clone(Tensor([1, 77673, 192, 288],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 20022 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:39:16.184165 132102 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:39:16.185194 132102 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 80, 1073742, 50],"float32"), )
[torch error] paddle.clone(Tensor([1, 80, 1073742, 50],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 46205 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:40:24.297816 132320 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:40:24.298838 132320 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 80, 1220162, 44],"float32"), )
[torch error] paddle.clone(Tensor([1, 80, 1220162, 44],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 75534 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:41:31.954746 132537 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:41:31.955835 132537 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 80, 44, 1220162],"float32"), )
[torch error] paddle.clone(Tensor([1, 80, 44, 1220162],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 102006 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:42:44.694836 132842 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:42:44.695868 132842 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 80, 50, 1073742],"float32"), )
[torch error] paddle.clone(Tensor([1, 80, 50, 1073742],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 128670 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:43:53.005254 133061 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:43:53.006297 133061 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 96, 128, 349526],"float32"), )
[torch error] paddle.clone(Tensor([1, 96, 128, 349526],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 150594 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:45:02.459666 133278 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:45:02.460749 133278 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 96, 349526, 128],"float32"), )
[torch error] paddle.clone(Tensor([1, 96, 349526, 128],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 11132 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:46:13.667668 133580 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:46:13.695966 133580 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1, 99865, 168, 256],"float32"), )
[torch error] paddle.clone(Tensor([1, 99865, 168, 256],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 39803 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:47:21.655437 133812 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:47:21.656646 133812 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 122, 125731, 28],"float32"), )
[torch error] paddle.clone(Tensor([10, 122, 125731, 28],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 68191 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:48:37.690793 134030 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:48:37.691934 134030 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 122, 28, 125731],"float32"), )
[torch error] paddle.clone(Tensor([10, 122, 28, 125731],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 102283 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:49:47.928215 134332 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:49:47.929301 134332 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 1280, 1, 335545],"float32"), )
[torch error] paddle.clone(Tensor([10, 1280, 1, 335545],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 125448 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:50:59.350206 134548 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:50:59.351346 134548 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 1280, 335545, 1],"float32"), )
[torch error] paddle.clone(Tensor([10, 1280, 335545, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 149298 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:52:06.630306 134768 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:52:06.631296 134768 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 136957, 196, 16],"float32"), )
[torch error] paddle.clone(Tensor([10, 136957, 196, 16],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 9653 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:53:21.839550 135055 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:53:21.840654 135055 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 136957, 56, 56],"float32"), )
[torch error] paddle.clone(Tensor([10, 136957, 56, 56],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 42854 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:54:33.480093 135271 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:54:33.481178 135271 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 196, 2191310],"float32"), )
[torch error] paddle.clone(Tensor([10, 196, 2191310],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 71231 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:55:46.116878 135560 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:55:46.117992 135560 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 2048, 10, 20972],"float32"), )
[torch error] paddle.clone(Tensor([10, 2048, 10, 20972],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 100432 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:56:59.441906 135749 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:56:59.442903 135749 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 2048, 20972, 10],"float32"), )
[torch error] paddle.clone(Tensor([10, 2048, 20972, 10],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 127635 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:58:12.054726 135952 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:58:12.055734 135952 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 2048, 29960, 7],"float32"), )
[torch error] paddle.clone(Tensor([10, 2048, 29960, 7],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 154118 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:59:20.423197 136255 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:59:20.424211 136255 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 2048, 7, 29960],"float32"), )
[torch error] paddle.clone(Tensor([10, 2048, 7, 29960],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 15676 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:00:31.220923 136471 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:00:31.222033 136471 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 2191310, 14, 14],"float32"), )
[torch error] paddle.clone(Tensor([10, 2191310, 14, 14],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 46726 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:01:37.625102 136773 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:01:37.626688 136773 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 2236963, 192],"float32"), )
[torch error] paddle.clone(Tensor([10, 2236963, 192],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 68623 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:02:50.005125 136992 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:02:50.006228 136992 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 2304, 186414],"float32"), )
[torch error] paddle.clone(Tensor([10, 2304, 186414],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 94552 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:04:02.083288 137198 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:04:02.084303 137198 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 256, 119838, 14],"float32"), )
[torch error] paddle.clone(Tensor([10, 256, 119838, 14],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 119523 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:05:09.835224 137486 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:05:09.836201 137486 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 256, 14, 119838],"float32"), )
[torch error] paddle.clone(Tensor([10, 256, 14, 119838],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 142666 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:06:23.511945 137703 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:06:23.513034 137703 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 3, 224, 639133],"float32"), )
[torch error] paddle.clone(Tensor([10, 3, 224, 639133],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 15867 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:07:30.360417 137908 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:07:30.361743 137908 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 3, 639133, 224],"float32"), )
[torch error] paddle.clone(Tensor([10, 3, 639133, 224],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 41844 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:08:45.704249 138194 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:08:45.705364 138194 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 32, 14, 958699],"float32"), )
[torch error] paddle.clone(Tensor([10, 32, 14, 958699],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 73266 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:09:58.888449 138413 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:09:58.889575 138413 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 32, 239675, 56],"float32"), )
[torch error] paddle.clone(Tensor([10, 32, 239675, 56],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 98303 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:11:09.854436 138647 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:11:09.855451 138647 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 32, 56, 239675],"float32"), )
[torch error] paddle.clone(Tensor([10, 32, 56, 239675],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 125454 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:12:23.419909 138934 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:12:23.420907 138934 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 32, 958699, 14],"float32"), )
[torch error] paddle.clone(Tensor([10, 32, 958699, 14],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 154186 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:13:35.880775 139167 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:13:35.881739 139167 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 320, 167773, 8],"float32"), )
[torch error] paddle.clone(Tensor([10, 320, 167773, 8],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 17884 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:14:48.939530 139469 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:14:48.940655 139469 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 320, 8, 167773],"float32"), )
[torch error] paddle.clone(Tensor([10, 320, 8, 167773],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 43195 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:16:01.226279 139688 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:16:01.227269 139688 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 3355444, 128],"float32"), )
[torch error] paddle.clone(Tensor([10, 3355444, 128],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 69973 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:17:08.655651 140003 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:17:08.656770 140003 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 34240, 196, 64],"float32"), )
[torch error] paddle.clone(Tensor([10, 34240, 196, 64],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 98216 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:18:16.104542 140236 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:18:16.105558 140236 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 36, 28, 426089],"float32"), )
[torch error] paddle.clone(Tensor([10, 36, 28, 426089],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 124615 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:19:23.586218 140470 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:19:23.587225 140470 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 36, 426089, 28],"float32"), )
[torch error] paddle.clone(Tensor([10, 36, 426089, 28],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 151893 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:20:37.324942 140687 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:20:37.325906 140687 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 429496730, 1, 1],"float32"), )
[torch error] paddle.clone(Tensor([10, 429496730, 1, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 15841 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:21:47.567605 140988 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:21:47.568650 140988 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 429496730],"float32"), )
[torch error] paddle.clone(Tensor([10, 429496730],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 40986 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:22:56.070052 141178 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:22:56.082394 141178 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 4294968, 10, 10],"float32"), )
[torch error] paddle.clone(Tensor([10, 4294968, 10, 10],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 64290 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:24:08.453070 141380 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:24:08.454119 141380 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 49, 8765240],"float32"), )
[torch error] paddle.clone(Tensor([10, 49, 8765240],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 92616 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:25:18.280875 141683 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:25:18.283257 141683 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 512, 1, 838861],"float32"), )
[torch error] paddle.clone(Tensor([10, 512, 1, 838861],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 123725 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:26:37.382102 141887 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:26:37.391682 141887 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 512, 119838, 7],"float32"), )
[torch error] paddle.clone(Tensor([10, 512, 119838, 7],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 5520 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:27:45.588137 142175 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:27:45.589231 142175 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 512, 7, 119838],"float32"), )
[torch error] paddle.clone(Tensor([10, 512, 7, 119838],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 34586 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:28:52.987504 142392 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:28:52.988610 142392 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 512, 838861, 1],"float32"), )
[torch error] paddle.clone(Tensor([10, 512, 838861, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 64650 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:29:59.760049 142597 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:29:59.761066 142597 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 547828, 28, 28],"float32"), )
[torch error] paddle.clone(Tensor([10, 547828, 28, 28],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 91768 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:31:20.700085 142787 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:31:20.701077 142787 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 64, 14, 479350],"float32"), )
[torch error] paddle.clone(Tensor([10, 64, 14, 479350],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 126003 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:32:36.365823 143071 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:32:36.366917 143071 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 64, 479350, 14],"float32"), )
[torch error] paddle.clone(Tensor([10, 64, 479350, 14],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 163363 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:33:53.977514 143349 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:33:53.978648 143349 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 6710887, 8, 8],"float32"), )
[torch error] paddle.clone(Tensor([10, 6710887, 8, 8],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 31735 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:35:07.803761 143552 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:35:07.804759 143552 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 671089, 640],"float32"), )
[torch error] paddle.clone(Tensor([10, 671089, 640],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 60315 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:36:16.692407 143828 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:36:16.693529 143828 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 8, 196, 273914],"float32"), )
[torch error] paddle.clone(Tensor([10, 8, 196, 273914],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 98202 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:37:30.170512 144017 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:37:30.171518 144017 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 8, 3355444, 16],"float32"), )
[torch error] paddle.clone(Tensor([10, 8, 3355444, 16],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 135478 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:38:44.759172 144303 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:38:44.760142 144303 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 8, 838861, 64],"float32"), )
[torch error] paddle.clone(Tensor([10, 8, 838861, 64],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 5804 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:39:55.538443 144494 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:39:55.539438 144494 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 8560, 224, 224],"float32"), )
[torch error] paddle.clone(Tensor([10, 8560, 224, 224],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 35174 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:41:03.525631 144698 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:41:03.526631 144698 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10, 8765240, 7, 7],"float32"), )
[torch error] paddle.clone(Tensor([10, 8765240, 7, 7],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 66598 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:42:12.163472 144987 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:42:12.166355 144987 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10700, 128, 56, 56],"float32"), )
[torch error] paddle.clone(Tensor([10700, 128, 56, 56],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 96904 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:43:20.366283 145190 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:43:20.367367 145190 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10700, 32, 112, 112],"float32"), )
[torch error] paddle.clone(Tensor([10700, 32, 112, 112],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 123424 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:44:26.940021 145378 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:44:26.941130 145378 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1073741824, 4],"float32"), )
[torch error] paddle.clone(Tensor([1073741824, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 156604 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:45:38.044478 145595 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:45:38.045491 145595 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10737419, 100, 4],"float32"), )
[torch error] paddle.clone(Tensor([10737419, 100, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 26166 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:46:53.336979 145887 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:46:53.338078 145887 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([107375, 10000, 4],"float32"), )
[torch error] paddle.clone(Tensor([107375, 10000, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 53140 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:48:00.572952 146097 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:48:00.573930 146097 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10923, 384, 32, 32],"float32"), )
[torch error] paddle.clone(Tensor([10923, 384, 32, 32],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 75139 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:49:09.012494 146125 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:49:09.013453 146125 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([10956550, 196],"int64"), )
[torch error] paddle.clone(Tensor([10956550, 196],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 101644 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:49:57.412509 146152 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:49:57.413668 146152 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([11, 124507, 56, 56],"float32"), )
[torch error] paddle.clone(Tensor([11, 124507, 56, 56],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 120639 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:51:10.398613 146179 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:51:10.399565 146179 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([11, 1280, 43578, 7],"float32"), )
[torch error] paddle.clone(Tensor([11, 1280, 43578, 7],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 145531 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:52:18.530436 146221 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:52:18.531513 146221 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([11, 1280, 7, 43578],"float32"), )
[torch error] paddle.clone(Tensor([11, 1280, 7, 43578],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 6184 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:53:26.632157 146264 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:53:26.633179 146264 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([11, 24, 290515, 56],"float32"), )
[torch error] paddle.clone(Tensor([11, 24, 290515, 56],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 34113 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:54:40.195574 146306 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:54:40.196732 146306 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([11, 24, 56, 290515],"float32"), )
[torch error] paddle.clone(Tensor([11, 24, 56, 290515],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 60799 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:55:52.285629 146348 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:55:52.286639 146348 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([11, 7968400, 7, 7],"float32"), )
[torch error] paddle.clone(Tensor([11, 7968400, 7, 7],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 89296 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:57:00.217540 146376 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:57:00.218562 146376 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([11, 976, 57151, 7],"float32"), )
[torch error] paddle.clone(Tensor([11, 976, 57151, 7],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 119613 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:58:12.653816 146417 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:58:12.654887 146417 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([11, 976, 7, 57151],"float32"), )
[torch error] paddle.clone(Tensor([11, 976, 7, 57151],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 146002 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 00:59:20.644881 146465 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:59:20.646226 146465 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([11097, 36, 84, 128],"float32"), )
[torch error] paddle.clone(Tensor([11097, 36, 84, 128],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 5553 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:00:28.255553 146508 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:00:28.256569 146508 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([112978, 198, 192],"float32"), )
[torch error] paddle.clone(Tensor([112978, 198, 192],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 33652 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:01:41.932917 146550 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:01:41.934022 146550 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([11555, 192, 44, 44],"float32"), )
[torch error] paddle.clone(Tensor([11555, 192, 44, 44],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 61747 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:02:50.496017 146601 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:02:50.496991 146601 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([12, 1864136, 192],"float32"), )
[torch error] paddle.clone(Tensor([12, 1864136, 192],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 85506 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:04:03.290127 146633 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:04:03.291253 146633 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([12, 288, 1242757],"float32"), )
[torch error] paddle.clone(Tensor([12, 288, 1242757],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 109727 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:05:10.594056 146675 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:05:10.595177 146675 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1214, 1024, 48, 72],"float32"), )
[torch error] paddle.clone(Tensor([1214, 1024, 48, 72],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.01 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 133324 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:06:28.531908 146704 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:06:28.532905 146704 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1214, 256, 96, 144],"float32"), )
[torch error] paddle.clone(Tensor([1214, 256, 96, 144],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.01 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 9626 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:07:36.872977 146758 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:07:36.873963 146758 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([124507, 704, 7, 7],"float32"), )
[torch error] paddle.clone(Tensor([124507, 704, 7, 7],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 31529 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:08:43.633148 146801 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:08:43.634258 146801 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([129024, 33289],"float32"), )
[torch error] paddle.clone(Tensor([129024, 33289],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 58309 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:09:53.880499 146830 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:09:53.890537 146830 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([133153, 12, 42, 64],"float32"), )
[torch error] paddle.clone(Tensor([133153, 12, 42, 64],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 82172 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:11:05.268075 146872 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:11:05.270534 146872 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([133153, 3, 84, 128],"float32"), )
[torch error] paddle.clone(Tensor([133153, 3, 84, 128],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 105394 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:12:17.891111 146916 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:12:17.892113 146916 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([13316, 21504, 15],"float32"), )
[torch error] paddle.clone(Tensor([13316, 21504, 15],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 137117 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:13:29.919512 146971 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:13:29.920521 146971 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([145, 12, 112, 22040],"float32"), )
[torch error] paddle.clone(Tensor([145, 12, 112, 22040],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 2139 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:14:38.948741 147000 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:14:38.949872 147000 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([145, 12, 22040, 112],"float32"), )
[torch error] paddle.clone(Tensor([145, 12, 22040, 112],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28785 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:15:50.383860 147042 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:15:50.384846 147042 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([145, 2362, 112, 112],"float32"), )
[torch error] paddle.clone(Tensor([145, 2362, 112, 112],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.01 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 55845 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:17:01.440474 147097 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:17:01.441617 147097 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([14609, 1500, 14, 14],"float32"), )
[torch error] paddle.clone(Tensor([14609, 1500, 14, 14],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 81176 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:18:09.962204 147139 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:18:09.963148 147139 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([152175, 36, 28, 28],"float32"), )
[torch error] paddle.clone(Tensor([152175, 36, 28, 28],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 105699 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:19:18.916808 147181 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:19:18.917934 147181 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([155345, 3, 96, 96, 1],"float32"), )
[torch error] paddle.clone(Tensor([155345, 3, 96, 96, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 130714 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:20:25.861335 147237 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:20:25.862826 147237 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1561, 256, 84, 128],"float32"), )
[torch error] paddle.clone(Tensor([1561, 256, 84, 128],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.01 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 156752 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:21:39.278647 147252 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:21:39.279757 147252 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([16, 134217729],"float64"), )
[torch error] paddle.clone(Tensor([16, 134217729],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 21285 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:22:24.058125 147294 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:22:24.059199 147294 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([16, 268435456],"float32"), )
[torch error] paddle.clone(Tensor([16, 268435456],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 31529 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:23:37.425997 147350 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:23:37.426973 147350 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([16384, 262144],"float32"), )
[torch error] paddle.clone(Tensor([16384, 262144],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 58916 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:24:48.000346 147393 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:24:48.001323 147393 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([167773, 100, 256],"float32"), )
[torch error] paddle.clone(Tensor([167773, 100, 256],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 83303 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:25:57.437040 147422 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:25:57.438138 147422 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1690267, 2541],"bool"), )
[torch error] paddle.clone(Tensor([1690267, 2541],"bool"), ) 
 CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 108430 has 4.99 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:27:05.292733 147464 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:27:05.293843 147464 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([171197, 128, 14, 14],"float32"), )
[torch error] paddle.clone(Tensor([171197, 128, 14, 14],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 132917 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:28:15.121184 147520 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:28:15.122360 147520 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([171197, 196, 128],"float32"), )
[torch error] paddle.clone(Tensor([171197, 196, 128],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 162378 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:29:22.498690 147562 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:29:22.499776 147562 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([171197, 49, 512],"float32"), )
[torch error] paddle.clone(Tensor([171197, 49, 512],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 20881 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:30:30.083482 147604 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:30:30.084601 147604 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([171197, 512, 7, 7],"float32"), )
[torch error] paddle.clone(Tensor([171197, 512, 7, 7],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 49352 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:31:38.552484 147645 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:31:38.553987 147645 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([171197, 8, 196, 16],"float32"), )
[torch error] paddle.clone(Tensor([171197, 8, 196, 16],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 72963 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:32:51.632072 147686 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:32:51.633097 147686 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1717987, 2500, 1],"float32"), )
[torch error] paddle.clone(Tensor([1717987, 2500, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 95936 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:34:04.015626 147702 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:34:04.016605 147702 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([1717987, 625, 4],"float32"), )
[torch error] paddle.clone(Tensor([1717987, 625, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 118108 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:35:16.706969 147742 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:35:16.708084 147742 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([182610, 480, 7, 7],"float32"), )
[torch error] paddle.clone(Tensor([182610, 480, 7, 7],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 142237 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:36:24.765002 147785 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:36:24.766394 147785 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([19419, 256, 24, 36],"float32"), )
[torch error] paddle.clone(Tensor([19419, 256, 24, 36],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 11771 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:37:54.454129 147827 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:37:54.455215 147827 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([195653, 28, 28, 28],"float32"), )
[torch error] paddle.clone(Tensor([195653, 28, 28, 28],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 50157 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:39:01.692490 147882 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:39:01.693624 147882 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([199729, 21504, 1],"float32"), )
[torch error] paddle.clone(Tensor([199729, 21504, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 72851 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:40:10.707226 147912 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:40:10.712514 147912 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([2, 1073741825],"int64"), )
[torch error] paddle.clone(Tensor([2, 1073741825],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 97086 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:40:53.836758 147953 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:40:53.837697 147953 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([2, 2147483648],"float32"), )
[torch error] paddle.clone(Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 114143 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:42:01.987401 147967 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:42:01.988459 147967 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([2, 256, 28, 299594],"float32"), )
[torch error] paddle.clone(Tensor([2, 256, 28, 299594],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 136514 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:43:08.976826 148009 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:43:08.987498 148009 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([2, 256, 299594, 28],"float32"), )
[torch error] paddle.clone(Tensor([2, 256, 299594, 28],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 159044 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:44:16.416965 148038 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:44:16.418481 148038 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([2, 2739138, 28, 28],"float32"), )
[torch error] paddle.clone(Tensor([2, 2739138, 28, 28],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 21843 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:45:52.116132 148079 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:45:52.117177 148079 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([2, 28, 76695845],"int32"), )
[torch error] paddle.clone(Tensor([2, 28, 76695845],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 60122 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:47:01.214495 148121 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:47:01.215608 148121 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([2, 76695845, 28],"int32"), )
[torch error] paddle.clone(Tensor([2, 76695845, 28],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 85301 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:48:08.440094 148163 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:48:08.441540 148163 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([2016, 2130441],"float32"), )
[torch error] paddle.clone(Tensor([2016, 2130441],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 107565 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:49:15.328313 148205 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:49:15.329291 148205 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([2033602, 12, 11, 16],"float32"), )
[torch error] paddle.clone(Tensor([2033602, 12, 11, 16],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 132662 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:50:27.168269 148249 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:50:27.169411 148249 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([20752, 1056, 14, 14],"float32"), )
[torch error] paddle.clone(Tensor([20752, 1056, 14, 14],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 156649 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:51:41.698279 148291 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:51:41.699370 148291 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([209716, 320, 8, 8],"float32"), )
[torch error] paddle.clone(Tensor([209716, 320, 8, 8],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 22907 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:52:49.532925 148346 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:52:49.537346 148346 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([20972, 2048, 10, 10],"float32"), )
[torch error] paddle.clone(Tensor([20972, 2048, 10, 10],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 44746 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:54:02.294561 148362 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:54:02.295554 148362 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([21129, 2541, 80],"float32"), )
[torch error] paddle.clone(Tensor([21129, 2541, 80],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 65610 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:55:17.750685 148403 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:55:17.751677 148403 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([2130441, 3, 21, 32],"float32"), )
[torch error] paddle.clone(Tensor([2130441, 3, 21, 32],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 90628 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:56:27.816072 148458 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:56:27.819491 148458 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([21400, 1024, 14, 14],"float32"), )
[torch error] paddle.clone(Tensor([21400, 1024, 14, 14],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 121456 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:57:35.225818 148500 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:57:35.226954 148500 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([21400, 256, 28, 28],"float32"), )
[torch error] paddle.clone(Tensor([21400, 256, 28, 28],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 148372 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:58:45.075918 148529 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:58:45.077080 148529 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([21400, 4, 224, 224],"float32"), )
[torch error] paddle.clone(Tensor([21400, 4, 224, 224],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 11449 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:59:52.247236 148557 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:59:52.248312 148557 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([21400, 64, 56, 56],"float32"), )
[torch error] paddle.clone(Tensor([21400, 64, 56, 56],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 36064 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:01:05.974701 148600 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:01:05.975708 148600 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([2145339, 2002],"float32"), )
[torch error] paddle.clone(Tensor([2145339, 2002],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 58954 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:02:12.154938 148628 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:02:12.156353 148628 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([2147483648, 2],"float32"), )
[torch error] paddle.clone(Tensor([2147483648, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 81614 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:03:19.366959 148656 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:03:19.368078 148656 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([2147483649, 1],"int64"), )
[torch error] paddle.clone(Tensor([2147483649, 1],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 103360 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:04:03.216382 148699 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:04:03.217514 148699 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([2147483649],"float64"), )
[torch error] paddle.clone(Tensor([2147483649],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 120549 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:04:50.985236 148713 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:04:50.986354 148713 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([21475, 2500, 80],"float32"), )
[torch error] paddle.clone(Tensor([21475, 2500, 80],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 138134 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:05:57.891160 148740 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:05:57.898519 148740 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([21475, 80, 50, 50],"float32"), )
[torch error] paddle.clone(Tensor([21475, 80, 50, 50],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 435 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:07:08.762641 148768 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:07:08.763634 148768 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([21846, 192, 32, 32],"float32"), )
[torch error] paddle.clone(Tensor([21846, 192, 32, 32],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 25584 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:08:20.953070 148809 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:08:20.954118 148809 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([2195, 21504, 91],"float32"), )
[torch error] paddle.clone(Tensor([2195, 21504, 91],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 49978 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:09:26.570117 148843 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:09:26.571564 148843 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 1024, 1, 190651],"float32"), )
[torch error] paddle.clone(Tensor([22, 1024, 1, 190651],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 71816 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:10:32.535110 148879 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:10:32.536264 148879 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 1024, 13618, 14],"float32"), )
[torch error] paddle.clone(Tensor([22, 1024, 13618, 14],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 101392 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:11:38.093634 148909 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:11:38.094712 148909 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 1024, 14, 13618],"float32"), )
[torch error] paddle.clone(Tensor([22, 1024, 14, 13618],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 124320 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:12:44.088168 148937 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:12:44.089277 148937 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 1024, 190651, 1],"float32"), )
[torch error] paddle.clone(Tensor([22, 1024, 190651, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 147111 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:13:57.105826 148951 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:13:57.106819 148951 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 1056, 13206, 14],"float32"), )
[torch error] paddle.clone(Tensor([22, 1056, 13206, 14],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 5035 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:15:02.362282 148979 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:15:02.363390 148979 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 1056, 14, 13206],"float32"), )
[torch error] paddle.clone(Tensor([22, 1056, 14, 13206],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 26296 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:16:10.498332 149007 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:16:10.507784 149007 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 128, 108943, 14],"float32"), )
[torch error] paddle.clone(Tensor([22, 128, 108943, 14],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 57623 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:17:16.244864 149047 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:17:16.251324 149047 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 128, 14, 108943],"float32"), )
[torch error] paddle.clone(Tensor([22, 128, 14, 108943],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 82020 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:18:26.404709 149063 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:18:26.413914 149063 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 128, 27236, 56],"float32"), )
[torch error] paddle.clone(Tensor([22, 128, 27236, 56],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 109732 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:19:41.812320 149103 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:19:41.813320 149103 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 128, 28, 54472],"float32"), )
[torch error] paddle.clone(Tensor([22, 128, 28, 54472],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 137653 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:20:53.037817 149145 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:20:53.038911 149145 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 128, 54472, 28],"float32"), )
[torch error] paddle.clone(Tensor([22, 128, 54472, 28],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 161327 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:21:59.524080 149161 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:21:59.525278 149161 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 128, 56, 27236],"float32"), )
[torch error] paddle.clone(Tensor([22, 128, 56, 27236],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 18460 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:23:05.992246 149201 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:23:05.993291 149201 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 144, 24210, 56],"float32"), )
[torch error] paddle.clone(Tensor([22, 144, 24210, 56],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 39614 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:24:19.414446 149217 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:24:19.415648 149217 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 144, 56, 24210],"float32"), )
[torch error] paddle.clone(Tensor([22, 144, 56, 24210],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 63664 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:25:34.507143 149245 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:25:34.508128 149245 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 1500, 1, 130151],"float32"), )
[torch error] paddle.clone(Tensor([22, 1500, 1, 130151],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 97323 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:26:40.711755 149287 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:26:40.712865 149287 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 1500, 130151, 1],"float32"), )
[torch error] paddle.clone(Tensor([22, 1500, 130151, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 124273 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:27:46.873943 149329 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:27:46.874961 149329 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 1500, 14, 9297],"float32"), )
[torch error] paddle.clone(Tensor([22, 1500, 14, 9297],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 144702 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:29:02.302680 149357 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:29:02.303671 149357 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 1500, 9297, 14],"float32"), )
[torch error] paddle.clone(Tensor([22, 1500, 9297, 14],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 6222 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:30:10.584492 149384 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:30:10.585546 149384 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 1525202, 128],"float32"), )
[torch error] paddle.clone(Tensor([22, 1525202, 128],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 29581 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:31:21.391590 149439 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:31:21.392709 149439 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 1536, 15888, 8],"float32"), )
[torch error] paddle.clone(Tensor([22, 1536, 15888, 8],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 51827 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:32:31.797317 149468 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:32:31.798413 149468 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 1536, 8, 15888],"float32"), )
[torch error] paddle.clone(Tensor([22, 1536, 8, 15888],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 85003 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:33:44.219957 149507 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:33:44.221077 149507 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 15564, 112, 112],"float32"), )
[torch error] paddle.clone(Tensor([22, 15564, 112, 112],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 110066 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:34:58.063098 149525 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:34:58.064085 149525 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 16, 12201612],"float32"), )
[torch error] paddle.clone(Tensor([22, 16, 12201612],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 132310 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:36:04.658753 149567 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:36:04.659875 149567 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 195225787, 1, 1],"float32"), )
[torch error] paddle.clone(Tensor([22, 195225787, 1, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 157682 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:37:11.259343 149608 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:37:11.260403 149608 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 196, 996050],"float32"), )
[torch error] paddle.clone(Tensor([22, 196, 996050],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 18930 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:38:18.655273 149651 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:38:18.656252 149651 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 2048, 13618, 7],"float32"), )
[torch error] paddle.clone(Tensor([22, 2048, 13618, 7],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 42886 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:39:26.088810 149706 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:39:26.090152 149706 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 2048, 7, 13618],"float32"), )
[torch error] paddle.clone(Tensor([22, 2048, 7, 13618],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 63761 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:40:33.816628 149762 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:40:33.818092 149762 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 249013, 28, 28],"float32"), )
[torch error] paddle.clone(Tensor([22, 249013, 28, 28],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 94817 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:41:51.183432 149804 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:41:51.184412 149804 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 256, 14, 54472],"float32"), )
[torch error] paddle.clone(Tensor([22, 256, 14, 54472],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 121276 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:43:00.261387 149859 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:43:00.262356 149859 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 256, 54472, 14],"float32"), )
[torch error] paddle.clone(Tensor([22, 256, 54472, 14],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 142011 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:44:13.016770 149914 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:44:13.017768 149914 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 28, 124507, 56],"float32"), )
[torch error] paddle.clone(Tensor([22, 28, 124507, 56],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 3244 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:45:27.579548 149944 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:45:27.588940 149944 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 28, 249013, 28],"float32"), )
[torch error] paddle.clone(Tensor([22, 28, 249013, 28],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 26351 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:46:41.359330 149973 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:46:41.360459 149973 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 28, 28, 249013],"float32"), )
[torch error] paddle.clone(Tensor([22, 28, 28, 249013],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 62200 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:47:54.489039 150014 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:47:54.490248 150014 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 28, 56, 124507],"float32"), )
[torch error] paddle.clone(Tensor([22, 28, 56, 124507],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 90507 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:49:07.523962 150071 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:49:07.525079 150071 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 288, 14, 48420],"float32"), )
[torch error] paddle.clone(Tensor([22, 288, 14, 48420],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 114401 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:50:16.016938 150099 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:50:16.017932 150099 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 288, 48420, 14],"float32"), )
[torch error] paddle.clone(Tensor([22, 288, 48420, 14],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 138531 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:51:28.994921 150127 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:51:28.995890 150127 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 3050403, 8, 8],"float32"), )
[torch error] paddle.clone(Tensor([22, 3050403, 8, 8],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 162387 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:52:38.274062 150170 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:52:38.275025 150170 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 360, 14, 38736],"float32"), )
[torch error] paddle.clone(Tensor([22, 360, 14, 38736],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 26920 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:53:47.615257 150225 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:53:47.616246 150225 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 360, 38736, 14],"float32"), )
[torch error] paddle.clone(Tensor([22, 360, 38736, 14],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 50039 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:54:54.529695 150281 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:54:54.531165 150281 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 381301, 512],"float32"), )
[torch error] paddle.clone(Tensor([22, 381301, 512],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 70166 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:56:00.980438 150338 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:56:00.981753 150338 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 3891, 224, 224],"float32"), )
[torch error] paddle.clone(Tensor([22, 3891, 224, 224],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 96525 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:57:09.675590 150393 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:57:09.676700 150393 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 3984200, 7, 7],"float32"), )
[torch error] paddle.clone(Tensor([22, 3984200, 7, 7],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 123318 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:58:16.477353 150435 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:58:16.478520 150435 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 4, 217886, 224],"float32"), )
[torch error] paddle.clone(Tensor([22, 4, 217886, 224],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 145628 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:59:23.090112 150478 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:59:23.092615 150478 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 4, 224, 217886],"float32"), )
[torch error] paddle.clone(Tensor([22, 4, 224, 217886],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 4914 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:00:30.920224 150519 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:00:30.921229 150519 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 480, 58103, 7],"float32"), )
[torch error] paddle.clone(Tensor([22, 480, 58103, 7],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 29034 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:01:36.364374 150562 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:01:36.365342 150562 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 480, 7, 58103],"float32"), )
[torch error] paddle.clone(Tensor([22, 480, 7, 58103],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 52452 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:02:47.398298 150591 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:02:47.399415 150591 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 49, 3984200],"float32"), )
[torch error] paddle.clone(Tensor([22, 49, 3984200],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 77551 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:03:59.743084 150633 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:03:59.744194 150633 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 508401, 384],"float32"), )
[torch error] paddle.clone(Tensor([22, 508401, 384],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 104868 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:05:12.988232 150675 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:05:13.000186 150675 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 512, 54472, 7],"float32"), )
[torch error] paddle.clone(Tensor([22, 512, 54472, 7],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 130045 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:06:20.601301 150715 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:06:20.602375 150715 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 512, 7, 54472],"float32"), )
[torch error] paddle.clone(Tensor([22, 512, 7, 54472],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 156622 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:07:32.135499 150745 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:07:32.136482 150745 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 62254, 56, 56],"float32"), )
[torch error] paddle.clone(Tensor([22, 62254, 56, 56],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 20301 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:08:40.615073 150785 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:08:40.616210 150785 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 64, 112, 27236],"float32"), )
[torch error] paddle.clone(Tensor([22, 64, 112, 27236],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 48291 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:09:55.380697 150814 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:09:55.381862 150814 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 64, 27236, 112],"float32"), )
[torch error] paddle.clone(Tensor([22, 64, 27236, 112],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 70847 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:11:01.634392 150855 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:11:01.635473 150855 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 64, 54472, 56],"float32"), )
[torch error] paddle.clone(Tensor([22, 64, 54472, 56],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 92768 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:12:13.125269 150870 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:12:13.126466 150870 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 64, 56, 54472],"float32"), )
[torch error] paddle.clone(Tensor([22, 64, 56, 54472],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 119208 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:13:25.120931 150913 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:13:25.122012 150913 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22, 996050, 14, 14],"float32"), )
[torch error] paddle.clone(Tensor([22, 996050, 14, 14],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 140904 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:14:37.399248 150955 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:14:37.400254 150955 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22193, 72, 42, 64],"float32"), )
[torch error] paddle.clone(Tensor([22193, 72, 42, 64],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 6511 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:15:47.410627 151024 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:15:47.411657 151024 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([22369622, 192],"float32"), )
[torch error] paddle.clone(Tensor([22369622, 192],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 31655 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:17:01.267401 151067 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:17:01.268417 151067 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([24, 178956971],"float32"), )
[torch error] paddle.clone(Tensor([24, 178956971],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 54553 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:18:12.871023 151109 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:18:12.872129 151109 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([2402107, 1788],"float32"), )
[torch error] paddle.clone(Tensor([2402107, 1788],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 76234 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:19:22.094158 151150 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:19:22.095196 151150 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([2428, 2048, 24, 36],"float32"), )
[torch error] paddle.clone(Tensor([2428, 2048, 24, 36],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.01 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 98697 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:20:32.286531 151193 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:20:32.288933 151193 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([24857, 2541, 68],"float32"), )
[torch error] paddle.clone(Tensor([24857, 2541, 68],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 125751 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:21:43.870946 151234 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:21:43.872048 151234 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([24967, 256, 21, 32],"float32"), )
[torch error] paddle.clone(Tensor([24967, 256, 21, 32],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 152495 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:22:52.820904 151263 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:22:52.821933 151263 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([24988, 171888, 1],"float32"), )
[torch error] paddle.clone(Tensor([24988, 171888, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 9970 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:24:01.598136 151304 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:24:01.599109 151304 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([2541, 1690267],"float32"), )
[torch error] paddle.clone(Tensor([2541, 1690267],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28015 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:25:10.615638 151347 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:25:10.616688 151347 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([262144, 4, 64, 64],"float32"), )
[torch error] paddle.clone(Tensor([262144, 4, 64, 64],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 48931 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:26:21.691754 151389 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:26:21.692865 151389 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([2731, 96, 128, 128],"float32"), )
[torch error] paddle.clone(Tensor([2731, 96, 128, 128],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 74572 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:27:32.767625 151418 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:27:32.768774 151418 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([27731, 80, 44, 44],"float32"), )
[torch error] paddle.clone(Tensor([27731, 80, 44, 44],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 100188 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:28:39.901567 151460 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:28:39.902704 151460 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([28533, 12, 112, 112],"float32"), )
[torch error] paddle.clone(Tensor([28533, 12, 112, 112],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 127000 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:29:52.649880 151515 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:29:52.650982 151515 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([28533, 3, 224, 224],"float32"), )
[torch error] paddle.clone(Tensor([28533, 3, 224, 224],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 146715 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:31:04.057729 151544 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:31:04.058836 151544 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([2863312, 1500, 1, 1],"float32"), )
[torch error] paddle.clone(Tensor([2863312, 1500, 1, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 4597 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:32:11.473687 151584 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:32:11.474805 151584 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([304, 256, 192, 288],"float32"), )
[torch error] paddle.clone(Tensor([304, 256, 192, 288],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.03 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 23747 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:33:23.325846 151626 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:33:23.326946 151626 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([32256, 133153],"float32"), )
[torch error] paddle.clone(Tensor([32256, 133153],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 43458 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:34:29.699383 151655 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:34:29.700410 151655 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([33289, 12, 84, 128],"float32"), )
[torch error] paddle.clone(Tensor([33289, 12, 84, 128],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 59846 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:35:39.998055 151696 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:35:39.999132 151696 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([33289, 3, 168, 256],"float32"), )
[torch error] paddle.clone(Tensor([33289, 3, 168, 256],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 94055 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:36:46.875047 151725 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:36:46.879171 151725 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([33554433, 64],"float64"), )
[torch error] paddle.clone(Tensor([33554433, 64],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 123299 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:37:31.075901 151740 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:37:31.077008 151740 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([3355444, 1280, 1, 1],"float32"), )
[torch error] paddle.clone(Tensor([3355444, 1280, 1, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 132829 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:38:43.509198 151754 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:38:43.510162 151754 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([342393, 256, 7, 7],"float32"), )
[torch error] paddle.clone(Tensor([342393, 256, 7, 7],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 160270 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:39:56.989678 151795 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:39:56.990800 151795 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([342393, 64, 14, 14],"float32"), )
[torch error] paddle.clone(Tensor([342393, 64, 14, 14],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 16405 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:41:13.270856 151825 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:41:13.293375 151825 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([34240, 196, 640],"float32"), )
[torch error] paddle.clone(Tensor([34240, 196, 640],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 37850 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:42:22.299919 151853 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:42:22.300906 151853 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([343598, 5, 50, 50],"float32"), )
[torch error] paddle.clone(Tensor([343598, 5, 50, 50],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 54725 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:43:30.998759 151894 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:43:30.999922 151894 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([3576, 3, 544, 736],"float32"), )
[torch error] paddle.clone(Tensor([3576, 3, 544, 736],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 74045 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:44:43.300927 151936 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:44:43.301919 151936 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([391, 256, 168, 256],"float32"), )
[torch error] paddle.clone(Tensor([391, 256, 168, 256],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.04 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 100424 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:45:52.391351 151965 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:45:52.392460 151965 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([4, 116509, 96, 96],"float32"), )
[torch error] paddle.clone(Tensor([4, 116509, 96, 96],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 122681 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:47:07.333122 152021 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:47:07.334157 152021 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([4, 3, 384, 932068],"float32"), )
[torch error] paddle.clone(Tensor([4, 3, 384, 932068],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 143753 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:48:16.274546 152063 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:48:16.275604 152063 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([4, 3, 932068, 384],"float32"), )
[torch error] paddle.clone(Tensor([4, 3, 932068, 384],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 163392 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:49:28.872023 152118 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:49:28.873029 152118 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([4, 48, 233017, 96],"float32"), )
[torch error] paddle.clone(Tensor([4, 48, 233017, 96],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 19474 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:50:38.167837 152146 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:50:38.168823 152146 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([4, 48, 96, 233017],"float32"), )
[torch error] paddle.clone(Tensor([4, 48, 96, 233017],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 45696 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:51:48.019354 152201 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:51:48.020370 152201 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([4, 7282, 384, 384],"float32"), )
[torch error] paddle.clone(Tensor([4, 7282, 384, 384],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 68495 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:53:01.745555 152258 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:53:01.746559 152258 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([4194304, 1024, 1, 1],"float32"), )
[torch error] paddle.clone(Tensor([4194304, 1024, 1, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 87745 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:54:10.523285 152300 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:54:10.524252 152300 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([422567, 2541, 4],"float32"), )
[torch error] paddle.clone(Tensor([422567, 2541, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 104988 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:55:17.035394 152369 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:55:17.066854 152369 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([42800, 128, 28, 28],"float32"), )
[torch error] paddle.clone(Tensor([42800, 128, 28, 28],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 124775 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:56:24.706423 152398 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:56:24.707470 152398 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([42800, 2048, 7, 7],"float32"), )
[torch error] paddle.clone(Tensor([42800, 2048, 7, 7],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 148147 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:57:36.373195 152426 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:57:36.374167 152426 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([42800, 32, 56, 56],"float32"), )
[torch error] paddle.clone(Tensor([42800, 32, 56, 56],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 10784 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:58:48.424486 152455 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:58:48.425596 152455 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([42800, 8, 196, 64],"float32"), )
[torch error] paddle.clone(Tensor([42800, 8, 196, 64],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 31513 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:00:06.757503 152496 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:00:06.758600 152496 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([4294967295],"float32"), )
[torch error] paddle.clone(Tensor([4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 50893 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:01:13.797343 152538 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:01:13.798408 152538 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([4294967295],"int32"), )
[torch error] paddle.clone(Tensor([4294967295],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 69767 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:02:20.755880 152567 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:02:20.757025 152567 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([4294968, 500],"int64"), )
[torch error] paddle.clone(Tensor([4294968, 500],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 87144 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:03:02.889799 152608 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:03:02.890821 152608 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([429497, 10000, 1],"float32"), )
[torch error] paddle.clone(Tensor([429497, 10000, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 101469 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:04:10.250640 152623 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:04:10.251645 152623 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([429497, 2500, 4],"float32"), )
[torch error] paddle.clone(Tensor([429497, 2500, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 119966 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:05:24.347766 152665 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:05:24.348809 152665 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([43, 256, 56, 6968],"float32"), )
[torch error] paddle.clone(Tensor([43, 256, 56, 6968],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 138883 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:06:31.106436 152707 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:06:31.107440 152707 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([43, 256, 6968, 56],"float32"), )
[torch error] paddle.clone(Tensor([43, 256, 6968, 56],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 162509 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:07:39.556803 152749 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:07:39.557839 152749 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([43, 31851, 56, 56],"float32"), )
[torch error] paddle.clone(Tensor([43, 31851, 56, 56],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 29382 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:08:51.263957 152791 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:08:51.264992 152791 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([43, 32, 112, 27870],"float32"), )
[torch error] paddle.clone(Tensor([43, 32, 112, 27870],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 50393 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:10:05.394250 152832 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:10:05.395268 152832 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([43, 32, 27870, 112],"float32"), )
[torch error] paddle.clone(Tensor([43, 32, 27870, 112],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 69151 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:11:20.403856 152874 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:11:20.404960 152874 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([43, 7963, 112, 112],"float32"), )
[torch error] paddle.clone(Tensor([43, 7963, 112, 112],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 89802 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:12:28.760026 152902 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:12:28.761442 152902 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([4312, 996050],"float32"), )
[torch error] paddle.clone(Tensor([4312, 996050],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 108384 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:13:35.723821 152957 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:13:35.724810 152957 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([43691, 1536, 8, 8],"float32"), )
[torch error] paddle.clone(Tensor([43691, 1536, 8, 8],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 128631 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:14:47.494271 152986 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:14:47.495407 152986 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([43826197, 49],"int64"), )
[torch error] paddle.clone(Tensor([43826197, 49],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 152296 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:15:30.406965 153029 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:15:30.408108 153029 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([44385, 144, 21, 32],"float32"), )
[torch error] paddle.clone(Tensor([44385, 144, 21, 32],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 159007 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:16:43.890821 153084 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:16:43.891925 153084 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([44904, 122, 28, 28],"float32"), )
[torch error] paddle.clone(Tensor([44904, 122, 28, 28],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 30060 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:17:57.770124 153125 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:17:57.771334 153125 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([4855, 256, 48, 72],"float32"), )
[torch error] paddle.clone(Tensor([4855, 256, 48, 72],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 48436 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:19:06.837829 153155 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:19:06.838877 153155 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([4855, 9216, 96],"float32"), )
[torch error] paddle.clone(Tensor([4855, 9216, 96],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 68595 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:20:19.290925 153197 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:20:19.299980 153197 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([48914, 28, 56, 56],"float32"), )
[torch error] paddle.clone(Tensor([48914, 28, 56, 56],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 88539 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:21:27.123221 153251 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:21:27.124203 153251 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([49, 43826197],"int64"), )
[torch error] paddle.clone(Tensor([49, 43826197],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 106235 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:22:11.367049 153280 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:22:11.368173 153280 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([49933, 21504, 4],"float32"), )
[torch error] paddle.clone(Tensor([49933, 21504, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 121466 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:23:24.825763 153322 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:23:24.826771 153322 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([512, 171197, 7, 7],"float32"), )
[torch error] paddle.clone(Tensor([512, 171197, 7, 7],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 145628 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:24:37.446825 153377 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:24:37.447919 153377 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([512, 256, 4682, 7],"float32"), )
[torch error] paddle.clone(Tensor([512, 256, 4682, 7],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 5554 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:25:44.919224 153420 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:25:44.920382 153420 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([512, 256, 7, 4682],"float32"), )
[torch error] paddle.clone(Tensor([512, 256, 7, 4682],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 30638 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:26:55.028443 153448 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:26:55.029457 153448 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([512, 8388608],"float32"), )
[torch error] paddle.clone(Tensor([512, 8388608],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 52015 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:28:06.480492 153490 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:28:06.481490 153490 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([528, 8134408],"float32"), )
[torch error] paddle.clone(Tensor([528, 8134408],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 68823 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:29:18.067674 153519 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:29:18.068780 153519 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([532611, 12, 21, 32],"float32"), )
[torch error] paddle.clone(Tensor([532611, 12, 21, 32],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 91078 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:30:27.864717 153560 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:30:27.865686 153560 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([532611, 3, 42, 64],"float32"), )
[torch error] paddle.clone(Tensor([532611, 3, 42, 64],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 109724 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:31:33.653765 153602 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:31:33.654876 153602 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([5350, 256, 56, 56],"float32"), )
[torch error] paddle.clone(Tensor([5350, 256, 56, 56],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 129818 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:33:04.959544 153631 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:33:04.960559 153631 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([5350, 64, 112, 112],"float32"), )
[torch error] paddle.clone(Tensor([5350, 64, 112, 112],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 157052 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:34:16.324882 153673 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:34:16.325945 153673 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([536870912, 8],"float32"), )
[torch error] paddle.clone(Tensor([536870912, 8],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 12993 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:35:29.111843 153715 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:35:29.112856 153715 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([536871, 100, 80],"float32"), )
[torch error] paddle.clone(Tensor([536871, 100, 80],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 31565 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:36:43.798033 153756 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:36:43.799048 153756 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([5369, 10000, 80],"float32"), )
[torch error] paddle.clone(Tensor([5369, 10000, 80],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 64760 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:38:03.994977 153784 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:38:03.996033 153784 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([5462, 192, 64, 64],"float32"), )
[torch error] paddle.clone(Tensor([5462, 192, 64, 64],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 85173 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:39:11.049903 153826 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:39:11.050913 153826 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([5478275, 28, 28],"int32"), )
[torch error] paddle.clone(Tensor([5478275, 28, 28],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 108471 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:40:32.125734 153854 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:40:32.126819 153854 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([5549, 18, 168, 256],"float32"), )
[torch error] paddle.clone(Tensor([5549, 18, 168, 256],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 129888 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:41:38.246814 153882 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:41:38.247987 153882 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([5592406, 12, 1, 64],"float32"), )
[torch error] paddle.clone(Tensor([5592406, 12, 1, 64],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 155689 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:42:55.399253 153923 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:42:55.400341 153923 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([57066, 24, 56, 56],"float32"), )
[torch error] paddle.clone(Tensor([57066, 24, 56, 56],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 12899 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:44:03.753206 153953 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:44:03.754271 153953 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([6, 7456541, 96],"float32"), )
[torch error] paddle.clone(Tensor([6, 7456541, 96],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 31622 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:45:10.932435 154007 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:45:10.933532 154007 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([6, 9216, 77673],"float32"), )
[torch error] paddle.clone(Tensor([6, 9216, 77673],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 48601 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:46:20.532370 154050 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:46:20.533445 154050 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([607, 512, 96, 144],"float32"), )
[torch error] paddle.clone(Tensor([607, 512, 96, 144],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.01 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 73725 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:47:27.093214 154091 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:47:27.094305 154091 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([60870, 360, 14, 14],"float32"), )
[torch error] paddle.clone(Tensor([60870, 360, 14, 14],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 92436 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:48:33.525130 154120 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:48:33.526237 154120 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([6242, 256, 42, 64],"float32"), )
[torch error] paddle.clone(Tensor([6242, 256, 42, 64],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 113040 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:49:46.793710 154148 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:49:46.794679 154148 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([6247, 171888, 4],"float32"), )
[torch error] paddle.clone(Tensor([6247, 171888, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 139961 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:50:56.107101 154189 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:50:56.108160 154189 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([67108864, 64],"float32"), )
[torch error] paddle.clone(Tensor([67108864, 64],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 157442 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:52:11.161074 154205 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:52:11.162179 154205 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([6710887, 640],"float32"), )
[torch error] paddle.clone(Tensor([6710887, 640],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 13091 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:53:23.614341 154233 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:53:23.615440 154233 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([684785, 32, 14, 14],"float32"), )
[torch error] paddle.clone(Tensor([684785, 32, 14, 14],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 32070 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:54:40.405660 154261 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:54:40.406718 154261 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([684785, 49, 128],"float32"), )
[torch error] paddle.clone(Tensor([684785, 49, 128],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 58921 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:55:53.770104 154289 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:55:53.771108 154289 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([68479, 1280, 7, 7],"float32"), )
[torch error] paddle.clone(Tensor([68479, 1280, 7, 7],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 87015 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:57:10.817028 154317 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:57:10.818043 154317 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([6871948, 625, 1],"float32"), )
[torch error] paddle.clone(Tensor([6871948, 625, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 108322 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:58:19.248214 154344 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:58:19.249203 154344 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([699051, 16, 384],"float32"), )
[torch error] paddle.clone(Tensor([699051, 16, 384],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 128502 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:59:27.404297 154372 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:59:27.405297 154372 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([69906, 15, 64, 64],"float32"), )
[torch error] paddle.clone(Tensor([69906, 15, 64, 64],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 146956 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:00:52.168342 154387 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:00:52.169309 154387 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([76088, 288, 14, 14],"float32"), )
[torch error] paddle.clone(Tensor([76088, 288, 14, 14],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 12392 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:02:08.336436 154415 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:02:08.337442 154415 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([77673, 288, 192],"float32"), )
[torch error] paddle.clone(Tensor([77673, 288, 192],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 30570 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:03:31.320078 154443 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:03:31.321162 154443 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([8064, 532611],"float32"), )
[torch error] paddle.clone(Tensor([8064, 532611],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 50782 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:04:45.445729 154471 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:04:45.446831 154471 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([812, 128, 152, 272],"float32"), )
[torch error] paddle.clone(Tensor([812, 128, 152, 272],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.01 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 77880 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:06:06.958357 154498 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:06:06.959388 154498 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([8134408, 3, 11, 16],"float32"), )
[torch error] paddle.clone(Tensor([8134408, 3, 11, 16],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 102006 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:07:31.446348 154541 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:07:31.447340 154541 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([8323, 12, 168, 256],"float32"), )
[torch error] paddle.clone(Tensor([8323, 12, 168, 256],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 125619 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:08:53.051360 154582 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:08:53.055986 154582 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([8388608, 512, 1, 1],"float32"), )
[torch error] paddle.clone(Tensor([8388608, 512, 1, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 156172 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:10:13.950906 154624 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:10:13.951975 154624 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([85599, 256, 14, 14],"float32"), )
[torch error] paddle.clone(Tensor([85599, 256, 14, 14],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 12226 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:11:55.825565 154652 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:11:55.826705 154652 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([858993459, 5],"float32"), )
[torch error] paddle.clone(Tensor([858993459, 5],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 49645 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:13:06.782024 154694 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:13:06.783008 154694 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([8589935, 500],"int32"), )
[torch error] paddle.clone(Tensor([8589935, 500],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 66266 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:14:20.946753 154722 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:14:20.947845 154722 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([85900, 625, 80],"float32"), )
[torch error] paddle.clone(Tensor([85900, 625, 80],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 84880 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:15:33.180948 154763 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:15:33.181942 154763 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([86, 1019214, 7, 7],"float32"), )
[torch error] paddle.clone(Tensor([86, 1019214, 7, 7],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 106545 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:16:39.780441 154805 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:16:39.781472 154805 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([86, 198, 252230],"float32"), )
[torch error] paddle.clone(Tensor([86, 198, 252230],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 133985 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:17:50.333673 154835 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:17:50.334658 154835 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([86, 260112, 192],"float32"), )
[torch error] paddle.clone(Tensor([86, 260112, 192],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 153978 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:19:02.649276 154876 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:19:02.650267 154876 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([86, 3, 224, 74318],"float32"), )
[torch error] paddle.clone(Tensor([86, 3, 224, 74318],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 11921 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:20:15.067248 154918 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:20:15.068331 154918 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([86, 3, 74318, 224],"float32"), )
[torch error] paddle.clone(Tensor([86, 3, 74318, 224],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 31093 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:21:27.622823 154947 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:21:27.623886 154947 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([86, 49941481],"float32"), )
[torch error] paddle.clone(Tensor([86, 49941481],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 49755 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:22:39.748464 154988 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:22:39.749465 154988 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([86, 704, 10135, 7],"float32"), )
[torch error] paddle.clone(Tensor([86, 704, 10135, 7],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 72032 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:23:51.515921 155017 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:23:51.516971 155017 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([86, 704, 7, 10135],"float32"), )
[torch error] paddle.clone(Tensor([86, 704, 7, 10135],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 95095 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:25:03.191833 155057 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:25:03.192795 155057 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([86, 996, 224, 224],"float32"), )
[torch error] paddle.clone(Tensor([86, 996, 224, 224],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.01 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 113045 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:26:08.918810 155087 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:26:08.919924 155087 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([89808, 976, 7, 7],"float32"), )
[torch error] paddle.clone(Tensor([89808, 976, 7, 7],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 135729 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:27:21.615000 155115 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:27:21.616003 155115 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([9511, 144, 56, 56],"float32"), )
[torch error] paddle.clone(Tensor([9511, 144, 56, 56],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 161239 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:28:29.486085 155129 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:28:29.487116 155129 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([9710, 2304, 192],"float32"), )
[torch error] paddle.clone(Tensor([9710, 2304, 192],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 18006 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:29:43.937805 155170 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:29:43.938819 155170 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([9710, 3, 384, 384],"float32"), )
[torch error] paddle.clone(Tensor([9710, 3, 384, 384],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 45296 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:30:50.454102 155212 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:30:50.455230 155212 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([9710, 48, 96, 96],"float32"), )
[torch error] paddle.clone(Tensor([9710, 48, 96, 96],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 62041 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:32:13.924003 155254 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:32:13.925076 155254 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.clone(Tensor([99865, 21504, 2],"float32"), )
[torch error] paddle.clone(Tensor([99865, 21504, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 83388 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:33:26.650286 155296 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:33:26.651378 155296 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 102072 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:34:13.565205 155325 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:34:13.566263 155325 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 118002 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:35:02.035301 155366 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:35:02.036495 155366 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 132239 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:35:51.341871 155390 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:35:51.342981 155390 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 153270 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:36:40.339183 155408 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:36:40.340309 155408 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 16242 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:37:29.729923 155436 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:37:29.731065 155436 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 29032 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:38:17.189666 155451 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:38:17.190735 155451 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 53053 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:39:05.662748 155491 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:39:05.663863 155491 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 72180 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:39:54.541728 155533 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:39:54.542969 155533 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 1, 1, 2147483649],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 1, 1, 2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 91746 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:40:40.672520 155547 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:40:40.673528 155547 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 107814 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:41:29.532496 155576 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:41:29.533564 155576 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 123341 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:42:16.331475 155590 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:42:16.332559 155590 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 2147483649],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 142453 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:43:03.236960 155618 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:43:03.238063 155618 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 1464 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:43:47.940933 155645 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:43:47.942001 155645 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 19059 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:44:34.047168 155674 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:44:34.048158 155674 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 29561 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:45:19.247987 155689 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:45:19.248992 155689 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 1, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 47751 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:46:04.862061 155716 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:46:04.863059 155716 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 69425 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:46:49.179564 155731 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:46:49.180531 155731 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 1, 2147483649, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 1, 2147483649, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 90125 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:47:37.167487 155759 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:47:37.168474 155759 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 101728 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:48:22.641371 155773 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:48:22.642387 155773 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 120762 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:49:09.676887 155814 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:49:09.677942 155814 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 1, 2147483649],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 1, 2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 137861 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:49:54.513110 155856 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:49:54.514150 155856 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 154990 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:50:48.991206 155871 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:50:49.002684 155871 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 2147483649],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 12243 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:51:38.427604 155913 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:51:38.428637 155913 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),Tensor([1, 2147483649],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),Tensor([1, 2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 25484 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:52:26.537425 155941 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:52:26.538395 155941 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),Tensor([2147483649, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),Tensor([2147483649, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 40170 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:53:11.239105 155974 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:53:11.240084 155974 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 1],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 1],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 57191 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:53:55.759055 155997 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:53:55.760026 155997 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 1],"float64"),Tensor([2147483649, 1],"float64"),Tensor([1, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 1],"float64"),Tensor([2147483649, 1],"float64"),Tensor([1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 72367 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:54:40.779218 156038 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:54:40.780171 156038 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 2147483649, 1, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 2147483649, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 85385 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:55:26.048156 156065 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:55:26.049139 156065 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 94397 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:56:12.113986 156094 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:56:12.114991 156094 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 112610 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:56:56.354127 156123 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:56:56.355150 156123 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 2147483649, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 2147483649, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 130281 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:57:42.948365 156137 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:57:42.949338 156137 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 144837 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:58:33.286195 156177 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:58:33.287146 156177 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 154888 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:59:19.908571 156219 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:59:19.909567 156219 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 2147483649],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 10522 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:00:06.174707 156233 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:00:06.175688 156233 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 2147483649],"float64"),Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 2147483649],"float64"),Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 24963 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:00:52.864598 156262 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:00:52.865559 156262 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 40346 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:01:40.866236 156290 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:01:40.867228 156290 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1],"float64"),Tensor([1],"float64"),Tensor([2147483649],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1],"float64"),Tensor([1],"float64"),Tensor([2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 51381 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:02:24.620820 156304 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:02:24.621829 156304 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1],"float64"),Tensor([2147483649],"float64"),Tensor([1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1],"float64"),Tensor([2147483649],"float64"),Tensor([1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 61288 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:03:08.661396 156332 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:03:08.662377 156332 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1073741825, 2],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1073741825, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 75112 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:03:55.385851 156347 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:03:55.387053 156347 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1073741825, 2],"float64"),Tensor([1073741825, 2],"float64"),Tensor([1073741825, 2],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1073741825, 2],"float64"),Tensor([1073741825, 2],"float64"),Tensor([1073741825, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 91020 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:04:41.231338 156374 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:04:41.232653 156374 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([1073741825, 2],"float64"),Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([1073741825, 2],"float64"),Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 102183 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:05:34.065240 156402 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:05:34.066277 156402 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([2],"float64"),Tensor([2, 1073741825],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([2],"float64"),Tensor([2, 1073741825],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 118310 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:06:21.341310 156444 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:06:21.342314 156444 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([2],"float64"),Tensor([2147483649, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([2],"float64"),Tensor([2147483649, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 135828 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:07:06.654722 156468 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:07:06.657120 156468 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([2147483649, 1, 1, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([2147483649, 1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 149781 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:07:56.083498 156487 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:07:56.084501 156487 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([2147483649, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([2147483649, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 2248 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:08:45.653005 156528 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:08:45.654011 156528 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([2147483649, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([2147483649, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 19599 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:09:30.943303 156543 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:09:30.944309 156543 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([2147483649, 1, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([2147483649, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 25779 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:10:19.783295 156585 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:10:19.784286 156585 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([2147483649, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([2147483649, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 41266 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:11:04.092768 156627 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:11:04.093766 156627 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 56891 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:11:49.517511 156641 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:11:49.518505 156641 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([2147483649, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([2147483649, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 71301 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:12:38.179775 156683 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:12:38.180805 156683 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([2147483649, 1],"float64"),Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([2147483649, 1],"float64"),Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 79215 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:13:23.524174 156710 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:13:23.525162 156710 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([2147483649, 1],"float64"),Tensor([2147483649, 1],"float64"),Tensor([2147483649, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([2147483649, 1],"float64"),Tensor([2147483649, 1],"float64"),Tensor([2147483649, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 93640 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:14:10.150365 156739 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:14:10.151391 156739 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([2147483649],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 108581 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:14:55.260294 156779 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:14:55.261284 156779 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([2147483649],"float64"),Tensor([1],"float64"),Tensor([1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([2147483649],"float64"),Tensor([1],"float64"),Tensor([1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 128147 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:15:40.717710 156806 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:15:40.718731 156806 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([2147483649],"float64"),Tensor([2, 1],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([2147483649],"float64"),Tensor([2, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 142497 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:16:25.289176 156835 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:16:25.290243 156835 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 155407 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:17:09.528673 156851 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:17:09.529791 156851 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([2147483649],"float64"),Tensor([5],"float64"),Tensor([5],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([2147483649],"float64"),Tensor([5],"float64"),Tensor([5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 6761 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:17:56.221045 156878 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:17:56.222046 156878 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([268435457, 4, 2],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([268435457, 4, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 22427 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:18:49.467883 156912 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:18:49.469106 156912 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([268435457, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([268435457, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 40383 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:19:35.099294 156948 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:19:35.100427 156948 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([268435457, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([268435457, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 46823 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:20:22.185303 156990 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:20:22.186327 156990 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 2],"float64"),Tensor([1073741825, 2],"float64"),Tensor([3, 2],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 2],"float64"),Tensor([1073741825, 2],"float64"),Tensor([3, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 61729 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:21:10.820077 157004 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:21:10.821260 157004 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),Tensor([1073741825, 2],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),Tensor([1073741825, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 76726 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:21:55.644693 157046 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:21:55.645670 157046 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),Tensor([3, 715827883],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),Tensor([3, 715827883],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 91898 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:22:44.370970 157061 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:22:44.371961 157061 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 2],"float64"),Tensor([3, 715827883],"float64"),Tensor([3, 2],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 2],"float64"),Tensor([3, 715827883],"float64"),Tensor([3, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 106927 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:23:29.277758 157102 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:23:29.280004 157102 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 357913942, 2],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 357913942, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 113467 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:24:14.510493 157130 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:24:14.511497 157130 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 129376 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:24:58.168706 157158 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:24:58.169703 157158 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 143227 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:25:47.665845 157186 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:25:47.667088 157186 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 4, 178956971],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 4, 178956971],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 162185 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:26:37.006204 157214 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:26:37.007366 157214 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 8531 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:27:21.662786 157256 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:27:21.663868 157256 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 22919 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:28:06.552249 157270 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:28:06.553367 157270 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 37386 has 1016.00 MiB memory in use. Of the allocated memory 2.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:28:53.317476 157313 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:28:53.318457 157313 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 54899 has 1016.00 MiB memory in use. Of the allocated memory 2.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:29:44.286998 157341 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:29:44.288041 157341 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 69935 has 1016.00 MiB memory in use. Of the allocated memory 2.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:30:33.579329 157369 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:30:33.580344 157369 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 81774 has 1016.00 MiB memory in use. Of the allocated memory 2.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:31:19.708549 157409 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:31:19.709514 157409 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 97871 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:32:08.424525 157438 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:32:08.425529 157438 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 112537 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:32:53.695183 157466 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:32:53.696197 157466 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 128085 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:33:38.114333 157481 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:33:38.115315 157481 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 135344 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:34:27.402899 157508 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:34:27.405536 157508 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 4, 2, 89478486],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 4, 2, 89478486],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 149203 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:35:14.504348 157536 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:35:14.505360 157536 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 1126 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:36:02.693984 157564 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:36:02.694976 157564 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 19668 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:36:49.192028 157592 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:36:49.193048 157592 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 36427 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:37:38.523841 157606 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:37:38.524860 157606 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 45890 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:38:23.409101 157647 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:38:23.410094 157647 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 60363 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:39:17.752650 157663 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:39:17.753970 157663 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 76969 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:40:03.754634 157704 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:40:03.755618 157704 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 92238 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:40:54.623253 157733 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:40:54.624255 157733 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 108167 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:41:42.535377 157747 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:41:42.536489 157747 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 4, 35791395, 5],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 4, 35791395, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 123658 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:42:39.212226 157775 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:42:39.213421 157775 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 133720 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:43:25.597235 157802 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:43:25.598348 157802 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 147200 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:44:10.929234 157845 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:44:10.930245 157845 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 715827883],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 715827883],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 160968 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:44:59.572212 157872 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:44:59.573210 157872 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 715827883],"float64"),Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 715827883],"float64"),Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 13788 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:45:47.270220 157900 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:45:47.271224 157900 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 715827883],"float64"),Tensor([3, 715827883],"float64"),Tensor([3, 715827883],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 715827883],"float64"),Tensor([3, 715827883],"float64"),Tensor([3, 715827883],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 32315 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:46:32.927454 157928 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:46:32.928463 157928 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 71582789, 2, 5],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 71582789, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 45906 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:47:18.543071 157956 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:47:18.544128 157956 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 61120 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:48:15.760071 157984 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:48:15.761078 157984 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 79342 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:49:01.670075 158013 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:49:01.671224 158013 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([5],"float64"),Tensor([2147483649],"float64"),Tensor([5],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([5],"float64"),Tensor([2147483649],"float64"),Tensor([5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 94589 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:49:50.258425 158027 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:49:50.261188 158027 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([5],"float64"),Tensor([5],"float64"),Tensor([2147483649],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([5],"float64"),Tensor([5],"float64"),Tensor([2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 109652 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:50:39.945367 158069 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:50:39.946386 158069 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([53687092, 4, 2, 5],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([53687092, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 120085 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:51:27.476980 158097 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:51:27.478067 158097 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 132863 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:52:17.345458 158125 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:52:17.346489 158125 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.column_stack(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], )
[torch error] paddle.column_stack(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 147535 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:53:04.947549 158153 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:53:04.948729 158153 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.combinations(Tensor([2147483649],"float64"), 5, False, )
[torch error] paddle.combinations(Tensor([2147483649],"float64"), 5, False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 162079 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:53:51.609393 158181 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:53:51.610661 158181 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.combinations(Tensor([2147483649],"int64"), 0, True, )
[torch error] paddle.combinations(Tensor([2147483649],"int64"), 0, True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 13583 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:54:35.213330 158223 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:54:35.215080 158223 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.combinations(Tensor([4294967295],"float32"), r=2, )
[torch error] paddle.combinations(Tensor([4294967295],"float32"), r=2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 19927 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:55:48.378118 158250 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:55:48.379148 158250 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.combinations(Tensor([4294967295],"float32"), r=2, with_replacement=True, )
[torch error] paddle.combinations(Tensor([4294967295],"float32"), r=2, with_replacement=True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 51267 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:56:55.805470 158291 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:56:55.806633 158291 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.combinations(Tensor([4294967295],"float32"), r=4, )
[torch error] paddle.combinations(Tensor([4294967295],"float32"), r=4, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 71105 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:58:04.261835 158333 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:58:04.263131 158333 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.combinations(Tensor([4294967295],"int32"), 1, True, )
[torch error] paddle.combinations(Tensor([4294967295],"int32"), 1, True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 90075 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:59:18.684087 158376 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:59:18.695851 158376 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([10, 10],"float64"), Tensor([10, 214748365],"float64"), )
[torch error] paddle.complex(Tensor([10, 10],"float64"), Tensor([10, 214748365],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 112147 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:00:02.644898 158417 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:00:02.646003 158417 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([10, 10],"float64"), Tensor([214748365, 10],"float64"), )
[torch error] paddle.complex(Tensor([10, 10],"float64"), Tensor([214748365, 10],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 128109 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:00:52.040302 158432 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:00:52.041438 158432 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([10, 214748365],"float64"), Tensor([10, 10],"float64"), )
[torch error] paddle.complex(Tensor([10, 214748365],"float64"), Tensor([10, 10],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 143646 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:01:39.081197 158473 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:01:39.082238 158473 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([10, 214748365],"float64"), Tensor([10, 214748365],"float64"), )
[torch error] paddle.complex(Tensor([10, 214748365],"float64"), Tensor([10, 214748365],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 149903 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:02:24.606205 158489 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:02:24.608208 158489 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([1431655765, 3],"float32"), Tensor([1431655765, 3],"float32"), )
[torch error] paddle.complex(Tensor([1431655765, 3],"float32"), Tensor([1431655765, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 5192 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:03:32.432530 158529 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:03:32.433589 158529 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([1431655765, 3],"float32"), Tensor([2, 3],"float32"), )
[torch error] paddle.complex(Tensor([1431655765, 3],"float32"), Tensor([2, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 24989 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:04:38.630074 158558 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:04:38.631246 158558 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([2, 1073741825],"float64"), Tensor([2, 1073741825],"float64"), )
[torch error] paddle.complex(Tensor([2, 1073741825],"float64"), Tensor([2, 1073741825],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 42117 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:05:24.461728 158586 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:05:24.462881 158586 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([2, 1073741825],"float64"), Tensor([2, 3],"float64"), )
[torch error] paddle.complex(Tensor([2, 1073741825],"float64"), Tensor([2, 3],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 57780 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:06:11.145002 158614 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:06:11.146071 158614 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([2, 2147483648],"float32"), Tensor([2, 2147483648],"float32"), )
[torch error] paddle.complex(Tensor([2, 2147483648],"float32"), Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 75874 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:07:21.783365 158642 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:07:21.784536 158642 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([2, 2147483648],"float32"), Tensor([2, 3],"float32"), )
[torch error] paddle.complex(Tensor([2, 2147483648],"float32"), Tensor([2, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 98027 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:08:30.841610 158684 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:08:30.842614 158684 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([2, 3, 4],"float32"), Tensor([2, 3, 715827883],"float32"), )
[torch error] paddle.complex(Tensor([2, 3, 4],"float32"), Tensor([2, 3, 715827883],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 118707 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:09:44.593845 158713 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:09:44.595021 158713 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([2, 3, 4],"float32"), Tensor([2, 536870912, 4],"float32"), )
[torch error] paddle.complex(Tensor([2, 3, 4],"float32"), Tensor([2, 536870912, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 146815 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:10:58.174291 158755 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:10:58.175379 158755 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([2, 3, 4],"float32"), Tensor([357913942, 3, 4],"float32"), )
[torch error] paddle.complex(Tensor([2, 3, 4],"float32"), Tensor([357913942, 3, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 4820 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:12:05.716248 158796 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:12:05.717242 158796 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([2, 3, 715827883],"float32"), Tensor([2, 3, 4],"float32"), )
[torch error] paddle.complex(Tensor([2, 3, 715827883],"float32"), Tensor([2, 3, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 25010 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:13:18.395881 158837 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:13:18.396998 158837 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([2, 3, 715827883],"float32"), Tensor([2, 3, 715827883],"float32"), )
[torch error] paddle.complex(Tensor([2, 3, 715827883],"float32"), Tensor([2, 3, 715827883],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 45111 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:14:24.924209 158853 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:14:24.925338 158853 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([2, 3],"float32"), Tensor([1431655765, 3],"float32"), )
[torch error] paddle.complex(Tensor([2, 3],"float32"), Tensor([1431655765, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 63909 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:15:31.163128 158894 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:15:31.164258 158894 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([2, 3],"float32"), Tensor([2, 2147483648],"float32"), )
[torch error] paddle.complex(Tensor([2, 3],"float32"), Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 84570 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:16:43.505084 158922 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:16:43.506220 158922 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([2, 3],"float64"), Tensor([2, 1073741825],"float64"), )
[torch error] paddle.complex(Tensor([2, 3],"float64"), Tensor([2, 1073741825],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 116660 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:17:29.212970 158977 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:17:29.214069 158977 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([2, 3],"float64"), Tensor([715827883, 3],"float64"), )
[torch error] paddle.complex(Tensor([2, 3],"float64"), Tensor([715827883, 3],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 127818 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:18:14.639640 159019 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:18:14.640697 159019 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([2, 536870912, 4],"float32"), Tensor([2, 3, 4],"float32"), )
[torch error] paddle.complex(Tensor([2, 536870912, 4],"float32"), Tensor([2, 3, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 145938 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:19:22.531980 159046 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:19:22.533115 159046 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([2, 536870912, 4],"float32"), Tensor([2, 536870912, 4],"float32"), )
[torch error] paddle.complex(Tensor([2, 536870912, 4],"float32"), Tensor([2, 536870912, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 6597 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:20:34.394827 159090 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:20:34.395991 159090 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([2],"float32"), Tensor([4294967295],"float32"), )
[torch error] paddle.complex(Tensor([2],"float32"), Tensor([4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 26642 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:21:41.534332 159132 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:21:41.535323 159132 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([2],"float64"), Tensor([2147483649],"float64"), )
[torch error] paddle.complex(Tensor([2],"float64"), Tensor([2147483649],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 48060 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:22:26.791607 159187 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:22:26.792704 159187 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([2147483649],"float64"), Tensor([2],"float64"), )
[torch error] paddle.complex(Tensor([2147483649],"float64"), Tensor([2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 60244 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:23:13.219388 159201 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:23:13.222659 159201 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([2147483649],"float64"), Tensor([2147483649],"float64"), )
[torch error] paddle.complex(Tensor([2147483649],"float64"), Tensor([2147483649],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 76596 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:24:00.046269 159231 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:24:00.047324 159231 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([2147483649],"float64"), Tensor([5],"float64"), )
[torch error] paddle.complex(Tensor([2147483649],"float64"), Tensor([5],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 92320 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:24:45.682243 159258 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:24:45.683239 159258 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([214748365, 10],"float64"), Tensor([10, 10],"float64"), )
[torch error] paddle.complex(Tensor([214748365, 10],"float64"), Tensor([10, 10],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 104845 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:25:32.786836 159286 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:25:32.789551 159286 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([214748365, 10],"float64"), Tensor([214748365, 10],"float64"), )
[torch error] paddle.complex(Tensor([214748365, 10],"float64"), Tensor([214748365, 10],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 120622 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:26:21.853564 159327 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:26:21.854684 159327 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([357913942, 3, 4],"float32"), Tensor([2, 3, 4],"float32"), )
[torch error] paddle.complex(Tensor([357913942, 3, 4],"float32"), Tensor([2, 3, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 140035 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:27:29.062986 159342 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:27:29.064079 159342 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([357913942, 3, 4],"float32"), Tensor([357913942, 3, 4],"float32"), )
[torch error] paddle.complex(Tensor([357913942, 3, 4],"float32"), Tensor([357913942, 3, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 158562 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:28:36.573397 159383 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:28:36.574417 159383 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([4],"float32"), Tensor([4294967295],"float32"), )
[torch error] paddle.complex(Tensor([4],"float32"), Tensor([4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 17493 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:29:50.219650 159425 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:29:50.220758 159425 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([4294967295],"float32"), Tensor([2],"float32"), )
[torch error] paddle.complex(Tensor([4294967295],"float32"), Tensor([2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 46007 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:31:06.277495 159441 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:31:06.278642 159441 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([4294967295],"float32"), Tensor([4],"float32"), )
[torch error] paddle.complex(Tensor([4294967295],"float32"), Tensor([4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 64041 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:32:15.454510 159483 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:32:15.455657 159483 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([4294967295],"float32"), Tensor([4294967295],"float32"), )
[torch error] paddle.complex(Tensor([4294967295],"float32"), Tensor([4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 84161 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:33:28.223450 159523 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:33:28.224493 159523 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([5],"float64"), Tensor([2147483649],"float64"), )
[torch error] paddle.complex(Tensor([5],"float64"), Tensor([2147483649],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 102299 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:34:16.965713 159566 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:34:16.966837 159566 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([715827883, 3],"float64"), Tensor([2, 3],"float64"), )
[torch error] paddle.complex(Tensor([715827883, 3],"float64"), Tensor([2, 3],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 120181 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:35:06.544605 159595 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:35:06.545688 159595 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.complex(Tensor([715827883, 3],"float64"), Tensor([715827883, 3],"float64"), )
[torch error] paddle.complex(Tensor([715827883, 3],"float64"), Tensor([715827883, 3],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 138824 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:35:51.712464 159609 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:35:51.713563 159609 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 154999 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:36:39.427362 159650 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:36:39.428397 159650 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 9720 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:37:27.384851 159679 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:37:27.385865 159679 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28492 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:38:11.685395 159706 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:38:11.686498 159706 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 44103 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:38:56.185307 159734 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:38:56.186321 159734 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 59784 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:39:41.027829 159749 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:39:41.028825 159749 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 66277 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:40:29.354466 159790 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:40:29.355574 159790 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 82128 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:41:22.850462 159818 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:41:22.851557 159818 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 100254 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:42:07.935009 159874 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:42:07.936029 159874 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 113909 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:42:53.102144 159903 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:42:53.103134 159903 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 130332 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:43:42.254403 159944 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:43:42.257249 159944 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 139116 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:44:27.549263 159972 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:44:27.550385 159972 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 151506 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:45:13.342813 160027 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:45:13.343779 160027 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 3592 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:45:58.645702 160042 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:45:58.648264 160042 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 22789 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:46:46.733589 160097 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:46:46.734755 160097 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 37459 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:47:35.138828 160112 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:47:35.139842 160112 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 48189 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:48:21.984651 160153 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:48:21.985736 160153 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 64956 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:49:08.072237 160182 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:49:08.073225 160182 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 79093 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:49:53.765769 160210 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:49:53.766774 160210 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 96359 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:50:42.232537 160238 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:50:42.233541 160238 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 109601 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:51:27.590946 160279 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:51:27.591874 160279 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 123092 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:52:13.212620 160308 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:52:13.213605 160308 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 137883 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:52:57.687844 160335 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:52:57.688908 160335 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 151481 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:53:46.314841 160351 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:53:46.315827 160351 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 3769 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:54:51.294695 160391 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:54:51.295711 160391 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 2147483649],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 2147483649],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 21690 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:55:43.284757 160421 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:55:43.285764 160421 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 2147483649],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 2147483649],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 35437 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:56:32.988519 160475 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:56:32.989696 160475 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 2147483649],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 2147483649],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 51290 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:57:19.487403 160490 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:57:19.488852 160490 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 66172 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:58:06.757730 160545 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:58:06.758785 160545 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 81603 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:58:57.264722 160573 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:58:57.265700 160573 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 100084 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:59:47.522868 160603 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:59:47.523862 160603 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 113767 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:00:38.207247 160657 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:00:38.208472 160657 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 123332 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:01:28.628147 160673 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:01:28.629146 160673 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 139136 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:02:18.053720 160724 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:02:18.054950 160724 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 2147483649],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 2147483649],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 154690 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:03:04.216573 160742 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:03:04.217530 160742 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 2147483649],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 2147483649],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 6616 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:03:49.784845 160784 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:03:49.785884 160784 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 2147483649],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 2147483649],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 21540 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:04:38.905740 160817 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:04:38.906876 160817 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28279 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:05:26.083977 160839 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:05:26.086508 160839 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 43966 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:06:10.625217 160882 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:06:10.626312 160882 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 63680 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:06:55.872642 160909 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:06:55.875489 160909 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 84474 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:07:48.298199 160939 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:07:48.299170 160939 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 100187 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:08:38.267982 160980 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:08:38.269042 160980 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 109512 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:09:24.073192 160994 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:09:24.074183 160994 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 125700 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:10:11.886307 161023 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:10:11.888021 161023 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 140806 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:11:00.121251 161064 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:11:00.123987 161064 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 155658 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:11:45.578533 161079 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:11:45.579516 161079 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 5152 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:12:30.473904 161120 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:12:30.476244 161120 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 15285 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:13:14.992570 161134 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:13:14.994887 161134 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 30798 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:13:59.666172 161163 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:13:59.667166 161163 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 45630 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:14:47.432823 161203 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:14:47.435462 161203 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 55617 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:15:35.799914 161218 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:15:35.800916 161218 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 71445 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:16:24.327558 161259 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:16:24.328572 161259 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 2],"float32"),Tensor([1, 1, 4294967295],"float32"),], axis=-2, )
[torch error] paddle.concat(list[Tensor([1, 1, 2],"float32"),Tensor([1, 1, 4294967295],"float32"),], axis=-2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 89778 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:17:36.249389 161275 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:17:36.250411 161275 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 2],"float32"),Tensor([1, 2147483648, 2],"float32"),], axis=-2, )
[torch error] paddle.concat(list[Tensor([1, 1, 2],"float32"),Tensor([1, 2147483648, 2],"float32"),], axis=-2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 108196 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:18:42.423502 161315 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:18:42.424471 161315 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 2],"float32"),Tensor([2147483648, 1, 2],"float32"),], axis=-2, )
[torch error] paddle.concat(list[Tensor([1, 1, 2],"float32"),Tensor([2147483648, 1, 2],"float32"),], axis=-2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 130125 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:20:15.348892 161344 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:20:15.352267 161344 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 2147483649, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 2147483649, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 159310 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:21:02.570820 161386 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:21:02.571758 161386 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 2147483649, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 2147483649, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 11449 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:21:47.511807 161427 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:21:47.512878 161427 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 2147483649, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 2147483649, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 24580 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:22:34.303107 161441 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:22:34.304236 161441 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 36890 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:23:24.277395 161457 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:23:24.278390 161457 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 52544 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:24:09.847437 161497 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:24:09.849001 161497 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 66264 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:25:11.011549 161540 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:25:11.014248 161540 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 84811 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:25:56.527731 161582 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:25:56.528904 161582 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 104542 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:26:45.799319 161610 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:26:45.800408 161610 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 121043 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:27:37.489104 161649 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:27:37.490095 161649 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 2147483649],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 2147483649],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 130031 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:28:26.214762 161693 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:28:26.215746 161693 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 2147483649],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 2147483649],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 148095 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:29:14.097110 161722 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:29:14.107470 161722 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 2147483649],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 2147483649],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 163218 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:29:59.983865 161764 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:29:59.984876 161764 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 15023 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:30:47.255376 161806 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:30:47.256470 161806 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 26527 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:31:33.248391 161821 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:31:33.260067 161821 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 37681 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:32:20.455037 161876 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:32:20.456035 161876 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 2147483649],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 2147483649],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 52413 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:33:07.711674 161905 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:33:07.712796 161905 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 2147483649],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 2147483649],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 66941 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:33:54.689693 161946 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:33:54.690683 161946 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 2147483649],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 2147483649],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 83168 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:34:41.895068 161988 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:34:41.896147 161988 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 2147483649],"int64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 2147483649],"int64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 89516 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:35:25.837515 162016 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:35:25.838660 162016 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 4294967295],"float16"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 4294967295],"float16"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 105068 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:36:50.655834 162058 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:36:50.656903 162058 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 4294967295],"float32"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 4294967295],"float32"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 140450 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:37:57.934332 162100 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:37:57.935462 162100 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 4294967295],"float32"),Tensor([1, 1, 2],"float32"),], axis=-2, )
[torch error] paddle.concat(list[Tensor([1, 1, 4294967295],"float32"),Tensor([1, 1, 2],"float32"),], axis=-2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 158436 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:39:11.539348 162142 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:39:11.540330 162142 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 4294967295],"float32"),Tensor([1, 1, 4294967295],"float32"),], axis=-2, )
[torch error] paddle.concat(list[Tensor([1, 1, 4294967295],"float32"),Tensor([1, 1, 4294967295],"float32"),], axis=-2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 20041 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:40:19.083099 162171 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:40:19.085801 162171 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1, 4294967295],"int32"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1, 4294967295],"int32"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 39205 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:41:25.582469 162212 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:41:25.583531 162212 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),Tensor([1, 2147483649],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),Tensor([1, 2147483649],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 58689 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:42:09.946756 162241 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:42:09.949434 162241 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),Tensor([1, 2147483649],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),Tensor([1, 2147483649],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 72596 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:42:54.685309 162282 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:42:54.686419 162282 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),Tensor([2147483649, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),Tensor([2147483649, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 88163 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:43:42.870961 162297 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:43:42.871948 162297 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),Tensor([2147483649, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),Tensor([2147483649, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 95523 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:44:27.456758 162325 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:44:27.457898 162325 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 110012 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:45:17.570739 162352 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:45:17.571727 162352 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 125833 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:46:01.754624 162381 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:46:01.755700 162381 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1],"float64"),Tensor([2147483649, 1],"float64"),Tensor([1, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1],"float64"),Tensor([2147483649, 1],"float64"),Tensor([1, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 144616 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:46:46.132594 162421 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:46:46.133682 162421 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1],"float64"),Tensor([2147483649, 1],"float64"),Tensor([1, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 1],"float64"),Tensor([2147483649, 1],"float64"),Tensor([1, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 156858 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:47:31.291023 162449 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:47:31.292032 162449 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1],"int64"),Tensor([1, 2147483649],"int64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 1],"int64"),Tensor([1, 2147483649],"int64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 4769 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:48:14.049613 162491 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:48:14.050763 162491 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1],"int64"),Tensor([1073741825, 2],"int64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 1],"int64"),Tensor([1073741825, 2],"int64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 21606 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:48:56.513958 162520 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:48:56.515060 162520 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 10, 429496730],"float32"),Tensor([1, 10, 429496730],"float32"),], )
[torch error] paddle.concat(list[Tensor([1, 10, 429496730],"float32"),Tensor([1, 10, 429496730],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 36041 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:50:10.014324 162548 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:50:10.015419 162548 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 10, 429496730],"float32"),Tensor([1, 10, 5],"float32"),], )
[torch error] paddle.concat(list[Tensor([1, 10, 429496730],"float32"),Tensor([1, 10, 5],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 55115 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:51:20.628306 162605 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:51:20.629518 162605 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 10, 5],"float32"),Tensor([1, 10, 429496730],"float32"),], )
[torch error] paddle.concat(list[Tensor([1, 10, 5],"float32"),Tensor([1, 10, 429496730],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 72951 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:52:25.981855 162648 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:52:25.982856 162648 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 10, 5],"float32"),Tensor([1, 858993459, 5],"float32"),], )
[torch error] paddle.concat(list[Tensor([1, 10, 5],"float32"),Tensor([1, 858993459, 5],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 92388 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:53:31.800137 162676 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:53:31.801129 162676 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 10, 5],"float32"),Tensor([85899346, 10, 5],"float32"),], )
[torch error] paddle.concat(list[Tensor([1, 10, 5],"float32"),Tensor([85899346, 10, 5],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 110707 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:54:47.898792 162705 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:54:47.899895 162705 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1073741824, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 1073741824, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 140038 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:56:05.957037 162733 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:56:05.958535 162733 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 1073741824, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 1073741824, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 3159 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:57:11.714746 162761 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:57:11.715739 162761 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 10737419, 20, 20],"float32"),Tensor([1, 10737419, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 10737419, 20, 20],"float32"),Tensor([1, 10737419, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 22859 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:58:25.512125 162776 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:58:25.513232 162776 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 10737419, 20, 20],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 10737419, 20, 20],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 44859 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:59:39.039971 162803 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:59:39.040971 162803 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 12, 10, 10],"float32"),Tensor([1, 12, 10, 35791395],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 12, 10, 10],"float32"),Tensor([1, 12, 10, 35791395],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 63384 has 1016.00 MiB memory in use. Of the allocated memory 5.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:00:45.202435 162831 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:00:45.203455 162831 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 12, 10, 10],"float32"),Tensor([1, 12, 35791395, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 12, 10, 10],"float32"),Tensor([1, 12, 35791395, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 83790 has 1016.00 MiB memory in use. Of the allocated memory 5.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:01:59.189625 162860 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:01:59.194341 162860 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 12, 10, 10],"float32"),Tensor([1, 42949673, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 12, 10, 10],"float32"),Tensor([1, 42949673, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 109870 has 1016.00 MiB memory in use. Of the allocated memory 5.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:03:11.992600 162900 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:03:11.993674 162900 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 12, 10, 10],"float32"),Tensor([3579140, 12, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 12, 10, 10],"float32"),Tensor([3579140, 12, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 129695 has 1016.00 MiB memory in use. Of the allocated memory 5.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:04:31.052544 162916 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:04:31.053561 162916 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 12, 10, 35791395],"float32"),Tensor([1, 12, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 12, 10, 35791395],"float32"),Tensor([1, 12, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 148948 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:05:43.659945 162956 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:05:43.661079 162956 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 12, 10, 35791395],"float32"),Tensor([1, 12, 10, 35791395],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 12, 10, 35791395],"float32"),Tensor([1, 12, 10, 35791395],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 8223 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:06:52.211627 162996 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:06:52.212757 162996 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 12, 35791395, 10],"float32"),Tensor([1, 12, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 12, 35791395, 10],"float32"),Tensor([1, 12, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 37035 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:08:02.137056 163025 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:08:02.138134 163025 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 12, 35791395, 10],"float32"),Tensor([1, 12, 35791395, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 12, 35791395, 10],"float32"),Tensor([1, 12, 35791395, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 55702 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:09:09.942757 163040 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:09:09.943912 163040 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 128, 10, 10],"float32"),Tensor([1, 32, 10, 13421773],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 128, 10, 10],"float32"),Tensor([1, 32, 10, 13421773],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 75012 has 1016.00 MiB memory in use. Of the allocated memory 50.00 KiB is allocated by PyTorch, and 1.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:10:24.732789 163067 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:10:24.733856 163067 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 128, 10, 10],"float32"),Tensor([1, 32, 13421773, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 128, 10, 10],"float32"),Tensor([1, 32, 13421773, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 101189 has 1016.00 MiB memory in use. Of the allocated memory 50.00 KiB is allocated by PyTorch, and 1.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:11:31.775751 163095 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:11:31.776850 163095 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 128, 10, 10],"float32"),Tensor([1, 42949673, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 128, 10, 10],"float32"),Tensor([1, 42949673, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 120401 has 1016.00 MiB memory in use. Of the allocated memory 50.00 KiB is allocated by PyTorch, and 1.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:12:37.879055 163124 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:12:37.880177 163124 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 128, 10, 10],"float32"),Tensor([1342178, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 128, 10, 10],"float32"),Tensor([1342178, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 138479 has 1016.00 MiB memory in use. Of the allocated memory 50.00 KiB is allocated by PyTorch, and 1.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:13:44.648865 163165 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:13:44.649940 163165 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 128, 10, 3355444],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 128, 10, 3355444],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 155906 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:14:52.786897 163194 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:14:52.788098 163194 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 128, 10, 3355444],"float32"),Tensor([1, 32, 10, 3355444],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 128, 10, 3355444],"float32"),Tensor([1, 32, 10, 3355444],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 19647 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:16:08.024703 163248 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:16:08.025789 163248 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 128, 1677722, 20],"float32"),Tensor([1, 32, 1677722, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 128, 1677722, 20],"float32"),Tensor([1, 32, 1677722, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 43192 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:17:17.008060 163278 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:17:17.009093 163278 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 128, 1677722, 20],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 128, 1677722, 20],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 62762 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:18:33.301652 163318 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:18:33.302646 163318 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 128, 20, 1677722],"float32"),Tensor([1, 32, 20, 1677722],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 128, 20, 1677722],"float32"),Tensor([1, 32, 20, 1677722],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 85709 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:19:39.460023 163376 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:19:39.461104 163376 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 128, 20, 1677722],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 128, 20, 1677722],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 102641 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:20:50.163784 163392 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:20:50.164805 163392 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 128, 20, 20],"float32"),Tensor([1, 10737419, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 128, 20, 20],"float32"),Tensor([1, 10737419, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 128442 has 1016.00 MiB memory in use. Of the allocated memory 200.00 KiB is allocated by PyTorch, and 1.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:22:00.127625 163432 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:22:00.128777 163432 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 128, 20, 20],"float32"),Tensor([1, 32, 20, 6710887],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 128, 20, 20],"float32"),Tensor([1, 32, 20, 6710887],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 149396 has 1016.00 MiB memory in use. Of the allocated memory 200.00 KiB is allocated by PyTorch, and 1.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:23:12.405189 163466 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:23:12.406286 163466 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 128, 20, 20],"float32"),Tensor([1, 32, 6710887, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 128, 20, 20],"float32"),Tensor([1, 32, 6710887, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 4959 has 1016.00 MiB memory in use. Of the allocated memory 200.00 KiB is allocated by PyTorch, and 1.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:24:18.265373 163490 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:24:18.266417 163490 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 128, 20, 20],"float32"),Tensor([335545, 32, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 128, 20, 20],"float32"),Tensor([335545, 32, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 23109 has 1016.00 MiB memory in use. Of the allocated memory 200.00 KiB is allocated by PyTorch, and 1.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:25:26.589710 163517 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:25:26.590648 163517 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 128, 3355444, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 128, 3355444, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 41789 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:26:38.385376 163532 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:26:38.386396 163532 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 128, 3355444, 10],"float32"),Tensor([1, 32, 3355444, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 128, 3355444, 10],"float32"),Tensor([1, 32, 3355444, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 70005 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:27:44.622645 163559 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:27:44.623709 163559 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 134217728, 8, 4],"float32"),Tensor([1, 134217728, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([1, 134217728, 8, 4],"float32"),Tensor([1, 134217728, 8, 4],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 88554 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:28:51.044952 163587 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:28:51.046080 163587 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 134217728, 8, 4],"float32"),Tensor([1, 2, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([1, 134217728, 8, 4],"float32"),Tensor([1, 2, 8, 4],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 116642 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:30:03.829979 163615 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:30:03.830991 163615 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 134217728, 8, 4],"float32"),Tensor([1, 4, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([1, 134217728, 8, 4],"float32"),Tensor([1, 4, 8, 4],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 137904 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:31:11.131986 163630 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:31:11.133157 163630 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 160, 10, 10],"float32"),Tensor([1, 32, 10, 13421773],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 160, 10, 10],"float32"),Tensor([1, 32, 10, 13421773],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 154645 has 1016.00 MiB memory in use. Of the allocated memory 62.50 KiB is allocated by PyTorch, and 1.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:32:17.059859 163657 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:32:17.060971 163657 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 160, 10, 10],"float32"),Tensor([1, 32, 13421773, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 160, 10, 10],"float32"),Tensor([1, 32, 13421773, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 11013 has 1016.00 MiB memory in use. Of the allocated memory 62.50 KiB is allocated by PyTorch, and 1.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:33:26.868800 163672 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:33:26.869894 163672 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 160, 10, 10],"float32"),Tensor([1, 42949673, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 160, 10, 10],"float32"),Tensor([1, 42949673, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28302 has 1016.00 MiB memory in use. Of the allocated memory 62.50 KiB is allocated by PyTorch, and 1.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:34:32.464664 163700 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:34:32.465714 163700 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 160, 10, 10],"float32"),Tensor([1342178, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 160, 10, 10],"float32"),Tensor([1342178, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 46704 has 1016.00 MiB memory in use. Of the allocated memory 62.50 KiB is allocated by PyTorch, and 1.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:35:43.193568 163727 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:35:43.194554 163727 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 160, 10, 2684355],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 160, 10, 2684355],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 67829 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:36:51.483095 163742 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:36:51.484118 163742 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 160, 10, 2684355],"float32"),Tensor([1, 32, 10, 2684355],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 160, 10, 2684355],"float32"),Tensor([1, 32, 10, 2684355],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 103064 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:37:58.159675   843 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:37:58.160735   843 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 160, 1342178, 20],"float32"),Tensor([1, 32, 1342178, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 160, 1342178, 20],"float32"),Tensor([1, 32, 1342178, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 127207 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:39:06.499861  1153 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:39:06.501116  1153 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 160, 1342178, 20],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 160, 1342178, 20],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 147727 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:40:14.322180  1544 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:40:14.323415  1544 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 160, 20, 1342178],"float32"),Tensor([1, 32, 20, 1342178],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 160, 20, 1342178],"float32"),Tensor([1, 32, 20, 1342178],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 6196 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:41:26.422479  1868 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:41:26.423631  1868 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 160, 20, 1342178],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 160, 20, 1342178],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 27471 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:42:37.087754  2182 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:42:37.089126  2182 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 160, 20, 20],"float32"),Tensor([1, 10737419, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 160, 20, 20],"float32"),Tensor([1, 10737419, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 51352 has 1016.00 MiB memory in use. Of the allocated memory 250.00 KiB is allocated by PyTorch, and 1.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:43:47.192975  2586 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:43:47.193905  2586 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 160, 20, 20],"float32"),Tensor([1, 32, 20, 6710887],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 160, 20, 20],"float32"),Tensor([1, 32, 20, 6710887],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 73294 has 1016.00 MiB memory in use. Of the allocated memory 250.00 KiB is allocated by PyTorch, and 1.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:45:03.548089  2889 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:45:03.549196  2889 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 160, 20, 20],"float32"),Tensor([1, 32, 6710887, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 160, 20, 20],"float32"),Tensor([1, 32, 6710887, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 100545 has 1016.00 MiB memory in use. Of the allocated memory 250.00 KiB is allocated by PyTorch, and 1.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:46:16.092545  3296 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:46:16.093519  3296 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 160, 20, 20],"float32"),Tensor([335545, 32, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 160, 20, 20],"float32"),Tensor([335545, 32, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 129227 has 1016.00 MiB memory in use. Of the allocated memory 250.00 KiB is allocated by PyTorch, and 1.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:47:28.697731  3582 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:47:28.698984  3582 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 160, 2684355, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 160, 2684355, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 148877 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:48:36.591635  3900 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:48:36.592602  3900 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 160, 2684355, 10],"float32"),Tensor([1, 32, 2684355, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 160, 2684355, 10],"float32"),Tensor([1, 32, 2684355, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 7139 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:49:44.146142  4293 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:49:44.147284  4293 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 171798692, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 171798692, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 27399 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:50:52.993326  4584 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:50:52.994341  4584 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 171798692, 5, 5],"float32"),Tensor([1, 24, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 171798692, 5, 5],"float32"),Tensor([1, 24, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 53735 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:52:04.469836  4893 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:52:04.470929  4893 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 171798692, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 171798692, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 75004 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:53:12.736477  5278 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:53:12.737418  5278 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 192, 10, 10],"float32"),Tensor([1, 32, 10, 13421773],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 192, 10, 10],"float32"),Tensor([1, 32, 10, 13421773],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 96293 has 1016.00 MiB memory in use. Of the allocated memory 75.00 KiB is allocated by PyTorch, and 1.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:54:21.005591  5576 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:54:21.006670  5576 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 192, 10, 10],"float32"),Tensor([1, 32, 13421773, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 192, 10, 10],"float32"),Tensor([1, 32, 13421773, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 115856 has 1016.00 MiB memory in use. Of the allocated memory 75.00 KiB is allocated by PyTorch, and 1.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:55:30.258360  5894 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:55:30.259363  5894 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 192, 10, 10],"float32"),Tensor([1, 42949673, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 192, 10, 10],"float32"),Tensor([1, 42949673, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 136450 has 1016.00 MiB memory in use. Of the allocated memory 75.00 KiB is allocated by PyTorch, and 1.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:56:35.924818  6192 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:56:35.925899  6192 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 192, 10, 10],"float32"),Tensor([1342178, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 192, 10, 10],"float32"),Tensor([1342178, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 160534 has 1016.00 MiB memory in use. Of the allocated memory 75.00 KiB is allocated by PyTorch, and 1.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:57:45.449082  6580 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:57:45.450065  6580 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 192, 10, 2236963],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 192, 10, 2236963],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 21559 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:58:56.923575  6904 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:58:56.924636  6904 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 192, 10, 2236963],"float32"),Tensor([1, 32, 10, 2236963],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 192, 10, 2236963],"float32"),Tensor([1, 32, 10, 2236963],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 52674 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:00:08.159246  7171 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:00:08.160249  7171 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 192, 1118482, 20],"float32"),Tensor([1, 32, 1118482, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 192, 1118482, 20],"float32"),Tensor([1, 32, 1118482, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 70816 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:01:39.813320  7568 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:01:39.814486  7568 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 192, 1118482, 20],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 192, 1118482, 20],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 94389 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:02:48.888388  8035 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:02:48.889401  8035 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 192, 20, 1118482],"float32"),Tensor([1, 32, 20, 1118482],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 192, 20, 1118482],"float32"),Tensor([1, 32, 20, 1118482],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 116049 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:03:56.147840  8327 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:03:56.148929  8327 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 192, 20, 1118482],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 192, 20, 1118482],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 140270 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:05:03.884029  8645 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:05:03.885223  8645 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 192, 20, 20],"float32"),Tensor([1, 10737419, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 192, 20, 20],"float32"),Tensor([1, 10737419, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 158526 has 1016.00 MiB memory in use. Of the allocated memory 300.00 KiB is allocated by PyTorch, and 1.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:06:09.973412  9047 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:06:09.974347  9047 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 192, 20, 20],"float32"),Tensor([1, 32, 20, 6710887],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 192, 20, 20],"float32"),Tensor([1, 32, 20, 6710887],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 17871 has 1016.00 MiB memory in use. Of the allocated memory 300.00 KiB is allocated by PyTorch, and 1.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:07:16.975822  9378 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:07:16.976781  9378 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 192, 20, 20],"float32"),Tensor([1, 32, 6710887, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 192, 20, 20],"float32"),Tensor([1, 32, 6710887, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 39138 has 1016.00 MiB memory in use. Of the allocated memory 300.00 KiB is allocated by PyTorch, and 1.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:08:28.645007  9704 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:08:28.646034  9704 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 192, 20, 20],"float32"),Tensor([335545, 32, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 192, 20, 20],"float32"),Tensor([335545, 32, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 60419 has 1016.00 MiB memory in use. Of the allocated memory 300.00 KiB is allocated by PyTorch, and 1.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:09:38.112749 10046 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:09:38.113711 10046 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 192, 2236963, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 192, 2236963, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 78170 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:10:46.396143 10432 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:10:46.397388 10432 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 192, 2236963, 10],"float32"),Tensor([1, 32, 2236963, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 192, 2236963, 10],"float32"),Tensor([1, 32, 2236963, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 98351 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:12:00.544066 10746 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:12:00.545097 10746 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2, 1],"float64"),Tensor([1, 2, 1073741825],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2, 1],"float64"),Tensor([1, 2, 1073741825],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 127263 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:12:48.751848 11082 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:12:48.752975 11082 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 137913 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:13:38.189709 11374 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:13:38.190827 11374 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2, 1],"float64"),Tensor([1073741825, 2, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2, 1],"float64"),Tensor([1073741825, 2, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 152532 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:14:28.514571 11632 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:14:28.515743 11632 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2, 1073741825],"float64"),Tensor([1, 2, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2, 1073741825],"float64"),Tensor([1, 2, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 8219 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:15:21.570513 11849 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:15:21.571687 11849 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2, 1073741825],"float64"),Tensor([1, 2, 1073741825],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2, 1073741825],"float64"),Tensor([1, 2, 1073741825],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 23819 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:16:06.907377 12122 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:16:06.908555 12122 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2, 536870912, 4],"float32"),Tensor([1, 2, 536870912, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([1, 2, 536870912, 4],"float32"),Tensor([1, 2, 536870912, 4],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 43038 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:17:14.511256 12421 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:17:14.512549 12421 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2, 536870912, 4],"float32"),Tensor([1, 2, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([1, 2, 536870912, 4],"float32"),Tensor([1, 2, 8, 4],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 63891 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:18:21.777806 12739 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:18:21.778996 12739 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2, 8, 268435456],"float32"),Tensor([1, 2, 8, 268435456],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([1, 2, 8, 268435456],"float32"),Tensor([1, 2, 8, 268435456],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 84540 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:19:29.421305 13067 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:19:29.422425 13067 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2, 8, 268435456],"float32"),Tensor([1, 2, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([1, 2, 8, 268435456],"float32"),Tensor([1, 2, 8, 4],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 104303 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:20:36.475656 13375 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:20:36.476815 13375 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2, 8, 4],"float32"),Tensor([1, 134217728, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([1, 2, 8, 4],"float32"),Tensor([1, 134217728, 8, 4],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 123115 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:21:42.220110 13782 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:21:42.221117 13782 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2, 8, 4],"float32"),Tensor([1, 2, 536870912, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([1, 2, 8, 4],"float32"),Tensor([1, 2, 536870912, 4],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 142199 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:22:53.614550 14098 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:22:53.615738 14098 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2, 8, 4],"float32"),Tensor([1, 2, 8, 268435456],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([1, 2, 8, 4],"float32"),Tensor([1, 2, 8, 268435456],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 4386 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:24:03.522483 14411 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:24:03.523612 14411 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2, 8, 4],"float32"),Tensor([67108864, 2, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([1, 2, 8, 4],"float32"),Tensor([67108864, 2, 8, 4],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 23969 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:25:10.617621 14819 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:25:10.618675 14819 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2],"float32"),Tensor([1, 4294967295],"float32"),], )
[torch error] paddle.concat(list[Tensor([1, 2],"float32"),Tensor([1, 4294967295],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 41775 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:26:18.137121 15122 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:26:18.138234 15122 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2],"float32"),Tensor([1, 4294967295],"float32"),], axis=-2, )
[torch error] paddle.concat(list[Tensor([1, 2],"float32"),Tensor([1, 4294967295],"float32"),], axis=-2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 66619 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:27:29.927266 15440 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:27:29.928282 15440 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2],"float32"),Tensor([2147483648, 2],"float32"),], )
[torch error] paddle.concat(list[Tensor([1, 2],"float32"),Tensor([2147483648, 2],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 86981 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:28:35.916671 15752 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:28:35.917755 15752 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2],"float32"),Tensor([2147483648, 2],"float32"),], axis=-2, )
[torch error] paddle.concat(list[Tensor([1, 2],"float32"),Tensor([2147483648, 2],"float32"),], axis=-2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 107181 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:29:45.850528 16143 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:29:45.851631 16143 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2],"float64"),Tensor([1, 2147483649],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2],"float64"),Tensor([1, 2147483649],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 132113 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:30:33.479532 16471 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:30:33.480600 16471 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2],"float64"),Tensor([1073741825, 2],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2],"float64"),Tensor([1073741825, 2],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 147426 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:31:18.849066 16749 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:31:18.850076 16749 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2],"int64"),Tensor([1, 2147483649],"int64"),], )
[torch error] paddle.concat(list[Tensor([1, 2],"int64"),Tensor([1, 2147483649],"int64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 162648 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:32:03.783566 16932 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:32:03.784628 16932 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2],"int64"),Tensor([1073741825, 2],"int64"),], )
[torch error] paddle.concat(list[Tensor([1, 2],"int64"),Tensor([1073741825, 2],"int64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 14572 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:32:48.650242 17204 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:32:48.651242 17204 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483648, 2],"float32"),Tensor([1, 1, 2],"float32"),], axis=-2, )
[torch error] paddle.concat(list[Tensor([1, 2147483648, 2],"float32"),Tensor([1, 1, 2],"float32"),], axis=-2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 22622 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:33:57.931219 17389 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:33:57.932240 17389 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483648, 2],"float32"),Tensor([1, 2147483648, 2],"float32"),], axis=-2, )
[torch error] paddle.concat(list[Tensor([1, 2147483648, 2],"float32"),Tensor([1, 2147483648, 2],"float32"),], axis=-2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 47680 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:35:03.982511 17692 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:35:03.983762 17692 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649, 1, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649, 1, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 65761 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:35:49.044777 18101 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:35:49.045876 18101 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649, 1, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649, 1, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 76601 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:36:33.397939 18285 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:36:33.399101 18285 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649, 1, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649, 1, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 94882 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:37:17.932339 18558 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:37:17.933877 18558 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 110099 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:38:01.816085 18750 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:38:01.817217 18750 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 125249 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:38:50.945361 18935 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:38:50.946548 18935 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 138479 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:39:40.869843 19215 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:39:40.871047 19215 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 149784 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:40:29.878475 19505 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:40:29.879467 19505 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 5462 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:41:20.702427 19697 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:41:20.703538 19697 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 27885 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:42:06.553481 19986 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:42:06.554700 19986 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 46981 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:42:54.794317 20260 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:42:54.795404 20260 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 65367 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:43:46.365545 20458 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:43:46.366763 20458 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 77847 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:44:35.103219 20729 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:44:35.104351 20729 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 98389 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:45:21.686153 21013 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:45:21.687173 21013 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 120704 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:46:34.692579 21200 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:46:34.693869 21200 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 15201 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:47:29.824512 21606 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:47:29.827389 21606 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 35715 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:48:44.603771 21782 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:48:44.605304 21782 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 62910 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:49:59.239795 22188 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:49:59.241439 22188 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 117850 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:51:17.243911 22488 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:51:17.245992 22488 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 162252 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:52:38.421952 22899 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:52:38.423275 22899 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 41898 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:53:59.173995 23307 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:53:59.175604 23307 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 5, 1],"float64"),Tensor([1, 5, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 5, 1],"float64"),Tensor([1, 5, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 83382 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:55:19.096280 23613 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:55:19.098039 23613 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649, 1],"int64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649, 1],"int64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 120505 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:56:13.819438 24015 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:56:13.820644 24015 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 150176 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:57:07.721838 24270 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:57:07.723560 24270 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 14298 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:57:59.397833 24551 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:57:59.408238 24551 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649],"float64"),Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649],"float64"),Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 35577 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:58:48.577314 24717 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:58:48.578478 24717 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649],"float64"),Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649],"float64"),Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 52975 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 10:59:40.270750 25005 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:59:40.271878 25005 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649],"float64"),Tensor([1, 2],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649],"float64"),Tensor([1, 2],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 74483 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:00:27.958384 25260 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:00:27.959481 25260 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 97197 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:01:15.613683 25446 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:01:15.614709 25446 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 119705 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:02:06.840404 25706 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:02:06.841421 25706 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 143057 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:02:56.155687 25966 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:02:56.156836 25966 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649],"float64"),Tensor([1, 5],"float64"),Tensor([1, 5],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649],"float64"),Tensor([1, 5],"float64"),Tensor([1, 5],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 162183 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:03:47.807873 26149 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:03:47.808988 26149 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649],"int64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649],"int64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 24648 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:04:34.200577 26413 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:04:34.212430 26413 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649],"int64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 2147483649],"int64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 54590 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:05:22.616852 26685 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:05:22.617946 26685 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649],"int64"),Tensor([1, 2],"int64"),], )
[torch error] paddle.concat(list[Tensor([1, 2147483649],"int64"),Tensor([1, 2],"int64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 98093 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:06:07.351279 26873 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:06:07.352428 26873 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649],"int64"),Tensor([1, 2],"int64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 2147483649],"int64"),Tensor([1, 2],"int64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 139643 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:06:54.647614 27134 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:06:54.648615 27134 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649],"int64"),Tensor([1, 2147483649],"int64"),], )
[torch error] paddle.concat(list[Tensor([1, 2147483649],"int64"),Tensor([1, 2147483649],"int64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 9552 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:07:38.384306 27322 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:07:38.385506 27322 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 2147483649],"int64"),Tensor([1, 2147483649],"int64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 2147483649],"int64"),Tensor([1, 2147483649],"int64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 44026 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:08:21.434521 27575 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:08:21.435526 27575 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 224, 10, 10],"float32"),Tensor([1, 32, 10, 13421773],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 224, 10, 10],"float32"),Tensor([1, 32, 10, 13421773],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 74938 has 1016.00 MiB memory in use. Of the allocated memory 87.50 KiB is allocated by PyTorch, and 1.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:09:34.475847 27755 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:09:34.476842 27755 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 224, 10, 10],"float32"),Tensor([1, 32, 13421773, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 224, 10, 10],"float32"),Tensor([1, 32, 13421773, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 123839 has 1016.00 MiB memory in use. Of the allocated memory 87.50 KiB is allocated by PyTorch, and 1.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:10:48.974743 28162 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:10:48.975807 28162 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 224, 10, 10],"float32"),Tensor([1, 42949673, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 224, 10, 10],"float32"),Tensor([1, 42949673, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 19235 has 1016.00 MiB memory in use. Of the allocated memory 87.50 KiB is allocated by PyTorch, and 1.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:11:57.249904 28461 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:11:57.254462 28461 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 224, 10, 10],"float32"),Tensor([1342178, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 224, 10, 10],"float32"),Tensor([1342178, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 74775 has 1016.00 MiB memory in use. Of the allocated memory 87.50 KiB is allocated by PyTorch, and 1.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:13:07.016095 28767 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:13:07.017225 28767 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 224, 10, 1917397],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 224, 10, 1917397],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 129855 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:14:16.181963 29154 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:14:16.183082 29154 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 224, 10, 1917397],"float32"),Tensor([1, 32, 10, 1917397],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 224, 10, 1917397],"float32"),Tensor([1, 32, 10, 1917397],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 17595 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:15:24.274369 29461 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:15:24.276031 29461 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 224, 1917397, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 224, 1917397, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 63026 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:16:39.173022 29761 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:16:39.174039 29761 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 224, 1917397, 10],"float32"),Tensor([1, 32, 1917397, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 224, 1917397, 10],"float32"),Tensor([1, 32, 1917397, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 129290 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:17:51.813807 30144 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:17:51.814924 30144 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 224, 20, 20],"float32"),Tensor([1, 10737419, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 224, 20, 20],"float32"),Tensor([1, 10737419, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 18737 has 1016.00 MiB memory in use. Of the allocated memory 350.00 KiB is allocated by PyTorch, and 1.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:18:57.934893 30456 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:18:57.935853 30456 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 224, 20, 20],"float32"),Tensor([1, 32, 20, 6710887],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 224, 20, 20],"float32"),Tensor([1, 32, 20, 6710887],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 73293 has 1016.00 MiB memory in use. Of the allocated memory 350.00 KiB is allocated by PyTorch, and 1.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:20:04.533921 30741 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:20:04.534817 30741 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 224, 20, 20],"float32"),Tensor([1, 32, 6710887, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 224, 20, 20],"float32"),Tensor([1, 32, 6710887, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 121714 has 1016.00 MiB memory in use. Of the allocated memory 350.00 KiB is allocated by PyTorch, and 1.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:21:14.610337 31115 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:21:14.611460 31115 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 224, 20, 20],"float32"),Tensor([335545, 32, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 224, 20, 20],"float32"),Tensor([335545, 32, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 16900 has 1016.00 MiB memory in use. Of the allocated memory 350.00 KiB is allocated by PyTorch, and 1.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:22:23.919898 31441 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:22:23.920812 31441 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 224, 20, 958699],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 224, 20, 958699],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 61990 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:23:36.626173 31736 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:23:36.627346 31736 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 224, 20, 958699],"float32"),Tensor([1, 32, 20, 958699],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 224, 20, 958699],"float32"),Tensor([1, 32, 20, 958699],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 115264 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:24:43.815874 32127 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:24:43.816988 32127 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 224, 958699, 20],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 224, 958699, 20],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 3815 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:25:55.249321 32424 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:25:55.250458 32424 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 224, 958699, 20],"float32"),Tensor([1, 32, 958699, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 224, 958699, 20],"float32"),Tensor([1, 32, 958699, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 59081 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:27:04.091409 32732 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:27:04.092597 32732 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 24, 35791395, 5],"float32"),Tensor([1, 24, 35791395, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 24, 35791395, 5],"float32"),Tensor([1, 24, 35791395, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 111650 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:28:14.683077 33115 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:28:14.684198 33115 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 24, 35791395, 5],"float32"),Tensor([1, 24, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 24, 35791395, 5],"float32"),Tensor([1, 24, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 9195 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:29:29.122395 33422 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:29:29.384640 33422 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 24, 5, 35791395],"float32"),Tensor([1, 24, 5, 35791395],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 24, 5, 35791395],"float32"),Tensor([1, 24, 5, 35791395],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 56848 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:30:40.830027 33747 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:30:40.831138 33747 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 24, 5, 35791395],"float32"),Tensor([1, 24, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 24, 5, 35791395],"float32"),Tensor([1, 24, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 115902 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:31:52.540138 34141 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:31:52.541273 34141 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 24, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 24, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 1666 has 1016.00 MiB memory in use. Of the allocated memory 2.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:33:04.499030 34459 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:33:04.500155 34459 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 24, 5, 5],"float32"),Tensor([1, 24, 35791395, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 24, 5, 5],"float32"),Tensor([1, 24, 35791395, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 56367 has 1016.00 MiB memory in use. Of the allocated memory 2.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:34:17.447259 34853 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:34:17.448380 34853 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 24, 5, 5],"float32"),Tensor([1, 24, 5, 35791395],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 24, 5, 5],"float32"),Tensor([1, 24, 5, 35791395],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 119833 has 1016.00 MiB memory in use. Of the allocated memory 2.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:35:28.312439 35158 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:35:28.313616 35158 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 24, 5, 5],"float32"),Tensor([7158279, 24, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 24, 5, 5],"float32"),Tensor([7158279, 24, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 4491 has 1016.00 MiB memory in use. Of the allocated memory 2.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:36:35.556095 35464 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:36:35.557154 35464 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 256, 10, 10],"float32"),Tensor([1, 32, 10, 13421773],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 256, 10, 10],"float32"),Tensor([1, 32, 10, 13421773],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 64231 has 1016.00 MiB memory in use. Of the allocated memory 100.00 KiB is allocated by PyTorch, and 1.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:37:47.398650 35865 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:37:47.399662 35865 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 256, 10, 10],"float32"),Tensor([1, 32, 13421773, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 256, 10, 10],"float32"),Tensor([1, 32, 13421773, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 124212 has 1016.00 MiB memory in use. Of the allocated memory 100.00 KiB is allocated by PyTorch, and 1.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:38:54.730798 36163 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:38:54.731866 36163 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 256, 10, 10],"float32"),Tensor([1, 42949673, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 256, 10, 10],"float32"),Tensor([1, 42949673, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 11536 has 1016.00 MiB memory in use. Of the allocated memory 100.00 KiB is allocated by PyTorch, and 1.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:40:01.675040 36461 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:40:01.676086 36461 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 256, 10, 10],"float32"),Tensor([1342178, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 256, 10, 10],"float32"),Tensor([1342178, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 62374 has 1016.00 MiB memory in use. Of the allocated memory 100.00 KiB is allocated by PyTorch, and 1.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:41:14.032050 36748 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:41:14.033234 36748 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 256, 10, 1677722],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 256, 10, 1677722],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 125183 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:42:32.122360 37160 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:42:32.123378 37160 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 256, 10, 1677722],"float32"),Tensor([1, 32, 10, 1677722],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 256, 10, 1677722],"float32"),Tensor([1, 32, 10, 1677722],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 9839 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:43:48.191906 37559 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:43:48.193023 37559 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 256, 1677722, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 256, 1677722, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 66523 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:45:03.115235 37872 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:45:03.116325 37872 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 256, 1677722, 10],"float32"),Tensor([1, 32, 1677722, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 256, 1677722, 10],"float32"),Tensor([1, 32, 1677722, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 124700 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:46:16.620025 38282 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:46:16.621054 38282 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 256, 3355444, 5],"float32"),Tensor([1, 32, 3355444, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 256, 3355444, 5],"float32"),Tensor([1, 32, 3355444, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 24697 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:47:25.707729 38589 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:47:25.709374 38589 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 256, 3355444, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 256, 3355444, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 71435 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:48:36.701373 38880 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:48:36.710543 38880 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 256, 5, 3355444],"float32"),Tensor([1, 32, 5, 3355444],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 256, 5, 3355444],"float32"),Tensor([1, 32, 5, 3355444],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 121789 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:49:43.779803 39281 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:49:43.780942 39281 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 256, 5, 3355444],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 256, 5, 3355444],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 19620 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:50:50.820437 39583 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:50:50.821568 39583 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 256, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 256, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 65307 has 1016.00 MiB memory in use. Of the allocated memory 25.00 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:51:57.077651 39881 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:51:57.078652 39881 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 256, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 256, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 119063 has 1016.00 MiB memory in use. Of the allocated memory 25.00 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:53:04.760687 40180 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:53:04.761775 40180 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 256, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 256, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 163303 has 1016.00 MiB memory in use. Of the allocated memory 25.00 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:54:13.333243 40572 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:54:13.334303 40572 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 256, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 256, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 59967 has 1016.00 MiB memory in use. Of the allocated memory 25.00 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:55:20.787636 40875 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:55:20.788653 40875 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 288, 10, 10],"float32"),Tensor([1, 32, 10, 13421773],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 288, 10, 10],"float32"),Tensor([1, 32, 10, 13421773],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 106671 has 1016.00 MiB memory in use. Of the allocated memory 112.50 KiB is allocated by PyTorch, and 1.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:56:28.229794 41173 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:56:28.230867 41173 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 288, 10, 10],"float32"),Tensor([1, 32, 13421773, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 288, 10, 10],"float32"),Tensor([1, 32, 13421773, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 158871 has 1016.00 MiB memory in use. Of the allocated memory 112.50 KiB is allocated by PyTorch, and 1.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:57:38.936388 41473 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:57:38.937463 41473 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 288, 10, 10],"float32"),Tensor([1, 42949673, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 288, 10, 10],"float32"),Tensor([1, 42949673, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 53566 has 1016.00 MiB memory in use. Of the allocated memory 112.50 KiB is allocated by PyTorch, and 1.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:58:50.418653 41845 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:58:50.419654 41845 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 288, 10, 10],"float32"),Tensor([1342178, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 288, 10, 10],"float32"),Tensor([1342178, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 103164 has 1016.00 MiB memory in use. Of the allocated memory 112.50 KiB is allocated by PyTorch, and 1.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:59:56.606393 42155 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:59:56.607520 42155 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 288, 10, 1491309],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 288, 10, 1491309],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 154950 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:01:10.115154 42449 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:01:10.116302 42449 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 288, 10, 1491309],"float32"),Tensor([1, 32, 10, 1491309],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 288, 10, 1491309],"float32"),Tensor([1, 32, 10, 1491309],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 52809 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:02:21.832448 42835 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:02:21.833559 42835 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 288, 1491309, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 288, 1491309, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 99674 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:03:29.064417 43132 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:03:29.065451 43132 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 288, 1491309, 10],"float32"),Tensor([1, 32, 1491309, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 288, 1491309, 10],"float32"),Tensor([1, 32, 1491309, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 146468 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:04:38.483062 43430 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:04:38.484740 43430 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 288, 2982617, 5],"float32"),Tensor([1, 32, 2982617, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 288, 2982617, 5],"float32"),Tensor([1, 32, 2982617, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 40903 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:05:45.615720 43821 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:05:45.616865 43821 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 288, 2982617, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 288, 2982617, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 95732 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:06:54.293846 44123 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:06:54.294865 44123 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 288, 5, 2982617],"float32"),Tensor([1, 32, 5, 2982617],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 288, 5, 2982617],"float32"),Tensor([1, 32, 5, 2982617],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 146280 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:08:03.936167 44411 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:08:03.937294 44411 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 288, 5, 2982617],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 288, 5, 2982617],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 35521 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:09:21.441296 44802 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:09:21.442291 44802 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 288, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 288, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 97553 has 1016.00 MiB memory in use. Of the allocated memory 28.50 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:10:32.565431 45119 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:10:32.566421 45119 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 288, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 288, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 145881 has 1016.00 MiB memory in use. Of the allocated memory 28.50 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:11:42.316743 45515 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:11:42.317718 45515 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 288, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 288, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 40991 has 1016.00 MiB memory in use. Of the allocated memory 28.50 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:12:53.762005 45803 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:12:53.762991 45803 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 288, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 288, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 89317 has 1016.00 MiB memory in use. Of the allocated memory 28.50 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:14:02.009645 46113 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:14:02.010718 46113 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 3, 256, 256],"float32"),Tensor([1, 10, 1677722, 256],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([1, 3, 256, 256],"float32"),Tensor([1, 10, 1677722, 256],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 142603 has 1016.00 MiB memory in use. Of the allocated memory 768.00 KiB is allocated by PyTorch, and 1.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:15:27.760089 46418 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:15:27.761015 46418 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 3, 256, 256],"float32"),Tensor([1, 10, 256, 1677722],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([1, 3, 256, 256],"float32"),Tensor([1, 10, 256, 1677722],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 40631 has 1016.00 MiB memory in use. Of the allocated memory 768.00 KiB is allocated by PyTorch, and 1.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:16:37.380012 46822 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:16:37.380918 46822 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 3, 256, 256],"float32"),Tensor([1, 65536, 256, 256],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([1, 3, 256, 256],"float32"),Tensor([1, 65536, 256, 256],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 104571 has 1016.00 MiB memory in use. Of the allocated memory 768.00 KiB is allocated by PyTorch, and 1.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:17:45.662885 47190 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:17:45.663743 47190 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 3, 256, 256],"float32"),Tensor([6554, 10, 256, 256],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([1, 3, 256, 256],"float32"),Tensor([6554, 10, 256, 256],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 151205 has 1016.00 MiB memory in use. Of the allocated memory 768.00 KiB is allocated by PyTorch, and 1.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:18:57.523597 47501 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:18:57.524479 47501 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 3, 256, 5592406],"float32"),Tensor([1, 10, 256, 256],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([1, 3, 256, 5592406],"float32"),Tensor([1, 10, 256, 256],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 43082 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:20:07.108098 47808 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:20:07.109671 47808 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 3, 256, 5592406],"float32"),Tensor([1, 10, 256, 5592406],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([1, 3, 256, 5592406],"float32"),Tensor([1, 10, 256, 5592406],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 98176 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:21:12.982113 48215 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:21:12.983227 48215 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 3, 32, 32],"float32"),Tensor([1, 10, 13421773, 32],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([1, 3, 32, 32],"float32"),Tensor([1, 10, 13421773, 32],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 151002 has 1016.00 MiB memory in use. Of the allocated memory 12.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:22:21.633708 48513 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:22:21.634882 48513 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 3, 32, 32],"float32"),Tensor([1, 10, 32, 13421773],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([1, 3, 32, 32],"float32"),Tensor([1, 10, 32, 13421773],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 38558 has 1016.00 MiB memory in use. Of the allocated memory 12.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:23:34.622370 48831 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:23:34.623507 48831 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 3, 32, 32],"float32"),Tensor([1, 4194304, 32, 32],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([1, 3, 32, 32],"float32"),Tensor([1, 4194304, 32, 32],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 84760 has 1016.00 MiB memory in use. Of the allocated memory 12.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:24:42.563881 49251 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:24:42.564988 49251 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 3, 32, 32],"float32"),Tensor([419431, 10, 32, 32],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([1, 3, 32, 32],"float32"),Tensor([419431, 10, 32, 32],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 143226 has 1016.00 MiB memory in use. Of the allocated memory 12.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:25:49.641500 49555 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:25:49.642477 49555 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 3, 32, 44739243],"float32"),Tensor([1, 10, 32, 32],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([1, 3, 32, 44739243],"float32"),Tensor([1, 10, 32, 32],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28442 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:26:58.290879 49856 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:26:58.292356 49856 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 3, 32, 44739243],"float32"),Tensor([1, 10, 32, 44739243],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([1, 3, 32, 44739243],"float32"),Tensor([1, 10, 32, 44739243],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 82772 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:28:05.626896 50169 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:28:05.628315 50169 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 3, 44739243, 32],"float32"),Tensor([1, 10, 32, 32],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([1, 3, 44739243, 32],"float32"),Tensor([1, 10, 32, 32],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 131832 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:29:13.345315 50562 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:29:13.346768 50562 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 3, 44739243, 32],"float32"),Tensor([1, 10, 44739243, 32],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([1, 3, 44739243, 32],"float32"),Tensor([1, 10, 44739243, 32],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28737 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:30:20.347081 50869 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:30:20.348513 50869 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 3, 5592406, 256],"float32"),Tensor([1, 10, 256, 256],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([1, 3, 5592406, 256],"float32"),Tensor([1, 10, 256, 256],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 74539 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:31:32.171073 51194 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:31:32.172184 51194 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 3, 5592406, 256],"float32"),Tensor([1, 10, 5592406, 256],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([1, 3, 5592406, 256],"float32"),Tensor([1, 10, 5592406, 256],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 122685 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:32:38.345103 51507 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:32:38.346132 51507 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 320, 10, 10],"float32"),Tensor([1, 32, 10, 13421773],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 320, 10, 10],"float32"),Tensor([1, 32, 10, 13421773],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 16274 has 1016.00 MiB memory in use. Of the allocated memory 125.00 KiB is allocated by PyTorch, and 1.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:33:44.499205 51881 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:33:44.500285 51881 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 320, 10, 10],"float32"),Tensor([1, 32, 13421773, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 320, 10, 10],"float32"),Tensor([1, 32, 13421773, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 61019 has 1016.00 MiB memory in use. Of the allocated memory 125.00 KiB is allocated by PyTorch, and 1.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:34:51.497946 52199 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:34:51.498901 52199 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 320, 10, 10],"float32"),Tensor([1, 42949673, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 320, 10, 10],"float32"),Tensor([1, 42949673, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 107599 has 1016.00 MiB memory in use. Of the allocated memory 125.00 KiB is allocated by PyTorch, and 1.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:36:03.513020 52512 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:36:03.514112 52512 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 320, 10, 10],"float32"),Tensor([1342178, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 320, 10, 10],"float32"),Tensor([1342178, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 4013 has 1016.00 MiB memory in use. Of the allocated memory 125.00 KiB is allocated by PyTorch, and 1.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:37:12.541930 52917 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:37:12.542991 52917 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 320, 10, 1342178],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 320, 10, 1342178],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 66464 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:38:21.169890 53259 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:38:21.171411 53259 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 320, 10, 1342178],"float32"),Tensor([1, 32, 10, 1342178],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 320, 10, 1342178],"float32"),Tensor([1, 32, 10, 1342178],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 117034 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:39:34.001113 53566 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:39:34.002128 53566 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 320, 1342178, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 320, 1342178, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 1581 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:40:46.161676 53965 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:40:46.162670 53965 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 320, 1342178, 10],"float32"),Tensor([1, 32, 1342178, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 320, 1342178, 10],"float32"),Tensor([1, 32, 1342178, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 59886 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:41:54.395500 54284 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:41:54.396596 54284 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 320, 2684355, 5],"float32"),Tensor([1, 32, 2684355, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 320, 2684355, 5],"float32"),Tensor([1, 32, 2684355, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 107624 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:43:03.144634 54576 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:43:03.145735 54576 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 320, 2684355, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 320, 2684355, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 160513 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:44:09.977123 54952 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:44:09.978238 54952 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 320, 5, 2684355],"float32"),Tensor([1, 32, 5, 2684355],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 320, 5, 2684355],"float32"),Tensor([1, 32, 5, 2684355],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 55120 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:45:19.419296 55270 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:45:19.420454 55270 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 320, 5, 2684355],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 320, 5, 2684355],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 103191 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:46:26.089550 55576 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:46:26.090530 55576 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 320, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 320, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 154998 has 1016.00 MiB memory in use. Of the allocated memory 31.50 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:47:32.698594 55867 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:47:32.699571 55867 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 320, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 320, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 38154 has 1016.00 MiB memory in use. Of the allocated memory 31.50 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:48:42.336763 56171 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:48:42.337880 56171 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 320, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 320, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 97880 has 1016.00 MiB memory in use. Of the allocated memory 31.50 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:49:54.188454 56578 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:49:54.189441 56578 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 320, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 320, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 145309 has 1016.00 MiB memory in use. Of the allocated memory 31.50 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:51:06.035795 56889 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:51:06.036943 56889 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 352, 10, 10],"float32"),Tensor([1, 32, 10, 13421773],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 352, 10, 10],"float32"),Tensor([1, 32, 10, 13421773],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 40969 has 1016.00 MiB memory in use. Of the allocated memory 137.50 KiB is allocated by PyTorch, and 1.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:52:18.768532 57287 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:52:18.769615 57287 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 352, 10, 10],"float32"),Tensor([1, 32, 13421773, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 352, 10, 10],"float32"),Tensor([1, 32, 13421773, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 95847 has 1016.00 MiB memory in use. Of the allocated memory 137.50 KiB is allocated by PyTorch, and 1.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:53:28.569391 57612 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:53:28.570286 57612 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 352, 10, 10],"float32"),Tensor([1, 42949673, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 352, 10, 10],"float32"),Tensor([1, 42949673, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 147435 has 1016.00 MiB memory in use. Of the allocated memory 137.50 KiB is allocated by PyTorch, and 1.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:54:36.950011 57917 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:54:36.950949 57917 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 352, 10, 10],"float32"),Tensor([1342178, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 352, 10, 10],"float32"),Tensor([1342178, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 36615 has 1016.00 MiB memory in use. Of the allocated memory 137.50 KiB is allocated by PyTorch, and 1.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:55:49.468398 58300 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:55:49.469372 58300 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 352, 10, 1220162],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 352, 10, 1220162],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 91938 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:57:00.026623 58621 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:57:00.027658 58621 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 352, 10, 1220162],"float32"),Tensor([1, 32, 10, 1220162],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 352, 10, 1220162],"float32"),Tensor([1, 32, 10, 1220162],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 146477 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:58:07.823089 58929 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:58:07.824245 58929 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 352, 1220162, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 352, 1220162, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 42047 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:59:16.890401 59309 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:59:16.891546 59309 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 352, 1220162, 10],"float32"),Tensor([1, 32, 1220162, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 352, 1220162, 10],"float32"),Tensor([1, 32, 1220162, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 92411 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:00:28.053628 59626 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:00:28.054625 59626 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 352, 2440323, 5],"float32"),Tensor([1, 32, 2440323, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 352, 2440323, 5],"float32"),Tensor([1, 32, 2440323, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 139465 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:01:38.229517 59941 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:01:38.230628 59941 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 352, 2440323, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 352, 2440323, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 33983 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:02:45.655974 60338 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:02:45.657053 60338 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 352, 5, 2440323],"float32"),Tensor([1, 32, 5, 2440323],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 352, 5, 2440323],"float32"),Tensor([1, 32, 5, 2440323],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 79852 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:03:58.645532 60656 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:03:58.646683 60656 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 352, 5, 2440323],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 352, 5, 2440323],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 130512 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:05:05.664040 60955 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:05:05.665365 60955 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 352, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 352, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 17847 has 1016.00 MiB memory in use. Of the allocated memory 34.50 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:06:20.898232 61345 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:06:20.899345 61345 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 352, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 352, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 84977 has 1016.00 MiB memory in use. Of the allocated memory 34.50 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:07:27.973387 61677 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:07:27.974463 61677 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 352, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 352, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 130513 has 1016.00 MiB memory in use. Of the allocated memory 34.50 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:08:34.558315 61965 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:08:34.559243 61965 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 352, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 352, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 16266 has 1016.00 MiB memory in use. Of the allocated memory 34.50 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:09:46.150350 62357 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:09:46.151343 62357 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 384, 10, 10],"float32"),Tensor([1, 32, 10, 13421773],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 384, 10, 10],"float32"),Tensor([1, 32, 10, 13421773],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 76720 has 1016.00 MiB memory in use. Of the allocated memory 150.00 KiB is allocated by PyTorch, and 1.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:10:53.314900 62688 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:10:53.315827 62688 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 384, 10, 10],"float32"),Tensor([1, 32, 13421773, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 384, 10, 10],"float32"),Tensor([1, 32, 13421773, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 125228 has 1016.00 MiB memory in use. Of the allocated memory 150.00 KiB is allocated by PyTorch, and 1.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:11:59.519006 62973 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:11:59.519917 62973 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 384, 10, 10],"float32"),Tensor([1, 42949673, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 384, 10, 10],"float32"),Tensor([1, 42949673, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 12960 has 1016.00 MiB memory in use. Of the allocated memory 150.00 KiB is allocated by PyTorch, and 1.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:13:07.139020 63280 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:13:07.140236 63280 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 384, 10, 10],"float32"),Tensor([1342178, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 384, 10, 10],"float32"),Tensor([1342178, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 69454 has 1016.00 MiB memory in use. Of the allocated memory 150.00 KiB is allocated by PyTorch, and 1.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:14:19.362860 63665 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:14:19.363871 63665 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 384, 10, 1118482],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 384, 10, 1118482],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 121736 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:15:32.592542 63978 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:15:32.593638 63978 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 384, 10, 1118482],"float32"),Tensor([1, 32, 10, 1118482],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 384, 10, 1118482],"float32"),Tensor([1, 32, 10, 1118482],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 7995 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:16:42.904527 64289 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:16:42.905781 64289 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 384, 1118482, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 384, 1118482, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 69107 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:18:02.547238 64686 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:18:02.548344 64686 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 384, 1118482, 10],"float32"),Tensor([1, 32, 1118482, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 384, 1118482, 10],"float32"),Tensor([1, 32, 1118482, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 122391 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:19:09.350626 65010 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:19:09.351742 65010 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 384, 2236963, 5],"float32"),Tensor([1, 32, 2236963, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 384, 2236963, 5],"float32"),Tensor([1, 32, 2236963, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 21616 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:20:16.749174 65416 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:20:16.750365 65416 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 384, 2236963, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 384, 2236963, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 68186 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:21:26.115139 65722 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:21:26.116169 65722 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 384, 5, 2236963],"float32"),Tensor([1, 32, 5, 2236963],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 384, 5, 2236963],"float32"),Tensor([1, 32, 5, 2236963],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 115993 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:22:38.368439 66032 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:22:38.369457 66032 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 384, 5, 2236963],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 384, 5, 2236963],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 10555 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:23:49.120368 66429 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:23:49.121380 66429 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 384, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 384, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 55829 has 1016.00 MiB memory in use. Of the allocated memory 37.50 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:24:55.271387 66741 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:24:55.272413 66741 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 384, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 384, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 103640 has 1016.00 MiB memory in use. Of the allocated memory 37.50 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:26:05.308018 67047 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:26:05.309064 67047 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 384, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 384, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 3861 has 1016.00 MiB memory in use. Of the allocated memory 37.50 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:27:18.292008 67453 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:27:18.293187 67453 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 384, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 384, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 63420 has 1016.00 MiB memory in use. Of the allocated memory 37.50 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:28:30.401563 67777 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:28:30.402545 67777 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4, 10],"float32"),Tensor([1, 4, 10],"float32"),Tensor([1, 4, 1073741824],"float32"),], 0, )
[torch error] paddle.concat(list[Tensor([1, 4, 10],"float32"),Tensor([1, 4, 10],"float32"),Tensor([1, 4, 1073741824],"float32"),], 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 113814 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:29:39.672484 68075 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:29:39.673478 68075 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4, 10],"float32"),Tensor([1, 4, 10],"float32"),Tensor([1, 429496730, 10],"float32"),], 0, )
[torch error] paddle.concat(list[Tensor([1, 4, 10],"float32"),Tensor([1, 4, 10],"float32"),Tensor([1, 429496730, 10],"float32"),], 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 7362 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:30:48.503659 68468 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:30:48.504659 68468 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4, 10],"float32"),Tensor([1, 4, 10],"float32"),Tensor([107374183, 4, 10],"float32"),], 0, )
[torch error] paddle.concat(list[Tensor([1, 4, 10],"float32"),Tensor([1, 4, 10],"float32"),Tensor([107374183, 4, 10],"float32"),], 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 54620 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:32:00.631903 68786 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:32:00.632897 68786 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4, 10],"float32"),Tensor([1, 4, 1073741824],"float32"),Tensor([1, 4, 10],"float32"),], 0, )
[torch error] paddle.concat(list[Tensor([1, 4, 10],"float32"),Tensor([1, 4, 1073741824],"float32"),Tensor([1, 4, 10],"float32"),], 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 105071 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:33:12.992655 69098 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:33:12.993793 69098 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4, 10],"float32"),Tensor([1, 429496730, 10],"float32"),Tensor([1, 4, 10],"float32"),], 0, )
[torch error] paddle.concat(list[Tensor([1, 4, 10],"float32"),Tensor([1, 429496730, 10],"float32"),Tensor([1, 4, 10],"float32"),], 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 5733 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:34:25.465332 69510 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:34:25.469514 69510 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4, 10],"float32"),Tensor([107374183, 4, 10],"float32"),Tensor([1, 4, 10],"float32"),], 0, )
[torch error] paddle.concat(list[Tensor([1, 4, 10],"float32"),Tensor([107374183, 4, 10],"float32"),Tensor([1, 4, 10],"float32"),], 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 52539 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:35:38.190690 69841 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:35:38.191820 69841 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4, 1073741824],"float32"),Tensor([1, 4, 10],"float32"),Tensor([1, 4, 10],"float32"),], 0, )
[torch error] paddle.concat(list[Tensor([1, 4, 1073741824],"float32"),Tensor([1, 4, 10],"float32"),Tensor([1, 4, 10],"float32"),], 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 113975 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:36:46.673493 70254 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:36:46.674588 70254 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4, 1073741824],"float32"),Tensor([1, 4, 1073741824],"float32"),Tensor([1, 4, 1073741824],"float32"),], 0, )
[torch error] paddle.concat(list[Tensor([1, 4, 1073741824],"float32"),Tensor([1, 4, 1073741824],"float32"),Tensor([1, 4, 1073741824],"float32"),], 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 7047 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:37:54.728717 70576 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:37:54.729874 70576 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4, 268435456, 4],"float32"),Tensor([1, 4, 268435456, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([1, 4, 268435456, 4],"float32"),Tensor([1, 4, 268435456, 4],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 56290 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:39:02.756711 70895 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:39:02.757766 70895 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4, 268435456, 4],"float32"),Tensor([1, 4, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([1, 4, 268435456, 4],"float32"),Tensor([1, 4, 8, 4],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 111131 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:40:18.256419 71187 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:40:18.257556 71187 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4, 8, 134217728],"float32"),Tensor([1, 4, 8, 134217728],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([1, 4, 8, 134217728],"float32"),Tensor([1, 4, 8, 134217728],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 9361 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:41:25.741200 71605 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:41:25.742202 71605 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4, 8, 134217728],"float32"),Tensor([1, 4, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([1, 4, 8, 134217728],"float32"),Tensor([1, 4, 8, 4],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 60502 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:42:33.814288 71924 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:42:33.815304 71924 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4, 8, 4],"float32"),Tensor([1, 134217728, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([1, 4, 8, 4],"float32"),Tensor([1, 134217728, 8, 4],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 107587 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:43:45.067874 72326 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:43:45.068993 72326 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4, 8, 4],"float32"),Tensor([1, 4, 268435456, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([1, 4, 8, 4],"float32"),Tensor([1, 4, 268435456, 4],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 3154 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:44:54.006019 72647 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:44:54.007108 72647 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4, 8, 4],"float32"),Tensor([1, 4, 8, 134217728],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([1, 4, 8, 4],"float32"),Tensor([1, 4, 8, 134217728],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 48466 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:46:06.282179 72951 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:46:06.283461 72951 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4, 8, 4],"float32"),Tensor([33554432, 4, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([1, 4, 8, 4],"float32"),Tensor([33554432, 4, 8, 4],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 114637 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:47:13.142056 73366 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:47:13.143147 73366 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 416, 10, 10],"float32"),Tensor([1, 32, 10, 13421773],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 416, 10, 10],"float32"),Tensor([1, 32, 10, 13421773],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 4442 has 1016.00 MiB memory in use. Of the allocated memory 162.50 KiB is allocated by PyTorch, and 1.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:48:27.290901 73677 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:48:27.292126 73677 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 416, 10, 10],"float32"),Tensor([1, 32, 13421773, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 416, 10, 10],"float32"),Tensor([1, 32, 13421773, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 53822 has 1016.00 MiB memory in use. Of the allocated memory 162.50 KiB is allocated by PyTorch, and 1.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:49:36.882404 73994 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:49:36.883502 73994 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 416, 10, 10],"float32"),Tensor([1, 42949673, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 416, 10, 10],"float32"),Tensor([1, 42949673, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 107654 has 1016.00 MiB memory in use. Of the allocated memory 162.50 KiB is allocated by PyTorch, and 1.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:50:43.750941 74412 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:50:43.752003 74412 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 416, 10, 10],"float32"),Tensor([1342178, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 416, 10, 10],"float32"),Tensor([1342178, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 157922 has 1016.00 MiB memory in use. Of the allocated memory 162.50 KiB is allocated by PyTorch, and 1.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:51:50.933367 74717 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:51:50.934372 74717 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 416, 10, 1032445],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 416, 10, 1032445],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 40899 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:53:00.057030 75022 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:53:00.058254 75022 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 416, 10, 1032445],"float32"),Tensor([1, 32, 10, 1032445],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 416, 10, 1032445],"float32"),Tensor([1, 32, 10, 1032445],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 89953 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:54:14.919449 75341 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:54:14.920478 75341 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 416, 1032445, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 416, 1032445, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 156220 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:55:21.914152 75746 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:55:21.915167 75746 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 416, 1032445, 10],"float32"),Tensor([1, 32, 1032445, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 416, 1032445, 10],"float32"),Tensor([1, 32, 1032445, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 38693 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:56:29.838949 76050 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:56:29.839941 76050 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 416, 2064889, 5],"float32"),Tensor([1, 32, 2064889, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 416, 2064889, 5],"float32"),Tensor([1, 32, 2064889, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 93460 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:57:37.385321 76383 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:57:37.386525 76383 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 416, 2064889, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 416, 2064889, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 150603 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:59:14.258600 76777 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:59:14.260476 76777 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 416, 5, 2064889],"float32"),Tensor([1, 32, 5, 2064889],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 416, 5, 2064889],"float32"),Tensor([1, 32, 5, 2064889],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 93042 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:00:34.124681 77221 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:00:34.125989 77221 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 416, 5, 2064889],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 416, 5, 2064889],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 146715 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:02:16.860757 77612 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:02:16.862329 77612 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 416, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 416, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 82891 has 1016.00 MiB memory in use. Of the allocated memory 41.00 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:04:25.443878 78025 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:04:25.445725 78025 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 416, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 416, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28904 has 1016.00 MiB memory in use. Of the allocated memory 41.00 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:06:28.888608 78569 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:06:28.890151 78569 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 416, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 416, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 135966 has 1016.00 MiB memory in use. Of the allocated memory 41.00 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:08:22.363613 79198 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:08:22.364748 79198 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 416, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 416, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 72655 has 1016.00 MiB memory in use. Of the allocated memory 41.00 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:09:41.061401 79637 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:09:41.062491 79637 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4194304, 32, 32],"float32"),Tensor([1, 10, 32, 32],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([1, 4194304, 32, 32],"float32"),Tensor([1, 10, 32, 32],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 137443 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:10:59.491531 80033 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:10:59.492658 80033 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4194304, 32, 32],"float32"),Tensor([1, 4194304, 32, 32],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([1, 4194304, 32, 32],"float32"),Tensor([1, 4194304, 32, 32],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 25645 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:12:10.050689 80351 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:12:10.051707 80351 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4294967295, 1],"float16"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 4294967295, 1],"float16"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 95171 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:13:35.562528 80726 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:13:35.564576 80726 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4294967295, 1],"float32"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 4294967295, 1],"float32"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 155085 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:14:51.225461 81123 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:14:51.226811 81123 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4294967295, 1],"int32"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 4294967295, 1],"int32"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 50681 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:15:58.606871 81455 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:15:58.607899 81455 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4294967295],"float16"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 4294967295],"float16"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 102181 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:17:21.529650 81755 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:17:21.531175 81755 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4294967295],"float16"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 4294967295],"float16"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 11324 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:18:48.325624 82173 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:18:48.326843 82173 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4294967295],"float32"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 4294967295],"float32"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 74379 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:19:56.729090 82610 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:19:56.730391 82610 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4294967295],"float32"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 4294967295],"float32"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 121419 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:21:03.992172 82898 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:21:03.993263 82898 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4294967295],"float32"),Tensor([1, 2],"float32"),], )
[torch error] paddle.concat(list[Tensor([1, 4294967295],"float32"),Tensor([1, 2],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 5170 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:22:21.217846 83281 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:22:21.224639 83281 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4294967295],"float32"),Tensor([1, 2],"float32"),], axis=-2, )
[torch error] paddle.concat(list[Tensor([1, 4294967295],"float32"),Tensor([1, 2],"float32"),], axis=-2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 71929 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:23:35.081847 83620 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:23:35.082846 83620 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4294967295],"float32"),Tensor([1, 4294967295],"float32"),], )
[torch error] paddle.concat(list[Tensor([1, 4294967295],"float32"),Tensor([1, 4294967295],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 120756 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:24:47.887655 84019 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:24:47.888695 84019 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4294967295],"float32"),Tensor([1, 4294967295],"float32"),], axis=-2, )
[torch error] paddle.concat(list[Tensor([1, 4294967295],"float32"),Tensor([1, 4294967295],"float32"),], axis=-2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 15921 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:25:54.492285 84330 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:25:54.493388 84330 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4294967295],"int32"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 4294967295],"int32"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 65034 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:27:01.555117 84637 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:27:01.556178 84637 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 4294967295],"int32"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1, 4294967295],"int32"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 115197 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:28:17.037318 84947 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:28:17.038390 84947 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 42949673, 10, 10],"float32"),Tensor([1, 12, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 42949673, 10, 10],"float32"),Tensor([1, 12, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 20066 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:29:32.935828 85365 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:29:32.936841 85365 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 42949673, 10, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 42949673, 10, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 74112 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:30:41.034219 85676 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:30:41.035297 85676 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 42949673, 10, 10],"float32"),Tensor([1, 42949673, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 42949673, 10, 10],"float32"),Tensor([1, 42949673, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 133715 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:31:49.975864 86076 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:31:49.977035 86076 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 429496730, 10],"float32"),Tensor([1, 4, 10],"float32"),Tensor([1, 4, 10],"float32"),], 0, )
[torch error] paddle.concat(list[Tensor([1, 429496730, 10],"float32"),Tensor([1, 4, 10],"float32"),Tensor([1, 4, 10],"float32"),], 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 17038 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:33:03.367321 86376 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:33:03.368431 86376 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 429496730, 10],"float32"),Tensor([1, 429496730, 10],"float32"),Tensor([1, 429496730, 10],"float32"),], 0, )
[torch error] paddle.concat(list[Tensor([1, 429496730, 10],"float32"),Tensor([1, 429496730, 10],"float32"),Tensor([1, 429496730, 10],"float32"),], 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 65324 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:34:10.911159 86716 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:34:10.912261 86716 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 448, 10, 10],"float32"),Tensor([1, 32, 10, 13421773],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 448, 10, 10],"float32"),Tensor([1, 32, 10, 13421773],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 126727 has 1016.00 MiB memory in use. Of the allocated memory 175.00 KiB is allocated by PyTorch, and 1.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:35:19.969705 87057 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:35:19.970752 87057 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 448, 10, 10],"float32"),Tensor([1, 32, 13421773, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 448, 10, 10],"float32"),Tensor([1, 32, 13421773, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 15917 has 1016.00 MiB memory in use. Of the allocated memory 175.00 KiB is allocated by PyTorch, and 1.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:36:29.658408 87342 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:36:29.659340 87342 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 448, 10, 10],"float32"),Tensor([1, 42949673, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 448, 10, 10],"float32"),Tensor([1, 42949673, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 68767 has 1016.00 MiB memory in use. Of the allocated memory 175.00 KiB is allocated by PyTorch, and 1.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:37:41.206305 87649 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:37:41.207324 87649 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 448, 10, 10],"float32"),Tensor([1342178, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 448, 10, 10],"float32"),Tensor([1342178, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 127967 has 1016.00 MiB memory in use. Of the allocated memory 175.00 KiB is allocated by PyTorch, and 1.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:38:49.806939 88034 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:38:49.807890 88034 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 448, 10, 958699],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 448, 10, 958699],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 13534 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:40:00.174521 88306 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:40:00.175534 88306 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 448, 10, 958699],"float32"),Tensor([1, 32, 10, 958699],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 448, 10, 958699],"float32"),Tensor([1, 32, 10, 958699],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 59165 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:41:10.456527 88621 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:41:10.457664 88621 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 448, 1917397, 5],"float32"),Tensor([1, 32, 1917397, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 448, 1917397, 5],"float32"),Tensor([1, 32, 1917397, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 121214 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:42:22.997794 89035 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:42:22.998801 89035 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 448, 1917397, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 448, 1917397, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 11217 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:43:32.647032 89345 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:43:32.647992 89345 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 448, 5, 1917397],"float32"),Tensor([1, 32, 5, 1917397],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 448, 5, 1917397],"float32"),Tensor([1, 32, 5, 1917397],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 58754 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:44:42.317479 89654 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:44:42.318578 89654 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 448, 5, 1917397],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 448, 5, 1917397],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 119347 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:45:49.687983 90065 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:45:49.689109 90065 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 448, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 448, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 9282 has 1016.00 MiB memory in use. Of the allocated memory 44.00 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:46:56.175585 90339 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:46:56.176577 90339 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 448, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 448, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 57558 has 1016.00 MiB memory in use. Of the allocated memory 44.00 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:48:08.056346 90638 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:48:08.057420 90638 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 448, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 448, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 116484 has 1016.00 MiB memory in use. Of the allocated memory 44.00 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:49:17.739706 91042 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:49:17.740818 91042 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 448, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 448, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 7025 has 1016.00 MiB memory in use. Of the allocated memory 44.00 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:50:29.482920 91322 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:50:29.484089 91322 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 448, 958699, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 448, 958699, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 57517 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:51:39.749387 91614 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:51:39.750499 91614 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 448, 958699, 10],"float32"),Tensor([1, 32, 958699, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 448, 958699, 10],"float32"),Tensor([1, 32, 958699, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 117627 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:52:54.676872 92023 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:52:54.678052 92023 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 477218589, 3, 3],"float32"),Tensor([1, 477218589, 3, 3],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 477218589, 3, 3],"float32"),Tensor([1, 477218589, 3, 3],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28031 has 1014.00 MiB memory in use. Process 42111 has 1.05 GiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:54:04.471378 92303 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:54:04.472501 92303 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 477218589, 3, 3],"float32"),Tensor([1, 48, 3, 3],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 477218589, 3, 3],"float32"),Tensor([1, 48, 3, 3],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 42111 has 1.05 GiB memory in use. Process 77983 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:55:14.259740 92614 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:55:14.260885 92614 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 48, 29826162, 3],"float32"),Tensor([1, 48, 29826162, 3],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 48, 29826162, 3],"float32"),Tensor([1, 48, 29826162, 3],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 42111 has 1.05 GiB memory in use. Process 140110 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:56:23.471635 92902 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:56:23.472718 92902 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 48, 29826162, 3],"float32"),Tensor([1, 48, 3, 3],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 48, 29826162, 3],"float32"),Tensor([1, 48, 3, 3],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 38673 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:57:35.468345 93194 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:57:35.469506 93194 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 48, 3, 29826162],"float32"),Tensor([1, 48, 3, 29826162],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 48, 3, 29826162],"float32"),Tensor([1, 48, 3, 29826162],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 89324 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:58:45.169063 93583 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:58:45.170174 93583 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 48, 3, 29826162],"float32"),Tensor([1, 48, 3, 3],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 48, 3, 29826162],"float32"),Tensor([1, 48, 3, 3],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 151247 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:00:03.123052 93903 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:00:03.124128 93903 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 48, 3, 3],"float32"),Tensor([1, 477218589, 3, 3],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 48, 3, 3],"float32"),Tensor([1, 477218589, 3, 3],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 40148 has 1016.00 MiB memory in use. Of the allocated memory 2.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:01:13.711097 94230 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:01:13.712261 94230 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 48, 3, 3],"float32"),Tensor([1, 48, 29826162, 3],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 48, 3, 3],"float32"),Tensor([1, 48, 29826162, 3],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 105252 has 1016.00 MiB memory in use. Of the allocated memory 2.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:02:25.197598 94628 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:02:25.198707 94628 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 48, 3, 3],"float32"),Tensor([1, 48, 3, 29826162],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 48, 3, 3],"float32"),Tensor([1, 48, 3, 29826162],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 162658 has 1016.00 MiB memory in use. Of the allocated memory 2.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:03:40.924209 94947 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:03:40.925209 94947 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 48, 3, 3],"float32"),Tensor([9942054, 48, 3, 3],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 48, 3, 3],"float32"),Tensor([9942054, 48, 3, 3],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 61335 has 1016.00 MiB memory in use. Of the allocated memory 2.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:04:52.440563 95359 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:04:52.441622 95359 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 480, 10, 10],"float32"),Tensor([1, 32, 10, 13421773],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 480, 10, 10],"float32"),Tensor([1, 32, 10, 13421773],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 110813 has 1016.00 MiB memory in use. Of the allocated memory 187.50 KiB is allocated by PyTorch, and 1.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:06:05.128263 95652 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:06:05.129357 95652 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 480, 10, 10],"float32"),Tensor([1, 32, 13421773, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 480, 10, 10],"float32"),Tensor([1, 32, 13421773, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 1342 has 1016.00 MiB memory in use. Of the allocated memory 187.50 KiB is allocated by PyTorch, and 1.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:07:13.308023 96068 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:07:13.309114 96068 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 480, 10, 10],"float32"),Tensor([1, 42949673, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 480, 10, 10],"float32"),Tensor([1, 42949673, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 63414 has 1016.00 MiB memory in use. Of the allocated memory 187.50 KiB is allocated by PyTorch, and 1.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:08:20.298238 96378 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:08:20.299185 96378 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 480, 10, 10],"float32"),Tensor([1342178, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 480, 10, 10],"float32"),Tensor([1342178, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 120794 has 1016.00 MiB memory in use. Of the allocated memory 187.50 KiB is allocated by PyTorch, and 1.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:09:32.576689 96680 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:09:32.577785 96680 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 480, 10, 894785],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 480, 10, 894785],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 9502 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:10:40.846632 97054 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:10:40.848138 97054 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 480, 10, 894785],"float32"),Tensor([1, 32, 10, 894785],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 480, 10, 894785],"float32"),Tensor([1, 32, 10, 894785],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 68510 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:11:49.611830 97390 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:11:49.612833 97390 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 480, 1789570, 5],"float32"),Tensor([1, 32, 1789570, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 480, 1789570, 5],"float32"),Tensor([1, 32, 1789570, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 120228 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:12:56.797643 97705 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:12:56.798676 97705 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 480, 1789570, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 480, 1789570, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 3987 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:14:08.581751 97995 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:14:08.582880 97995 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 480, 5, 1789570],"float32"),Tensor([1, 32, 5, 1789570],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 480, 5, 1789570],"float32"),Tensor([1, 32, 5, 1789570],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 65103 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:15:25.186126 98391 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:15:25.187258 98391 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 480, 5, 1789570],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 480, 5, 1789570],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 123837 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:16:31.933794 98730 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:16:31.934931 98730 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 480, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 480, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 16132 has 1016.00 MiB memory in use. Of the allocated memory 47.00 KiB is allocated by PyTorch, and 1.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:17:40.507565 99030 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:17:40.508680 99030 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 480, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 480, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 81651 has 1016.00 MiB memory in use. Of the allocated memory 47.00 KiB is allocated by PyTorch, and 1.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:18:49.356089 99421 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:18:49.357121 99421 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 480, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 480, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 131774 has 1016.00 MiB memory in use. Of the allocated memory 47.00 KiB is allocated by PyTorch, and 1.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:20:01.467845 99720 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:20:01.468844 99720 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 480, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 480, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 18021 has 1016.00 MiB memory in use. Of the allocated memory 47.00 KiB is allocated by PyTorch, and 1.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:21:13.779537 100028 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:21:13.780615 100028 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 480, 894785, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 480, 894785, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 79685 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:22:23.120631 100411 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:22:23.122148 100411 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 480, 894785, 10],"float32"),Tensor([1, 32, 894785, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 480, 894785, 10],"float32"),Tensor([1, 32, 894785, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 137832 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:23:30.048677 100729 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:23:30.049676 100729 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 5, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 5, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 5, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 5, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 21688 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:24:14.700843 101028 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:24:14.701974 101028 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 5, 1],"float64"),Tensor([1, 5, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 5, 1],"float64"),Tensor([1, 5, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 57411 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:25:00.027156 101314 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:25:00.028198 101314 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 5, 1],"float64"),Tensor([1, 5, 1],"float64"),Tensor([1, 5, 429496730],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 5, 1],"float64"),Tensor([1, 5, 1],"float64"),Tensor([1, 5, 429496730],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 88093 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:25:45.608026 101486 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:25:45.609083 101486 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 5, 1],"float64"),Tensor([1, 5, 1],"float64"),Tensor([429496730, 5, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 5, 1],"float64"),Tensor([1, 5, 1],"float64"),Tensor([429496730, 5, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 135419 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:26:33.938994 101760 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:26:33.939982 101760 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 5, 1],"float64"),Tensor([1, 5, 429496730],"float64"),Tensor([1, 5, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 5, 1],"float64"),Tensor([1, 5, 429496730],"float64"),Tensor([1, 5, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 6247 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:27:23.003847 102018 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:27:23.005029 102018 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 5, 1],"float64"),Tensor([429496730, 5, 1],"float64"),Tensor([1, 5, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 5, 1],"float64"),Tensor([429496730, 5, 1],"float64"),Tensor([1, 5, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 51001 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:28:13.534525 102210 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:28:13.535631 102210 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 5, 429496730],"float64"),Tensor([1, 5, 1],"float64"),Tensor([1, 5, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 5, 429496730],"float64"),Tensor([1, 5, 1],"float64"),Tensor([1, 5, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 87797 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:29:00.420817 102490 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:29:00.421975 102490 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 5, 429496730],"float64"),Tensor([1, 5, 429496730],"float64"),Tensor([1, 5, 429496730],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1, 5, 429496730],"float64"),Tensor([1, 5, 429496730],"float64"),Tensor([1, 5, 429496730],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 119501 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:29:48.062762 102663 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:29:48.063819 102663 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 5],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 5],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 5],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 5],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 161215 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:30:32.341418 102931 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:30:32.342394 102931 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 5],"float64"),Tensor([1, 5],"float64"),Tensor([1, 2147483649],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 5],"float64"),Tensor([1, 5],"float64"),Tensor([1, 2147483649],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 31495 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:31:20.476820 103116 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:31:20.477804 103116 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 5],"float64"),Tensor([1, 5],"float64"),Tensor([429496730, 5],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 5],"float64"),Tensor([1, 5],"float64"),Tensor([429496730, 5],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 71068 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:32:09.379575 103382 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:32:09.380616 103382 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 5],"float64"),Tensor([429496730, 5],"float64"),Tensor([1, 5],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1, 5],"float64"),Tensor([429496730, 5],"float64"),Tensor([1, 5],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 110883 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:32:59.904592 103673 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:32:59.905709 103673 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 512, 1677722, 5],"float32"),Tensor([1, 32, 1677722, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 512, 1677722, 5],"float32"),Tensor([1, 32, 1677722, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 147096 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:34:14.075030 103854 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:34:14.076129 103854 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 512, 1677722, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 512, 1677722, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 46443 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:35:21.646420 104246 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:35:21.647516 104246 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 512, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 512, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 99303 has 1016.00 MiB memory in use. Of the allocated memory 8.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:36:28.420958 104551 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:36:28.422070 104551 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 512, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 512, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 162339 has 1016.00 MiB memory in use. Of the allocated memory 8.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:37:40.328701 104881 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:37:40.329859 104881 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 512, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 512, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 64393 has 1016.00 MiB memory in use. Of the allocated memory 8.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:38:53.046885 105262 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:38:53.048027 105262 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 512, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 512, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 118399 has 1016.00 MiB memory in use. Of the allocated memory 8.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:40:04.358965 105582 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:40:04.359949 105582 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 512, 2, 4194304],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 512, 2, 4194304],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 2498 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:41:12.512099 105971 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:41:12.513135 105971 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 512, 2, 4194304],"float32"),Tensor([1, 32, 2, 4194304],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 512, 2, 4194304],"float32"),Tensor([1, 32, 2, 4194304],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 65104 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:42:20.336410 106277 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:42:20.337599 106277 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 512, 4194304, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 512, 4194304, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 116496 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:43:34.499635 106597 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:43:34.500624 106597 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 512, 4194304, 2],"float32"),Tensor([1, 32, 4194304, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 512, 4194304, 2],"float32"),Tensor([1, 32, 4194304, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 8636 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:44:47.193320 107009 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:44:47.194520 107009 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 512, 5, 1677722],"float32"),Tensor([1, 32, 5, 1677722],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 512, 5, 1677722],"float32"),Tensor([1, 32, 5, 1677722],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 69633 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:45:57.197698 107315 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:45:57.198825 107315 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 512, 5, 1677722],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 512, 5, 1677722],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 123283 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:47:03.797924 107646 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:47:03.799031 107646 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 512, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 512, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 10129 has 1016.00 MiB memory in use. Of the allocated memory 50.00 KiB is allocated by PyTorch, and 1.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:48:10.008070 108024 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:48:10.009035 108024 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 512, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 512, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 70152 has 1016.00 MiB memory in use. Of the allocated memory 50.00 KiB is allocated by PyTorch, and 1.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:49:16.408649 108310 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:49:16.409744 108310 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 512, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 512, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 125525 has 1016.00 MiB memory in use. Of the allocated memory 50.00 KiB is allocated by PyTorch, and 1.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:50:24.195348 108601 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:50:24.196354 108601 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 512, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 512, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 15121 has 1016.00 MiB memory in use. Of the allocated memory 50.00 KiB is allocated by PyTorch, and 1.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:51:31.197950 108900 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:51:31.198982 108900 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 544, 1579033, 5],"float32"),Tensor([1, 32, 1579033, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 544, 1579033, 5],"float32"),Tensor([1, 32, 1579033, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 67505 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:52:43.446601 109204 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:52:43.447600 109204 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 544, 1579033, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 544, 1579033, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 129089 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:53:49.834842 109581 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:53:49.835948 109581 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 544, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 544, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 11918 has 1016.00 MiB memory in use. Of the allocated memory 8.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:55:00.903976 109886 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:55:00.905002 109886 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 544, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 544, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 61892 has 1016.00 MiB memory in use. Of the allocated memory 8.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:56:12.395651 110177 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:56:12.396740 110177 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 544, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 544, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 129425 has 1016.00 MiB memory in use. Of the allocated memory 8.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:57:25.136843 110576 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:57:25.138033 110576 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 544, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 544, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 24459 has 1016.00 MiB memory in use. Of the allocated memory 8.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:58:37.363183 110913 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:58:37.364271 110913 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 544, 2, 3947581],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 544, 2, 3947581],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 88412 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:59:47.310155 111294 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:59:47.311303 111294 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 544, 2, 3947581],"float32"),Tensor([1, 32, 2, 3947581],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 544, 2, 3947581],"float32"),Tensor([1, 32, 2, 3947581],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 135922 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:01:03.869092 111601 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:01:03.870121 111601 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 544, 3947581, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 544, 3947581, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 23897 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:02:17.593194 112000 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:02:17.594297 112000 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 544, 3947581, 2],"float32"),Tensor([1, 32, 3947581, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 544, 3947581, 2],"float32"),Tensor([1, 32, 3947581, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 86040 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:03:28.744252 112300 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:03:28.745378 112300 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 544, 5, 1579033],"float32"),Tensor([1, 32, 5, 1579033],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 544, 5, 1579033],"float32"),Tensor([1, 32, 5, 1579033],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 143581 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:04:34.787995 112577 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:04:34.788995 112577 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 544, 5, 1579033],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 544, 5, 1579033],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 33968 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:05:52.477888 112962 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:05:52.479001 112962 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 544, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 544, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 99370 has 1016.00 MiB memory in use. Of the allocated memory 53.50 KiB is allocated by PyTorch, and 1.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:07:03.650537 113266 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:07:03.654505 113266 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 544, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 544, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 151282 has 1016.00 MiB memory in use. Of the allocated memory 53.50 KiB is allocated by PyTorch, and 1.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:08:16.541769 113632 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:08:16.542783 113632 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 544, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 544, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 52265 has 1016.00 MiB memory in use. Of the allocated memory 53.50 KiB is allocated by PyTorch, and 1.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:09:30.909091 113942 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:09:30.910128 113942 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 544, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 544, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 109780 has 1016.00 MiB memory in use. Of the allocated memory 53.50 KiB is allocated by PyTorch, and 1.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:10:37.987227 114240 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:10:37.988174 114240 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 576, 1491309, 5],"float32"),Tensor([1, 32, 1491309, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 576, 1491309, 5],"float32"),Tensor([1, 32, 1491309, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 7161 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:11:49.691780 114619 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:11:49.692821 114619 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 576, 1491309, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 576, 1491309, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 57781 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:12:59.341895 114925 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:12:59.342960 114925 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 576, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 576, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 107027 has 1016.00 MiB memory in use. Of the allocated memory 9.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:14:06.202450 115223 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:14:06.203459 115223 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 576, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 576, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 159143 has 1016.00 MiB memory in use. Of the allocated memory 9.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:15:18.610474 115607 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:15:18.611598 115607 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 576, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 576, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 53492 has 1016.00 MiB memory in use. Of the allocated memory 9.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:16:28.222116 115904 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:16:28.223157 115904 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 576, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 576, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 118762 has 1016.00 MiB memory in use. Of the allocated memory 9.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:17:36.262207 116198 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:17:36.263212 116198 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 576, 2, 3728271],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 576, 2, 3728271],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 7077 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:18:44.071755 116575 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:18:44.072782 116575 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 576, 2, 3728271],"float32"),Tensor([1, 32, 2, 3728271],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 576, 2, 3728271],"float32"),Tensor([1, 32, 2, 3728271],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 64629 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:19:51.642695 116868 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:19:51.643725 116868 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 576, 3728271, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 576, 3728271, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 112213 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:20:57.706727 117152 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:20:57.707816 117152 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 576, 3728271, 2],"float32"),Tensor([1, 32, 3728271, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 576, 3728271, 2],"float32"),Tensor([1, 32, 3728271, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 2699 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:22:13.212337 117438 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:22:13.213382 117438 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 576, 5, 1491309],"float32"),Tensor([1, 32, 5, 1491309],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 576, 5, 1491309],"float32"),Tensor([1, 32, 5, 1491309],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 65859 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:23:20.865401 117838 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:23:20.866425 117838 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 576, 5, 1491309],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 576, 5, 1491309],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 118676 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:24:33.354871 118144 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:24:33.355955 118144 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 576, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 576, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 13377 has 1016.00 MiB memory in use. Of the allocated memory 56.50 KiB is allocated by PyTorch, and 1.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:25:39.208168 118443 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:25:39.209156 118443 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 576, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 576, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 77396 has 1016.00 MiB memory in use. Of the allocated memory 56.50 KiB is allocated by PyTorch, and 1.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:26:45.867535 118827 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:26:45.868465 118827 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 576, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 576, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 130754 has 1016.00 MiB memory in use. Of the allocated memory 56.50 KiB is allocated by PyTorch, and 1.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:27:53.403085 119123 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:27:53.404121 119123 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 576, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 576, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 15968 has 1016.00 MiB memory in use. Of the allocated memory 56.50 KiB is allocated by PyTorch, and 1.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:29:01.366564 119418 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:29:01.367539 119418 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 608, 1412819, 5],"float32"),Tensor([1, 32, 1412819, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 608, 1412819, 5],"float32"),Tensor([1, 32, 1412819, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 67730 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:30:15.388057 119709 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:30:15.389101 119709 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 608, 1412819, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 608, 1412819, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 131257 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:31:22.505615 120107 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:31:22.506807 120107 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 608, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 608, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 19695 has 1016.00 MiB memory in use. Of the allocated memory 9.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:32:33.555358 120399 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:32:33.556427 120399 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 608, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 608, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 77025 has 1016.00 MiB memory in use. Of the allocated memory 9.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:33:40.629143 120776 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:33:40.630213 120776 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 608, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 608, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 137344 has 1016.00 MiB memory in use. Of the allocated memory 9.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:34:47.812831 121054 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:34:47.813925 121054 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 608, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 608, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 23857 has 1016.00 MiB memory in use. Of the allocated memory 9.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:35:56.312845 121359 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:35:56.313928 121359 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 608, 2, 3532046],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 608, 2, 3532046],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 78625 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:37:08.087821 121644 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:37:08.088943 121644 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 608, 2, 3532046],"float32"),Tensor([1, 32, 2, 3532046],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 608, 2, 3532046],"float32"),Tensor([1, 32, 2, 3532046],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 146937 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:38:17.759873 122045 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:38:17.760975 122045 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 608, 3532046, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 608, 3532046, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 37139 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:39:27.858271 122342 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:39:27.859378 122342 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 608, 3532046, 2],"float32"),Tensor([1, 32, 3532046, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 608, 3532046, 2],"float32"),Tensor([1, 32, 3532046, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 96214 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:40:39.396823 122635 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:40:39.397826 122635 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 608, 5, 1412819],"float32"),Tensor([1, 32, 5, 1412819],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 608, 5, 1412819],"float32"),Tensor([1, 32, 5, 1412819],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 157092 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:41:50.765408 122999 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:41:50.766418 122999 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 608, 5, 1412819],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 608, 5, 1412819],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 47388 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:43:02.977094 123308 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:43:02.978224 123308 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 608, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 608, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 98639 has 1016.00 MiB memory in use. Of the allocated memory 59.50 KiB is allocated by PyTorch, and 1.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:44:09.320299 123613 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:44:09.321244 123613 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 608, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 608, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 157800 has 1016.00 MiB memory in use. Of the allocated memory 59.50 KiB is allocated by PyTorch, and 1.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:45:16.771588 124006 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:45:16.772637 124006 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 608, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 608, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 46350 has 1016.00 MiB memory in use. Of the allocated memory 59.50 KiB is allocated by PyTorch, and 1.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:46:25.017791 124298 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:46:25.018898 124298 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 608, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 608, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 108272 has 1016.00 MiB memory in use. Of the allocated memory 59.50 KiB is allocated by PyTorch, and 1.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:47:33.897665 124595 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:47:33.898780 124595 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 64, 20, 20],"float32"),Tensor([1, 10737419, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 64, 20, 20],"float32"),Tensor([1, 10737419, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 160290 has 1016.00 MiB memory in use. Of the allocated memory 100.00 KiB is allocated by PyTorch, and 1.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:48:43.102099 124980 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:48:43.103248 124980 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 64, 20, 20],"float32"),Tensor([1, 32, 20, 6710887],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 64, 20, 20],"float32"),Tensor([1, 32, 20, 6710887],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 61388 has 1016.00 MiB memory in use. Of the allocated memory 100.00 KiB is allocated by PyTorch, and 1.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:49:51.664933 125284 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:49:51.665974 125284 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 64, 20, 20],"float32"),Tensor([1, 32, 6710887, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 64, 20, 20],"float32"),Tensor([1, 32, 6710887, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 111737 has 1016.00 MiB memory in use. Of the allocated memory 100.00 KiB is allocated by PyTorch, and 1.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:50:57.631866 125589 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:50:57.632990 125589 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 64, 20, 20],"float32"),Tensor([335545, 32, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 64, 20, 20],"float32"),Tensor([335545, 32, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 161150 has 1016.00 MiB memory in use. Of the allocated memory 100.00 KiB is allocated by PyTorch, and 1.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:52:04.809567 125909 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:52:04.810787 125909 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 64, 20, 3355444],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 64, 20, 3355444],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 49857 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:53:13.014989 126296 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:53:13.016495 126296 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 64, 20, 3355444],"float32"),Tensor([1, 32, 20, 3355444],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 64, 20, 3355444],"float32"),Tensor([1, 32, 20, 3355444],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 115972 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:54:25.054342 126601 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:54:25.055356 126601 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 64, 3355444, 20],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 64, 3355444, 20],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 8075 has 1014.00 MiB memory in use. Process 28360 has 1.05 GiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:55:32.178315 126912 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:55:32.179816 126912 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 64, 3355444, 20],"float32"),Tensor([1, 32, 3355444, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 64, 3355444, 20],"float32"),Tensor([1, 32, 3355444, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 62190 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:56:43.460162 127217 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:56:43.461182 127217 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 640, 1342178, 5],"float32"),Tensor([1, 32, 1342178, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 640, 1342178, 5],"float32"),Tensor([1, 32, 1342178, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 131930 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:57:50.750556 127627 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:57:50.752091 127627 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 640, 1342178, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 640, 1342178, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 17923 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:58:56.714474 127932 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:58:56.715462 127932 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 640, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 640, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 70467 has 1016.00 MiB memory in use. Of the allocated memory 10.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:00:07.426445 128231 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:00:07.427418 128231 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 640, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 640, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 130449 has 1016.00 MiB memory in use. Of the allocated memory 10.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:01:15.445873 128644 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:01:15.446952 128644 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 640, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 640, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 20520 has 1016.00 MiB memory in use. Of the allocated memory 10.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:02:26.837075 128950 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:02:26.838133 128950 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 640, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 640, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 80117 has 1016.00 MiB memory in use. Of the allocated memory 10.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:03:34.326973 129255 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:03:34.328042 129255 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 640, 2, 3355444],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 640, 2, 3355444],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 132000 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:04:42.584129 129649 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:04:42.585186 129649 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 640, 2, 3355444],"float32"),Tensor([1, 32, 2, 3355444],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 640, 2, 3355444],"float32"),Tensor([1, 32, 2, 3355444],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 28850 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:05:54.660496 129957 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:05:54.661576 129957 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 640, 3355444, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 640, 3355444, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 86368 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:07:02.500200 130268 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:07:02.501605 130268 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 640, 3355444, 2],"float32"),Tensor([1, 32, 3355444, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 640, 3355444, 2],"float32"),Tensor([1, 32, 3355444, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 137786 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:08:16.635932 130586 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:08:16.636937 130586 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 640, 5, 1342178],"float32"),Tensor([1, 32, 5, 1342178],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 640, 5, 1342178],"float32"),Tensor([1, 32, 5, 1342178],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 44981 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:09:25.448153 130978 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:09:25.462291 130978 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 640, 5, 1342178],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 640, 5, 1342178],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 98954 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:10:39.028656 131276 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:10:39.029860 131276 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 640, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 640, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 4414 has 1016.00 MiB memory in use. Of the allocated memory 62.50 KiB is allocated by PyTorch, and 1.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:11:44.915154 131661 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:11:44.916153 131661 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 640, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 640, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 57100 has 1016.00 MiB memory in use. Of the allocated memory 62.50 KiB is allocated by PyTorch, and 1.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:12:57.886176 131957 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:12:57.887183 131957 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 640, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 640, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 108727 has 1016.00 MiB memory in use. Of the allocated memory 62.50 KiB is allocated by PyTorch, and 1.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:14:04.382623 132270 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:14:04.383606 132270 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 640, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 640, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 157680 has 1016.00 MiB memory in use. Of the allocated memory 62.50 KiB is allocated by PyTorch, and 1.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:15:14.705564 132646 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:15:14.706756 132646 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 65536, 256, 256],"float32"),Tensor([1, 10, 256, 256],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([1, 65536, 256, 256],"float32"),Tensor([1, 10, 256, 256],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 58021 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:16:23.206895 132950 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:16:23.207930 132950 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 65536, 256, 256],"float32"),Tensor([1, 65536, 256, 256],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([1, 65536, 256, 256],"float32"),Tensor([1, 65536, 256, 256],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 117355 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:17:31.020502 133234 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:17:31.021687 133234 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 672, 1278265, 5],"float32"),Tensor([1, 32, 1278265, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 672, 1278265, 5],"float32"),Tensor([1, 32, 1278265, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 9368 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:18:44.176828 133528 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:18:44.178424 133528 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 672, 1278265, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 672, 1278265, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 74848 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:19:56.105872 133923 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:19:56.106949 133923 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 672, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 672, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 127460 has 1016.00 MiB memory in use. Of the allocated memory 10.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:21:02.469894 134237 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:21:02.470988 134237 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 672, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 672, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 13573 has 1016.00 MiB memory in use. Of the allocated memory 10.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:22:09.270256 134541 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:22:09.271342 134541 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 672, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 672, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 75060 has 1016.00 MiB memory in use. Of the allocated memory 10.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:23:17.138751 134931 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:23:17.139748 134931 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 672, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 672, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 126734 has 1016.00 MiB memory in use. Of the allocated memory 10.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:24:29.754360 135223 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:24:29.755398 135223 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 672, 2, 3195661],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 672, 2, 3195661],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 26749 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:25:37.987017 135520 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:25:37.988432 135520 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 672, 2, 3195661],"float32"),Tensor([1, 32, 2, 3195661],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 672, 2, 3195661],"float32"),Tensor([1, 32, 2, 3195661],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 92582 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:26:45.657125 135913 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:26:45.658274 135913 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 672, 3195661, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 672, 3195661, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 146033 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:27:57.734613 136198 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:27:57.735695 136198 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 672, 3195661, 2],"float32"),Tensor([1, 32, 3195661, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 672, 3195661, 2],"float32"),Tensor([1, 32, 3195661, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 35286 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:29:05.304111 136505 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:29:05.305366 136505 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 672, 5, 1278265],"float32"),Tensor([1, 32, 5, 1278265],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 672, 5, 1278265],"float32"),Tensor([1, 32, 5, 1278265],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 86775 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:30:17.429724 136890 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:30:17.430801 136890 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 672, 5, 1278265],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 672, 5, 1278265],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 151238 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:31:25.005074 137202 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:31:25.006364 137202 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 672, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 672, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 63832 has 1016.00 MiB memory in use. Of the allocated memory 66.00 KiB is allocated by PyTorch, and 1.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:32:47.013657 137473 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:32:47.014786 137473 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 672, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 672, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 44501 has 1016.00 MiB memory in use. Of the allocated memory 66.00 KiB is allocated by PyTorch, and 1.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:34:00.399487 137862 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:34:00.400527 137862 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 672, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 672, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 144070 has 1016.00 MiB memory in use. Of the allocated memory 66.00 KiB is allocated by PyTorch, and 1.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:35:08.336833 138169 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:35:08.337901 138169 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 672, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 672, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 90286 has 1016.00 MiB memory in use. Of the allocated memory 66.00 KiB is allocated by PyTorch, and 1.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:36:19.851330 138539 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:36:19.852443 138539 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 704, 1220162, 5],"float32"),Tensor([1, 32, 1220162, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 704, 1220162, 5],"float32"),Tensor([1, 32, 1220162, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 33950 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:37:29.231225 138853 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:37:29.232223 138853 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 704, 1220162, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 704, 1220162, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 123138 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:38:37.468410 139166 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:38:37.469691 139166 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 704, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 704, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 38963 has 1016.00 MiB memory in use. Of the allocated memory 11.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:39:44.334507 139544 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:39:44.338642 139544 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 704, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 704, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 138771 has 1016.00 MiB memory in use. Of the allocated memory 11.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:40:52.678572 139832 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:40:52.679553 139832 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 704, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 704, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 53482 has 1016.00 MiB memory in use. Of the allocated memory 11.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:42:04.308686 140122 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:42:04.309638 140122 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 704, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 704, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 131185 has 1016.00 MiB memory in use. Of the allocated memory 11.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:43:16.230415 140508 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:43:16.231470 140508 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 704, 2, 3050403],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 704, 2, 3050403],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 65803 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:44:27.983448 140807 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:44:27.984560 140807 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 704, 2, 3050403],"float32"),Tensor([1, 32, 2, 3050403],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 704, 2, 3050403],"float32"),Tensor([1, 32, 2, 3050403],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 146339 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:45:35.188891 141113 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:45:35.189962 141113 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 704, 3050403, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 704, 3050403, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 62753 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:46:47.162820 141490 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:46:47.163892 141490 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 704, 3050403, 2],"float32"),Tensor([1, 32, 3050403, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 704, 3050403, 2],"float32"),Tensor([1, 32, 3050403, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 2150 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:47:58.446326 141788 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:47:58.447387 141788 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 704, 5, 1220162],"float32"),Tensor([1, 32, 5, 1220162],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 704, 5, 1220162],"float32"),Tensor([1, 32, 5, 1220162],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 101141 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:49:11.099148 142066 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:49:11.100272 142066 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 704, 5, 1220162],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 704, 5, 1220162],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 88282 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:50:22.742576 142466 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:50:22.743742 142466 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 704, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 704, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 73448 has 1016.00 MiB memory in use. Of the allocated memory 69.00 KiB is allocated by PyTorch, and 1.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:51:31.168417 142770 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:51:31.169497 142770 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 704, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 704, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 45067 has 1016.00 MiB memory in use. Of the allocated memory 69.00 KiB is allocated by PyTorch, and 1.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:52:38.524902 143062 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:52:38.525935 143062 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 704, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 704, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 5770 has 1016.00 MiB memory in use. Of the allocated memory 69.00 KiB is allocated by PyTorch, and 1.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:53:46.541301 143442 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:53:46.542387 143442 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 704, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 704, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 81751 has 1016.00 MiB memory in use. Of the allocated memory 69.00 KiB is allocated by PyTorch, and 1.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:54:58.981575 143720 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:54:58.982733 143720 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 736, 1167111, 5],"float32"),Tensor([1, 32, 1167111, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 736, 1167111, 5],"float32"),Tensor([1, 32, 1167111, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 160639 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:56:14.688624 144025 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:56:14.689775 144025 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 736, 1167111, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 736, 1167111, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 108691 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:57:26.739686 144414 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:57:26.740846 144414 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 736, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 736, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 30605 has 1016.00 MiB memory in use. Of the allocated memory 11.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:58:38.453819 144708 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:58:38.454908 144708 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 736, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 736, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 139449 has 1016.00 MiB memory in use. Of the allocated memory 11.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:59:46.407399 145075 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:59:46.408531 145075 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 736, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 736, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 52007 has 1016.00 MiB memory in use. Of the allocated memory 11.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:01:00.902841 145368 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:01:00.903961 145368 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 736, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 736, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 132525 has 1016.00 MiB memory in use. Of the allocated memory 11.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:02:08.102715 145689 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:02:08.103772 145689 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 736, 2, 2917777],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 736, 2, 2917777],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 66973 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:03:21.647024 146077 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:03:21.648152 146077 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 736, 2, 2917777],"float32"),Tensor([1, 32, 2, 2917777],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 736, 2, 2917777],"float32"),Tensor([1, 32, 2, 2917777],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 147567 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:04:32.111935 146374 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:04:32.113013 146374 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 736, 2917777, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 736, 2917777, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 66248 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:05:45.505977 146683 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:05:45.507094 146683 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 736, 2917777, 2],"float32"),Tensor([1, 32, 2917777, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 736, 2917777, 2],"float32"),Tensor([1, 32, 2917777, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 12696 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:06:58.257429 147069 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:06:58.258504 147069 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 736, 5, 1167111],"float32"),Tensor([1, 32, 5, 1167111],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 736, 5, 1167111],"float32"),Tensor([1, 32, 5, 1167111],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 93608 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:08:07.560133 147383 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:08:07.561278 147383 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 736, 5, 1167111],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 736, 5, 1167111],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 29130 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:09:20.082247 147790 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:09:20.083359 147790 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 736, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 736, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 111146 has 1016.00 MiB memory in use. Of the allocated memory 72.00 KiB is allocated by PyTorch, and 1.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:10:29.006558 148096 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:10:29.007658 148096 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 736, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 736, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 32641 has 1016.00 MiB memory in use. Of the allocated memory 72.00 KiB is allocated by PyTorch, and 1.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:11:36.500048 148377 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:11:36.501070 148377 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 736, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 736, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 133360 has 1016.00 MiB memory in use. Of the allocated memory 72.00 KiB is allocated by PyTorch, and 1.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:12:44.877848 148767 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:12:44.878847 148767 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 736, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 736, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 54398 has 1016.00 MiB memory in use. Of the allocated memory 72.00 KiB is allocated by PyTorch, and 1.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:13:54.851121 149052 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:13:54.852206 149052 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 768, 1118482, 5],"float32"),Tensor([1, 32, 1118482, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 768, 1118482, 5],"float32"),Tensor([1, 32, 1118482, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 131566 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:15:07.256429 149358 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:15:07.257535 149358 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 768, 1118482, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 768, 1118482, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 59943 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:16:18.650117 149736 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:16:18.651261 149736 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 768, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 768, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 149226 has 1016.00 MiB memory in use. Of the allocated memory 12.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:17:25.475638 150038 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:17:25.476641 150038 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 768, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 768, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 63763 has 1016.00 MiB memory in use. Of the allocated memory 12.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:18:36.701511 150322 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:18:36.702687 150322 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 768, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 768, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 6945 has 1016.00 MiB memory in use. Of the allocated memory 12.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:19:44.134945 150720 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:19:44.136016 150720 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 768, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 768, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 85315 has 1016.00 MiB memory in use. Of the allocated memory 12.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:20:56.476280 151021 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:20:56.477430 151021 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 768, 2, 2796203],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 768, 2, 2796203],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 163334 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:22:10.536465 151347 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:22:10.537602 151347 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 768, 2, 2796203],"float32"),Tensor([1, 32, 2, 2796203],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 768, 2, 2796203],"float32"),Tensor([1, 32, 2, 2796203],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 100476 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:23:19.839847 151758 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:23:19.840840 151758 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 768, 2796203, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 768, 2796203, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 13763 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:24:27.556962 152078 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:24:27.558094 152078 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 768, 2796203, 2],"float32"),Tensor([1, 32, 2796203, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 768, 2796203, 2],"float32"),Tensor([1, 32, 2796203, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 91110 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:25:36.815145 152384 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:25:36.816267 152384 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 768, 5, 1118482],"float32"),Tensor([1, 32, 5, 1118482],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 768, 5, 1118482],"float32"),Tensor([1, 32, 5, 1118482],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 32770 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:26:44.153570 152775 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:26:44.154649 152775 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 768, 5, 1118482],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 768, 5, 1118482],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 116247 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:27:52.998914 153092 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:27:53.001291 153092 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 768, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 768, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 32488 has 1016.00 MiB memory in use. Of the allocated memory 75.00 KiB is allocated by PyTorch, and 1.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:29:03.907642 153412 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:29:03.908736 153412 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 768, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 768, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 124981 has 1016.00 MiB memory in use. Of the allocated memory 75.00 KiB is allocated by PyTorch, and 1.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:30:11.590741 153803 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:30:11.591760 153803 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 768, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 768, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 49380 has 1016.00 MiB memory in use. Of the allocated memory 75.00 KiB is allocated by PyTorch, and 1.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:31:24.066609 154135 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:31:24.067662 154135 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 768, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 768, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 126827 has 1016.00 MiB memory in use. Of the allocated memory 75.00 KiB is allocated by PyTorch, and 1.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:32:35.963726 154450 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:32:35.964754 154450 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 800, 1073742, 5],"float32"),Tensor([1, 32, 1073742, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 800, 1073742, 5],"float32"),Tensor([1, 32, 1073742, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 67916 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:33:44.327967 154843 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:33:44.329094 154843 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 800, 1073742, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 800, 1073742, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 147175 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:34:57.702706 155148 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:34:57.703826 155148 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 800, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 800, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 60377 has 1016.00 MiB memory in use. Of the allocated memory 12.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:36:03.561365 155466 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:36:03.562379 155466 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 800, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 800, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 152833 has 1016.00 MiB memory in use. Of the allocated memory 12.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:37:19.129953 155853 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:37:19.131063 155853 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 800, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 800, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 81212 has 1016.00 MiB memory in use. Of the allocated memory 12.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:38:27.587792 156206 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:38:27.588747 156206 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 800, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 800, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 2529 has 1016.00 MiB memory in use. Of the allocated memory 12.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:39:42.492444 156512 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:39:42.493549 156512 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 800, 2, 2684355],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 800, 2, 2684355],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 105506 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:40:56.633795 156922 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:40:56.634788 156922 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 800, 2, 2684355],"float32"),Tensor([1, 32, 2, 2684355],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 800, 2, 2684355],"float32"),Tensor([1, 32, 2, 2684355],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 19830 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:42:03.642105 157233 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:42:03.643285 157233 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 800, 2684355, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 800, 2684355, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 106351 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:43:15.937112 157538 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:43:15.938199 157538 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 800, 2684355, 2],"float32"),Tensor([1, 32, 2684355, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 800, 2684355, 2],"float32"),Tensor([1, 32, 2684355, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 34415 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:44:29.449036 157933 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:44:29.450088 157933 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 800, 5, 1073742],"float32"),Tensor([1, 32, 5, 1073742],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 800, 5, 1073742],"float32"),Tensor([1, 32, 5, 1073742],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 121133 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:45:43.139092 158244 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:45:43.140214 158244 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 800, 5, 1073742],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 800, 5, 1073742],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 66415 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:46:55.473503 158658 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:46:55.474611 158658 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 800, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 800, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 146099 has 1016.00 MiB memory in use. Of the allocated memory 78.50 KiB is allocated by PyTorch, and 1.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:48:01.797878 158957 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:48:01.798884 158957 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 800, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 800, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 59181 has 1016.00 MiB memory in use. Of the allocated memory 78.50 KiB is allocated by PyTorch, and 1.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:49:15.941743 159230 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:49:15.942950 159230 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 800, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 800, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 161286 has 1016.00 MiB memory in use. Of the allocated memory 78.50 KiB is allocated by PyTorch, and 1.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:50:27.832743 159645 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:50:27.833735 159645 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 800, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 800, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 76180 has 1016.00 MiB memory in use. Of the allocated memory 78.50 KiB is allocated by PyTorch, and 1.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:51:34.633666 159938 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:51:34.634697 159938 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 832, 1032445, 5],"float32"),Tensor([1, 32, 1032445, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 832, 1032445, 5],"float32"),Tensor([1, 32, 1032445, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 7926 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:52:47.835829 160316 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:52:47.836851 160316 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 832, 1032445, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 832, 1032445, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 95634 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:54:00.273804 160629 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:54:00.274900 160629 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 832, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 832, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 9618 has 1016.00 MiB memory in use. Of the allocated memory 13.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:55:12.884420 160927 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:55:12.885501 160927 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 832, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 832, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 110402 has 1016.00 MiB memory in use. Of the allocated memory 13.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:56:20.360616 161326 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:56:20.361718 161326 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 832, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 832, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 28925 has 1016.00 MiB memory in use. Of the allocated memory 13.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:57:27.533999 161626 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:57:27.534973 161626 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 832, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 832, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 105820 has 1016.00 MiB memory in use. Of the allocated memory 13.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:58:43.702049 161905 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:58:43.703189 161905 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 832, 2, 2581111],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 832, 2, 2581111],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 54134 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:59:58.111534 162293 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:59:58.112748 162293 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 832, 2, 2581111],"float32"),Tensor([1, 32, 2, 2581111],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 832, 2, 2581111],"float32"),Tensor([1, 32, 2, 2581111],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 136061 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:01:05.467108 162621 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:01:05.468569 162621 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 832, 2581111, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 832, 2581111, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 59730 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:02:18.445214 163015 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:02:18.446348 163015 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 832, 2581111, 2],"float32"),Tensor([1, 32, 2581111, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 832, 2581111, 2],"float32"),Tensor([1, 32, 2581111, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 148768 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:03:31.572845 163326 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:03:31.573877 163326 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 832, 5, 1032445],"float32"),Tensor([1, 32, 5, 1032445],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 832, 5, 1032445],"float32"),Tensor([1, 32, 5, 1032445],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 67581 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:04:46.331168 163638 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:04:46.332278 163638 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 832, 5, 1032445],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 832, 5, 1032445],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 9319 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:05:54.939718   717 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:05:54.940742   717 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 832, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 832, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 88986 has 1016.00 MiB memory in use. Of the allocated memory 81.50 KiB is allocated by PyTorch, and 1.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:07:03.381934  1024 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:07:03.382961  1024 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 832, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 832, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 12389 has 1016.00 MiB memory in use. Of the allocated memory 81.50 KiB is allocated by PyTorch, and 1.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:08:12.638968  1404 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:08:12.640400  1404 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 832, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 832, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 105417 has 1016.00 MiB memory in use. Of the allocated memory 81.50 KiB is allocated by PyTorch, and 1.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:09:22.094060  1725 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:09:22.095088  1725 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 832, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 832, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 19776 has 1016.00 MiB memory in use. Of the allocated memory 81.50 KiB is allocated by PyTorch, and 1.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:10:29.853116  2016 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:10:29.854092  2016 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 858993459, 5],"float32"),Tensor([1, 10, 5],"float32"),], )
[torch error] paddle.concat(list[Tensor([1, 858993459, 5],"float32"),Tensor([1, 10, 5],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 98248 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:11:43.642697  2337 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:11:43.643699  2337 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 858993459, 5],"float32"),Tensor([1, 858993459, 5],"float32"),], )
[torch error] paddle.concat(list[Tensor([1, 858993459, 5],"float32"),Tensor([1, 858993459, 5],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 42447 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:12:51.408612  2745 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:12:51.409732  2745 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 864, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 864, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 119333 has 1016.00 MiB memory in use. Of the allocated memory 13.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:13:57.814392  3067 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:13:57.815490  3067 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 864, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 864, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 29816 has 1016.00 MiB memory in use. Of the allocated memory 13.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:15:05.617862  3359 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:15:05.622129  3359 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 864, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 864, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 123956 has 1016.00 MiB memory in use. Of the allocated memory 13.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:16:12.524479  3749 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:16:12.525488  3749 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 864, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 864, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 50341 has 1016.00 MiB memory in use. Of the allocated memory 13.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:17:25.191274  4041 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:17:25.192394  4041 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 864, 2, 2485514],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 864, 2, 2485514],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 132038 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:18:34.406750  4338 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:18:34.407951  4338 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 864, 2, 2485514],"float32"),Tensor([1, 32, 2, 2485514],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 864, 2, 2485514],"float32"),Tensor([1, 32, 2, 2485514],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 56317 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:19:43.802335  4651 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:19:43.803424  4651 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 864, 2485514, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 864, 2485514, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 149898 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:20:50.918479  4914 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:20:50.919488  4914 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 864, 2485514, 2],"float32"),Tensor([1, 32, 2485514, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 864, 2485514, 2],"float32"),Tensor([1, 32, 2485514, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 61531 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:21:57.691700  5206 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:21:57.692983  5206 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 864, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 864, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 136919 has 1016.00 MiB memory in use. Of the allocated memory 84.50 KiB is allocated by PyTorch, and 1.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:23:09.550957  5497 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:23:09.552320  5497 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 864, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 864, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 71247 has 1016.00 MiB memory in use. Of the allocated memory 84.50 KiB is allocated by PyTorch, and 1.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:24:17.984375  5902 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:24:17.985343  5902 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 864, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 864, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 147632 has 1016.00 MiB memory in use. Of the allocated memory 84.50 KiB is allocated by PyTorch, and 1.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:25:25.676239  6195 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:25:25.677274  6195 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 864, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 864, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 58066 has 1016.00 MiB memory in use. Of the allocated memory 84.50 KiB is allocated by PyTorch, and 1.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:26:33.436861  6500 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:26:33.437878  6500 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 864, 5, 994206],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 864, 5, 994206],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 155423 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:27:47.344259  6890 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:27:47.345279  6890 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 864, 5, 994206],"float32"),Tensor([1, 32, 5, 994206],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 864, 5, 994206],"float32"),Tensor([1, 32, 5, 994206],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 83120 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:28:54.773072  7191 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:28:54.774333  7191 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 864, 994206, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 864, 994206, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 161075 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:30:02.271381  7491 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:30:02.272761  7491 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 864, 994206, 5],"float32"),Tensor([1, 32, 994206, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 864, 994206, 5],"float32"),Tensor([1, 32, 994206, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 71534 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:31:25.236254  7808 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:31:25.237504  7808 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 896, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 896, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 12228 has 1016.00 MiB memory in use. Of the allocated memory 14.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:32:32.012956  8209 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:32:32.014063  8209 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 896, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 896, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 92437 has 1016.00 MiB memory in use. Of the allocated memory 14.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:33:40.393952  8487 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:33:40.398629  8487 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 896, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 896, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 32680 has 1016.00 MiB memory in use. Of the allocated memory 14.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:34:53.451906  8893 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:34:53.452944  8893 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 896, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 896, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 109404 has 1016.00 MiB memory in use. Of the allocated memory 14.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:36:06.517985  9188 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:36:06.519069  9188 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 896, 2, 2396746],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 896, 2, 2396746],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 48589 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:37:17.116673  9592 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:37:17.117719  9592 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 896, 2, 2396746],"float32"),Tensor([1, 32, 2, 2396746],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 896, 2, 2396746],"float32"),Tensor([1, 32, 2, 2396746],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 135985 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:38:33.015059  9911 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:38:33.016178  9911 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 896, 2396746, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 896, 2396746, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 64425 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:39:46.978826 10212 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:39:46.979836 10212 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 896, 2396746, 2],"float32"),Tensor([1, 32, 2396746, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 896, 2396746, 2],"float32"),Tensor([1, 32, 2396746, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 162154 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:41:08.705677 10589 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:41:08.706808 10589 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 896, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 896, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 102563 has 1016.00 MiB memory in use. Of the allocated memory 87.50 KiB is allocated by PyTorch, and 1.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:42:15.242050 10994 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:42:15.243235 10994 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 896, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 896, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 15757 has 1016.00 MiB memory in use. Of the allocated memory 87.50 KiB is allocated by PyTorch, and 1.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:43:25.069945 11285 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:43:25.071013 11285 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 896, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 896, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 89950 has 1016.00 MiB memory in use. Of the allocated memory 87.50 KiB is allocated by PyTorch, and 1.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:44:34.580701 11590 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:44:34.581686 11590 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 896, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 896, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 21010 has 1016.00 MiB memory in use. Of the allocated memory 87.50 KiB is allocated by PyTorch, and 1.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:45:48.787750 11982 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:45:48.788898 11982 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 896, 5, 958699],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 896, 5, 958699],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 114640 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:46:57.924541 12287 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:46:57.925657 12287 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 896, 5, 958699],"float32"),Tensor([1, 32, 5, 958699],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 896, 5, 958699],"float32"),Tensor([1, 32, 5, 958699],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 29403 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:48:05.565243 12559 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:48:05.566601 12559 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 896, 958699, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 896, 958699, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 120605 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:49:13.009426 12954 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:49:13.010576 12954 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 896, 958699, 5],"float32"),Tensor([1, 32, 958699, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 896, 958699, 5],"float32"),Tensor([1, 32, 958699, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 45233 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:50:21.708608 13249 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:50:21.709712 13249 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 928, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 928, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 121446 has 1016.00 MiB memory in use. Of the allocated memory 14.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:51:26.855419 13527 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:51:26.856521 13527 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 928, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 928, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 32378 has 1016.00 MiB memory in use. Of the allocated memory 14.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:52:34.097323 13824 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:52:34.098330 13824 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 928, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 928, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 120624 has 1016.00 MiB memory in use. Of the allocated memory 14.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:53:42.291596 14203 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:53:42.292680 14203 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 928, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 928, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 49740 has 1016.00 MiB memory in use. Of the allocated memory 14.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:54:57.198133 14509 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:54:57.199220 14509 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 928, 2, 2314099],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 928, 2, 2314099],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 126881 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:56:11.033674 14821 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:56:11.035048 14821 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 928, 2, 2314099],"float32"),Tensor([1, 32, 2, 2314099],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 928, 2, 2314099],"float32"),Tensor([1, 32, 2, 2314099],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 65486 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:57:20.560038 15186 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:57:20.561069 15186 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 928, 2314099, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 928, 2314099, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 145895 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:58:28.374373 15476 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:58:28.375445 15476 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 928, 2314099, 2],"float32"),Tensor([1, 32, 2314099, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 928, 2314099, 2],"float32"),Tensor([1, 32, 2314099, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 59540 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:59:39.561100 15796 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:59:39.562697 15796 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 928, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 928, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 3271 has 1016.00 MiB memory in use. Of the allocated memory 91.00 KiB is allocated by PyTorch, and 1.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:00:46.397274 16178 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:00:46.398353 16178 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 928, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 928, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 77862 has 1016.00 MiB memory in use. Of the allocated memory 91.00 KiB is allocated by PyTorch, and 1.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:01:53.591989 16469 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:01:53.595968 16469 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 928, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 928, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 153706 has 1016.00 MiB memory in use. Of the allocated memory 91.00 KiB is allocated by PyTorch, and 1.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:02:59.886368 16740 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:02:59.887418 16740 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 928, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 928, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 63243 has 1016.00 MiB memory in use. Of the allocated memory 91.00 KiB is allocated by PyTorch, and 1.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:04:11.666561 17039 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:04:11.667641 17039 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 928, 5, 925640],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 928, 5, 925640],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 4635 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:05:22.115358 17450 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:05:22.116447 17450 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 928, 5, 925640],"float32"),Tensor([1, 32, 5, 925640],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 928, 5, 925640],"float32"),Tensor([1, 32, 5, 925640],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 80080 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:06:30.899361 17755 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:06:30.900476 17755 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 928, 925640, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 928, 925640, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 161350 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:07:43.435689 18066 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:07:43.436781 18066 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 928, 925640, 5],"float32"),Tensor([1, 32, 925640, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 928, 925640, 5],"float32"),Tensor([1, 32, 925640, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 105759 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:08:51.009197 18447 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:08:51.010473 18447 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 96, 20, 20],"float32"),Tensor([1, 10737419, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 96, 20, 20],"float32"),Tensor([1, 10737419, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 21084 has 1016.00 MiB memory in use. Of the allocated memory 150.00 KiB is allocated by PyTorch, and 1.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:10:02.953828 18751 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:10:02.958369 18751 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 96, 20, 20],"float32"),Tensor([1, 32, 20, 6710887],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 96, 20, 20],"float32"),Tensor([1, 32, 20, 6710887],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 105362 has 1016.00 MiB memory in use. Of the allocated memory 150.00 KiB is allocated by PyTorch, and 1.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:11:16.244338 19160 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:11:16.245409 19160 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 96, 20, 20],"float32"),Tensor([1, 32, 6710887, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 96, 20, 20],"float32"),Tensor([1, 32, 6710887, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 35680 has 1016.00 MiB memory in use. Of the allocated memory 150.00 KiB is allocated by PyTorch, and 1.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:12:24.480199 19468 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:12:24.481223 19468 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 96, 20, 20],"float32"),Tensor([335545, 32, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 96, 20, 20],"float32"),Tensor([335545, 32, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 109681 has 1016.00 MiB memory in use. Of the allocated memory 150.00 KiB is allocated by PyTorch, and 1.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:13:32.571611 19759 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:13:32.572533 19759 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 96, 20, 2236963],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 96, 20, 2236963],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 32090 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:14:48.669647 20064 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:14:48.670680 20064 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 96, 20, 2236963],"float32"),Tensor([1, 32, 20, 2236963],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 96, 20, 2236963],"float32"),Tensor([1, 32, 20, 2236963],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 130923 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:16:00.226680 20475 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:16:00.227803 20475 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 96, 2236963, 20],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 96, 2236963, 20],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 46670 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:17:14.980764 20774 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:17:14.981833 20774 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 96, 2236963, 20],"float32"),Tensor([1, 32, 2236963, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 96, 2236963, 20],"float32"),Tensor([1, 32, 2236963, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 150433 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:18:23.581220 21185 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:18:23.582793 21185 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 960, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 960, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 62282 has 1016.00 MiB memory in use. Of the allocated memory 15.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:19:34.901284 21477 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:19:34.902305 21477 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 960, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 960, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 159861 has 1016.00 MiB memory in use. Of the allocated memory 15.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:20:52.498224 21862 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:20:52.499346 21862 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 960, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 960, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 91923 has 1016.00 MiB memory in use. Of the allocated memory 15.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:22:03.393451 22187 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:22:03.394570 22187 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 960, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 960, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 13040 has 1016.00 MiB memory in use. Of the allocated memory 15.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:23:15.108981 22584 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:23:15.110746 22584 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 960, 2, 2236963],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 960, 2, 2236963],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 103508 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:24:33.789835 22888 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:24:33.790792 22888 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 960, 2, 2236963],"float32"),Tensor([1, 32, 2, 2236963],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 960, 2, 2236963],"float32"),Tensor([1, 32, 2, 2236963],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 40589 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:25:46.889272 23305 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:25:46.913260 23305 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 960, 2236963, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 960, 2236963, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 143705 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:26:57.234871 23605 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:26:57.235911 23605 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 960, 2236963, 2],"float32"),Tensor([1, 32, 2236963, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 960, 2236963, 2],"float32"),Tensor([1, 32, 2236963, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 57333 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:28:06.790724 23897 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:28:06.791713 23897 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 960, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 960, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 150818 has 1016.00 MiB memory in use. Of the allocated memory 94.00 KiB is allocated by PyTorch, and 1.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:29:13.550477 24294 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:29:13.551481 24294 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 960, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 960, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 68989 has 1016.00 MiB memory in use. Of the allocated memory 94.00 KiB is allocated by PyTorch, and 1.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:30:23.591970 24587 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:30:23.592954 24587 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 960, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 960, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 146250 has 1016.00 MiB memory in use. Of the allocated memory 94.00 KiB is allocated by PyTorch, and 1.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:31:31.436254 24879 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:31:31.437284 24879 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 960, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 960, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 56434 has 1016.00 MiB memory in use. Of the allocated memory 94.00 KiB is allocated by PyTorch, and 1.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:32:39.881050 25184 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:32:39.882025 25184 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 960, 5, 894785],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 960, 5, 894785],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 163268 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:33:53.506371 25594 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:33:53.507506 25594 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 960, 5, 894785],"float32"),Tensor([1, 32, 5, 894785],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 960, 5, 894785],"float32"),Tensor([1, 32, 5, 894785],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 76100 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:35:00.623837 25914 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:35:00.625003 25914 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 960, 894785, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 960, 894785, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 151354 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:36:08.832391 26206 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:36:08.833385 26206 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 960, 894785, 5],"float32"),Tensor([1, 32, 894785, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 960, 894785, 5],"float32"),Tensor([1, 32, 894785, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 94878 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:37:17.044708 26626 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:37:17.045727 26626 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 992, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 992, 2, 2],"float32"),Tensor([1, 1073741824, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 9189 has 1016.00 MiB memory in use. Of the allocated memory 15.50 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:38:28.582532 26930 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:38:28.583549 26930 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 992, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 992, 2, 2],"float32"),Tensor([1, 32, 2, 67108864],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 88563 has 1016.00 MiB memory in use. Of the allocated memory 15.50 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:39:45.118685 27241 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:39:45.119676 27241 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 992, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 992, 2, 2],"float32"),Tensor([1, 32, 67108864, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 33517 has 1016.00 MiB memory in use. Of the allocated memory 15.50 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:40:55.431320 27632 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:40:55.432276 27632 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 992, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 992, 2, 2],"float32"),Tensor([33554432, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 108518 has 1016.00 MiB memory in use. Of the allocated memory 15.50 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:42:08.809680 27932 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:42:08.810722 27932 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 992, 2, 2164803],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 992, 2, 2164803],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 47189 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:43:17.630450 28318 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:43:17.631574 28318 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 992, 2, 2164803],"float32"),Tensor([1, 32, 2, 2164803],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 992, 2, 2164803],"float32"),Tensor([1, 32, 2, 2164803],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 121420 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:44:31.472287 28636 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:44:31.473299 28636 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 992, 2164803, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 992, 2164803, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 34849 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:45:44.892809 28921 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:45:44.893922 28921 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 992, 2164803, 2],"float32"),Tensor([1, 32, 2164803, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 992, 2164803, 2],"float32"),Tensor([1, 32, 2164803, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 145698 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:46:53.882802 29298 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:46:53.884344 29298 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 992, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 992, 5, 5],"float32"),Tensor([1, 171798692, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 60835 has 1016.00 MiB memory in use. Of the allocated memory 97.00 KiB is allocated by PyTorch, and 1.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:47:59.782789 29603 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:47:59.783767 29603 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 992, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 992, 5, 5],"float32"),Tensor([1, 32, 26843546, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 136901 has 1016.00 MiB memory in use. Of the allocated memory 97.00 KiB is allocated by PyTorch, and 1.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:49:07.056643 29919 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:49:07.057771 29919 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 992, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 992, 5, 5],"float32"),Tensor([1, 32, 5, 26843546],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 67822 has 1016.00 MiB memory in use. Of the allocated memory 97.00 KiB is allocated by PyTorch, and 1.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:50:21.423179 30310 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:50:21.424204 30310 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 992, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 992, 5, 5],"float32"),Tensor([5368710, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 150722 has 1016.00 MiB memory in use. Of the allocated memory 97.00 KiB is allocated by PyTorch, and 1.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:51:34.576100 30637 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:51:34.577114 30637 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 992, 5, 865921],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 992, 5, 865921],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 81326 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:52:43.258087 31035 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:52:43.259635 31035 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 992, 5, 865921],"float32"),Tensor([1, 32, 5, 865921],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 992, 5, 865921],"float32"),Tensor([1, 32, 5, 865921],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 11338 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:53:56.793864 31342 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:53:56.794896 31342 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 992, 865921, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 992, 865921, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 88385 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:55:05.415110 31653 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:55:05.416253 31653 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1, 992, 865921, 5],"float32"),Tensor([1, 32, 865921, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1, 992, 865921, 5],"float32"),Tensor([1, 32, 865921, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 11054 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:56:16.883677 32044 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:56:16.884794 32044 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 102532 has 1016.00 MiB memory in use. Of the allocated memory 49.50 KiB is allocated by PyTorch, and 1.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:57:25.118732 32356 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:57:25.119833 32356 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 18271 has 1016.00 MiB memory in use. Of the allocated memory 49.00 KiB is allocated by PyTorch, and 1.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:58:37.989818 32647 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:58:37.990985 32647 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 123631 has 1016.00 MiB memory in use. Of the allocated memory 48.50 KiB is allocated by PyTorch, and 1.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:59:47.964388 33060 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:59:47.965492 33060 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 40053 has 1016.00 MiB memory in use. Of the allocated memory 48.00 KiB is allocated by PyTorch, and 1.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:00:55.860776 33356 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:00:55.864863 33356 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 114149 has 1016.00 MiB memory in use. Of the allocated memory 47.50 KiB is allocated by PyTorch, and 1.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:02:03.508827 33667 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:02:03.509850 33667 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 34802 has 1016.00 MiB memory in use. Of the allocated memory 47.00 KiB is allocated by PyTorch, and 1.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:03:16.275569 34072 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:03:16.279851 34072 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 125357 has 1016.00 MiB memory in use. Of the allocated memory 46.50 KiB is allocated by PyTorch, and 1.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:04:29.370136 34385 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:04:29.371151 34385 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 38691 has 1016.00 MiB memory in use. Of the allocated memory 46.00 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:05:37.658038 34684 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:05:37.659025 34684 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 144091 has 1016.00 MiB memory in use. Of the allocated memory 45.50 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:06:45.740842 35088 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:06:45.741942 35088 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 63578 has 1016.00 MiB memory in use. Of the allocated memory 45.00 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:07:57.844236 35392 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:07:57.848070 35392 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 145467 has 1016.00 MiB memory in use. Of the allocated memory 44.50 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:09:05.595120 35706 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:09:05.596096 35706 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 69149 has 1016.00 MiB memory in use. Of the allocated memory 44.00 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:10:13.302466 36092 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:10:13.303592 36092 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 156714 has 1016.00 MiB memory in use. Of the allocated memory 43.50 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:11:21.707455 36396 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:11:21.708514 36396 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 68519 has 1016.00 MiB memory in use. Of the allocated memory 43.00 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:12:29.371685 36707 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:12:29.372699 36707 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 144963 has 1016.00 MiB memory in use. Of the allocated memory 42.50 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:13:41.557875 37018 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:13:41.558959 37018 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 86247 has 1016.00 MiB memory in use. Of the allocated memory 42.00 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:14:49.655033 37432 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:14:49.656054 37432 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 163150 has 1016.00 MiB memory in use. Of the allocated memory 41.50 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:16:01.459069 37719 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:16:01.460184 37719 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 83540 has 1016.00 MiB memory in use. Of the allocated memory 41.00 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:17:10.076535 38016 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:17:10.077590 38016 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 17859 has 1016.00 MiB memory in use. Of the allocated memory 40.50 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:18:16.827886 38426 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:18:16.828982 38426 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 94384 has 1016.00 MiB memory in use. Of the allocated memory 40.00 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:19:23.895725 38712 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:19:23.896688 38712 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 6232 has 1016.00 MiB memory in use. Of the allocated memory 39.50 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:20:33.808488 39002 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:20:33.809597 39002 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 93195 has 1016.00 MiB memory in use. Of the allocated memory 39.00 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:21:42.878371 39387 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:21:42.879374 39387 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 23733 has 1016.00 MiB memory in use. Of the allocated memory 38.50 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:22:54.958159 39691 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:22:54.959304 39691 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 101757 has 1016.00 MiB memory in use. Of the allocated memory 38.00 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:24:06.577333 39994 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:24:06.578385 39994 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 38220 has 1016.00 MiB memory in use. Of the allocated memory 37.50 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:25:12.948067 40381 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:25:12.949072 40381 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 116522 has 1016.00 MiB memory in use. Of the allocated memory 37.00 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:26:20.640141 40685 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:26:20.641171 40685 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 34651 has 1016.00 MiB memory in use. Of the allocated memory 36.50 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:27:27.704512 40970 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:27:27.708752 40970 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 108185 has 1016.00 MiB memory in use. Of the allocated memory 36.00 KiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:28:39.678423 41273 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:28:39.679442 41273 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 52075 has 1016.00 MiB memory in use. Of the allocated memory 35.50 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:29:48.004421 41680 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:29:48.005466 41680 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 132330 has 1016.00 MiB memory in use. Of the allocated memory 35.00 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:30:54.892681 41978 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:30:54.893774 41978 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 42655 has 1016.00 MiB memory in use. Of the allocated memory 34.50 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:32:07.589145 42262 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:32:07.593807 42262 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 142517 has 1016.00 MiB memory in use. Of the allocated memory 34.00 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:33:15.850590 42687 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:33:15.851589 42687 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 52601 has 1016.00 MiB memory in use. Of the allocated memory 33.50 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:34:22.560887 42973 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:34:22.561846 42973 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 127359 has 1016.00 MiB memory in use. Of the allocated memory 33.00 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:35:30.471097 43258 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:35:30.472169 43258 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 39207 has 1016.00 MiB memory in use. Of the allocated memory 32.50 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:36:37.974963 43570 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:36:37.976018 43570 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 151451 has 1016.00 MiB memory in use. Of the allocated memory 32.00 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:37:44.957063 43960 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:37:44.958155 43960 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 72342 has 1016.00 MiB memory in use. Of the allocated memory 31.50 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:38:57.939028 44250 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:38:57.940055 44250 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 152701 has 1016.00 MiB memory in use. Of the allocated memory 31.00 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:40:11.018118 44575 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:40:11.019196 44575 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 92715 has 1016.00 MiB memory in use. Of the allocated memory 30.50 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:41:19.210402 44975 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:41:19.211467 44975 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 6373 has 1016.00 MiB memory in use. Of the allocated memory 30.00 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:42:31.055848 45294 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:42:31.056951 45294 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 82058 has 1016.00 MiB memory in use. Of the allocated memory 29.50 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:43:39.103639 45592 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:43:39.108182 45592 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 19203 has 1016.00 MiB memory in use. Of the allocated memory 29.00 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:44:51.391140 46000 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:44:51.392222 46000 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 100259 has 1016.00 MiB memory in use. Of the allocated memory 28.50 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:45:58.640313 46301 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:45:58.644390 46301 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 17115 has 1016.00 MiB memory in use. Of the allocated memory 28.00 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:47:05.425858 46600 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:47:05.426884 46600 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 107202 has 1016.00 MiB memory in use. Of the allocated memory 27.50 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:48:12.481550 47005 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:48:12.482564 47005 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 29853 has 1016.00 MiB memory in use. Of the allocated memory 27.00 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:49:19.926151 47297 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:49:19.927173 47297 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 103999 has 1016.00 MiB memory in use. Of the allocated memory 26.50 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:50:32.718925 47590 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:50:32.720084 47590 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 25678 has 1016.00 MiB memory in use. Of the allocated memory 26.00 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:51:45.536477 47914 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:51:45.537564 47914 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 124359 has 1016.00 MiB memory in use. Of the allocated memory 25.50 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:52:58.073873 48298 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:52:58.074949 48298 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 38472 has 1016.00 MiB memory in use. Of the allocated memory 25.00 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:54:05.669517 48611 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:54:05.670539 48611 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 129023 has 1016.00 MiB memory in use. Of the allocated memory 24.50 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:55:18.567293 49000 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:55:18.568364 49000 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 54466 has 1016.00 MiB memory in use. Of the allocated memory 24.00 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:56:25.863508 49306 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:56:25.867774 49306 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 137154 has 1016.00 MiB memory in use. Of the allocated memory 23.50 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:57:32.076350 49610 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:57:32.077308 49610 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 54739 has 1016.00 MiB memory in use. Of the allocated memory 23.00 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:58:41.137884 49929 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:58:41.138935 49929 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 152475 has 1016.00 MiB memory in use. Of the allocated memory 22.50 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:59:49.150869 50336 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:59:49.151928 50336 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 67203 has 1016.00 MiB memory in use. Of the allocated memory 22.00 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:00:58.450735 50650 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:00:58.451824 50650 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 143375 has 1016.00 MiB memory in use. Of the allocated memory 21.50 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:02:09.630843 50963 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:02:09.634976 50963 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 77644 has 1016.00 MiB memory in use. Of the allocated memory 21.00 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:03:18.079278 51356 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:03:18.080272 51356 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 153939 has 1016.00 MiB memory in use. Of the allocated memory 20.50 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:04:29.512223 51648 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:04:29.513237 51648 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 64943 has 1016.00 MiB memory in use. Of the allocated memory 20.00 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:05:42.003909 51945 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:05:42.005012 51945 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 8351 has 1016.00 MiB memory in use. Of the allocated memory 19.50 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:06:50.563496 52342 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:06:50.564625 52342 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 91335 has 1016.00 MiB memory in use. Of the allocated memory 19.00 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:07:57.585685 52643 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:07:57.586700 52643 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 3573 has 1016.00 MiB memory in use. Of the allocated memory 18.50 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:09:05.941864 52922 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:09:05.946059 52922 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 95084 has 1016.00 MiB memory in use. Of the allocated memory 18.00 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:10:14.349103 53313 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:10:14.350057 53313 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 15737 has 1016.00 MiB memory in use. Of the allocated memory 17.50 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:11:21.471706 53605 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:11:21.472779 53605 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 96652 has 1016.00 MiB memory in use. Of the allocated memory 17.00 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:12:29.389014 53896 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:12:29.389971 53896 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 8356 has 1016.00 MiB memory in use. Of the allocated memory 16.50 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:13:41.968194 54186 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:13:41.969219 54186 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 113012 has 1016.00 MiB memory in use. Of the allocated memory 16.00 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:14:58.021838 54570 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:14:58.022929 54570 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 29616 has 1016.00 MiB memory in use. Of the allocated memory 15.50 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:16:10.612241 54895 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:16:10.613353 54895 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 133953 has 1016.00 MiB memory in use. Of the allocated memory 15.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:17:23.637354 55292 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:17:23.641189 55292 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 49874 has 1016.00 MiB memory in use. Of the allocated memory 14.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:18:38.045944 55604 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:18:38.046927 55604 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 152431 has 1016.00 MiB memory in use. Of the allocated memory 14.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:19:46.768115 56014 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:19:46.769188 56014 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 70370 has 1016.00 MiB memory in use. Of the allocated memory 13.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:21:00.254628 56302 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:21:00.255750 56302 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 148610 has 1016.00 MiB memory in use. Of the allocated memory 13.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:22:08.257038 56613 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:22:08.258013 56613 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 82156 has 1016.00 MiB memory in use. Of the allocated memory 12.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:23:22.040989 56998 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:23:22.042081 56998 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 159749 has 1016.00 MiB memory in use. Of the allocated memory 12.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:24:35.712270 57308 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:24:35.713279 57308 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 89001 has 1016.00 MiB memory in use. Of the allocated memory 11.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:25:48.461820 57707 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:25:48.462900 57707 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 20318 has 1016.00 MiB memory in use. Of the allocated memory 11.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:27:01.323752 58029 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:27:01.324751 58029 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 98371 has 1016.00 MiB memory in use. Of the allocated memory 10.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:28:09.097728 58340 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:28:09.098768 58340 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 35623 has 1016.00 MiB memory in use. Of the allocated memory 10.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:29:17.157099 58733 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:29:17.158165 58733 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 111767 has 1016.00 MiB memory in use. Of the allocated memory 9.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:30:24.325698 59041 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:30:24.326785 59041 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 23597 has 1016.00 MiB memory in use. Of the allocated memory 9.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:31:32.504559 59345 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:31:32.508692 59345 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 105403 has 1016.00 MiB memory in use. Of the allocated memory 8.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:32:47.401939 59665 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:32:47.402947 59665 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 41361 has 1016.00 MiB memory in use. Of the allocated memory 8.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:33:55.213374 60078 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:33:55.214454 60078 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 114936 has 1016.00 MiB memory in use. Of the allocated memory 7.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:35:09.607578 60395 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:35:09.608741 60395 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 50191 has 1016.00 MiB memory in use. Of the allocated memory 7.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:36:19.196452 60821 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:36:19.197445 60821 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 132470 has 1016.00 MiB memory in use. Of the allocated memory 6.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:37:32.050653 61144 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:37:32.051741 61144 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 45921 has 1016.00 MiB memory in use. Of the allocated memory 6.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:38:44.677829 61443 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:38:44.678928 61443 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 147496 has 1016.00 MiB memory in use. Of the allocated memory 5.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:39:57.243721 61873 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:39:57.244848 61873 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 63455 has 1016.00 MiB memory in use. Of the allocated memory 5.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:41:06.253233 62169 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:41:06.254284 62169 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 159478 has 1016.00 MiB memory in use. Of the allocated memory 4.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:42:18.971565 62559 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:42:18.975771 62559 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 75616 has 1016.00 MiB memory in use. Of the allocated memory 4.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:43:31.907578 62883 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:43:31.908635 62883 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 158936 has 1016.00 MiB memory in use. Of the allocated memory 3.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:44:45.112088 63196 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:44:45.113165 63196 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 99511 has 1016.00 MiB memory in use. Of the allocated memory 3.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:45:57.295636 63607 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:45:57.297952 63607 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 16877 has 1016.00 MiB memory in use. Of the allocated memory 2.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:47:10.080397 63931 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:47:10.081386 63931 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 117571 has 1016.00 MiB memory in use. Of the allocated memory 2.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:48:24.225760 64332 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:48:24.226696 64332 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 32958 has 1016.00 MiB memory in use. Of the allocated memory 1.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:49:38.250154 64657 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:49:38.251248 64657 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 132084 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:50:54.865888 65062 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:50:54.866982 65062 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([4294967295],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 52910 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:52:02.355877 65383 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:52:02.357010 65383 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[torch error] paddle.concat(list[Tensor([1],"float32"),Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 132147 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:53:09.619177 65674 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:53:09.620229 65674 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float64"),Tensor([1],"float64"),Tensor([2147483649],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1],"float64"),Tensor([1],"float64"),Tensor([2147483649],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 59671 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:53:59.018564 66080 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:53:59.019726 66080 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float64"),Tensor([2147483649],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1],"float64"),Tensor([2147483649],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 105222 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:54:49.615651 66273 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:54:49.616637 66273 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float64"),Tensor([2147483649],"float64"),Tensor([1],"float64"),], )
[torch error] paddle.concat(list[Tensor([1],"float64"),Tensor([2147483649],"float64"),Tensor([1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 12093 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:55:36.446367 66552 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:55:36.447417 66552 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float64"),Tensor([2147483649],"float64"),Tensor([1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1],"float64"),Tensor([2147483649],"float64"),Tensor([1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 71944 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:56:22.715071 66817 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:56:22.716145 66817 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"float64"),Tensor([511],"float64"),Tensor([2147483649],"float64"),], )
[torch error] paddle.concat(list[Tensor([1],"float64"),Tensor([511],"float64"),Tensor([2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 124007 has 1016.00 MiB memory in use. Of the allocated memory 4.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:57:09.849975 66994 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:57:09.850989 66994 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"int64"),Tensor([1],"int64"),Tensor([2147483649],"int64"),], axis=0, )
[torch error] paddle.concat(list[Tensor([1],"int64"),Tensor([1],"int64"),Tensor([2147483649],"int64"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 28534 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:57:54.355194 67281 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:57:54.356293 67281 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1],"int64"),Tensor([2147483649],"int64"),Tensor([1],"int64"),], axis=0, )
[torch error] paddle.concat(list[Tensor([1],"int64"),Tensor([2147483649],"int64"),Tensor([1],"int64"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 72454 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:58:38.564527 67459 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:58:38.565528 67459 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10, 10],"float32"),Tensor([10, 429496730],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([10, 10],"float32"),Tensor([10, 429496730],"float32"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 134916 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:59:50.371663 67731 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:59:50.372659 67731 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10, 10],"float32"),Tensor([429496730, 10],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([10, 10],"float32"),Tensor([429496730, 10],"float32"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 57975 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:01:02.683614 68034 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:01:02.684576 68034 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10, 2],"float32"),Tensor([10, 429496730],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([10, 2],"float32"),Tensor([10, 429496730],"float32"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 142045 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:02:10.413437 68353 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:02:10.417482 68353 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10, 2],"float32"),Tensor([2147483648, 2],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([10, 2],"float32"),Tensor([2147483648, 2],"float32"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 67672 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:03:23.065747 68725 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:03:23.066772 68725 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10, 429496730],"float32"),Tensor([10, 10],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([10, 429496730],"float32"),Tensor([10, 10],"float32"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 144360 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:04:37.875193 69050 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:04:37.876140 69050 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10, 429496730],"float32"),Tensor([10, 2],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([10, 429496730],"float32"),Tensor([10, 2],"float32"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 76793 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:05:46.641705 69468 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:05:46.642807 69468 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10, 429496730],"float32"),Tensor([10, 429496730],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([10, 429496730],"float32"),Tensor([10, 429496730],"float32"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 163045 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:06:59.483469 69771 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:06:59.484578 69771 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([100, 200],"float32"),Tensor([100, 42949673],"float32"),], )
[torch error] paddle.concat(list[Tensor([100, 200],"float32"),Tensor([100, 42949673],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 79760 has 1016.00 MiB memory in use. Of the allocated memory 78.50 KiB is allocated by PyTorch, and 1.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:08:11.525894 70090 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:08:11.526939 70090 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([100, 200],"float32"),Tensor([21474837, 200],"float32"),], )
[torch error] paddle.concat(list[Tensor([100, 200],"float32"),Tensor([21474837, 200],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 17343 has 1016.00 MiB memory in use. Of the allocated memory 78.50 KiB is allocated by PyTorch, and 1.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:09:24.766350 70502 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:09:24.767444 70502 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([100, 42949673],"float32"),Tensor([100, 200],"float32"),], )
[torch error] paddle.concat(list[Tensor([100, 42949673],"float32"),Tensor([100, 200],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 94546 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:10:34.206732 70815 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:10:34.207901 70815 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([100, 42949673],"float32"),Tensor([100, 42949673],"float32"),], )
[torch error] paddle.concat(list[Tensor([100, 42949673],"float32"),Tensor([100, 42949673],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 14448 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:11:47.118492 71134 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:11:47.119588 71134 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([100],"bfloat16"),Tensor([4294967295],"bfloat16"),], )
[torch error] paddle.concat(list[Tensor([100],"bfloat16"),Tensor([4294967295],"bfloat16"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 112131 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:12:54.513396 71532 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:12:54.514492 71532 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.concat(list[Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([4294967295],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 25023 has 1016.00 MiB memory in use. Of the allocated memory 7.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:14:02.177592 71851 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:14:02.178596 71851 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([4294967295],"float32"),Tensor([10],"float32"),], )
[torch error] paddle.concat(list[Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([4294967295],"float32"),Tensor([10],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 102211 has 1016.00 MiB memory in use. Of the allocated memory 6.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:15:14.390820 72171 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:15:14.391920 72171 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([4294967295],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),], )
[torch error] paddle.concat(list[Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([4294967295],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 39000 has 1016.00 MiB memory in use. Of the allocated memory 6.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:16:26.440188 72560 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:16:26.441286 72560 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([4294967295],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),], )
[torch error] paddle.concat(list[Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([4294967295],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 120942 has 1016.00 MiB memory in use. Of the allocated memory 5.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:17:35.247576 72880 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:17:35.248560 72880 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([4294967295],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),], )
[torch error] paddle.concat(list[Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([4294967295],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 44104 has 1016.00 MiB memory in use. Of the allocated memory 5.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:18:48.935009 73260 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:18:48.936092 73260 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([4294967295],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),], )
[torch error] paddle.concat(list[Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([4294967295],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 141860 has 1016.00 MiB memory in use. Of the allocated memory 4.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:19:58.049979 73574 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:19:58.050911 73574 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([4294967295],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),], )
[torch error] paddle.concat(list[Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([4294967295],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 52325 has 1016.00 MiB memory in use. Of the allocated memory 4.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:21:10.815716 73865 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:21:10.816972 73865 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([4294967295],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),], )
[torch error] paddle.concat(list[Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([4294967295],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 150895 has 1016.00 MiB memory in use. Of the allocated memory 3.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:22:21.193859 74262 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:22:21.194891 74262 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([4294967295],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),], )
[torch error] paddle.concat(list[Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([4294967295],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 61922 has 1016.00 MiB memory in use. Of the allocated memory 3.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:23:31.837327 74560 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:23:31.838284 74560 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([4294967295],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),], )
[torch error] paddle.concat(list[Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([4294967295],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 140640 has 1016.00 MiB memory in use. Of the allocated memory 2.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:24:42.709805 74884 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:24:42.714032 74884 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([4294967295],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),], )
[torch error] paddle.concat(list[Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([4294967295],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 72399 has 1016.00 MiB memory in use. Of the allocated memory 2.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:25:55.301456 75263 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:25:55.302526 75263 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([4294967295],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),], )
[torch error] paddle.concat(list[Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([4294967295],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 160534 has 1016.00 MiB memory in use. Of the allocated memory 1.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:27:09.037698 75593 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:27:09.038774 75593 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([100],"float32"),Tensor([100],"float32"),Tensor([4294967295],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),], )
[torch error] paddle.concat(list[Tensor([100],"float32"),Tensor([100],"float32"),Tensor([4294967295],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 98109 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:28:21.343166 76006 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:28:21.344137 76006 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([100],"float32"),Tensor([4294967295],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),], )
[torch error] paddle.concat(list[Tensor([100],"float32"),Tensor([4294967295],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 12103 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:29:31.053465 76325 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:29:31.057485 76325 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1000],"float16"),Tensor([4294967295],"float16"),], )
[torch error] paddle.concat(list[Tensor([1000],"float16"),Tensor([4294967295],"float16"),], ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 86429 has 1016.00 MiB memory in use. Of the allocated memory 2.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:30:59.013989 76623 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:30:59.014982 76623 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1000],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.concat(list[Tensor([1000],"float32"),Tensor([4294967295],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 39921 has 1016.00 MiB memory in use. Of the allocated memory 4.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:32:10.764025 77063 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:32:10.765036 77063 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1000],"float64"),Tensor([2147483649],"float64"),], )
[torch error] paddle.concat(list[Tensor([1000],"float64"),Tensor([2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 138475 has 1016.00 MiB memory in use. Of the allocated memory 8.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:32:58.803505 77461 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:32:58.804481 77461 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1000],"int32"),Tensor([4294967295],"int32"),], )
[torch error] paddle.concat(list[Tensor([1000],"int32"),Tensor([4294967295],"int32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 19991 has 1016.00 MiB memory in use. Of the allocated memory 4.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:34:12.918812 77653 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:34:12.919831 77653 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1000],"int64"),Tensor([2147483649],"int64"),], )
[torch error] paddle.concat(list[Tensor([1000],"int64"),Tensor([2147483649],"int64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 119364 has 1016.00 MiB memory in use. Of the allocated memory 8.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:34:57.806458 78072 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:34:57.807523 78072 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10071, 2176, 14, 14],"float32"),Tensor([10071, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([10071, 2176, 14, 14],"float32"),Tensor([10071, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 163010 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:36:07.070399 78260 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:36:07.071486 78260 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10071, 2176, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([10071, 2176, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 95019 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:37:18.531054 78658 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:37:18.532198 78658 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([101450, 864, 7, 7],"float32"),Tensor([101450, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([101450, 864, 7, 7],"float32"),Tensor([101450, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 22250 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:38:27.896595 78952 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:38:27.897795 78952 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([101450, 864, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([101450, 864, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 101889 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:39:41.474433 79248 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:39:41.475425 79248 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10221, 2144, 14, 14],"float32"),Tensor([10221, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([10221, 2144, 14, 14],"float32"),Tensor([10221, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 36121 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:40:54.863729 79640 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:40:54.864830 79640 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10221, 2144, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([10221, 2144, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 121706 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:42:06.714970 79925 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:42:06.725919 79925 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([103245, 416, 10, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([103245, 416, 10, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 51205 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:43:19.145834 80308 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:43:19.146963 80308 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([103245, 416, 10, 10],"float32"),Tensor([103245, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([103245, 416, 10, 10],"float32"),Tensor([103245, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 134386 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:44:31.232023 80631 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:44:31.233152 80631 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10376, 2112, 14, 14],"float32"),Tensor([10376, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([10376, 2112, 14, 14],"float32"),Tensor([10376, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 44954 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:45:41.346419 80930 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:45:41.347512 80930 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10376, 2112, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([10376, 2112, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 146356 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:46:54.185927 81294 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:46:54.186993 81294 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10376, 528, 28, 28],"float32"),Tensor([10376, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([10376, 528, 28, 28],"float32"),Tensor([10376, 48, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 73669 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:48:03.840500 81595 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:48:03.841507 81595 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10376, 528, 28, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([10376, 528, 28, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 156908 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:49:15.809497 81897 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:49:15.810616 81897 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1048065, 4098],"float32"),Tensor([1048065, 4098],"float32"),], )
[torch error] paddle.concat(list[Tensor([1048065, 4098],"float32"),Tensor([1048065, 4098],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 85824 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:50:29.615109 82293 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:50:29.616168 82293 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1048065, 4098],"float32"),Tensor([4098, 4098],"float32"),], )
[torch error] paddle.concat(list[Tensor([1048065, 4098],"float32"),Tensor([4098, 4098],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 162453 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:51:42.957396 82592 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:51:42.958461 82592 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([105352, 832, 7, 7],"float32"),Tensor([105352, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([105352, 832, 7, 7],"float32"),Tensor([105352, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 97180 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:52:54.509027 82980 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:52:54.510140 82980 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([105352, 832, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([105352, 832, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 18770 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:54:02.071923 83278 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:54:02.072994 83278 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10536, 2080, 14, 14],"float32"),Tensor([10536, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([10536, 2080, 14, 14],"float32"),Tensor([10536, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 91652 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:55:12.607127 83569 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:55:12.608186 83569 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10536, 2080, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([10536, 2080, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 26074 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:56:22.354027 83976 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:56:22.355103 83976 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10617, 2064, 14, 14],"float32"),Tensor([10617, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([10617, 2064, 14, 14],"float32"),Tensor([10617, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 107472 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:57:34.805960 84256 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:57:34.806986 84256 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10617, 2064, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([10617, 2064, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 31289 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:58:48.152264 84639 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:58:48.153242 84639 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10700, 128, 56, 56],"float32"),Tensor([10700, 32, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([10700, 128, 56, 56],"float32"),Tensor([10700, 32, 56, 56],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 125162 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:59:57.855980 84949 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:59:57.857082 84949 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10700, 128, 56, 56],"float32"),Tensor([2, 32, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([10700, 128, 56, 56],"float32"),Tensor([2, 32, 56, 56],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 40427 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:01:07.319839 85243 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:01:07.320859 85243 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10700, 2048, 14, 14],"float32"),Tensor([10700, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([10700, 2048, 14, 14],"float32"),Tensor([10700, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 133730 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:02:15.725396 85623 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:02:15.726410 85623 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10700, 2048, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([10700, 2048, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 50208 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:03:25.708904 85928 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:03:25.710018 85928 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1073741824, 2, 2],"float32"),Tensor([1073741824, 2, 2],"float32"),], axis=2, )
[torch error] paddle.concat(list[Tensor([1073741824, 2, 2],"float32"),Tensor([1073741824, 2, 2],"float32"),], axis=2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 128332 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:04:34.727200 86220 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:04:34.728324 86220 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1073741824, 2, 2],"float32"),Tensor([5, 2, 2],"float32"),], axis=2, )
[torch error] paddle.concat(list[Tensor([1073741824, 2, 2],"float32"),Tensor([5, 2, 2],"float32"),], axis=2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 51014 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:05:47.680843 86585 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:05:47.681833 86585 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1073741824, 4],"float32"),Tensor([1073741824, 4],"float32"),], )
[torch error] paddle.concat(list[Tensor([1073741824, 4],"float32"),Tensor([1073741824, 4],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 145800 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:07:00.401983 86908 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:07:00.402956 86908 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1073741824, 4],"float32"),Tensor([1073741824, 4],"float32"),Tensor([1073741824, 4],"float32"),], )
[torch error] paddle.concat(list[Tensor([1073741824, 4],"float32"),Tensor([1073741824, 4],"float32"),Tensor([1073741824, 4],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 64068 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:08:10.512617 87208 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:08:10.513553 87208 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1073741824, 4],"float32"),Tensor([1073741824, 4],"float32"),Tensor([1073741824, 4],"float32"),Tensor([1073741824, 4],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1073741824, 4],"float32"),Tensor([1073741824, 4],"float32"),Tensor([1073741824, 4],"float32"),Tensor([1073741824, 4],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 162829 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:09:22.065346 87572 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:09:22.066303 87572 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1073741824, 4],"float32"),Tensor([3, 4],"float32"),Tensor([3, 4],"float32"),], )
[torch error] paddle.concat(list[Tensor([1073741824, 4],"float32"),Tensor([3, 4],"float32"),Tensor([3, 4],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 75512 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:10:29.525071 87882 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:10:29.526257 87882 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1073741824, 4],"float32"),Tensor([4, 4],"float32"),], )
[torch error] paddle.concat(list[Tensor([1073741824, 4],"float32"),Tensor([4, 4],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 151129 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:11:40.133319 88173 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:11:40.134406 88173 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1073741824, 4],"float32"),Tensor([4, 4],"float32"),Tensor([4, 4],"float32"),], )
[torch error] paddle.concat(list[Tensor([1073741824, 4],"float32"),Tensor([4, 4],"float32"),Tensor([4, 4],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 86056 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:12:49.268761 88571 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:12:49.269907 88571 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1073741824, 4],"float32"),Tensor([5, 4],"float32"),Tensor([5, 4],"float32"),Tensor([5, 4],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1073741824, 4],"float32"),Tensor([5, 4],"float32"),Tensor([5, 4],"float32"),Tensor([5, 4],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 4359 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:13:59.234071 88893 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:13:59.238189 88893 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1073741825, 2, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1073741825, 2, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 80224 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:14:48.572815 89204 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:14:48.573908 89204 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1073741825, 2, 1],"float64"),Tensor([1, 2, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1073741825, 2, 1],"float64"),Tensor([1, 2, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 146498 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:15:38.350971 89471 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:15:38.352062 89471 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1073741825, 2, 1],"float64"),Tensor([1073741825, 2, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1073741825, 2, 1],"float64"),Tensor([1073741825, 2, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 50785 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:16:24.230477 89741 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:16:24.231630 89741 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1073741825, 2, 1],"float64"),Tensor([1073741825, 2, 1],"float64"),Tensor([1073741825, 2, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1073741825, 2, 1],"float64"),Tensor([1073741825, 2, 1],"float64"),Tensor([1073741825, 2, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 98204 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:17:14.375694 89927 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:17:14.376658 89927 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1073741825, 2, 1],"float64"),Tensor([3, 2, 1],"float64"),Tensor([3, 2, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([1073741825, 2, 1],"float64"),Tensor([3, 2, 1],"float64"),Tensor([3, 2, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 3903 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:18:00.803362 90198 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:18:00.804587 90198 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1073741825, 2],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1073741825, 2],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 47838 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:18:47.237977 90373 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:18:47.238917 90373 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1073741825, 2],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1073741825, 2],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 117000 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:19:37.033025 90639 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:19:37.033977 90639 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1073741825, 2],"float64"),Tensor([1, 2],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1073741825, 2],"float64"),Tensor([1, 2],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 13622 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:20:26.881840 90918 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:20:26.882920 90918 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1073741825, 2],"float64"),Tensor([1073741825, 2],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1073741825, 2],"float64"),Tensor([1073741825, 2],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 65131 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:21:12.284801 91099 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:21:12.285936 91099 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1073741825, 2],"float64"),Tensor([1073741825, 2],"float64"),Tensor([1073741825, 2],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1073741825, 2],"float64"),Tensor([1073741825, 2],"float64"),Tensor([1073741825, 2],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 134233 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:21:58.491727 91373 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:21:58.492904 91373 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1073741825, 2],"float64"),Tensor([1073741825, 2],"float64"),Tensor([1073741825, 2],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1073741825, 2],"float64"),Tensor([1073741825, 2],"float64"),Tensor([1073741825, 2],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 15591 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:22:44.044119 91555 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:22:44.045166 91555 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1073741825, 2],"float64"),Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([1073741825, 2],"float64"),Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 73400 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:23:34.667702 91819 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:23:34.668678 91819 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1073741825, 2],"float64"),Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([1073741825, 2],"float64"),Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 133401 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:24:23.853857 92098 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:24:23.854982 92098 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1073741825, 2],"int64"),Tensor([1, 2],"int64"),], )
[torch error] paddle.concat(list[Tensor([1073741825, 2],"int64"),Tensor([1, 2],"int64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 26995 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:25:06.765854 92276 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:25:06.766981 92276 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1073741825, 2],"int64"),Tensor([1073741825, 2],"int64"),], )
[torch error] paddle.concat(list[Tensor([1073741825, 2],"int64"),Tensor([1073741825, 2],"int64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 85517 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:25:50.663645 92535 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:25:50.664813 92535 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1073741825, 2],"int64"),Tensor([1073741825, 2],"int64"),], axis=0, )
[torch error] paddle.concat(list[Tensor([1073741825, 2],"int64"),Tensor([1073741825, 2],"int64"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 140780 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:26:36.209666 92708 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:26:36.210642 92708 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1073741825, 2],"int64"),Tensor([1073741825, 2],"int64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1073741825, 2],"int64"),Tensor([1073741825, 2],"int64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 29928 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:27:21.296368 92972 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:27:21.297417 92972 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1073741825, 2],"int64"),Tensor([2, 2],"int64"),], axis=0, )
[torch error] paddle.concat(list[Tensor([1073741825, 2],"int64"),Tensor([2, 2],"int64"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 84729 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:28:06.463254 93145 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:28:06.464344 93145 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1073741825, 2],"int64"),Tensor([2, 2],"int64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1073741825, 2],"int64"),Tensor([2, 2],"int64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 143837 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:28:50.128440 93417 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:28:50.129561 93417 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([107374183, 4, 10],"float32"),Tensor([1, 4, 10],"float32"),Tensor([1, 4, 10],"float32"),], 0, )
[torch error] paddle.concat(list[Tensor([107374183, 4, 10],"float32"),Tensor([1, 4, 10],"float32"),Tensor([1, 4, 10],"float32"),], 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 32756 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:30:00.123858 93577 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:30:00.124959 93577 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([107374183, 4, 10],"float32"),Tensor([107374183, 4, 10],"float32"),Tensor([107374183, 4, 10],"float32"),], 0, )
[torch error] paddle.concat(list[Tensor([107374183, 4, 10],"float32"),Tensor([107374183, 4, 10],"float32"),Tensor([107374183, 4, 10],"float32"),], 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 108078 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:31:12.821235 93894 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:31:12.822342 93894 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10737419, 20, 20],"float16"),Tensor([10737419, 20, 20],"float16"),], )
[torch error] paddle.concat(list[Tensor([10737419, 20, 20],"float16"),Tensor([10737419, 20, 20],"float16"),], ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 44715 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:32:39.327442 94294 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:32:39.328416 94294 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10737419, 20, 20],"float16"),Tensor([2, 20, 20],"float16"),], )
[torch error] paddle.concat(list[Tensor([10737419, 20, 20],"float16"),Tensor([2, 20, 20],"float16"),], ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 147447 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:34:08.759799 94703 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:34:08.760870 94703 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10737419, 20, 20],"float16"),Tensor([4, 20, 20],"float16"),], )
[torch error] paddle.concat(list[Tensor([10737419, 20, 20],"float16"),Tensor([4, 20, 20],"float16"),], ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 96105 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:35:36.571974 95157 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:35:36.573125 95157 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([107375, 64, 25, 25],"float32"),Tensor([107375, 64, 25, 25],"float32"),Tensor([107375, 96, 25, 25],"float32"),Tensor([107375, 32, 25, 25],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([107375, 64, 25, 25],"float32"),Tensor([107375, 64, 25, 25],"float32"),Tensor([107375, 96, 25, 25],"float32"),Tensor([107375, 32, 25, 25],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 32710 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:36:46.536324 95563 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:36:46.537426 95563 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([107375, 64, 25, 25],"float32"),Tensor([107375, 64, 25, 25],"float32"),Tensor([107375, 96, 25, 25],"float32"),Tensor([107375, 64, 25, 25],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([107375, 64, 25, 25],"float32"),Tensor([107375, 64, 25, 25],"float32"),Tensor([107375, 96, 25, 25],"float32"),Tensor([107375, 64, 25, 25],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 123145 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:38:02.578418 95883 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:38:02.579434 95883 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([107375, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 32, 25, 25],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([107375, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 32, 25, 25],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 42583 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:39:12.215335 96220 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:39:12.216434 96220 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([107375, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([107375, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 143399 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:40:21.156046 96598 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:40:21.157209 96598 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1082402, 992, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1082402, 992, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 54355 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:41:31.253981 96902 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:41:31.255074 96902 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1082402, 992, 2, 2],"float32"),Tensor([1082402, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1082402, 992, 2, 2],"float32"),Tensor([1082402, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 129656 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:42:40.686731 97222 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:42:40.687853 97222 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10870, 2016, 14, 14],"float32"),Tensor([10870, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([10870, 2016, 14, 14],"float32"),Tensor([10870, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 64186 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:43:50.385706 97621 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:43:50.386858 97621 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10870, 2016, 14, 14],"float32"),Tensor([10870, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([10870, 2016, 14, 14],"float32"),Tensor([10870, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 145357 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:45:01.194849 97899 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:45:01.195959 97899 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10870, 2016, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([10870, 2016, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 58647 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:46:12.540076 98222 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:46:12.541296 98222 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([10870, 2016, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([10870, 2016, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 161179 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:47:22.388692 98618 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:47:22.390034 98618 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([109566, 800, 7, 7],"float32"),Tensor([109566, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([109566, 800, 7, 7],"float32"),Tensor([109566, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 74922 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:48:38.316717 98923 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:48:38.317828 98923 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([109566, 800, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([109566, 800, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 11538 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:49:48.685189 99336 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:49:48.686322 99336 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([11, 20],"float32"),Tensor([11, 390451573],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([11, 20],"float32"),Tensor([11, 390451573],"float32"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 90565 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:51:00.203575 99632 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:51:00.204731 99632 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([11, 20],"float32"),Tensor([214748365, 20],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([11, 20],"float32"),Tensor([214748365, 20],"float32"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 14510 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:52:08.895831 99940 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:52:08.896770 99940 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([11, 390451573],"float32"),Tensor([11, 20],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([11, 390451573],"float32"),Tensor([11, 20],"float32"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 110473 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:53:24.748891 100347 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:53:24.749871 100347 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([11, 390451573],"float32"),Tensor([11, 390451573],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([11, 390451573],"float32"),Tensor([11, 390451573],"float32"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 24841 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:54:37.728682 100659 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:54:37.729919 100659 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([11045, 1984, 14, 14],"float32"),Tensor([11045, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([11045, 1984, 14, 14],"float32"),Tensor([11045, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 120654 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:55:46.224669 101056 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:55:46.225768 101056 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([11045, 1984, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([11045, 1984, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 37440 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:56:55.529234 101374 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:56:55.530208 101374 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([11135, 1968, 14, 14],"float32"),Tensor([11135, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([11135, 1968, 14, 14],"float32"),Tensor([11135, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 123594 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:58:09.146006 101668 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:58:09.147328 101668 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([11135, 1968, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([11135, 1968, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 58277 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:59:19.258988 102067 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:59:19.260097 102067 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1118482, 960, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1118482, 960, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 136573 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:00:30.677340 102385 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:00:30.678462 102385 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1118482, 960, 2, 2],"float32"),Tensor([1118482, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1118482, 960, 2, 2],"float32"),Tensor([1118482, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 47795 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:01:42.223249 102697 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:01:42.224413 102697 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([111849, 384, 10, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([111849, 384, 10, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 147239 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:02:55.623133 103081 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:02:55.624325 103081 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([111849, 384, 10, 10],"float32"),Tensor([111849, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([111849, 384, 10, 10],"float32"),Tensor([111849, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 67302 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:04:03.610730 103402 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:04:03.612262 103402 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([111849, 96, 20, 20],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([111849, 96, 20, 20],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 150808 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:05:12.342604 103704 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:05:12.343653 103704 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([111849, 96, 20, 20],"float32"),Tensor([111849, 32, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([111849, 96, 20, 20],"float32"),Tensor([111849, 32, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 74968 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:06:20.385656 104103 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:06:20.386821 104103 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([11226, 1952, 14, 14],"float32"),Tensor([11226, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([11226, 1952, 14, 14],"float32"),Tensor([11226, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 158116 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:07:29.559234 104401 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:07:29.560511 104401 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([11226, 1952, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([11226, 1952, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 71108 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:08:37.373934 104693 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:08:37.375466 104693 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([114131, 768, 7, 7],"float32"),Tensor([114131, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([114131, 768, 7, 7],"float32"),Tensor([114131, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 3081 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:09:50.004683 105084 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:09:50.005817 105084 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([114131, 768, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([114131, 768, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 85578 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:11:04.189077 105396 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:11:04.190094 105396 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([11414, 1920, 14, 14],"float32"),Tensor([11414, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([11414, 1920, 14, 14],"float32"),Tensor([11414, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 15462 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:12:12.044231 105720 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:12:12.045264 105720 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([11414, 1920, 14, 14],"float32"),Tensor([11414, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([11414, 1920, 14, 14],"float32"),Tensor([11414, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 103480 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:13:25.439388 106112 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:13:25.440474 106112 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([11414, 1920, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([11414, 1920, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 16831 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:14:33.008391 106410 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:14:33.009502 106410 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([11414, 1920, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([11414, 1920, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 92486 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:15:41.108914 106722 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:15:41.110067 106722 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([11414, 480, 28, 28],"float32"),Tensor([11414, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([11414, 480, 28, 28],"float32"),Tensor([11414, 32, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 27452 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:16:53.751329 107113 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:16:53.752424 107113 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([11414, 480, 28, 28],"float32"),Tensor([11414, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([11414, 480, 28, 28],"float32"),Tensor([11414, 48, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 113094 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:18:01.137439 107424 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:18:01.138424 107424 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([11414, 480, 28, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([11414, 480, 28, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 24900 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:19:15.892285 107730 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:19:15.893285 107730 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([11414, 480, 28, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([11414, 480, 28, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 125299 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:20:24.410504 108141 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:20:24.411641 108141 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([11508, 128, 54, 54],"float32"),Tensor([11508, 128, 54, 54],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([11508, 128, 54, 54],"float32"),Tensor([11508, 128, 54, 54],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 38222 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:21:32.242815 108432 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:21:32.243791 108432 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([11508, 128, 54, 54],"float32"),Tensor([2, 128, 54, 54],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([11508, 128, 54, 54],"float32"),Tensor([2, 128, 54, 54],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 109824 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:22:39.607148 108744 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:22:39.608254 108744 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1157050, 928, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1157050, 928, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 49549 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:23:54.421396 109144 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:23:54.422372 109144 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1157050, 928, 2, 2],"float32"),Tensor([1157050, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1157050, 928, 2, 2],"float32"),Tensor([1157050, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 132059 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:25:08.479647 109455 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:25:08.480569 109455 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([11607, 1888, 14, 14],"float32"),Tensor([11607, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([11607, 1888, 14, 14],"float32"),Tensor([11607, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 68555 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:26:24.012516 109868 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:26:24.013504 109868 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([11607, 1888, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([11607, 1888, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 153519 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:27:38.923385 110180 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:27:38.924362 110180 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([11619, 256, 38, 38],"float32"),Tensor([11619, 512, 38, 38],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([11619, 256, 38, 38],"float32"),Tensor([11619, 512, 38, 38],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 88292 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:28:47.813804 110566 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:28:47.815150 110566 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([11619, 256, 38, 38],"float32"),Tensor([4, 512, 38, 38],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([11619, 256, 38, 38],"float32"),Tensor([4, 512, 38, 38],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 1676 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:30:01.617174 110871 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:30:01.618170 110871 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([116509, 256, 12, 12],"float32"),Tensor([116509, 256, 12, 12],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([116509, 256, 12, 12],"float32"),Tensor([116509, 256, 12, 12],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 85566 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:31:10.911393 111172 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:31:10.913295 111172 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([116509, 256, 12, 12],"float32"),Tensor([2, 256, 12, 12],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([116509, 256, 12, 12],"float32"),Tensor([2, 256, 12, 12],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 21144 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:32:18.247439 111555 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:32:18.248571 111555 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([11706, 1872, 14, 14],"float32"),Tensor([11706, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([11706, 1872, 14, 14],"float32"),Tensor([11706, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 94269 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:33:25.549466 111853 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:33:25.550472 111853 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([11706, 1872, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([11706, 1872, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 6282 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:34:37.079381 112131 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:34:37.080507 112131 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([11807, 1856, 14, 14],"float32"),Tensor([11807, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([11807, 1856, 14, 14],"float32"),Tensor([11807, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 97734 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:35:50.217315 112517 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:35:50.218356 112517 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([11807, 1856, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([11807, 1856, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 20214 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:36:58.810853 112692 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:36:58.812173 112692 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([119093, 736, 7, 7],"float32"),Tensor([119093, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([119093, 736, 7, 7],"float32"),Tensor([119093, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 109628 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:38:05.703245 112734 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:38:05.704639 112734 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([119093, 736, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([119093, 736, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 36793 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:39:15.349171 112776 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:39:15.350286 112776 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1198373, 896, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1198373, 896, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 127539 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:40:24.823256 112804 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:40:24.824322 112804 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1198373, 896, 2, 2],"float32"),Tensor([1198373, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1198373, 896, 2, 2],"float32"),Tensor([1198373, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 40102 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:41:33.273432 112860 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:41:33.274595 112860 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([12, 22369622, 8],"float64"),Tensor([12, 22369622, 8],"float64"),], -1, )
[torch error] paddle.concat(list[Tensor([12, 22369622, 8],"float64"),Tensor([12, 22369622, 8],"float64"),], -1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 119082 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:42:19.667989 112914 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:42:19.686038 112914 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([12, 22369622, 8],"float64"),Tensor([12, 4, 8],"float64"),], -1, )
[torch error] paddle.concat(list[Tensor([12, 22369622, 8],"float64"),Tensor([12, 4, 8],"float64"),], -1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 20026 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:43:05.586845 112942 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:43:05.587850 112942 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([12, 4, 44739243],"float64"),Tensor([12, 4, 44739243],"float64"),], -1, )
[torch error] paddle.concat(list[Tensor([12, 4, 44739243],"float64"),Tensor([12, 4, 44739243],"float64"),], -1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 73844 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:43:51.388875 112958 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:43:51.390022 112958 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([12, 4, 44739243],"float64"),Tensor([12, 4, 8],"float64"),], -1, )
[torch error] paddle.concat(list[Tensor([12, 4, 44739243],"float64"),Tensor([12, 4, 8],"float64"),], -1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 125146 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:44:41.762053 112986 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:44:41.763092 112986 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([12, 4, 8],"float64"),Tensor([12, 22369622, 8],"float64"),], -1, )
[torch error] paddle.concat(list[Tensor([12, 4, 8],"float64"),Tensor([12, 22369622, 8],"float64"),], -1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 24993 has 1016.00 MiB memory in use. Of the allocated memory 3.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:45:30.981999 113013 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:45:30.983017 113013 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([12, 4, 8],"float64"),Tensor([12, 4, 44739243],"float64"),], -1, )
[torch error] paddle.concat(list[Tensor([12, 4, 8],"float64"),Tensor([12, 4, 44739243],"float64"),], -1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 69703 has 1016.00 MiB memory in use. Of the allocated memory 3.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:46:20.299194 113041 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:46:20.300221 113041 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([12, 4, 8],"float64"),Tensor([67108865, 4, 8],"float64"),], -1, )
[torch error] paddle.concat(list[Tensor([12, 4, 8],"float64"),Tensor([67108865, 4, 8],"float64"),], -1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 143979 has 1016.00 MiB memory in use. Of the allocated memory 3.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:47:08.704214 113070 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:47:08.705225 113070 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([12014, 1824, 14, 14],"float32"),Tensor([12014, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([12014, 1824, 14, 14],"float32"),Tensor([12014, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 46902 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:48:21.569403 113098 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:48:21.570832 113098 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([12014, 1824, 14, 14],"float32"),Tensor([12014, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([12014, 1824, 14, 14],"float32"),Tensor([12014, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 123695 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:49:29.700559 113126 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:49:29.701856 113126 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([12014, 1824, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([12014, 1824, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 31459 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:50:36.917464 113166 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:50:36.918684 113166 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([12014, 1824, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([12014, 1824, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 120660 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:51:43.096257 113195 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:51:43.097389 113195 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([122017, 352, 10, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([122017, 352, 10, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 35577 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:52:50.334750 113223 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:52:50.336086 113223 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([122017, 352, 10, 10],"float32"),Tensor([122017, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([122017, 352, 10, 10],"float32"),Tensor([122017, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 109316 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:53:58.202016 113265 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:53:58.203011 113265 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([12229, 1792, 14, 14],"float32"),Tensor([12229, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([12229, 1792, 14, 14],"float32"),Tensor([12229, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 26466 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:55:12.228777 113307 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:55:12.229760 113307 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([12229, 1792, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([12229, 1792, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 126866 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:56:25.129863 113349 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:56:25.131001 113349 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([12229, 448, 28, 28],"float32"),Tensor([12229, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([12229, 448, 28, 28],"float32"),Tensor([12229, 32, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 44666 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:57:33.995590 113391 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:57:33.996721 113391 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([12229, 448, 28, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([12229, 448, 28, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 118399 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:58:40.398273 113433 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:58:40.399449 113433 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([12339, 1776, 14, 14],"float32"),Tensor([12339, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([12339, 1776, 14, 14],"float32"),Tensor([12339, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 49808 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 01:59:46.564708 113474 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:59:46.565917 113474 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([12339, 1776, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([12339, 1776, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 121739 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:00:59.854008 113516 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:00:59.854979 113516 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1242757, 864, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1242757, 864, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 40684 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:02:06.464699 113571 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:02:06.465880 113571 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1242757, 864, 2, 2],"float32"),Tensor([1242757, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1242757, 864, 2, 2],"float32"),Tensor([1242757, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 125955 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:03:13.766907 113587 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:03:13.767946 113587 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([124507, 176, 14, 14],"float32"),Tensor([124507, 176, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([124507, 176, 14, 14],"float32"),Tensor([124507, 176, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 44541 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:04:23.783008 113615 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:04:23.784044 113615 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([124507, 176, 14, 14],"float32"),Tensor([2, 176, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([124507, 176, 14, 14],"float32"),Tensor([2, 176, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 118615 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:05:36.098804 113630 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:05:36.099881 113630 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([124507, 704, 7, 7],"float32"),Tensor([124507, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([124507, 704, 7, 7],"float32"),Tensor([124507, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 44174 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:06:44.015403 113671 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:06:44.016934 113671 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([124507, 704, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([124507, 704, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 129266 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:07:57.485576 113699 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:07:57.486716 113699 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([12451, 1760, 14, 14],"float32"),Tensor([12451, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([12451, 1760, 14, 14],"float32"),Tensor([12451, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 44334 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:09:11.075152 113741 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:09:11.076128 113741 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([12451, 1760, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([12451, 1760, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 145063 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:10:24.987571 113769 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:10:24.988545 113769 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([12682, 1728, 14, 14],"float32"),Tensor([12682, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([12682, 1728, 14, 14],"float32"),Tensor([12682, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 61058 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:11:32.649976 113798 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:11:32.651003 113798 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([12682, 1728, 14, 14],"float32"),Tensor([12682, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([12682, 1728, 14, 14],"float32"),Tensor([12682, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 140037 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:12:40.021559 113826 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:12:40.022763 113826 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([12682, 1728, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([12682, 1728, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 65758 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:13:47.587415 113867 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:13:47.588521 113867 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([12682, 1728, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([12682, 1728, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 137797 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:14:55.713933 113909 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:14:55.714977 113909 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([12682, 432, 28, 28],"float32"),Tensor([12682, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([12682, 432, 28, 28],"float32"),Tensor([12682, 48, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 50547 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:16:05.532060 113938 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:16:05.533062 113938 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([12682, 432, 28, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([12682, 432, 28, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 139308 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:17:18.709998 113966 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:17:18.710968 113966 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([128, 128, 2],"float32"),Tensor([128, 128, 262144],"float32"),], )
[torch error] paddle.concat(list[Tensor([128, 128, 2],"float32"),Tensor([128, 128, 262144],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 61150 has 1016.00 MiB memory in use. Of the allocated memory 128.00 KiB is allocated by PyTorch, and 1.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:18:24.797122 114021 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:18:24.798214 114021 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([128, 128, 2],"float32"),Tensor([128, 16777216, 2],"float32"),], )
[torch error] paddle.concat(list[Tensor([128, 128, 2],"float32"),Tensor([128, 16777216, 2],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 134609 has 1016.00 MiB memory in use. Of the allocated memory 128.00 KiB is allocated by PyTorch, and 1.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:19:34.636757 114063 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:19:34.637837 114063 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([128, 128, 2],"float32"),Tensor([16777216, 128, 2],"float32"),], )
[torch error] paddle.concat(list[Tensor([128, 128, 2],"float32"),Tensor([16777216, 128, 2],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 52955 has 1016.00 MiB memory in use. Of the allocated memory 128.00 KiB is allocated by PyTorch, and 1.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:20:47.271745 114106 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:20:47.272708 114106 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([128, 128, 262144],"float32"),Tensor([128, 128, 2],"float32"),], )
[torch error] paddle.concat(list[Tensor([128, 128, 262144],"float32"),Tensor([128, 128, 2],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 136417 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:21:58.003482 114174 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:21:58.004603 114174 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([128, 128, 262144],"float32"),Tensor([128, 128, 262144],"float32"),], )
[torch error] paddle.concat(list[Tensor([128, 128, 262144],"float32"),Tensor([128, 128, 262144],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 52464 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:23:04.619952 114203 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:23:04.621054 114203 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([128, 16777216, 2],"float32"),Tensor([128, 128, 2],"float32"),], )
[torch error] paddle.concat(list[Tensor([128, 16777216, 2],"float32"),Tensor([128, 128, 2],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 133264 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:24:16.465126 114245 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:24:16.466260 114245 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([128, 16777216, 2],"float32"),Tensor([128, 16777216, 2],"float32"),], )
[torch error] paddle.concat(list[Tensor([128, 16777216, 2],"float32"),Tensor([128, 16777216, 2],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 53984 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:25:27.398814 114297 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:25:27.399806 114297 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([128, 256],"float32"),Tensor([128, 33554432],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([128, 256],"float32"),Tensor([128, 33554432],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 126531 has 1016.00 MiB memory in use. Of the allocated memory 128.00 KiB is allocated by PyTorch, and 1.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:26:34.556540 114343 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:26:34.557572 114343 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([128, 256],"float32"),Tensor([16777216, 256],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([128, 256],"float32"),Tensor([16777216, 256],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 54681 has 1016.00 MiB memory in use. Of the allocated memory 128.00 KiB is allocated by PyTorch, and 1.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:27:49.945036 114385 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:27:49.946141 114385 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([128, 33554432],"float16"),Tensor([128, 128],"float16"),Tensor([128, 128],"float16"),], axis=1, )
[torch error] paddle.concat(list[Tensor([128, 33554432],"float16"),Tensor([128, 128],"float16"),Tensor([128, 128],"float16"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 139456 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:29:13.328078 114427 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:29:13.330935 114427 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([128, 33554432],"float16"),Tensor([128, 33554432],"float16"),Tensor([128, 33554432],"float16"),], axis=1, )
[torch error] paddle.concat(list[Tensor([128, 33554432],"float16"),Tensor([128, 33554432],"float16"),Tensor([128, 33554432],"float16"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 83711 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:30:43.401898 114455 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:30:43.403002 114455 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([128, 33554432],"float32"),Tensor([128, 256],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([128, 33554432],"float32"),Tensor([128, 256],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 19520 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:31:57.423092 114470 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:31:57.424059 114470 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([128, 33554432],"float32"),Tensor([128, 33554432],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([128, 33554432],"float32"),Tensor([128, 33554432],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 97933 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:33:05.882982 114523 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:33:05.883998 114523 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([128, 33554432],"float32"),Tensor([128, 64],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([128, 33554432],"float32"),Tensor([128, 64],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 17762 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:34:19.812438 114566 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:34:19.813656 114566 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([128, 33554432],"int32"),Tensor([128, 128],"int32"),Tensor([128, 128],"int32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([128, 33554432],"int32"),Tensor([128, 128],"int32"),Tensor([128, 128],"int32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 101122 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:35:37.690363 114582 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:35:37.691465 114582 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([128, 33554432],"int32"),Tensor([128, 33554432],"int32"),Tensor([128, 33554432],"int32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([128, 33554432],"int32"),Tensor([128, 33554432],"int32"),Tensor([128, 33554432],"int32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 33165 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:36:45.817039 114609 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:36:45.818174 114609 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([128, 512],"float16"),Tensor([128, 128],"float16"),Tensor([128, 33554432],"float16"),], axis=1, )
[torch error] paddle.concat(list[Tensor([128, 512],"float16"),Tensor([128, 128],"float16"),Tensor([128, 33554432],"float16"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 110635 has 1016.00 MiB memory in use. Of the allocated memory 160.00 KiB is allocated by PyTorch, and 1.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:38:13.029268 114637 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:38:13.030282 114637 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([128, 512],"float16"),Tensor([128, 128],"float16"),Tensor([33554432, 128],"float16"),], axis=1, )
[torch error] paddle.concat(list[Tensor([128, 512],"float16"),Tensor([128, 128],"float16"),Tensor([33554432, 128],"float16"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 55491 has 1016.00 MiB memory in use. Of the allocated memory 160.00 KiB is allocated by PyTorch, and 1.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:39:47.470077 114679 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:39:47.471124 114679 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([128, 512],"float16"),Tensor([128, 33554432],"float16"),Tensor([128, 128],"float16"),], axis=1, )
[torch error] paddle.concat(list[Tensor([128, 512],"float16"),Tensor([128, 33554432],"float16"),Tensor([128, 128],"float16"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 155126 has 1016.00 MiB memory in use. Of the allocated memory 128.00 KiB is allocated by PyTorch, and 1.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:41:09.658269 114734 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:41:09.659318 114734 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([128, 512],"float16"),Tensor([33554432, 128],"float16"),Tensor([128, 128],"float16"),], axis=1, )
[torch error] paddle.concat(list[Tensor([128, 512],"float16"),Tensor([33554432, 128],"float16"),Tensor([128, 128],"float16"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 98592 has 1016.00 MiB memory in use. Of the allocated memory 128.00 KiB is allocated by PyTorch, and 1.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:42:31.812971 114764 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:42:31.814004 114764 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([128, 512],"int32"),Tensor([128, 128],"int32"),Tensor([128, 33554432],"int32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([128, 512],"int32"),Tensor([128, 128],"int32"),Tensor([128, 33554432],"int32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 14533 has 1016.00 MiB memory in use. Of the allocated memory 320.00 KiB is allocated by PyTorch, and 1.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:43:40.223789 114792 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:43:40.224961 114792 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([128, 512],"int32"),Tensor([128, 128],"int32"),Tensor([33554432, 128],"int32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([128, 512],"int32"),Tensor([128, 128],"int32"),Tensor([33554432, 128],"int32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 106464 has 1016.00 MiB memory in use. Of the allocated memory 320.00 KiB is allocated by PyTorch, and 1.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:44:48.700477 114820 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:44:48.701659 114820 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([128, 512],"int32"),Tensor([128, 33554432],"int32"),Tensor([128, 128],"int32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([128, 512],"int32"),Tensor([128, 33554432],"int32"),Tensor([128, 128],"int32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 15546 has 1016.00 MiB memory in use. Of the allocated memory 256.00 KiB is allocated by PyTorch, and 1.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:46:01.008718 114861 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:46:01.009728 114861 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([128, 512],"int32"),Tensor([33554432, 128],"int32"),Tensor([128, 128],"int32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([128, 512],"int32"),Tensor([33554432, 128],"int32"),Tensor([128, 128],"int32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 98917 has 1016.00 MiB memory in use. Of the allocated memory 256.00 KiB is allocated by PyTorch, and 1.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:47:07.022320 114903 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:47:07.023350 114903 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([128, 64],"float32"),Tensor([128, 33554432],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([128, 64],"float32"),Tensor([128, 33554432],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 26652 has 1016.00 MiB memory in use. Of the allocated memory 32.00 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:48:19.264211 114932 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:48:19.265271 114932 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([128, 64],"float32"),Tensor([67108864, 64],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([128, 64],"float32"),Tensor([67108864, 64],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 104888 has 1016.00 MiB memory in use. Of the allocated memory 32.00 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:49:35.181428 114986 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:49:35.182456 114986 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1290556, 832, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1290556, 832, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 31507 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:50:47.735303 115030 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:50:47.736335 115030 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1290556, 832, 2, 2],"float32"),Tensor([1290556, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1290556, 832, 2, 2],"float32"),Tensor([1290556, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 108448 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:52:02.910982 115072 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:52:02.911934 115072 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([12921, 1696, 14, 14],"float32"),Tensor([12921, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([12921, 1696, 14, 14],"float32"),Tensor([12921, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 27427 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:53:10.182557 115100 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:53:10.183948 115100 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([12921, 1696, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([12921, 1696, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 118725 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:54:19.370595 115141 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:54:19.371610 115141 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([130436, 672, 7, 7],"float32"),Tensor([130436, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([130436, 672, 7, 7],"float32"),Tensor([130436, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 26481 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:55:34.283298 115170 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:55:34.284308 115170 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([130436, 672, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([130436, 672, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 112451 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:56:42.052304 115211 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:56:42.053428 115211 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([13044, 1680, 14, 14],"float32"),Tensor([13044, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([13044, 1680, 14, 14],"float32"),Tensor([13044, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 34421 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:57:49.258594 115239 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:57:49.259665 115239 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([13044, 1680, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([13044, 1680, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 106113 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:58:57.920166 115268 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:58:57.921288 115268 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([131072, 8, 64, 64],"float16"),Tensor([131072, 8, 1, 64],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([131072, 8, 64, 64],"float16"),Tensor([131072, 8, 1, 64],"float16"),], axis=2, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 27407 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:00:23.882246 115296 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:00:23.883234 115296 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([131072, 8, 64, 64],"float16"),Tensor([131072, 8, 64, 64],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([131072, 8, 64, 64],"float16"),Tensor([131072, 8, 64, 64],"float16"),], axis=2, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 127019 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:01:52.218814 115337 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:01:52.219954 115337 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([131072, 8, 64, 64],"float16"),Tensor([2, 8, 1, 64],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([131072, 8, 64, 64],"float16"),Tensor([2, 8, 1, 64],"float16"),], axis=2, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 60701 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:03:14.420853 115394 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:03:14.421964 115394 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([131072, 8, 64, 64],"float16"),Tensor([2, 8, 64, 64],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([131072, 8, 64, 64],"float16"),Tensor([2, 8, 64, 64],"float16"),], axis=2, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 3811 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:04:41.506763 115436 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:04:41.507800 115436 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([13169, 1664, 14, 14],"float32"),Tensor([13169, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([13169, 1664, 14, 14],"float32"),Tensor([13169, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 100426 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:05:48.480626 115491 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:05:48.481732 115491 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([13169, 1664, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([13169, 1664, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 12215 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:07:02.928787 115520 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:07:02.929811 115520 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([13169, 416, 28, 28],"float32"),Tensor([13169, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([13169, 416, 28, 28],"float32"),Tensor([13169, 32, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 97460 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:08:17.402968 115574 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:08:17.404050 115574 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([13169, 416, 28, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([13169, 416, 28, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 28477 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:09:31.568336 115604 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:09:31.569416 115604 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([132365, 192, 13, 13],"float32"),Tensor([132365, 192, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([132365, 192, 13, 13],"float32"),Tensor([132365, 192, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 100375 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:10:38.521524 115645 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:10:38.522723 115645 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([132365, 192, 13, 13],"float32"),Tensor([132365, 208, 13, 13],"float32"),Tensor([132365, 48, 13, 13],"float32"),Tensor([132365, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([132365, 192, 13, 13],"float32"),Tensor([132365, 208, 13, 13],"float32"),Tensor([132365, 48, 13, 13],"float32"),Tensor([132365, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 27249 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:11:45.445326 115674 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:11:45.446425 115674 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([132365, 192, 13, 13],"float32"),Tensor([2, 192, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([132365, 192, 13, 13],"float32"),Tensor([2, 192, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 101072 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:12:58.994858 115715 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:12:58.995911 115715 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([132365, 192, 13, 13],"float32"),Tensor([2, 208, 13, 13],"float32"),Tensor([2, 48, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([132365, 192, 13, 13],"float32"),Tensor([2, 208, 13, 13],"float32"),Tensor([2, 48, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 18732 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:14:13.381758 115757 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:14:13.382755 115757 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([134217728, 1, 8, 4],"float32"),Tensor([134217728, 1, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([134217728, 1, 8, 4],"float32"),Tensor([134217728, 1, 8, 4],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 119258 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:15:20.566393 115799 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:15:20.567508 115799 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([134217728, 1, 8, 4],"float32"),Tensor([2, 1, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([134217728, 1, 8, 4],"float32"),Tensor([2, 1, 8, 4],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 24733 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:16:31.248212 115828 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:16:31.249245 115828 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([134217728, 16, 2],"float32"),Tensor([134217728, 16, 2],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([134217728, 16, 2],"float32"),Tensor([134217728, 16, 2],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 102486 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:17:41.781706 115855 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:17:41.782789 115855 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([134217728, 16, 2],"float32"),Tensor([8, 16, 2],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([134217728, 16, 2],"float32"),Tensor([8, 16, 2],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 32253 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:18:47.487278 115893 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:18:47.489741 115893 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([134217728, 32],"float16"),Tensor([134217728, 32],"float16"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([134217728, 32],"float16"),Tensor([134217728, 32],"float16"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 104979 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:20:10.446009 115926 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:20:10.447190 115926 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([134217728, 32],"float16"),Tensor([64, 32],"float16"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([134217728, 32],"float16"),Tensor([64, 32],"float16"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 46994 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:21:32.669574 115994 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:21:32.671021 115994 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([134217728, 32],"float16"),Tensor([65, 32],"float16"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([134217728, 32],"float16"),Tensor([65, 32],"float16"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 122572 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:22:59.871896 116038 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:22:59.873016 116038 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1342178, 800, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1342178, 800, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 64337 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:24:10.492202 116080 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:24:10.493449 116080 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1342178, 800, 2, 2],"float32"),Tensor([1342178, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1342178, 800, 2, 2],"float32"),Tensor([1342178, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 157989 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:25:24.925976 116135 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:25:24.927044 116135 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([134218, 320, 10, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([134218, 320, 10, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 67588 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:26:39.507799 116178 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:26:39.508764 116178 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([134218, 320, 10, 10],"float32"),Tensor([134218, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([134218, 320, 10, 10],"float32"),Tensor([134218, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 5818 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:27:46.611490 116220 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:27:46.612596 116220 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([13428, 1632, 14, 14],"float32"),Tensor([13428, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([13428, 1632, 14, 14],"float32"),Tensor([13428, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 74590 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:28:55.795825 116262 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:28:55.796809 116262 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([13428, 1632, 14, 14],"float32"),Tensor([13428, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([13428, 1632, 14, 14],"float32"),Tensor([13428, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 152538 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:30:02.974231 116304 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:30:02.975718 116304 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([13428, 1632, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([13428, 1632, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 69763 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:31:12.874502 116332 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:31:12.875528 116332 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([13428, 1632, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([13428, 1632, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 163682 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:32:26.365768 116372 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:32:26.366880 116372 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1369569, 64, 7, 7],"float32"),Tensor([1369569, 64, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1369569, 64, 7, 7],"float32"),Tensor([1369569, 64, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 71819 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:33:34.544303 116428 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:33:34.545413 116428 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1369569, 64, 7, 7],"float32"),Tensor([2, 64, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1369569, 64, 7, 7],"float32"),Tensor([2, 64, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 151546 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:34:44.124109 116458 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:34:44.125250 116458 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([136957, 640, 7, 7],"float32"),Tensor([136957, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([136957, 640, 7, 7],"float32"),Tensor([136957, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 72075 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:35:51.891983 116500 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:35:51.893024 116500 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([136957, 640, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([136957, 640, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 148466 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:36:59.911767 116541 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:36:59.912897 116541 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([13696, 1600, 14, 14],"float32"),Tensor([13696, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([13696, 1600, 14, 14],"float32"),Tensor([13696, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 70595 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:38:08.222820 116596 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:38:08.223934 116596 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([13696, 1600, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([13696, 1600, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 3363 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:39:18.378649 116626 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:39:18.379762 116626 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([13835, 1584, 14, 14],"float32"),Tensor([13835, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([13835, 1584, 14, 14],"float32"),Tensor([13835, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 76950 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:40:25.245050 116667 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:40:25.262619 116667 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([13835, 1584, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([13835, 1584, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 148805 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:41:32.319136 116709 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:41:32.320158 116709 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([13976, 1568, 14, 14],"float32"),Tensor([13976, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([13976, 1568, 14, 14],"float32"),Tensor([13976, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 55953 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:42:44.296300 116752 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:42:44.297397 116752 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([13976, 1568, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([13976, 1568, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 151075 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:43:55.994452 116793 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:43:55.995524 116793 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1398102, 3, 32, 32],"float32"),Tensor([1, 10, 32, 32],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([1398102, 3, 32, 32],"float32"),Tensor([1, 10, 32, 32],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 60181 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:45:08.757925 116848 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:45:08.758913 116848 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1398102, 3, 32, 32],"float32"),Tensor([1398102, 10, 32, 32],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([1398102, 3, 32, 32],"float32"),Tensor([1398102, 10, 32, 32],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 161370 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:46:19.737145 116878 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:46:19.738129 116878 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1398102, 768, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1398102, 768, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 81562 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:47:34.118922 116906 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:47:34.119886 116906 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1398102, 768, 2, 2],"float32"),Tensor([1398102, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1398102, 768, 2, 2],"float32"),Tensor([1398102, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 160726 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:48:42.599751 116960 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:48:42.600765 116960 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([14267, 1536, 14, 14],"float32"),Tensor([14267, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([14267, 1536, 14, 14],"float32"),Tensor([14267, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 85555 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:49:52.525408 117003 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:49:52.526504 117003 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([14267, 1536, 14, 14],"float32"),Tensor([14267, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([14267, 1536, 14, 14],"float32"),Tensor([14267, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 155580 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:51:06.731426 117032 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:51:06.732391 117032 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([14267, 1536, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([14267, 1536, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 88614 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:52:21.782284 117086 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:52:21.783435 117086 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([14267, 1536, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([14267, 1536, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 5573 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:53:36.116128 117130 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:53:36.117203 117130 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([14267, 384, 28, 28],"float32"),Tensor([14267, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([14267, 384, 28, 28],"float32"),Tensor([14267, 32, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 89190 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:54:57.348906 117171 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:54:57.350014 117171 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([14267, 384, 28, 28],"float32"),Tensor([14267, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([14267, 384, 28, 28],"float32"),Tensor([14267, 48, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 13588 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:56:11.521776 117226 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:56:11.522784 117226 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([14267, 384, 28, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([14267, 384, 28, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 117615 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:57:20.631476 117256 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:57:20.632819 117256 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([14267, 384, 28, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([14267, 384, 28, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 27721 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:58:33.954640 117298 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:58:33.955654 117298 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([14267, 96, 56, 56],"float32"),Tensor([14267, 32, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([14267, 96, 56, 56],"float32"),Tensor([14267, 32, 56, 56],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 108903 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:59:45.940804 117352 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:59:45.942382 117352 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([14267, 96, 56, 56],"float32"),Tensor([14267, 48, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([14267, 96, 56, 56],"float32"),Tensor([14267, 48, 56, 56],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 31906 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:00:53.042997 117382 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:00:53.044520 117382 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([14267, 96, 56, 56],"float32"),Tensor([2, 32, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([14267, 96, 56, 56],"float32"),Tensor([2, 32, 56, 56],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 103291 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:02:02.090606 117415 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:02:02.091863 117415 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([14267, 96, 56, 56],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([14267, 96, 56, 56],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 23298 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:03:14.119673 117452 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:03:14.121255 117452 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([144166, 608, 7, 7],"float32"),Tensor([144166, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([144166, 608, 7, 7],"float32"),Tensor([144166, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 119321 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:04:23.423863 117507 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:04:23.424988 117507 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([144166, 608, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([144166, 608, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 25395 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:05:31.741910 117536 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:05:31.743106 117536 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([14570, 1504, 14, 14],"float32"),Tensor([14570, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([14570, 1504, 14, 14],"float32"),Tensor([14570, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 95889 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:06:39.481791 117564 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:06:39.482956 117564 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([14570, 1504, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([14570, 1504, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 31627 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:07:53.988830 117619 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:07:53.989787 117619 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1458889, 736, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1458889, 736, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 104140 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:09:07.928977 117662 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:09:07.929970 117662 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1458889, 736, 2, 2],"float32"),Tensor([1458889, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1458889, 736, 2, 2],"float32"),Tensor([1458889, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 44904 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:10:15.234918 117690 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:10:15.236624 117690 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([14727, 1488, 14, 14],"float32"),Tensor([14727, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([14727, 1488, 14, 14],"float32"),Tensor([14727, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 117204 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:11:27.050426 117744 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:11:27.051662 117744 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([14727, 1488, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([14727, 1488, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 26625 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:12:34.843175 117787 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:12:34.844264 117787 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([14887, 1472, 14, 14],"float32"),Tensor([14887, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([14887, 1472, 14, 14],"float32"),Tensor([14887, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 107431 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:13:46.800112 117816 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:13:46.801108 117816 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([14887, 1472, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([14887, 1472, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 27646 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:14:54.726505 117844 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:14:54.727628 117844 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([149131, 288, 10, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([149131, 288, 10, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 98356 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:16:09.252022 117899 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:16:09.253098 117899 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([149131, 288, 10, 10],"float32"),Tensor([149131, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([149131, 288, 10, 10],"float32"),Tensor([149131, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 41036 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:17:15.560565 117942 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:17:15.561714 117942 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([152175, 576, 7, 7],"float32"),Tensor([152175, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([152175, 576, 7, 7],"float32"),Tensor([152175, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 115264 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:18:32.219328 117982 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:18:32.220324 117982 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([152175, 576, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([152175, 576, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 30536 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:19:39.124516 118022 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:19:39.125741 118022 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([15218, 1440, 14, 14],"float32"),Tensor([15218, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([15218, 1440, 14, 14],"float32"),Tensor([15218, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 123670 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:20:46.552384 118054 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:20:46.553411 118054 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([15218, 1440, 14, 14],"float32"),Tensor([15218, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([15218, 1440, 14, 14],"float32"),Tensor([15218, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 31219 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:21:56.181003 118096 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:21:56.182130 118096 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([15218, 1440, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([15218, 1440, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 102494 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:23:03.942214 118150 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:23:03.948818 118150 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([15218, 1440, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([15218, 1440, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 22618 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:24:17.101406 118193 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:24:17.102568 118193 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1525202, 704, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1525202, 704, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 111201 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:25:24.063060 118235 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:25:24.064157 118235 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1525202, 704, 2, 2],"float32"),Tensor([1525202, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1525202, 704, 2, 2],"float32"),Tensor([1525202, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 19622 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:26:31.579466 118290 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:26:31.580519 118290 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([155345, 192, 12, 12],"float32"),Tensor([155345, 192, 12, 12],"float32"),Tensor([155345, 192, 12, 12],"float32"),Tensor([155345, 192, 12, 12],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([155345, 192, 12, 12],"float32"),Tensor([155345, 192, 12, 12],"float32"),Tensor([155345, 192, 12, 12],"float32"),Tensor([155345, 192, 12, 12],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 94758 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:27:40.653074 118320 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:27:40.654193 118320 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([155345, 192, 12, 12],"float32"),Tensor([2, 192, 12, 12],"float32"),Tensor([2, 192, 12, 12],"float32"),Tensor([2, 192, 12, 12],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([155345, 192, 12, 12],"float32"),Tensor([2, 192, 12, 12],"float32"),Tensor([2, 192, 12, 12],"float32"),Tensor([2, 192, 12, 12],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 25323 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:28:47.942745 118361 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:28:47.943761 118361 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([15564, 1408, 14, 14],"float32"),Tensor([15564, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([15564, 1408, 14, 14],"float32"),Tensor([15564, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 97768 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:29:55.172498 118416 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:29:55.173663 118416 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([15564, 1408, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([15564, 1408, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 5418 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:31:09.842588 118459 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:31:09.844130 118459 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([15564, 352, 28, 28],"float32"),Tensor([15564, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([15564, 352, 28, 28],"float32"),Tensor([15564, 32, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 108905 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:32:17.078231 118501 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:32:17.079644 118501 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([15564, 352, 28, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([15564, 352, 28, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 16218 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:33:30.136047 118543 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:33:30.137179 118543 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([15743, 1392, 14, 14],"float32"),Tensor([15743, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([15743, 1392, 14, 14],"float32"),Tensor([15743, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 88870 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:34:36.271136 118585 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:34:36.272325 118585 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([15743, 1392, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([15743, 1392, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 11745 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:35:45.664043 118627 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:35:45.665436 118627 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([158838, 160, 13, 13],"float32"),Tensor([158838, 224, 13, 13],"float32"),Tensor([158838, 64, 13, 13],"float32"),Tensor([158838, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([158838, 160, 13, 13],"float32"),Tensor([158838, 224, 13, 13],"float32"),Tensor([158838, 64, 13, 13],"float32"),Tensor([158838, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 97261 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:36:53.670126 118668 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:36:53.671185 118668 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([158838, 160, 13, 13],"float32"),Tensor([2, 224, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([158838, 160, 13, 13],"float32"),Tensor([2, 224, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 6924 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:38:00.769686 118698 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:38:00.770785 118698 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([15926, 1376, 14, 14],"float32"),Tensor([15926, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([15926, 1376, 14, 14],"float32"),Tensor([15926, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 82386 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:39:09.961855 118739 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:39:09.962807 118739 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([15926, 1376, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([15926, 1376, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 17284 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:40:23.819290 118782 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:40:23.820271 118782 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1597831, 672, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1597831, 672, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 90069 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:41:36.915670 118838 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:41:36.916646 118838 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1597831, 672, 2, 2],"float32"),Tensor([1597831, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1597831, 672, 2, 2],"float32"),Tensor([1597831, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 17389 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:42:50.436393 118876 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:42:50.437382 118876 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([161126, 544, 7, 7],"float32"),Tensor([161126, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([161126, 544, 7, 7],"float32"),Tensor([161126, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 93618 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:43:58.955037 118908 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:43:58.956081 118908 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([161126, 544, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([161126, 544, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 5663 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:45:13.551223 118963 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:45:13.552213 118963 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([16305, 1344, 14, 14],"float32"),Tensor([16305, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([16305, 1344, 14, 14],"float32"),Tensor([16305, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 105411 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:46:26.604067 119004 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:46:26.605254 119004 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([16305, 1344, 14, 14],"float32"),Tensor([16305, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([16305, 1344, 14, 14],"float32"),Tensor([16305, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 20421 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:47:37.191259 119046 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:47:37.192783 119046 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([16305, 1344, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([16305, 1344, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 107678 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:48:43.922690 119088 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:48:43.923806 119088 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([16305, 1344, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([16305, 1344, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 23080 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:49:51.577371 119130 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:49:51.578442 119130 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([16305, 336, 28, 28],"float32"),Tensor([16305, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([16305, 336, 28, 28],"float32"),Tensor([16305, 48, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 97915 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:51:07.058979 119159 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:51:07.059953 119159 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([16305, 336, 28, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([16305, 336, 28, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 32217 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:52:16.952626 119200 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:52:16.954205 119200 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([16703, 1312, 14, 14],"float32"),Tensor([16703, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([16703, 1312, 14, 14],"float32"),Tensor([16703, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 109235 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:53:24.093008 119242 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:53:24.094024 119242 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([16703, 1312, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([16703, 1312, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 17469 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:54:32.415983 119284 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:54:32.417110 119284 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([16777216, 128, 2],"float32"),Tensor([128, 128, 2],"float32"),], )
[torch error] paddle.concat(list[Tensor([16777216, 128, 2],"float32"),Tensor([128, 128, 2],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 86594 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:55:40.468093 119326 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:55:40.469161 119326 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([16777216, 128, 2],"float32"),Tensor([16777216, 128, 2],"float32"),], )
[torch error] paddle.concat(list[Tensor([16777216, 128, 2],"float32"),Tensor([16777216, 128, 2],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 20996 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:56:48.268154 119355 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:56:48.269348 119355 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([16777216, 256],"float32"),Tensor([128, 256],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([16777216, 256],"float32"),Tensor([128, 256],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 94589 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:57:57.306094 119383 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:57:57.307205 119383 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([16777216, 256],"float32"),Tensor([16777216, 256],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([16777216, 256],"float32"),Tensor([16777216, 256],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 1882 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:59:04.329062 119424 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:59:04.330178 119424 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1677722, 640, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1677722, 640, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 89768 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:00:12.215314 119466 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:00:12.216392 119466 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1677722, 640, 2, 2],"float32"),Tensor([1677722, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1677722, 640, 2, 2],"float32"),Tensor([1677722, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 11933 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:01:25.376060 119496 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:01:25.377080 119496 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([167773, 256, 10, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([167773, 256, 10, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 84938 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:02:39.112701 119550 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:02:39.115150 119550 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([167773, 256, 10, 10],"float32"),Tensor([167773, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([167773, 256, 10, 10],"float32"),Tensor([167773, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 15972 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:03:53.071117 119580 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:03:53.072263 119580 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([167773, 64, 20, 20],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([167773, 64, 20, 20],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 88143 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:05:00.911671 119620 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:05:00.912698 119620 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([167773, 64, 20, 20],"float32"),Tensor([167773, 32, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([167773, 64, 20, 20],"float32"),Tensor([167773, 32, 20, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 163436 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:06:14.156227 119675 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:06:14.157202 119675 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([16909, 1296, 14, 14],"float32"),Tensor([16909, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([16909, 1296, 14, 14],"float32"),Tensor([16909, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 107692 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:07:21.169848 119692 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:07:21.170851 119692 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([16909, 1296, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([16909, 1296, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 17054 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:08:34.543011 119732 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:08:34.544155 119732 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([171197, 512, 7, 7],"float32"),Tensor([171197, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([171197, 512, 7, 7],"float32"),Tensor([171197, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 102062 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:09:42.839751 119774 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:09:42.841135 119774 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([171197, 512, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([171197, 512, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 21005 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:10:51.775653 119803 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:10:51.777088 119803 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([17120, 1280, 14, 14],"float32"),Tensor([17120, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([17120, 1280, 14, 14],"float32"),Tensor([17120, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 91992 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:12:04.971781 119844 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:12:04.972808 119844 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([17120, 1280, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([17120, 1280, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 22087 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:13:11.766649 119873 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:13:11.768131 119873 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([17120, 320, 28, 28],"float32"),Tensor([17120, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([17120, 320, 28, 28],"float32"),Tensor([17120, 32, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 103566 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:14:20.203070 119927 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:14:20.204107 119927 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([17120, 320, 28, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([17120, 320, 28, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 12124 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:15:28.843389 119970 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:15:28.844501 119970 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1717987, 50, 50],"float32"),Tensor([10, 50, 50],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([1717987, 50, 50],"float32"),Tensor([10, 50, 50],"float32"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 83035 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:16:36.343370 119999 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:16:36.344857 119999 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1717987, 50, 50],"float32"),Tensor([1717987, 50, 50],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([1717987, 50, 50],"float32"),Tensor([1717987, 50, 50],"float32"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 9212 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:17:44.518070 120053 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:17:44.519646 120053 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([173185, 992, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([173185, 992, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 89528 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:18:54.046934 120070 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:18:54.048023 120070 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([173185, 992, 5, 5],"float32"),Tensor([173185, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([173185, 992, 5, 5],"float32"),Tensor([173185, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 163551 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:20:07.583947 120084 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:20:07.585414 120084 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([17559, 1248, 14, 14],"float32"),Tensor([17559, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([17559, 1248, 14, 14],"float32"),Tensor([17559, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 98843 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:21:21.166268 120124 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:21:21.167375 120124 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([17559, 1248, 14, 14],"float32"),Tensor([17559, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([17559, 1248, 14, 14],"float32"),Tensor([17559, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 13397 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:22:37.334905 120140 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:22:37.336000 120140 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([17559, 1248, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([17559, 1248, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 108395 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:23:43.925354 120154 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:23:43.926317 120154 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([17559, 1248, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([17559, 1248, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 20686 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:24:56.050361 120182 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:24:56.051313 120182 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1766023, 608, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1766023, 608, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 90889 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:26:05.447505 120196 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:26:05.448460 120196 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1766023, 608, 2, 2],"float32"),Tensor([1766023, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1766023, 608, 2, 2],"float32"),Tensor([1766023, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 23083 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:27:14.195695 120224 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:27:14.197172 120224 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([178956971, 12],"float64"),Tensor([178956971, 12],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([178956971, 12],"float64"),Tensor([178956971, 12],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 106929 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:28:01.521798 120264 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:28:01.522882 120264 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([178956971, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([178956971, 12],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([178956971, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([178956971, 12],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 144654 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:28:46.206684 120293 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:28:46.207741 120293 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([178956971, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([178956971, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 45501 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:29:31.529603 120307 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:29:31.530616 120307 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([178956971, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([178956971, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 87672 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:30:17.544519 120335 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:30:17.545656 120335 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([178957, 100, 120],"float64"),Tensor([178957, 100, 120],"float64"),], axis=0, )
[torch error] paddle.concat(list[Tensor([178957, 100, 120],"float64"),Tensor([178957, 100, 120],"float64"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 153190 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:31:04.985189 120350 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:31:05.009940 120350 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([178957, 100, 120],"float64"),Tensor([3, 100, 120],"float64"),], axis=0, )
[torch error] paddle.concat(list[Tensor([178957, 100, 120],"float64"),Tensor([3, 100, 120],"float64"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 40066 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:31:50.521636 120377 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:31:50.522900 120377 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([178957, 960, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([178957, 960, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 89532 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:32:57.961616 120405 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:32:57.962728 120405 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([178957, 960, 5, 5],"float32"),Tensor([178957, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([178957, 960, 5, 5],"float32"),Tensor([178957, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 159441 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:34:10.049927 120433 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:34:10.050920 120433 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([179616, 488, 7, 7],"float32"),Tensor([179616, 488, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([179616, 488, 7, 7],"float32"),Tensor([179616, 488, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 99011 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:35:18.948279 120461 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:35:18.949374 120461 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([179616, 488, 7, 7],"float32"),Tensor([2, 488, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([179616, 488, 7, 7],"float32"),Tensor([2, 488, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 7840 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:36:27.454746 120489 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:36:27.455806 120489 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([18021, 1216, 14, 14],"float32"),Tensor([18021, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([18021, 1216, 14, 14],"float32"),Tensor([18021, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 89495 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:37:38.197618 120531 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:37:38.198702 120531 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([18021, 1216, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([18021, 1216, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 27261 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:38:45.559899 120573 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:38:45.561002 120573 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1826092, 48, 7, 7],"float32"),Tensor([1826092, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1826092, 48, 7, 7],"float32"),Tensor([1826092, 48, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 102310 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:39:52.523932 120601 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:39:52.525039 120601 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1826092, 48, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1826092, 48, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 10490 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:41:04.558869 120629 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:41:04.559849 120629 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([18261, 1200, 14, 14],"float32"),Tensor([18261, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([18261, 1200, 14, 14],"float32"),Tensor([18261, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 99493 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:42:19.176602 120657 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:42:19.177692 120657 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([18261, 1200, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([18261, 1200, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 23405 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:43:27.962198 120686 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:43:27.963295 120686 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([18508, 1184, 14, 14],"float32"),Tensor([18508, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([18508, 1184, 14, 14],"float32"),Tensor([18508, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 94453 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:44:36.190421 120713 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:44:36.191418 120713 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([18508, 1184, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([18508, 1184, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 12932 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:45:47.931895 120741 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:45:47.932957 120741 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([185128, 928, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([185128, 928, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 99788 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:46:56.153504 120769 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:46:56.154660 120769 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([185128, 928, 5, 5],"float32"),Tensor([185128, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([185128, 928, 5, 5],"float32"),Tensor([185128, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 9996 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:48:04.335057 120797 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:48:04.336143 120797 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1864136, 576, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1864136, 576, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 95737 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:49:12.604300 120851 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:49:12.605425 120851 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1864136, 576, 2, 2],"float32"),Tensor([1864136, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1864136, 576, 2, 2],"float32"),Tensor([1864136, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 21571 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:50:26.698096 120878 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:50:26.699090 120878 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([188907, 116, 14, 14],"float32"),Tensor([188907, 116, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([188907, 116, 14, 14],"float32"),Tensor([188907, 116, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 94551 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:51:35.541711 120910 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:51:35.542817 120910 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([188907, 116, 14, 14],"float32"),Tensor([2, 116, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([188907, 116, 14, 14],"float32"),Tensor([2, 116, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 13950 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:52:43.354105 120963 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:52:43.355135 120963 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([19022, 1152, 14, 14],"float32"),Tensor([19022, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([19022, 1152, 14, 14],"float32"),Tensor([19022, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 95814 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:53:51.900734 121006 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:53:51.901827 121006 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([19022, 1152, 14, 14],"float32"),Tensor([19022, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([19022, 1152, 14, 14],"float32"),Tensor([19022, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 8177 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:55:00.906366 121048 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:55:00.907402 121048 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([19022, 1152, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([19022, 1152, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 78486 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:56:13.148221 121077 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:56:13.149267 121077 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([19022, 1152, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([19022, 1152, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 23641 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:57:25.343218 121118 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:57:25.344300 121118 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([19022, 288, 28, 28],"float32"),Tensor([19022, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([19022, 288, 28, 28],"float32"),Tensor([19022, 32, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 97659 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:58:34.523453 121133 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:58:34.524447 121133 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([19022, 288, 28, 28],"float32"),Tensor([19022, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([19022, 288, 28, 28],"float32"),Tensor([19022, 48, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 16772 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:59:42.125825 121161 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:59:42.126929 121161 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([19022, 288, 28, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([19022, 288, 28, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 99165 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:00:51.161634 121189 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:00:51.162729 121189 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([19022, 288, 28, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([19022, 288, 28, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 7878 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:02:00.789263 121230 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:02:00.790378 121230 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([191740, 224, 10, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([191740, 224, 10, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 79095 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:03:12.172722 121246 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:03:12.173856 121246 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([191740, 224, 10, 10],"float32"),Tensor([191740, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([191740, 224, 10, 10],"float32"),Tensor([191740, 32, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 19434 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:04:20.416837 121273 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:04:20.417902 121273 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([191740, 896, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([191740, 896, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 89946 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:05:32.067219 121301 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:05:32.068257 121301 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([191740, 896, 5, 5],"float32"),Tensor([191740, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([191740, 896, 5, 5],"float32"),Tensor([191740, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 161992 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:06:40.195250 121329 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:06:40.196285 121329 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([19566, 1120, 14, 14],"float32"),Tensor([19566, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([19566, 1120, 14, 14],"float32"),Tensor([19566, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 98437 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:07:47.940708 121370 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:07:47.941915 121370 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([19566, 1120, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([19566, 1120, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 5966 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:09:00.500068 121412 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:09:00.501104 121412 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1973791, 544, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1973791, 544, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 81442 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:10:16.998976 121428 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:10:17.000027 121428 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([1973791, 544, 2, 2],"float32"),Tensor([1973791, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([1973791, 544, 2, 2],"float32"),Tensor([1973791, 32, 2, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 26229 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:11:29.658977 121455 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:11:29.660125 121455 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([19849, 1104, 14, 14],"float32"),Tensor([19849, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([19849, 1104, 14, 14],"float32"),Tensor([19849, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 99671 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:12:41.718318 121483 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:12:41.719430 121483 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([19849, 1104, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([19849, 1104, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 30749 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:13:53.182955 121512 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:13:53.184051 121512 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([198547, 128, 13, 13],"float32"),Tensor([198547, 256, 13, 13],"float32"),Tensor([198547, 64, 13, 13],"float32"),Tensor([198547, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([198547, 128, 13, 13],"float32"),Tensor([198547, 256, 13, 13],"float32"),Tensor([198547, 64, 13, 13],"float32"),Tensor([198547, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 103422 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:14:59.351154 121539 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:14:59.352146 121539 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([198547, 128, 13, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([198547, 128, 13, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 9838 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:16:09.307279 121567 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:16:09.308378 121567 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([198842, 864, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([198842, 864, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 113874 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:17:23.071286 121608 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:17:23.072455 121608 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([198842, 864, 5, 5],"float32"),Tensor([198842, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([198842, 864, 5, 5],"float32"),Tensor([198842, 32, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 27522 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:18:35.987118 121637 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:18:35.988191 121637 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 2],"float32"),Tensor([2, 1, 2147483648],"float32"),], axis=-2, )
[torch error] paddle.concat(list[Tensor([2, 1, 2],"float32"),Tensor([2, 1, 2147483648],"float32"),], axis=-2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 112344 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:19:45.266636 121652 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:19:45.267760 121652 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 2],"float32"),Tensor([2, 1073741824, 2],"float32"),], axis=-2, )
[torch error] paddle.concat(list[Tensor([2, 1, 2],"float32"),Tensor([2, 1073741824, 2],"float32"),], axis=-2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 31805 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:20:56.624017 121692 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:20:56.625141 121692 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 2],"float32"),Tensor([2147483648, 1, 2],"float32"),], axis=-2, )
[torch error] paddle.concat(list[Tensor([2, 1, 2],"float32"),Tensor([2147483648, 1, 2],"float32"),], axis=-2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 102962 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:22:12.506184 121727 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:22:12.507256 121727 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 2],"float32"),], axis=-2, )
[torch error] paddle.concat(list[Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 2],"float32"),], axis=-2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 44330 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:23:20.145921 121750 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:23:20.147024 121750 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 2147483648],"float32"),], axis=-2, )
[torch error] paddle.concat(list[Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 2147483648],"float32"),], axis=-2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 113596 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:24:26.147920 121790 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:24:26.149114 121790 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 2147483648],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 2147483648],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 21064 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:25:32.366679 121819 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:25:32.367790 121819 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 97108 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:26:43.729225 121847 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:26:43.730762 121847 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 536870912, 4],"float32"),Tensor([2, 1, 536870912, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([2, 1, 536870912, 4],"float32"),Tensor([2, 1, 536870912, 4],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 32670 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:27:51.527973 121888 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:27:51.528991 121888 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 536870912, 4],"float32"),Tensor([2, 1, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([2, 1, 536870912, 4],"float32"),Tensor([2, 1, 8, 4],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 102380 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:28:59.170485 121917 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:28:59.171499 121917 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 8, 268435456],"float32"),Tensor([2, 1, 8, 268435456],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([2, 1, 8, 268435456],"float32"),Tensor([2, 1, 8, 268435456],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 12381 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:30:10.793205 121946 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:30:10.794299 121946 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 8, 268435456],"float32"),Tensor([2, 1, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([2, 1, 8, 268435456],"float32"),Tensor([2, 1, 8, 4],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 112091 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:31:23.305943 121960 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:31:23.306983 121960 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 8, 4],"float32"),Tensor([134217728, 1, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([2, 1, 8, 4],"float32"),Tensor([134217728, 1, 8, 4],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 23857 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:32:29.826527 122000 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:32:29.827631 122000 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 8, 4],"float32"),Tensor([2, 1, 536870912, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([2, 1, 8, 4],"float32"),Tensor([2, 1, 536870912, 4],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 94249 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:33:37.110188 122029 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:33:37.111299 122029 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 8, 4],"float32"),Tensor([2, 1, 8, 268435456],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([2, 1, 8, 4],"float32"),Tensor([2, 1, 8, 268435456],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 19528 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:34:48.750440 122044 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:34:48.751775 122044 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 8, 4],"float32"),Tensor([2, 67108864, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([2, 1, 8, 4],"float32"),Tensor([2, 67108864, 8, 4],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 95271 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:35:59.105407 122072 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:35:59.106444 122072 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 7810 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:37:06.517520 122112 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:37:06.518533 122112 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 102343 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:38:19.000792 122142 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:38:19.001942 122142 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 21606 has 1016.00 MiB memory in use. Of the allocated memory 1.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:39:30.823055 122169 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:39:30.824082 122169 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 92276 has 1016.00 MiB memory in use. Of the allocated memory 2.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:40:39.127903 122210 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:40:39.128927 122210 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 23806 has 1016.00 MiB memory in use. Of the allocated memory 2.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:41:46.036921 122239 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:41:46.038291 122239 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 2147483648],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 99058 has 1016.00 MiB memory in use. Of the allocated memory 3.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:42:58.247185 122254 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:42:58.248136 122254 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 2147483648],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 2147483648],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 8238 has 1016.00 MiB memory in use. Of the allocated memory 3.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:44:10.211720 122295 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:44:10.212821 122295 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 268435456, 8],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 268435456, 8],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 106959 has 1016.00 MiB memory in use. Of the allocated memory 3.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:45:19.041893 122310 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:45:19.042897 122310 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([536870912, 1, 8],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([536870912, 1, 8],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 18157 has 1016.00 MiB memory in use. Of the allocated memory 3.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:46:25.196015 122324 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:46:25.196990 122324 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 95339 has 1016.00 MiB memory in use. Of the allocated memory 3.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:47:37.271880 122351 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:47:37.272914 122351 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([536870912, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([536870912, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 20792 has 1016.00 MiB memory in use. Of the allocated memory 3.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:48:48.880079 122379 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:48:48.881222 122379 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 99472 has 1016.00 MiB memory in use. Of the allocated memory 2.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:49:55.471338 122394 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:49:55.472322 122394 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([536870912, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([536870912, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 6164 has 1016.00 MiB memory in use. Of the allocated memory 2.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:51:07.506577 122421 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:51:07.507701 122421 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 106311 has 1016.00 MiB memory in use. Of the allocated memory 2.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:52:14.744424 122480 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:52:14.745561 122480 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([536870912, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([536870912, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 16920 has 1016.00 MiB memory in use. Of the allocated memory 2.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:53:28.500897 122506 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:53:28.501972 122506 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 87981 has 1016.00 MiB memory in use. Of the allocated memory 1.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:54:40.940331 122546 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:54:40.941421 122546 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([536870912, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([536870912, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 19771 has 1016.00 MiB memory in use. Of the allocated memory 1.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:55:53.726716 122601 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:55:53.727730 122601 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 95859 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:57:01.356635 122644 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:57:01.357756 122644 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([536870912, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([536870912, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 5883 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:58:08.557878 122660 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:58:08.558955 122660 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 107032 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:59:22.957413 122713 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:59:22.958516 122713 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([536870912, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1, 8],"float32"),Tensor([536870912, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 21937 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:00:29.757916 122743 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:00:29.758921 122743 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1],"float64"),Tensor([2, 1073741825],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([2, 1],"float64"),Tensor([2, 1073741825],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 92133 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:01:18.145040 122784 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:01:18.146029 122784 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1],"float64"),Tensor([2147483649, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([2, 1],"float64"),Tensor([2147483649, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 158281 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:02:08.248687 122813 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:02:08.249790 122813 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1],"int64"),Tensor([1073741825, 2],"int64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1],"int64"),Tensor([1073741825, 2],"int64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 57141 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:02:55.405062 122841 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:02:55.406206 122841 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1],"int64"),Tensor([2, 1073741825],"int64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1],"int64"),Tensor([2, 1073741825],"int64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 94855 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:03:39.354103 122856 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:03:39.355211 122856 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 10, 214748365],"float32"),Tensor([2, 10, 214748365],"float32"),], )
[torch error] paddle.concat(list[Tensor([2, 10, 214748365],"float32"),Tensor([2, 10, 214748365],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 159201 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:04:51.761159 122883 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:04:51.762252 122883 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 10, 214748365],"float32"),Tensor([2, 10, 5],"float32"),], )
[torch error] paddle.concat(list[Tensor([2, 10, 214748365],"float32"),Tensor([2, 10, 5],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 67508 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:05:58.708925 122916 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:05:58.710043 122916 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 10, 5],"float32"),Tensor([2, 10, 214748365],"float32"),], )
[torch error] paddle.concat(list[Tensor([2, 10, 5],"float32"),Tensor([2, 10, 214748365],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 142038 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:07:04.563705 122940 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:07:04.564704 122940 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 10, 5],"float32"),Tensor([2, 429496730, 5],"float32"),], )
[torch error] paddle.concat(list[Tensor([2, 10, 5],"float32"),Tensor([2, 429496730, 5],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 62945 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:08:15.660472 122993 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:08:15.661455 122993 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 10, 5],"float32"),Tensor([85899346, 10, 5],"float32"),], )
[torch error] paddle.concat(list[Tensor([2, 10, 5],"float32"),Tensor([85899346, 10, 5],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 155842 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:09:24.562624 123037 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:09:24.563647 123037 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1008, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1008, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 63213 has 1.01 GiB memory in use. Of the allocated memory 1.51 MiB is allocated by PyTorch, and 18.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:10:32.305756 123065 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:10:32.310117 123065 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1008, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1008, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 136327 has 1.01 GiB memory in use. Of the allocated memory 1.51 MiB is allocated by PyTorch, and 18.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:11:43.688623 123106 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:11:43.689623 123106 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1008, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1008, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 65491 has 1.01 GiB memory in use. Of the allocated memory 1.51 MiB is allocated by PyTorch, and 18.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:12:52.750598 123122 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:12:52.751627 123122 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1008, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1008, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 138787 has 1.01 GiB memory in use. Of the allocated memory 1.51 MiB is allocated by PyTorch, and 18.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:13:59.932098 123149 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:13:59.933085 123149 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1008, 14, 152175],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1008, 14, 152175],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 48233 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:15:07.995128 123177 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:15:07.996241 123177 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1008, 14, 152175],"float32"),Tensor([2, 48, 14, 152175],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1008, 14, 152175],"float32"),Tensor([2, 48, 14, 152175],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 140630 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:16:21.275279 123206 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:16:21.276427 123206 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1008, 152175, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1008, 152175, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 63929 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:17:30.403950 123247 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:17:30.405073 123247 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1008, 152175, 14],"float32"),Tensor([2, 48, 152175, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1008, 152175, 14],"float32"),Tensor([2, 48, 152175, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 135737 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:18:39.531282 123275 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:18:39.532326 123275 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1024, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1024, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 66376 has 1.01 GiB memory in use. Of the allocated memory 1.53 MiB is allocated by PyTorch, and 18.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:19:51.608369 123304 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:19:51.609490 123304 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1024, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1024, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 139627 has 1.01 GiB memory in use. Of the allocated memory 1.53 MiB is allocated by PyTorch, and 18.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:20:59.725672 123345 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:20:59.726788 123345 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1024, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1024, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 46705 has 1.01 GiB memory in use. Of the allocated memory 1.53 MiB is allocated by PyTorch, and 18.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:22:07.510993 123386 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:22:07.512008 123386 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1024, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1024, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 137304 has 1.01 GiB memory in use. Of the allocated memory 1.53 MiB is allocated by PyTorch, and 18.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:23:15.602540 123402 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:23:15.603534 123402 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1024, 14, 149797],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1024, 14, 149797],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 52702 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:24:31.422771 123429 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:24:31.423784 123429 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1024, 14, 149797],"float32"),Tensor([2, 32, 14, 149797],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1024, 14, 149797],"float32"),Tensor([2, 32, 14, 149797],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 127415 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:25:42.856307 123498 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:25:42.857755 123498 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1024, 149797, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1024, 149797, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 61514 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:26:49.321480 123514 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:26:49.322631 123514 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1024, 149797, 14],"float32"),Tensor([2, 32, 149797, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1024, 149797, 14],"float32"),Tensor([2, 32, 149797, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 134478 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:28:03.390033 123528 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:28:03.391070 123528 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1024, 299594, 7],"float32"),Tensor([2, 32, 299594, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1024, 299594, 7],"float32"),Tensor([2, 32, 299594, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 45655 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:29:10.388710 123570 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:29:10.403759 123570 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1024, 299594, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1024, 299594, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 144518 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:30:29.440002 123597 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:30:29.441123 123597 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1024, 7, 299594],"float32"),Tensor([2, 32, 7, 299594],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1024, 7, 299594],"float32"),Tensor([2, 32, 7, 299594],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 60680 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:31:39.017594 123639 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:31:39.018972 123639 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1024, 7, 299594],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1024, 7, 299594],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 154275 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:32:46.353926 123681 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:32:46.354934 123681 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1024, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1024, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 61284 has 1016.00 MiB memory in use. Of the allocated memory 392.00 KiB is allocated by PyTorch, and 1.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:33:51.687435 123709 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:33:51.691452 123709 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1024, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1024, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 131928 has 1016.00 MiB memory in use. Of the allocated memory 392.00 KiB is allocated by PyTorch, and 1.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:35:04.089505 123750 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:35:04.090385 123750 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1024, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1024, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 47467 has 1016.00 MiB memory in use. Of the allocated memory 392.00 KiB is allocated by PyTorch, and 1.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:36:17.285377 123792 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:36:17.286254 123792 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1024, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1024, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 147983 has 1016.00 MiB memory in use. Of the allocated memory 392.00 KiB is allocated by PyTorch, and 1.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:37:23.499681 123849 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:37:23.500694 123849 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 61676 has 1.01 GiB memory in use. Of the allocated memory 1.58 MiB is allocated by PyTorch, and 18.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:38:31.697567 123890 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:38:31.698606 123890 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 140535 has 1.01 GiB memory in use. Of the allocated memory 1.58 MiB is allocated by PyTorch, and 18.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:39:44.924751 123945 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:39:44.928787 123945 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 68204 has 1.01 GiB memory in use. Of the allocated memory 1.58 MiB is allocated by PyTorch, and 18.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:40:55.565251 123988 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:40:55.566238 123988 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 140830 has 1.01 GiB memory in use. Of the allocated memory 1.58 MiB is allocated by PyTorch, and 18.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:42:02.662429 124017 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:42:02.663424 124017 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 49687 has 1.01 GiB memory in use. Of the allocated memory 1.58 MiB is allocated by PyTorch, and 18.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:43:11.957290 124071 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:43:11.958273 124071 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 142809 has 1.01 GiB memory in use. Of the allocated memory 1.58 MiB is allocated by PyTorch, and 18.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:44:22.241732 124114 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:44:22.242834 124114 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 58488 has 1.01 GiB memory in use. Of the allocated memory 1.58 MiB is allocated by PyTorch, and 18.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:45:35.338827 124143 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:45:35.341434 124143 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 14, 145258],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 14, 145258],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 147317 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:46:43.952289 124171 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:46:43.953758 124171 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 14, 145258],"float32"),Tensor([2, 32, 14, 145258],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 14, 145258],"float32"),Tensor([2, 32, 14, 145258],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 70008 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:47:57.468456 124213 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:47:57.469480 124213 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 14, 145258],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 14, 145258],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 142295 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:49:05.694370 124254 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:49:05.695356 124254 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 14, 145258],"float32"),Tensor([2, 48, 14, 145258],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 14, 145258],"float32"),Tensor([2, 48, 14, 145258],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 62969 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:50:12.864360 124296 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:50:12.865458 124296 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 145258, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 145258, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 145405 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:51:24.607419 124338 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:51:24.608453 124338 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 145258, 14],"float32"),Tensor([2, 32, 145258, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 145258, 14],"float32"),Tensor([2, 32, 145258, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 61129 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:52:33.530514 124367 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:52:33.531755 124367 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 145258, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 145258, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 136055 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:53:41.199597 124421 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:53:41.201090 124421 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 145258, 14],"float32"),Tensor([2, 48, 145258, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 145258, 14],"float32"),Tensor([2, 48, 145258, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 61256 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:54:50.711445 124452 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:54:50.717408 124452 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 290515, 7],"float32"),Tensor([2, 32, 290515, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 290515, 7],"float32"),Tensor([2, 32, 290515, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 133599 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:56:03.169410 124507 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:56:03.170410 124507 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 290515, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 290515, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 49057 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:57:10.604884 124561 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:57:10.606477 124561 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 290515, 7],"float32"),Tensor([2, 48, 290515, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 290515, 7],"float32"),Tensor([2, 48, 290515, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 140809 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:58:16.877115 124591 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:58:16.878177 124591 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 290515, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 290515, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 50073 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:59:23.623803 124632 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:59:23.624872 124632 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 7, 290515],"float32"),Tensor([2, 32, 7, 290515],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 7, 290515],"float32"),Tensor([2, 32, 7, 290515],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 125621 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:00:36.526924 124661 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:00:36.528069 124661 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 7, 290515],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 7, 290515],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 50953 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:01:49.193068 124702 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:01:49.194216 124702 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 7, 290515],"float32"),Tensor([2, 48, 7, 290515],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 7, 290515],"float32"),Tensor([2, 48, 7, 290515],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 136336 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:03:01.685717 124744 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:03:01.686743 124744 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 7, 290515],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 7, 290515],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 44372 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:04:14.719902 124773 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:04:14.721024 124773 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 7, 7],"float32"),Tensor([1826092, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 7, 7],"float32"),Tensor([1826092, 48, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 139930 has 1016.00 MiB memory in use. Of the allocated memory 404.50 KiB is allocated by PyTorch, and 1.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:05:26.946764 124828 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:05:26.947858 124828 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 55550 has 1016.00 MiB memory in use. Of the allocated memory 404.50 KiB is allocated by PyTorch, and 1.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:06:39.228981 124871 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:06:39.230021 124871 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 156534 has 1016.00 MiB memory in use. Of the allocated memory 404.50 KiB is allocated by PyTorch, and 1.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:07:46.574522 124899 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:07:46.578666 124899 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 62210 has 1016.00 MiB memory in use. Of the allocated memory 404.50 KiB is allocated by PyTorch, and 1.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:08:58.092399 124954 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:08:58.093426 124954 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 7, 7],"float32"),Tensor([2, 48, 6391321, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 7, 7],"float32"),Tensor([2, 48, 6391321, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 136952 has 1016.00 MiB memory in use. Of the allocated memory 404.50 KiB is allocated by PyTorch, and 1.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:10:09.454638 124983 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:10:09.455696 124983 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 7, 7],"float32"),Tensor([2, 48, 7, 6391321],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 7, 7],"float32"),Tensor([2, 48, 7, 6391321],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 66808 has 1016.00 MiB memory in use. Of the allocated memory 404.50 KiB is allocated by PyTorch, and 1.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:11:16.869710 125011 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:11:16.870636 125011 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1056, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1056, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 142290 has 1016.00 MiB memory in use. Of the allocated memory 404.50 KiB is allocated by PyTorch, and 1.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:12:29.395121 125052 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:12:29.396138 125052 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1073741824, 2],"float32"),Tensor([2, 1, 2],"float32"),], axis=-2, )
[torch error] paddle.concat(list[Tensor([2, 1073741824, 2],"float32"),Tensor([2, 1, 2],"float32"),], axis=-2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 56318 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:13:41.558706 125081 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:13:41.559681 125081 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1073741824, 2],"float32"),Tensor([2, 1073741824, 2],"float32"),], axis=-2, )
[torch error] paddle.concat(list[Tensor([2, 1073741824, 2],"float32"),Tensor([2, 1073741824, 2],"float32"),], axis=-2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 149558 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:14:51.258533 125096 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:14:51.259708 125096 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1073741825],"float64"),Tensor([2, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([2, 1073741825],"float64"),Tensor([2, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 57357 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:15:40.652030 125136 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:15:40.653136 125136 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 124375 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:16:28.246868 125178 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:16:28.247852 125178 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 10940 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:17:17.133715 125194 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:17:17.134846 125194 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),], )
[torch error] paddle.concat(list[Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 71439 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:18:03.613161 125221 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:18:03.614306 125221 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 114131 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:18:48.859709 125249 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:18:48.860802 125249 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 1073741825],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 17796 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:19:34.595705 125277 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:19:34.596745 125277 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1073741825],"float64"),Tensor([2, 12],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1073741825],"float64"),Tensor([2, 12],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 69494 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:20:24.832309 125318 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:20:24.858235 125318 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1073741825],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1073741825],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 124251 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:21:14.933769 125334 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:21:14.934762 125334 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1073741825],"float64"),Tensor([2, 3],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1073741825],"float64"),Tensor([2, 3],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 22114 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:22:05.486605 125374 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:22:05.487648 125374 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1073741825],"float64"),Tensor([2, 3],"float64"),Tensor([2, 3],"float64"),], )
[torch error] paddle.concat(list[Tensor([2, 1073741825],"float64"),Tensor([2, 3],"float64"),Tensor([2, 3],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 75477 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:22:52.144203 125401 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:22:52.145941 125401 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1073741825],"float64"),Tensor([2, 3],"float64"),Tensor([2, 3],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1073741825],"float64"),Tensor([2, 3],"float64"),Tensor([2, 3],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 130563 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:23:37.700673 125431 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:23:37.701783 125431 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1073741825],"int64"),Tensor([2, 1073741825],"int64"),], axis=0, )
[torch error] paddle.concat(list[Tensor([2, 1073741825],"int64"),Tensor([2, 1073741825],"int64"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 27455 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:24:23.420244 125459 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:24:23.421366 125459 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1073741825],"int64"),Tensor([2, 1073741825],"int64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1073741825],"int64"),Tensor([2, 1073741825],"int64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 73084 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:25:09.739333 125487 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:25:09.740383 125487 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1073741825],"int64"),Tensor([2, 2],"int64"),], axis=0, )
[torch error] paddle.concat(list[Tensor([2, 1073741825],"int64"),Tensor([2, 2],"int64"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 130966 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:25:53.641017 125515 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:25:53.642513 125515 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1073741825],"int64"),Tensor([2, 2],"int64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1073741825],"int64"),Tensor([2, 2],"int64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 14389 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:26:36.152611 125556 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:26:36.153707 125556 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 107374183, 20],"float16"),Tensor([2, 107374183, 20],"float16"),], )
[torch error] paddle.concat(list[Tensor([2, 107374183, 20],"float16"),Tensor([2, 107374183, 20],"float16"),], ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 68410 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:28:03.627100 125571 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:28:03.628224 125571 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 107374183, 20],"float16"),Tensor([2, 20, 20],"float16"),], )
[torch error] paddle.concat(list[Tensor([2, 107374183, 20],"float16"),Tensor([2, 20, 20],"float16"),], ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 159592 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:29:26.368939 125627 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:29:26.369937 125627 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1088, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1088, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 100010 has 1.01 GiB memory in use. Of the allocated memory 1.63 MiB is allocated by PyTorch, and 18.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:30:32.681309 125661 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:30:32.682392 125661 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1088, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1088, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 11129 has 1.01 GiB memory in use. Of the allocated memory 1.63 MiB is allocated by PyTorch, and 18.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:31:39.968685 125710 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:31:39.969780 125710 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1088, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1088, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 99984 has 1.01 GiB memory in use. Of the allocated memory 1.63 MiB is allocated by PyTorch, and 18.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:32:46.931028 125752 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:32:46.932150 125752 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1088, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1088, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 11672 has 1.01 GiB memory in use. Of the allocated memory 1.63 MiB is allocated by PyTorch, and 18.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:33:59.371013 125794 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:33:59.372092 125794 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1088, 14, 140986],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1088, 14, 140986],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 83379 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:35:08.606184 125837 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:35:08.607719 125837 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1088, 14, 140986],"float32"),Tensor([2, 32, 14, 140986],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1088, 14, 140986],"float32"),Tensor([2, 32, 14, 140986],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 13346 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:36:16.327205 125865 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:36:16.328310 125865 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1088, 140986, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1088, 140986, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 90858 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:37:24.334262 125880 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:37:24.335790 125880 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1088, 140986, 14],"float32"),Tensor([2, 32, 140986, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1088, 140986, 14],"float32"),Tensor([2, 32, 140986, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 4190 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:38:38.841933 125933 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:38:38.842969 125933 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1088, 281971, 7],"float32"),Tensor([2, 32, 281971, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1088, 281971, 7],"float32"),Tensor([2, 32, 281971, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 102835 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:39:46.127483 125976 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:39:46.128558 125976 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1088, 281971, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1088, 281971, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 11228 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:40:52.390972 126005 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:40:52.392082 126005 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1088, 7, 281971],"float32"),Tensor([2, 32, 7, 281971],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1088, 7, 281971],"float32"),Tensor([2, 32, 7, 281971],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 80229 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:41:59.796847 126059 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:41:59.797859 126059 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1088, 7, 281971],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1088, 7, 281971],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 152894 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:43:11.449635 126089 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:43:11.450755 126089 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1088, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1088, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 83597 has 1016.00 MiB memory in use. Of the allocated memory 416.50 KiB is allocated by PyTorch, and 1.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:44:22.128290 126130 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:44:22.129329 126130 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1088, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1088, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 161404 has 1016.00 MiB memory in use. Of the allocated memory 416.50 KiB is allocated by PyTorch, and 1.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:45:39.948185 126172 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:45:39.949236 126172 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1088, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1088, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 99564 has 1016.00 MiB memory in use. Of the allocated memory 416.50 KiB is allocated by PyTorch, and 1.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:46:47.373186 126214 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:46:47.373989 126214 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1088, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1088, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 9208 has 1016.00 MiB memory in use. Of the allocated memory 416.50 KiB is allocated by PyTorch, and 1.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:47:59.290338 126256 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:47:59.291379 126256 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 10956550, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 10956550, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 79693 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:49:16.105086 126298 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:49:16.106195 126298 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 10956550, 14, 14],"float32"),Tensor([2, 116, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 10956550, 14, 14],"float32"),Tensor([2, 116, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 19672 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:50:23.588371 126327 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:50:23.589377 126327 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 10956550, 14, 14],"float32"),Tensor([2, 176, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 10956550, 14, 14],"float32"),Tensor([2, 176, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 94679 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:51:36.668054 126369 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:51:36.669199 126369 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 10956550, 14, 14],"float32"),Tensor([2, 24, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 10956550, 14, 14],"float32"),Tensor([2, 24, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 19358 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:52:48.392097 126410 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:52:48.393249 126410 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 10956550, 14, 14],"float32"),Tensor([2, 244, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 10956550, 14, 14],"float32"),Tensor([2, 244, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 101495 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:53:56.383951 126439 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:53:56.385545 126439 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 10956550, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 10956550, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 8643 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:55:03.720899 126493 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:55:03.722486 126493 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 10956550, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 10956550, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 83070 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:56:13.802973 126536 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:56:13.804008 126536 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1104, 138942, 14],"float32"),Tensor([2, 48, 138942, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1104, 138942, 14],"float32"),Tensor([2, 48, 138942, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 14077 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:57:27.967186 126578 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:57:27.968189 126578 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1104, 138942, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1104, 138942, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 95837 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:58:36.596668 126633 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:58:36.597955 126633 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1104, 14, 138942],"float32"),Tensor([2, 48, 14, 138942],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1104, 14, 138942],"float32"),Tensor([2, 48, 14, 138942],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 17296 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:59:49.227767 126650 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:59:49.228873 126650 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1104, 14, 138942],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1104, 14, 138942],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 99175 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:01:03.285049 126678 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:01:03.286075 126678 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1104, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1104, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 10841 has 1.01 GiB memory in use. Of the allocated memory 1.65 MiB is allocated by PyTorch, and 18.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:02:19.696800 126718 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:02:19.697902 126718 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1104, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1104, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 105729 has 1.01 GiB memory in use. Of the allocated memory 1.65 MiB is allocated by PyTorch, and 18.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:03:28.150485 126760 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:03:28.151472 126760 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1104, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1104, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 19555 has 1.01 GiB memory in use. Of the allocated memory 1.65 MiB is allocated by PyTorch, and 18.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:04:34.881497 126802 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:04:34.882561 126802 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1104, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1104, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 104840 has 1.01 GiB memory in use. Of the allocated memory 1.65 MiB is allocated by PyTorch, and 18.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:05:46.532752 126818 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:05:46.537098 126818 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1104, 277884, 7],"float32"),Tensor([2, 48, 277884, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1104, 277884, 7],"float32"),Tensor([2, 48, 277884, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 29319 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:06:57.099416 126858 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:06:57.100560 126858 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1104, 277884, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1104, 277884, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 102860 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:08:09.847935 126900 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:08:09.849011 126900 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1104, 7, 277884],"float32"),Tensor([2, 48, 7, 277884],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1104, 7, 277884],"float32"),Tensor([2, 48, 7, 277884],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 33667 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:09:22.922699 126942 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:09:22.923750 126942 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1104, 7, 277884],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1104, 7, 277884],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 111846 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:10:35.875654 126971 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:10:35.876650 126971 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1104, 7, 7],"float32"),Tensor([1826092, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1104, 7, 7],"float32"),Tensor([1826092, 48, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 36443 has 1016.00 MiB memory in use. Of the allocated memory 423.00 KiB is allocated by PyTorch, and 1.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:11:45.836845 127025 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:11:45.837872 127025 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1104, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1104, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 120871 has 1016.00 MiB memory in use. Of the allocated memory 423.00 KiB is allocated by PyTorch, and 1.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:12:53.055786 127055 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:12:53.057024 127055 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1104, 7, 7],"float32"),Tensor([2, 48, 6391321, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1104, 7, 7],"float32"),Tensor([2, 48, 6391321, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 28356 has 1016.00 MiB memory in use. Of the allocated memory 423.00 KiB is allocated by PyTorch, and 1.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:14:08.914232 127083 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:14:08.915431 127083 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1104, 7, 7],"float32"),Tensor([2, 48, 7, 6391321],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1104, 7, 7],"float32"),Tensor([2, 48, 7, 6391321],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 123532 has 1016.00 MiB memory in use. Of the allocated memory 423.00 KiB is allocated by PyTorch, and 1.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:15:16.470309 127124 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:15:16.471290 127124 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 112, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 112, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 29835 has 1016.00 MiB memory in use. Of the allocated memory 148.00 KiB is allocated by PyTorch, and 1.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:16:29.105329 127167 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:16:29.106453 127167 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 112, 13, 13],"float32"),Tensor([2, 288, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 112, 13, 13],"float32"),Tensor([2, 288, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 117245 has 1016.00 MiB memory in use. Of the allocated memory 528.50 KiB is allocated by PyTorch, and 1.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:17:36.820116 127200 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:17:36.821237 127200 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 112, 13, 13],"float32"),Tensor([2, 288, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 112, 13, 13],"float32"),Tensor([2, 288, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 42369 has 1016.00 MiB memory in use. Of the allocated memory 613.00 KiB is allocated by PyTorch, and 1.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:18:46.111698 127237 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:18:46.112973 127237 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 112, 13, 13],"float32"),Tensor([2, 288, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 2581111],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 112, 13, 13],"float32"),Tensor([2, 288, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 2581111],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 120085 has 1016.00 MiB memory in use. Of the allocated memory 613.00 KiB is allocated by PyTorch, and 1.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:20:00.546762 127291 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:20:00.548113 127291 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 112, 13, 13],"float32"),Tensor([2, 288, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 2581111, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 112, 13, 13],"float32"),Tensor([2, 288, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 2581111, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 29021 has 1016.00 MiB memory in use. Of the allocated memory 613.00 KiB is allocated by PyTorch, and 1.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:21:08.331413 127321 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:21:08.332415 127321 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 112, 13, 13],"float32"),Tensor([2, 288, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([397094, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 112, 13, 13],"float32"),Tensor([2, 288, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([397094, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 126142 has 1016.00 MiB memory in use. Of the allocated memory 613.00 KiB is allocated by PyTorch, and 1.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:22:15.593678 127348 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:22:15.594753 127348 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 112, 13, 13],"float32"),Tensor([2, 288, 13, 13],"float32"),Tensor([2, 64, 13, 2581111],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 112, 13, 13],"float32"),Tensor([2, 288, 13, 13],"float32"),Tensor([2, 64, 13, 2581111],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 33636 has 1016.00 MiB memory in use. Of the allocated memory 528.50 KiB is allocated by PyTorch, and 1.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:23:28.947412 127403 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:23:28.948678 127403 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 112, 13, 13],"float32"),Tensor([2, 288, 13, 13],"float32"),Tensor([2, 64, 2581111, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 112, 13, 13],"float32"),Tensor([2, 288, 13, 13],"float32"),Tensor([2, 64, 2581111, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 112877 has 1016.00 MiB memory in use. Of the allocated memory 528.50 KiB is allocated by PyTorch, and 1.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:24:37.132483 127438 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:24:37.136655 127438 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 112, 13, 13],"float32"),Tensor([2, 288, 13, 13],"float32"),Tensor([397094, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 112, 13, 13],"float32"),Tensor([2, 288, 13, 13],"float32"),Tensor([397094, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 39727 has 1016.00 MiB memory in use. Of the allocated memory 528.50 KiB is allocated by PyTorch, and 1.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:25:50.912822 127475 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:25:50.913771 127475 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 112, 13, 13],"float32"),Tensor([2, 288, 13, 573581],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 112, 13, 13],"float32"),Tensor([2, 288, 13, 573581],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 120246 has 1016.00 MiB memory in use. Of the allocated memory 148.00 KiB is allocated by PyTorch, and 1.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:27:03.607945 127543 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:27:03.608958 127543 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 112, 13, 13],"float32"),Tensor([2, 288, 573581, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 112, 13, 13],"float32"),Tensor([2, 288, 573581, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 37624 has 1016.00 MiB memory in use. Of the allocated memory 148.00 KiB is allocated by PyTorch, and 1.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:28:15.527948 127573 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:28:15.529122 127573 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 112, 13, 13],"float32"),Tensor([88244, 288, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 112, 13, 13],"float32"),Tensor([88244, 288, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 126302 has 1016.00 MiB memory in use. Of the allocated memory 148.00 KiB is allocated by PyTorch, and 1.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:29:23.597659 127614 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:29:23.598618 127614 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 112, 13, 1474921],"float32"),Tensor([2, 288, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 112, 13, 1474921],"float32"),Tensor([2, 288, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 34871 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:30:37.543823 127661 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:30:37.544816 127661 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 112, 13, 1474921],"float32"),Tensor([2, 288, 13, 1474921],"float32"),Tensor([2, 64, 13, 1474921],"float32"),Tensor([2, 64, 13, 1474921],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 112, 13, 1474921],"float32"),Tensor([2, 288, 13, 1474921],"float32"),Tensor([2, 64, 13, 1474921],"float32"),Tensor([2, 64, 13, 1474921],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 132045 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:31:45.147768 127699 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:31:45.149030 127699 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 112, 1474921, 13],"float32"),Tensor([2, 288, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 112, 1474921, 13],"float32"),Tensor([2, 288, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 44113 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:32:51.497134 127724 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:32:51.498144 127724 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 112, 1474921, 13],"float32"),Tensor([2, 288, 1474921, 13],"float32"),Tensor([2, 64, 1474921, 13],"float32"),Tensor([2, 64, 1474921, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 112, 1474921, 13],"float32"),Tensor([2, 288, 1474921, 13],"float32"),Tensor([2, 64, 1474921, 13],"float32"),Tensor([2, 64, 1474921, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 113709 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:33:58.902002 127756 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:33:58.903544 127756 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 112, 28, 28],"float32"),Tensor([2, 112, 28, 684785],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 112, 28, 28],"float32"),Tensor([2, 112, 28, 684785],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 22168 has 1016.00 MiB memory in use. Of the allocated memory 686.00 KiB is allocated by PyTorch, and 1.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:35:05.684731 127797 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:35:05.685681 127797 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 112, 28, 28],"float32"),Tensor([2, 112, 684785, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 112, 28, 28],"float32"),Tensor([2, 112, 684785, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 104383 has 1016.00 MiB memory in use. Of the allocated memory 686.00 KiB is allocated by PyTorch, and 1.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:36:17.706169 128227 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:36:17.707242 128227 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 112, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 112, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 36496 has 1016.00 MiB memory in use. Of the allocated memory 686.00 KiB is allocated by PyTorch, and 1.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:37:24.826390 128717 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:37:24.827299 128717 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 112, 28, 28],"float32"),Tensor([48914, 112, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 112, 28, 28],"float32"),Tensor([48914, 112, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 123675 has 1016.00 MiB memory in use. Of the allocated memory 686.00 KiB is allocated by PyTorch, and 1.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:38:37.194489 128992 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:38:37.195446 128992 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 112, 28, 684785],"float32"),Tensor([2, 112, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 112, 28, 684785],"float32"),Tensor([2, 112, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 60103 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:39:45.884896 129292 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:39:45.885995 129292 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 112, 28, 684785],"float32"),Tensor([2, 112, 28, 684785],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 112, 28, 684785],"float32"),Tensor([2, 112, 28, 684785],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 136050 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:40:53.429072 129653 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:40:53.430188 129653 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 112, 684785, 28],"float32"),Tensor([2, 112, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 112, 684785, 28],"float32"),Tensor([2, 112, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 45247 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:42:01.108752 129968 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:42:01.110179 129968 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 112, 684785, 28],"float32"),Tensor([2, 112, 684785, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 112, 684785, 28],"float32"),Tensor([2, 112, 684785, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 119185 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:43:07.483758 130262 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:43:07.484774 130262 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1120, 136957, 14],"float32"),Tensor([2, 32, 136957, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1120, 136957, 14],"float32"),Tensor([2, 32, 136957, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 42850 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:44:20.923871 130575 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:44:20.924844 130575 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1120, 136957, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1120, 136957, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 119554 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:45:28.570214 130887 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:45:28.571760 130887 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1120, 14, 136957],"float32"),Tensor([2, 32, 14, 136957],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1120, 14, 136957],"float32"),Tensor([2, 32, 14, 136957],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 33259 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:46:35.480778 131113 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:46:35.482262 131113 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1120, 14, 136957],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1120, 14, 136957],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 124642 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:47:41.972995 131402 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:47:41.974012 131402 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1120, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1120, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 42250 has 1.01 GiB memory in use. Of the allocated memory 1.67 MiB is allocated by PyTorch, and 18.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:48:48.273788 131693 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:48:48.274881 131693 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1120, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1120, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 116291 has 1.01 GiB memory in use. Of the allocated memory 1.67 MiB is allocated by PyTorch, and 18.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:50:01.966320 132096 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:50:01.967403 132096 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1120, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1120, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 27526 has 1.01 GiB memory in use. Of the allocated memory 1.67 MiB is allocated by PyTorch, and 18.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:51:14.285043 132335 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:51:14.286145 132335 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1120, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1120, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 124786 has 1.01 GiB memory in use. Of the allocated memory 1.67 MiB is allocated by PyTorch, and 18.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:52:21.853480 132701 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:52:21.854504 132701 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1120, 273914, 7],"float32"),Tensor([2, 32, 273914, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1120, 273914, 7],"float32"),Tensor([2, 32, 273914, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 39651 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:53:30.322201 132992 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:53:30.323377 132992 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1120, 273914, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1120, 273914, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 122317 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:54:43.314595 133291 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:54:43.315709 133291 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1120, 7, 273914],"float32"),Tensor([2, 32, 7, 273914],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1120, 7, 273914],"float32"),Tensor([2, 32, 7, 273914],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 57900 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:55:56.364957 133590 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:55:56.366087 133590 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1120, 7, 273914],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1120, 7, 273914],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 137847 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:57:03.958220 133989 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:57:03.959556 133989 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1120, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1120, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 54315 has 1016.00 MiB memory in use. Of the allocated memory 429.00 KiB is allocated by PyTorch, and 1.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:58:15.425098 134271 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:58:15.426134 134271 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1120, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1120, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 148332 has 1016.00 MiB memory in use. Of the allocated memory 429.00 KiB is allocated by PyTorch, and 1.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:59:22.310519 134657 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:59:22.311483 134657 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1120, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1120, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 57444 has 1016.00 MiB memory in use. Of the allocated memory 429.00 KiB is allocated by PyTorch, and 1.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:00:34.248350 134949 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:00:34.249279 134949 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1120, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1120, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 149314 has 1016.00 MiB memory in use. Of the allocated memory 429.00 KiB is allocated by PyTorch, and 1.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:01:47.685448 135251 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:01:47.686355 135251 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 133153, 14],"float32"),Tensor([2, 32, 133153, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 133153, 14],"float32"),Tensor([2, 32, 133153, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 75455 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:02:55.274163 135657 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:02:55.275274 135657 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 133153, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 133153, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 149067 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:04:11.364336 135949 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:04:11.365367 135949 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 133153, 14],"float32"),Tensor([2, 48, 133153, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 133153, 14],"float32"),Tensor([2, 48, 133153, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 87713 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:05:26.305238 136274 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:05:26.306354 136274 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 133153, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 133153, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 4474 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:06:42.321750 136671 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:06:42.322865 136671 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 14, 133153],"float32"),Tensor([2, 32, 14, 133153],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 14, 133153],"float32"),Tensor([2, 32, 14, 133153],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 113479 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:07:59.376297 136963 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:07:59.377388 136963 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 14, 133153],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 14, 133153],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 27754 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:09:12.530349 137362 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:09:12.538347 137362 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 14, 133153],"float32"),Tensor([2, 48, 14, 133153],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 14, 133153],"float32"),Tensor([2, 48, 14, 133153],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 129825 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:10:21.220427 137666 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:10:21.221537 137666 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 14, 133153],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 14, 133153],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 40499 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:11:34.579928 138052 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:11:34.581050 138052 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 134708 has 1.01 GiB memory in use. Of the allocated memory 1.72 MiB is allocated by PyTorch, and 18.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:12:46.155308 138374 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:12:46.156548 138374 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 58805 has 1.01 GiB memory in use. Of the allocated memory 1.72 MiB is allocated by PyTorch, and 18.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:13:53.056249 138768 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:13:53.057327 138768 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 134797 has 1.01 GiB memory in use. Of the allocated memory 1.72 MiB is allocated by PyTorch, and 18.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:15:00.781181 139066 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:15:00.782174 139066 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 45310 has 1.01 GiB memory in use. Of the allocated memory 1.72 MiB is allocated by PyTorch, and 18.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:16:12.653949 139386 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:16:12.655079 139386 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 146728 has 1.01 GiB memory in use. Of the allocated memory 1.72 MiB is allocated by PyTorch, and 18.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:17:25.264685 139678 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:17:25.265785 139678 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 63728 has 1.01 GiB memory in use. Of the allocated memory 1.72 MiB is allocated by PyTorch, and 18.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:18:32.087656 140070 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:18:32.088698 140070 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 142752 has 1.01 GiB memory in use. Of the allocated memory 1.72 MiB is allocated by PyTorch, and 18.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:19:45.046170 140388 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:19:45.047225 140388 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 266306, 7],"float32"),Tensor([2, 32, 266306, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 266306, 7],"float32"),Tensor([2, 32, 266306, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 75007 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:20:52.748859 140780 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:20:52.749954 140780 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 266306, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 266306, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 150889 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:22:04.256716 141076 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:22:04.257725 141076 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 266306, 7],"float32"),Tensor([2, 48, 266306, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 266306, 7],"float32"),Tensor([2, 48, 266306, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 66212 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:23:18.965924 141380 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:23:18.967335 141380 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 266306, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 266306, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 159816 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:24:25.122121 141780 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:24:25.123301 141780 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 7, 266306],"float32"),Tensor([2, 32, 7, 266306],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 7, 266306],"float32"),Tensor([2, 32, 7, 266306],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 76668 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:25:38.418766 142065 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:25:38.419822 142065 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 7, 266306],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 7, 266306],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 22222 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:26:50.532797 142371 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:26:50.533918 142371 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 7, 266306],"float32"),Tensor([2, 48, 7, 266306],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 7, 266306],"float32"),Tensor([2, 48, 7, 266306],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 101497 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:27:58.203722 142768 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:27:58.204741 142768 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 7, 266306],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 7, 266306],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 10591 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:29:11.615933 143042 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:29:11.617200 143042 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 7, 7],"float32"),Tensor([1826092, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 7, 7],"float32"),Tensor([1826092, 48, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 108482 has 1016.00 MiB memory in use. Of the allocated memory 441.00 KiB is allocated by PyTorch, and 1.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:30:18.834400 143366 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:30:18.835386 143366 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 19659 has 1016.00 MiB memory in use. Of the allocated memory 441.00 KiB is allocated by PyTorch, and 1.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:31:31.224586 143757 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:31:31.225920 143757 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 102481 has 1016.00 MiB memory in use. Of the allocated memory 441.00 KiB is allocated by PyTorch, and 1.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:32:44.341909 144055 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:32:44.342875 144055 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 36696 has 1016.00 MiB memory in use. Of the allocated memory 441.00 KiB is allocated by PyTorch, and 1.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:33:57.392168 144461 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:33:57.393244 144461 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 7, 7],"float32"),Tensor([2, 48, 6391321, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 7, 7],"float32"),Tensor([2, 48, 6391321, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 113630 has 1016.00 MiB memory in use. Of the allocated memory 441.00 KiB is allocated by PyTorch, and 1.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:35:05.396170 144768 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:35:05.397032 144768 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 7, 7],"float32"),Tensor([2, 48, 7, 6391321],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 7, 7],"float32"),Tensor([2, 48, 7, 6391321],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 35222 has 1016.00 MiB memory in use. Of the allocated memory 441.00 KiB is allocated by PyTorch, and 1.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:36:13.746683 145083 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:36:13.747638 145083 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1152, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1152, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 127779 has 1016.00 MiB memory in use. Of the allocated memory 441.00 KiB is allocated by PyTorch, and 1.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:37:24.780925 145388 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:37:24.781848 145388 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 116, 1322343, 14],"float32"),Tensor([2, 116, 1322343, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 116, 1322343, 14],"float32"),Tensor([2, 116, 1322343, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 40349 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:38:33.153873 145806 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:38:33.154989 145806 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 116, 1322343, 14],"float32"),Tensor([2, 116, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 116, 1322343, 14],"float32"),Tensor([2, 116, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 123807 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:39:45.055503 146092 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:39:45.056638 146092 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 116, 14, 1322343],"float32"),Tensor([2, 116, 14, 1322343],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 116, 14, 1322343],"float32"),Tensor([2, 116, 14, 1322343],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 54712 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:40:53.182971 146474 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:40:53.184049 146474 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 116, 14, 1322343],"float32"),Tensor([2, 116, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 116, 14, 1322343],"float32"),Tensor([2, 116, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 134515 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:42:02.373520 146803 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:42:02.374648 146803 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 116, 14, 14],"float32"),Tensor([188907, 116, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 116, 14, 14],"float32"),Tensor([188907, 116, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 45432 has 1016.00 MiB memory in use. Of the allocated memory 178.00 KiB is allocated by PyTorch, and 1.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:43:13.313905 147107 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:43:13.314947 147107 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 116, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 116, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 143281 has 1016.00 MiB memory in use. Of the allocated memory 178.00 KiB is allocated by PyTorch, and 1.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:44:22.857760 147400 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:44:22.858726 147400 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 116, 14, 14],"float32"),Tensor([2, 116, 1322343, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 116, 14, 14],"float32"),Tensor([2, 116, 1322343, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 56799 has 1016.00 MiB memory in use. Of the allocated memory 178.00 KiB is allocated by PyTorch, and 1.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:45:30.273622 147803 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:45:30.274616 147803 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 116, 14, 14],"float32"),Tensor([2, 116, 14, 1322343],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 116, 14, 14],"float32"),Tensor([2, 116, 14, 1322343],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 138043 has 1016.00 MiB memory in use. Of the allocated memory 178.00 KiB is allocated by PyTorch, and 1.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:46:38.846473 148096 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:46:38.847520 148096 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1184, 129554, 14],"float32"),Tensor([2, 32, 129554, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1184, 129554, 14],"float32"),Tensor([2, 32, 129554, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 78169 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:47:49.057374 148376 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:47:49.058418 148376 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1184, 129554, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1184, 129554, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 152739 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:49:00.851389 148773 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:49:00.852514 148773 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1184, 14, 129554],"float32"),Tensor([2, 32, 14, 129554],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1184, 14, 129554],"float32"),Tensor([2, 32, 14, 129554],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 63422 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:50:10.206965 149069 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:50:10.208099 149069 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1184, 14, 129554],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1184, 14, 129554],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 160318 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:51:21.872493 149353 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:51:21.873611 149353 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1184, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1184, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 72883 has 1.01 GiB memory in use. Of the allocated memory 1.77 MiB is allocated by PyTorch, and 18.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:52:29.730597 149750 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:52:29.731592 149750 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1184, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1184, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 150857 has 1.01 GiB memory in use. Of the allocated memory 1.77 MiB is allocated by PyTorch, and 18.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:53:42.260053 150065 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:53:42.261160 150065 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1184, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1184, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 89669 has 1.01 GiB memory in use. Of the allocated memory 1.77 MiB is allocated by PyTorch, and 18.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:54:50.875458 150377 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:54:50.876506 150377 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1184, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1184, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 4577 has 1.01 GiB memory in use. Of the allocated memory 1.77 MiB is allocated by PyTorch, and 18.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:56:04.113284 150771 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:56:04.114466 150771 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1184, 259108, 7],"float32"),Tensor([2, 32, 259108, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1184, 259108, 7],"float32"),Tensor([2, 32, 259108, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 90811 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:57:20.739491 151095 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:57:20.740558 151095 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1184, 259108, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1184, 259108, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 26435 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:58:28.159719 151464 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:58:28.160774 151464 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1184, 7, 259108],"float32"),Tensor([2, 32, 7, 259108],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1184, 7, 259108],"float32"),Tensor([2, 32, 7, 259108],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 102232 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:59:41.336179 151696 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:59:41.337292 151696 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1184, 7, 259108],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1184, 7, 259108],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 41321 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:00:47.485653 152014 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:00:47.486996 152014 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1184, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1184, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 116705 has 1016.00 MiB memory in use. Of the allocated memory 453.50 KiB is allocated by PyTorch, and 1.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:01:57.956533 152400 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:01:57.957453 152400 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1184, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1184, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 27177 has 1016.00 MiB memory in use. Of the allocated memory 453.50 KiB is allocated by PyTorch, and 1.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:03:10.495112 152692 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:03:10.496048 152692 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1184, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1184, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 125876 has 1016.00 MiB memory in use. Of the allocated memory 453.50 KiB is allocated by PyTorch, and 1.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:04:23.963644 153009 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:04:23.964991 153009 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1184, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1184, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 40505 has 1016.00 MiB memory in use. Of the allocated memory 453.50 KiB is allocated by PyTorch, and 1.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:05:30.300026 153394 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:05:30.300872 153394 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12, 28, 28],"float32"),Tensor([2, 12, 28, 6391321],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12, 28, 28],"float32"),Tensor([2, 12, 28, 6391321],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 120335 has 1016.00 MiB memory in use. Of the allocated memory 73.50 KiB is allocated by PyTorch, and 1.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:06:45.823733 153679 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:06:45.824838 153679 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12, 28, 28],"float32"),Tensor([2, 12, 6391321, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12, 28, 28],"float32"),Tensor([2, 12, 6391321, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 64196 has 1016.00 MiB memory in use. Of the allocated memory 73.50 KiB is allocated by PyTorch, and 1.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:07:53.583526 154089 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:07:53.587538 154089 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 139271 has 1016.00 MiB memory in use. Of the allocated memory 73.50 KiB is allocated by PyTorch, and 1.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:08:59.817766 154393 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:08:59.818881 154393 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12, 28, 28],"float32"),Tensor([456523, 12, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12, 28, 28],"float32"),Tensor([456523, 12, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 48800 has 1016.00 MiB memory in use. Of the allocated memory 73.50 KiB is allocated by PyTorch, and 1.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:10:15.526448 154697 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:10:15.527455 154697 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12, 28, 6391321],"float32"),Tensor([2, 12, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12, 28, 6391321],"float32"),Tensor([2, 12, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 148901 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:11:25.870671 155089 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:11:25.871896 155089 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12, 28, 6391321],"float32"),Tensor([2, 12, 28, 6391321],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12, 28, 6391321],"float32"),Tensor([2, 12, 28, 6391321],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 61837 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:12:34.129554 155406 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:12:34.131119 155406 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12, 6391321, 28],"float32"),Tensor([2, 12, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12, 6391321, 28],"float32"),Tensor([2, 12, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 156615 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:13:43.881621 155693 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:13:43.882858 155693 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12, 6391321, 28],"float32"),Tensor([2, 12, 6391321, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12, 6391321, 28],"float32"),Tensor([2, 12, 6391321, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 85133 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:14:50.825336 155997 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:14:50.826392 155997 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12],"float64"),Tensor([178956971, 12],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12],"float64"),Tensor([178956971, 12],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 1206 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:15:38.770934 156397 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:15:38.771924 156397 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 72607 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:16:24.725966 156585 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:16:24.726953 156585 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 1073741825],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 1073741825],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 116866 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:17:10.823236 156829 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:17:10.824297 156829 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 24591 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:17:57.812309 157001 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:17:57.813438 157001 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 69936 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:18:44.127521 157262 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:18:44.128643 157262 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 141177 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:19:29.765676 157527 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:19:29.766840 157527 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 20558 has 1016.00 MiB memory in use. Of the allocated memory 1.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:20:15.315749 157687 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:20:15.316890 157687 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 86511 has 1016.00 MiB memory in use. Of the allocated memory 1.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:21:03.159791 157932 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:21:03.160809 157932 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 141192 has 1016.00 MiB memory in use. Of the allocated memory 2.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:21:52.854460 158110 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:21:52.855569 158110 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 45218 has 1016.00 MiB memory in use. Of the allocated memory 2.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:22:42.997390 158374 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:22:42.998442 158374 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 116344 has 1016.00 MiB memory in use. Of the allocated memory 2.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:23:29.444700 158541 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:23:29.445709 158541 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 157958 has 1016.00 MiB memory in use. Of the allocated memory 2.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:24:18.736078 158806 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:24:18.737175 158806 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 63344 has 1016.00 MiB memory in use. Of the allocated memory 3.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:25:08.861258 159052 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:25:08.862363 159052 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 134371 has 1016.00 MiB memory in use. Of the allocated memory 3.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:25:54.538451 159224 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:25:54.539602 159224 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 21450 has 1016.00 MiB memory in use. Of the allocated memory 3.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:26:44.667702 159481 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:26:44.668871 159481 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 94103 has 1016.00 MiB memory in use. Of the allocated memory 3.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:27:30.886700 159761 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:27:30.889562 159761 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 139540 has 1016.00 MiB memory in use. Of the allocated memory 4.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:28:16.758373 159922 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:28:16.759449 159922 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 43709 has 1016.00 MiB memory in use. Of the allocated memory 4.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:29:02.652617 160167 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:29:02.655319 160167 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 91301 has 1016.00 MiB memory in use. Of the allocated memory 4.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:29:47.956841 160338 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:29:47.957849 160338 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 159851 has 1016.00 MiB memory in use. Of the allocated memory 4.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:30:33.053819 160613 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:30:33.054850 160613 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([178956971, 12],"float64"),Tensor([2, 12],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 46698 has 1016.00 MiB memory in use. Of the allocated memory 5.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:31:18.257493 160765 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:31:18.258534 160765 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 12],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 12],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 104463 has 1016.00 MiB memory in use. Of the allocated memory 5.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:32:04.127414 160983 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:32:04.128476 160983 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([178956971, 12],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([178956971, 12],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 158345 has 1016.00 MiB memory in use. Of the allocated memory 5.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:32:49.588342 161142 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:32:49.589362 161142 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 1073741825],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 12],"float64"),Tensor([2, 1073741825],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 58581 has 1016.00 MiB memory in use. Of the allocated memory 5.50 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:33:35.049283 161389 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:33:35.050400 161389 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1200, 127827, 14],"float32"),Tensor([2, 48, 127827, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1200, 127827, 14],"float32"),Tensor([2, 48, 127827, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 118091 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:34:50.051715 161562 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:34:50.052806 161562 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1200, 127827, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1200, 127827, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 47994 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:35:57.742226 161932 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:35:57.751209 161932 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1200, 14, 127827],"float32"),Tensor([2, 48, 14, 127827],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1200, 14, 127827],"float32"),Tensor([2, 48, 14, 127827],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 129574 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:37:14.518831 162202 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:37:14.519906 162202 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1200, 14, 127827],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1200, 14, 127827],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 74849 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:38:24.527674 162472 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:38:24.528825 162472 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1200, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1200, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 18218 has 1.01 GiB memory in use. Of the allocated memory 1.79 MiB is allocated by PyTorch, and 18.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:39:31.908552 162839 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:39:31.909567 162839 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1200, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1200, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 124459 has 1.01 GiB memory in use. Of the allocated memory 1.79 MiB is allocated by PyTorch, and 18.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:40:40.898795 163141 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:40:40.899906 163141 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1200, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1200, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 90085 has 1.01 GiB memory in use. Of the allocated memory 1.79 MiB is allocated by PyTorch, and 18.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:41:55.143474 163421 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:41:55.144644 163421 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1200, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1200, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 43591 has 1.01 GiB memory in use. Of the allocated memory 1.79 MiB is allocated by PyTorch, and 18.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:43:07.005182 163815 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:43:07.006273 163815 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1200, 255653, 7],"float32"),Tensor([2, 48, 255653, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1200, 255653, 7],"float32"),Tensor([2, 48, 255653, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 2038 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:44:21.487668   574 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:44:21.488795   574 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1200, 255653, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1200, 255653, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 128734 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:45:32.332934   977 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:45:32.334002   977 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1200, 7, 255653],"float32"),Tensor([2, 48, 7, 255653],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1200, 7, 255653],"float32"),Tensor([2, 48, 7, 255653],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 67244 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:46:49.531986  1275 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:46:49.533109  1275 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1200, 7, 255653],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1200, 7, 255653],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 57947 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:48:00.090147  1676 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:48:00.091290  1676 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1200, 7, 7],"float32"),Tensor([1826092, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1200, 7, 7],"float32"),Tensor([1826092, 48, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 159634 has 1016.00 MiB memory in use. Of the allocated memory 459.50 KiB is allocated by PyTorch, and 1.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:49:12.986001  1956 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:49:12.986896  1956 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1200, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1200, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 122141 has 1016.00 MiB memory in use. Of the allocated memory 459.50 KiB is allocated by PyTorch, and 1.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:50:23.489313  2254 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:50:23.490145  2254 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1200, 7, 7],"float32"),Tensor([2, 48, 6391321, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1200, 7, 7],"float32"),Tensor([2, 48, 6391321, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 72839 has 1016.00 MiB memory in use. Of the allocated memory 459.50 KiB is allocated by PyTorch, and 1.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:51:31.736773  2645 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:51:31.737752  2645 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1200, 7, 7],"float32"),Tensor([2, 48, 7, 6391321],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1200, 7, 7],"float32"),Tensor([2, 48, 7, 6391321],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 15291 has 1016.00 MiB memory in use. Of the allocated memory 459.50 KiB is allocated by PyTorch, and 1.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:52:42.772389  2919 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:52:42.773288  2919 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1216, 126145, 14],"float32"),Tensor([2, 32, 126145, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1216, 126145, 14],"float32"),Tensor([2, 32, 126145, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 145260 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:53:57.695116  3216 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:53:57.696280  3216 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1216, 126145, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1216, 126145, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 99439 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:55:11.529556  3602 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:55:11.530596  3602 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1216, 14, 126145],"float32"),Tensor([2, 32, 14, 126145],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1216, 14, 126145],"float32"),Tensor([2, 32, 14, 126145],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 61606 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:56:26.745859  3916 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:56:26.746896  3916 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1216, 14, 126145],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1216, 14, 126145],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 21644 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:57:37.838480  4317 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:57:37.839653  4317 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1216, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1216, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 150647 has 1.01 GiB memory in use. Of the allocated memory 1.82 MiB is allocated by PyTorch, and 18.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:58:49.300433  4611 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:58:49.301620  4611 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1216, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1216, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 106532 has 1.01 GiB memory in use. Of the allocated memory 1.82 MiB is allocated by PyTorch, and 18.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:00:04.924752  5010 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:00:04.925981  5010 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1216, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1216, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 63664 has 1.01 GiB memory in use. Of the allocated memory 1.82 MiB is allocated by PyTorch, and 18.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:01:16.577574  5322 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:01:16.578629  5322 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1216, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1216, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 25728 has 1.01 GiB memory in use. Of the allocated memory 1.82 MiB is allocated by PyTorch, and 18.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:02:25.420670  5698 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:02:25.421787  5698 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1216, 252289, 7],"float32"),Tensor([2, 32, 252289, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1216, 252289, 7],"float32"),Tensor([2, 32, 252289, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 127329 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:03:40.135422  6016 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:03:40.147222  6016 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1216, 252289, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1216, 252289, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 98826 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:04:50.786991  6328 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:04:50.788136  6328 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1216, 7, 252289],"float32"),Tensor([2, 32, 7, 252289],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1216, 7, 252289],"float32"),Tensor([2, 32, 7, 252289],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 52044 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:06:01.809645  6693 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:06:01.810763  6693 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1216, 7, 252289],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1216, 7, 252289],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 158208 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:07:12.935376  7011 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:07:12.936699  7011 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1216, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1216, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 123006 has 1016.00 MiB memory in use. Of the allocated memory 465.50 KiB is allocated by PyTorch, and 1.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:08:26.709980  7305 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:08:26.710902  7305 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1216, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1216, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 73627 has 1016.00 MiB memory in use. Of the allocated memory 465.50 KiB is allocated by PyTorch, and 1.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:09:41.488761  7709 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:09:41.489845  7709 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1216, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1216, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 47075 has 1016.00 MiB memory in use. Of the allocated memory 465.50 KiB is allocated by PyTorch, and 1.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:10:50.543001  8030 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:10:50.547235  8030 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1216, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1216, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 160399 has 1016.00 MiB memory in use. Of the allocated memory 465.50 KiB is allocated by PyTorch, and 1.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:11:57.475179  8417 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:11:57.476187  8417 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 122911, 14],"float32"),Tensor([2, 32, 122911, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 122911, 14],"float32"),Tensor([2, 32, 122911, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 98500 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:13:06.640197  8703 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:13:06.641253  8703 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 122911, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 122911, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 48252 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:14:17.328773  9018 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:14:17.329788  9018 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 122911, 14],"float32"),Tensor([2, 48, 122911, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 122911, 14],"float32"),Tensor([2, 48, 122911, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 12638 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:15:30.490424  9412 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:15:30.496769  9412 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 122911, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 122911, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 117388 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:16:37.950613  9697 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:16:37.951725  9697 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 14, 122911],"float32"),Tensor([2, 32, 14, 122911],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 14, 122911],"float32"),Tensor([2, 32, 14, 122911],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 91553 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:17:51.886732  9994 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:17:51.887863  9994 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 14, 122911],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 14, 122911],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 47116 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:19:00.603384 10371 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:19:00.604426 10371 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 14, 122911],"float32"),Tensor([2, 48, 14, 122911],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 14, 122911],"float32"),Tensor([2, 48, 14, 122911],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 146996 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:20:10.655133 10673 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:20:10.656275 10673 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 14, 122911],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 14, 122911],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 109219 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:21:21.128119 10955 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:21:21.129669 10955 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 60061 has 1.01 GiB memory in use. Of the allocated memory 1.87 MiB is allocated by PyTorch, and 18.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:22:35.633400 11346 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:22:35.634573 11346 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 23595 has 1.01 GiB memory in use. Of the allocated memory 1.87 MiB is allocated by PyTorch, and 18.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:23:44.579780 11645 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:23:44.580803 11645 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 137246 has 1.01 GiB memory in use. Of the allocated memory 1.87 MiB is allocated by PyTorch, and 18.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:24:58.866992 12008 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:24:58.868016 12008 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 85532 has 1.01 GiB memory in use. Of the allocated memory 1.87 MiB is allocated by PyTorch, and 18.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:26:10.448035 12318 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:26:10.449088 12318 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 51889 has 1.01 GiB memory in use. Of the allocated memory 1.87 MiB is allocated by PyTorch, and 18.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:27:21.872972 12620 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:27:21.874104 12620 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 5984 has 1.01 GiB memory in use. Of the allocated memory 1.87 MiB is allocated by PyTorch, and 18.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:28:33.924762 13017 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:28:33.925963 13017 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 118885 has 1.01 GiB memory in use. Of the allocated memory 1.87 MiB is allocated by PyTorch, and 18.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:29:47.996822 13309 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:29:47.997838 13309 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 245821, 7],"float32"),Tensor([2, 32, 245821, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 245821, 7],"float32"),Tensor([2, 32, 245821, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 90514 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:31:00.428833 13716 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:31:00.429996 13716 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 245821, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 245821, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 29041 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:32:14.086854 14028 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:32:14.087855 14028 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 245821, 7],"float32"),Tensor([2, 48, 245821, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 245821, 7],"float32"),Tensor([2, 48, 245821, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 159255 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:33:30.104257 14335 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:33:30.105362 14335 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 245821, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 245821, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 112051 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:34:44.129559 14719 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:34:44.130638 14719 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 7, 245821],"float32"),Tensor([2, 32, 7, 245821],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 7, 245821],"float32"),Tensor([2, 32, 7, 245821],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 84346 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:35:56.448282 15019 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:35:56.449326 15019 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 7, 245821],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 7, 245821],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 40019 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:37:17.192422 15412 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:37:17.193446 15412 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 7, 245821],"float32"),Tensor([2, 48, 7, 245821],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 7, 245821],"float32"),Tensor([2, 48, 7, 245821],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 19258 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:38:29.223948 15806 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:38:29.225211 15806 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 7, 245821],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 7, 245821],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 120611 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:39:43.004295 16130 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:39:43.005414 16130 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 7, 7],"float32"),Tensor([1826092, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 7, 7],"float32"),Tensor([1826092, 48, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 88760 has 1016.00 MiB memory in use. Of the allocated memory 478.00 KiB is allocated by PyTorch, and 1.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:40:55.003470 16435 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:40:55.004516 16435 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 39175 has 1016.00 MiB memory in use. Of the allocated memory 478.00 KiB is allocated by PyTorch, and 1.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:42:02.978505 16821 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:42:02.979334 16821 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 143593 has 1016.00 MiB memory in use. Of the allocated memory 478.00 KiB is allocated by PyTorch, and 1.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:43:15.252383 17125 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:43:15.253384 17125 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 106020 has 1016.00 MiB memory in use. Of the allocated memory 478.00 KiB is allocated by PyTorch, and 1.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:44:27.171751 17519 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:44:27.172578 17519 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 7, 7],"float32"),Tensor([2, 48, 6391321, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 7, 7],"float32"),Tensor([2, 48, 6391321, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 48561 has 1016.00 MiB memory in use. Of the allocated memory 478.00 KiB is allocated by PyTorch, and 1.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:45:34.134282 17811 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:45:34.135201 17811 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 7, 7],"float32"),Tensor([2, 48, 7, 6391321],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 7, 7],"float32"),Tensor([2, 48, 7, 6391321],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 158552 has 1016.00 MiB memory in use. Of the allocated memory 478.00 KiB is allocated by PyTorch, and 1.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:46:42.410420 18101 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:46:42.411453 18101 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1248, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1248, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 124175 has 1016.00 MiB memory in use. Of the allocated memory 478.00 KiB is allocated by PyTorch, and 1.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:47:57.678639 18405 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:47:57.679574 18405 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 81135 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:49:08.297782 18777 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:49:08.298804 18777 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 42511 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:50:17.466084 19087 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:50:17.467295 19087 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 192, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 192, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 160326 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:51:31.968410 19453 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:51:31.969545 19453 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 208, 13, 13],"float32"),Tensor([2, 48, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 208, 13, 13],"float32"),Tensor([2, 48, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 99050 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:52:40.580415 19749 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:52:40.582022 19749 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 224, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 224, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 66349 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:53:48.824594 20036 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:53:48.826118 20036 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 14196 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:55:02.284353 20420 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:55:02.285391 20420 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 117082 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:56:12.250126 20732 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:56:12.251127 20732 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 288, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 288, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 78986 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:57:25.711506 21018 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:57:25.712515 21018 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 30331 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:58:32.790576 21411 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:58:32.873435 21411 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 1290556, 13],"float32"),Tensor([2, 256, 1290556, 13],"float32"),Tensor([2, 64, 1290556, 13],"float32"),Tensor([2, 64, 1290556, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 1290556, 13],"float32"),Tensor([2, 256, 1290556, 13],"float32"),Tensor([2, 64, 1290556, 13],"float32"),Tensor([2, 64, 1290556, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 128766 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:59:48.720234 21698 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:59:48.721309 21698 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 1290556, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 1290556, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 108060 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:00:56.541612 22104 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:00:56.542711 22104 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 13, 1290556],"float32"),Tensor([2, 256, 13, 1290556],"float32"),Tensor([2, 64, 13, 1290556],"float32"),Tensor([2, 64, 13, 1290556],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 13, 1290556],"float32"),Tensor([2, 256, 13, 1290556],"float32"),Tensor([2, 64, 13, 1290556],"float32"),Tensor([2, 64, 13, 1290556],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 43975 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:02:04.091207 22402 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:02:04.092213 22402 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 13, 1290556],"float32"),Tensor([2, 256, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 13, 1290556],"float32"),Tensor([2, 256, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 146474 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:03:17.141667 22702 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:03:17.142853 22702 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 113519 has 1016.00 MiB memory in use. Of the allocated memory 169.00 KiB is allocated by PyTorch, and 1.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:04:27.005048 23101 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:04:27.006130 23101 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 13, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 13, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 55380 has 1016.00 MiB memory in use. Of the allocated memory 507.00 KiB is allocated by PyTorch, and 1.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:05:40.264389 23397 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:05:40.265291 23397 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 13, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 13, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 21553 has 1016.00 MiB memory in use. Of the allocated memory 591.50 KiB is allocated by PyTorch, and 1.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:06:48.749508 23702 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:06:48.750563 23702 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 13, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 2581111],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 13, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 2581111],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 141742 has 1016.00 MiB memory in use. Of the allocated memory 591.50 KiB is allocated by PyTorch, and 1.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:08:03.563886 24079 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:08:03.564749 24079 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 13, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 2581111, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 13, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 2581111, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 81606 has 1016.00 MiB memory in use. Of the allocated memory 591.50 KiB is allocated by PyTorch, and 1.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:09:12.614542 24389 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:09:12.615458 24389 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 13, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([397094, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 13, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([397094, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 35464 has 1016.00 MiB memory in use. Of the allocated memory 591.50 KiB is allocated by PyTorch, and 1.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:10:22.774578 24688 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:10:22.778435 24688 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 13, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),Tensor([2, 64, 13, 2581111],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 13, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),Tensor([2, 64, 13, 2581111],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 148077 has 1016.00 MiB memory in use. Of the allocated memory 507.00 KiB is allocated by PyTorch, and 1.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:11:34.530731 25095 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:11:34.535044 25095 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 13, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),Tensor([2, 64, 2581111, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 13, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),Tensor([2, 64, 2581111, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 96328 has 1016.00 MiB memory in use. Of the allocated memory 507.00 KiB is allocated by PyTorch, and 1.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:12:42.028761 25393 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:12:42.029784 25393 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 13, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),Tensor([397094, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 13, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),Tensor([397094, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 51054 has 1016.00 MiB memory in use. Of the allocated memory 507.00 KiB is allocated by PyTorch, and 1.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:13:51.932178 25691 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:13:51.933183 25691 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 13, 13],"float32"),Tensor([2, 256, 13, 645278],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 13, 13],"float32"),Tensor([2, 256, 13, 645278],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 1707 has 1016.00 MiB memory in use. Of the allocated memory 169.00 KiB is allocated by PyTorch, and 1.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:15:04.733441 26082 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:15:04.734530 26082 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 13, 13],"float32"),Tensor([2, 256, 645278, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 13, 13],"float32"),Tensor([2, 256, 645278, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 111803 has 1016.00 MiB memory in use. Of the allocated memory 169.00 KiB is allocated by PyTorch, and 1.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:16:12.258962 26380 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:16:12.260037 26380 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 13, 13],"float32"),Tensor([99274, 256, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 13, 13],"float32"),Tensor([99274, 256, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 62781 has 1016.00 MiB memory in use. Of the allocated memory 169.00 KiB is allocated by PyTorch, and 1.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:17:25.609517 26697 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:17:25.610672 26697 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 26, 26],"float32"),Tensor([2, 128, 26, 645278],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 26, 26],"float32"),Tensor([2, 128, 26, 645278],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 15394 has 1016.00 MiB memory in use. Of the allocated memory 676.00 KiB is allocated by PyTorch, and 1.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:18:37.535058 27077 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:18:37.535967 27077 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 26, 26],"float32"),Tensor([2, 128, 645278, 26],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 26, 26],"float32"),Tensor([2, 128, 645278, 26],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 133878 has 1016.00 MiB memory in use. Of the allocated memory 676.00 KiB is allocated by PyTorch, and 1.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:19:46.848395 27368 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:19:46.849328 27368 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 26, 26],"float32"),Tensor([2, 3176751, 26, 26],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 26, 26],"float32"),Tensor([2, 3176751, 26, 26],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 105916 has 1016.00 MiB memory in use. Of the allocated memory 676.00 KiB is allocated by PyTorch, and 1.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:20:54.524654 27773 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:20:54.525560 27773 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 26, 26],"float32"),Tensor([49637, 128, 26, 26],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 26, 26],"float32"),Tensor([49637, 128, 26, 26],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 43335 has 1016.00 MiB memory in use. Of the allocated memory 676.00 KiB is allocated by PyTorch, and 1.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:22:01.803104 28072 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:22:01.803946 28072 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 26, 645278],"float32"),Tensor([2, 128, 26, 26],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 26, 645278],"float32"),Tensor([2, 128, 26, 26],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 141251 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:23:16.776430 28365 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:23:16.777664 28365 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 26, 645278],"float32"),Tensor([2, 128, 26, 645278],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 26, 645278],"float32"),Tensor([2, 128, 26, 645278],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 114618 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:24:28.935473 28776 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:24:28.936630 28776 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([2, 128, 27, 621379],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([2, 128, 27, 621379],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 56346 has 1016.00 MiB memory in use. Of the allocated memory 729.00 KiB is allocated by PyTorch, and 1.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:25:34.962507 29069 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:25:34.963517 29069 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([2, 128, 621379, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([2, 128, 621379, 27],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 10261 has 1016.00 MiB memory in use. Of the allocated memory 729.00 KiB is allocated by PyTorch, and 1.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:26:42.605624 29365 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:26:42.606541 29365 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([2, 192, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 64, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([2, 192, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 64, 27, 27],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 132618 has 1.01 GiB memory in use. Of the allocated memory 1.78 MiB is allocated by PyTorch, and 20.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:27:50.192252 29670 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:27:50.193233 29670 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([2, 192, 27, 27],"float32"),Tensor([2, 96, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([2, 192, 27, 27],"float32"),Tensor([2, 96, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 81607 has 1.01 GiB memory in use. Of the allocated memory 2.31 MiB is allocated by PyTorch, and 19.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:28:58.075966 30057 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:28:58.076916 30057 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([2, 192, 27, 27],"float32"),Tensor([2, 96, 27, 27],"float32"),Tensor([2, 64, 1242757, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([2, 192, 27, 27],"float32"),Tensor([2, 96, 27, 27],"float32"),Tensor([2, 64, 1242757, 27],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 17340 has 1.01 GiB memory in use. Of the allocated memory 2.31 MiB is allocated by PyTorch, and 19.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:30:09.380898 30336 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:30:09.382179 30336 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([2, 192, 27, 27],"float32"),Tensor([2, 96, 27, 27],"float32"),Tensor([2, 64, 27, 1242757],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([2, 192, 27, 27],"float32"),Tensor([2, 96, 27, 27],"float32"),Tensor([2, 64, 27, 1242757],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 145518 has 1.01 GiB memory in use. Of the allocated memory 2.31 MiB is allocated by PyTorch, and 19.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:31:26.884171 30626 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:31:26.885215 30626 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([2, 192, 27, 27],"float32"),Tensor([2, 96, 27, 27],"float32"),Tensor([92057, 64, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([2, 192, 27, 27],"float32"),Tensor([2, 96, 27, 27],"float32"),Tensor([92057, 64, 27, 27],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 109711 has 1.01 GiB memory in use. Of the allocated memory 2.31 MiB is allocated by PyTorch, and 19.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:32:40.541215 31029 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:32:40.544603 31029 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([2, 192, 27, 27],"float32"),Tensor([2, 96, 27, 828505],"float32"),Tensor([2, 64, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([2, 192, 27, 27],"float32"),Tensor([2, 96, 27, 828505],"float32"),Tensor([2, 64, 27, 27],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 94719 has 1.01 GiB memory in use. Of the allocated memory 1.78 MiB is allocated by PyTorch, and 20.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:33:56.313130 31334 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:33:56.314154 31334 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([2, 192, 27, 27],"float32"),Tensor([2, 96, 828505, 27],"float32"),Tensor([2, 64, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([2, 192, 27, 27],"float32"),Tensor([2, 96, 828505, 27],"float32"),Tensor([2, 64, 27, 27],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 56635 has 1.01 GiB memory in use. Of the allocated memory 1.78 MiB is allocated by PyTorch, and 20.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:35:19.118912 31717 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:35:19.119932 31717 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([2, 192, 27, 27],"float32"),Tensor([61371, 96, 27, 27],"float32"),Tensor([2, 64, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([2, 192, 27, 27],"float32"),Tensor([61371, 96, 27, 27],"float32"),Tensor([2, 64, 27, 27],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 46566 has 1.01 GiB memory in use. Of the allocated memory 1.78 MiB is allocated by PyTorch, and 20.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:36:28.776984 32146 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:36:28.778018 32146 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([2, 192, 27, 414253],"float32"),Tensor([2, 96, 27, 27],"float32"),Tensor([2, 64, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([2, 192, 27, 414253],"float32"),Tensor([2, 96, 27, 27],"float32"),Tensor([2, 64, 27, 27],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 5553 has 1016.00 MiB memory in use. Of the allocated memory 729.00 KiB is allocated by PyTorch, and 1.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:37:45.668403 32432 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:37:45.669741 32432 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([2, 192, 414253, 27],"float32"),Tensor([2, 96, 27, 27],"float32"),Tensor([2, 64, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([2, 192, 414253, 27],"float32"),Tensor([2, 96, 27, 27],"float32"),Tensor([2, 64, 27, 27],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 1611 has 1016.00 MiB memory in use. Of the allocated memory 729.00 KiB is allocated by PyTorch, and 1.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:39:07.713593 32836 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:39:07.714967 32836 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 139682 has 1016.00 MiB memory in use. Of the allocated memory 729.00 KiB is allocated by PyTorch, and 1.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:40:21.474037 33141 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:40:21.475023 33141 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 96, 27, 27],"float32"),Tensor([2, 64, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 96, 27, 27],"float32"),Tensor([2, 64, 27, 27],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 102004 has 1016.00 MiB memory in use. Of the allocated memory 729.00 KiB is allocated by PyTorch, and 1.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:41:36.577589 33538 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:41:36.578670 33538 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([30686, 192, 27, 27],"float32"),Tensor([2, 96, 27, 27],"float32"),Tensor([2, 64, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([30686, 192, 27, 27],"float32"),Tensor([2, 96, 27, 27],"float32"),Tensor([2, 64, 27, 27],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 66232 has 1016.00 MiB memory in use. Of the allocated memory 729.00 KiB is allocated by PyTorch, and 1.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:42:47.690187 33835 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:42:47.691061 33835 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([46029, 128, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 27, 27],"float32"),Tensor([46029, 128, 27, 27],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 36852 has 1016.00 MiB memory in use. Of the allocated memory 729.00 KiB is allocated by PyTorch, and 1.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:43:58.724964 34227 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:43:58.725919 34227 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 27, 621379],"float32"),Tensor([2, 128, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 27, 621379],"float32"),Tensor([2, 128, 27, 27],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 144144 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:45:09.928140 34530 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:45:09.929723 34530 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 27, 621379],"float32"),Tensor([2, 128, 27, 621379],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 27, 621379],"float32"),Tensor([2, 128, 27, 621379],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 110540 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:46:25.748956 34819 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:46:25.750285 34819 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 27, 621379],"float32"),Tensor([2, 192, 27, 27],"float32"),Tensor([2, 96, 27, 27],"float32"),Tensor([2, 64, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 27, 621379],"float32"),Tensor([2, 192, 27, 27],"float32"),Tensor([2, 96, 27, 27],"float32"),Tensor([2, 64, 27, 27],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 73033 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:47:40.460541 35231 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:47:40.461670 35231 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 27, 621379],"float32"),Tensor([2, 192, 27, 621379],"float32"),Tensor([2, 96, 27, 621379],"float32"),Tensor([2, 64, 27, 621379],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 27, 621379],"float32"),Tensor([2, 192, 27, 621379],"float32"),Tensor([2, 96, 27, 621379],"float32"),Tensor([2, 64, 27, 621379],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 46430 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:48:49.014732 35535 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:48:49.015899 35535 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 28, 28],"float32"),Tensor([171197, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 28, 28],"float32"),Tensor([171197, 32, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 4799 has 1016.00 MiB memory in use. Of the allocated memory 784.00 KiB is allocated by PyTorch, and 1.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:50:03.894260 35927 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:50:03.895238 35927 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 118612 has 1016.00 MiB memory in use. Of the allocated memory 784.00 KiB is allocated by PyTorch, and 1.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:51:21.310287 36253 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:51:21.311334 36253 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 28, 28],"float32"),Tensor([2, 32, 2396746, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 28, 28],"float32"),Tensor([2, 32, 2396746, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 92401 has 1016.00 MiB memory in use. Of the allocated memory 784.00 KiB is allocated by PyTorch, and 1.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:52:32.220237 36653 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:52:32.221220 36653 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 28, 28],"float32"),Tensor([2, 32, 28, 2396746],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 28, 28],"float32"),Tensor([2, 32, 28, 2396746],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 45792 has 1016.00 MiB memory in use. Of the allocated memory 784.00 KiB is allocated by PyTorch, and 1.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:53:48.552837 36958 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:53:48.554391 36958 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 28, 599187],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 28, 599187],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 30272 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:54:57.606918 37342 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:54:57.608036 37342 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 28, 599187],"float32"),Tensor([2, 32, 28, 599187],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 28, 599187],"float32"),Tensor([2, 32, 28, 599187],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 133935 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:56:09.711350 37629 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:56:09.712468 37629 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 299594, 56],"float32"),Tensor([2, 32, 299594, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 299594, 56],"float32"),Tensor([2, 32, 299594, 56],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 105690 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:57:19.877665 37920 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:57:19.880708 37920 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 299594, 56],"float32"),Tensor([2, 32, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 299594, 56],"float32"),Tensor([2, 32, 56, 56],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 62343 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:58:36.462189 38313 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:58:36.463224 38313 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 310690, 54],"float32"),Tensor([2, 128, 310690, 54],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 310690, 54],"float32"),Tensor([2, 128, 310690, 54],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 18597 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:59:45.793877 38623 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:59:45.795063 38623 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 310690, 54],"float32"),Tensor([2, 128, 54, 54],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 310690, 54],"float32"),Tensor([2, 128, 54, 54],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 145798 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 14:01:00.196880 39001 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:01:00.198040 39001 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 54, 310690],"float32"),Tensor([2, 128, 54, 310690],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 54, 310690],"float32"),Tensor([2, 128, 54, 310690],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 99010 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 14:02:09.090055 39322 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:02:09.091089 39322 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 54, 310690],"float32"),Tensor([2, 128, 54, 54],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 54, 310690],"float32"),Tensor([2, 128, 54, 54],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 59590 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 14:03:23.010622 39617 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:03:23.011610 39617 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 54, 54],"float32"),Tensor([11508, 128, 54, 54],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 54, 54],"float32"),Tensor([11508, 128, 54, 54],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 10853 has 1.01 GiB memory in use. Of the allocated memory 2.85 MiB is allocated by PyTorch, and 17.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 14:04:30.253257 39995 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:04:30.254351 39995 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 54, 54],"float32"),Tensor([2, 128, 310690, 54],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 54, 54],"float32"),Tensor([2, 128, 310690, 54],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 111085 has 1.01 GiB memory in use. Of the allocated memory 2.85 MiB is allocated by PyTorch, and 17.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 14:05:38.344177 40297 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:05:38.345278 40297 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 54, 54],"float32"),Tensor([2, 128, 54, 310690],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 54, 54],"float32"),Tensor([2, 128, 54, 310690],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 76743 has 1.01 GiB memory in use. Of the allocated memory 2.85 MiB is allocated by PyTorch, and 17.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 14:06:52.447235 40599 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:06:52.448458 40599 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 54, 54],"float32"),Tensor([2, 736449, 54, 54],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 54, 54],"float32"),Tensor([2, 736449, 54, 54],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 42586 has 1.01 GiB memory in use. Of the allocated memory 2.85 MiB is allocated by PyTorch, and 17.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 14:08:00.214846 41009 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:08:00.215899 41009 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 56, 299594],"float32"),Tensor([2, 32, 56, 299594],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 56, 299594],"float32"),Tensor([2, 32, 56, 299594],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 149920 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 14:09:15.385629 41287 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:09:15.386634 41287 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 56, 299594],"float32"),Tensor([2, 32, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 56, 299594],"float32"),Tensor([2, 32, 56, 56],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 118931 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 14:10:31.453941 41678 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:10:31.454959 41678 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 56, 56],"float32"),Tensor([2, 32, 1198373, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 56, 56],"float32"),Tensor([2, 32, 1198373, 56],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 68059 has 1.01 GiB memory in use. Of the allocated memory 3.06 MiB is allocated by PyTorch, and 16.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 14:11:48.481745 41977 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:11:48.482926 41977 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 56, 56],"float32"),Tensor([2, 32, 56, 1198373],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 56, 56],"float32"),Tensor([2, 32, 56, 1198373],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 57533 has 1.01 GiB memory in use. Of the allocated memory 3.06 MiB is allocated by PyTorch, and 16.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 14:13:03.499143 42356 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:13:03.500140 42356 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 56, 56],"float32"),Tensor([2, 684785, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 56, 56],"float32"),Tensor([2, 684785, 56, 56],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 5460 has 1.01 GiB memory in use. Of the allocated memory 3.06 MiB is allocated by PyTorch, and 16.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 14:14:12.276068 42673 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:14:12.277132 42673 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 56, 56],"float32"),Tensor([42800, 32, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 56, 56],"float32"),Tensor([42800, 32, 56, 56],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 125415 has 1.01 GiB memory in use. Of the allocated memory 3.06 MiB is allocated by PyTorch, and 16.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 14:15:27.996524 42972 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:15:27.997742 42972 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 599187, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 599187, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 79129 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 14:16:39.077437 43375 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:16:39.078637 43375 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 599187, 28],"float32"),Tensor([2, 32, 599187, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 599187, 28],"float32"),Tensor([2, 32, 599187, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 48128 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 14:17:46.289044 43787 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:17:46.290174 43787 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 621379, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 621379, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 5888 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 14:18:54.937589 44154 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:18:54.938673 44154 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 621379, 27],"float32"),Tensor([2, 128, 621379, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 621379, 27],"float32"),Tensor([2, 128, 621379, 27],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 109150 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 14:20:03.491981 44416 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:20:03.492998 44416 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 621379, 27],"float32"),Tensor([2, 192, 27, 27],"float32"),Tensor([2, 96, 27, 27],"float32"),Tensor([2, 64, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 621379, 27],"float32"),Tensor([2, 192, 27, 27],"float32"),Tensor([2, 96, 27, 27],"float32"),Tensor([2, 64, 27, 27],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 48712 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 14:21:18.733821 44702 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:21:18.734956 44702 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 621379, 27],"float32"),Tensor([2, 192, 621379, 27],"float32"),Tensor([2, 96, 621379, 27],"float32"),Tensor([2, 64, 621379, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 621379, 27],"float32"),Tensor([2, 192, 621379, 27],"float32"),Tensor([2, 96, 621379, 27],"float32"),Tensor([2, 64, 621379, 27],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 23447 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 14:22:32.577354 45104 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:22:32.578450 45104 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 645278, 26],"float32"),Tensor([2, 128, 26, 26],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 645278, 26],"float32"),Tensor([2, 128, 26, 26],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 126236 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 14:23:47.050823 45384 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:23:47.051823 45384 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 128, 645278, 26],"float32"),Tensor([2, 128, 645278, 26],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 128, 645278, 26],"float32"),Tensor([2, 128, 645278, 26],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 113821 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 14:25:00.385356 45991 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:25:00.386399 45991 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1280, 119838, 14],"float32"),Tensor([2, 32, 119838, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1280, 119838, 14],"float32"),Tensor([2, 32, 119838, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 55951 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 14:26:09.212637 46439 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:26:09.213642 46439 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1280, 119838, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1280, 119838, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 22203 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 14:27:17.827991 46711 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:27:17.829094 46711 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1280, 14, 119838],"float32"),Tensor([2, 32, 14, 119838],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1280, 14, 119838],"float32"),Tensor([2, 32, 14, 119838],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 140280 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 14:28:25.858681 47056 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:28:25.859678 47056 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1280, 14, 119838],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1280, 14, 119838],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.34 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 78378 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 14:29:34.973672 47585 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:29:34.974715 47585 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 1280, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 1280, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.32 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28360 has 1.05 GiB memory in use. Process 26890 has 1.01 GiB memory in use. Of the allocated memory 1.91 MiB is allocated by PyTorch, and 18.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 14:30:43.380565 47974 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:30:43.381614 47974 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

Traceback (most recent call last):
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 70, in <module>
    main()
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 65, in main
    print(str(res.stdout.read(), encoding="utf-8"), flush=True)
KeyboardInterrupt
