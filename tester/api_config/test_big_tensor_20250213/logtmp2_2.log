test begin: paddle.equal(Tensor([715827883, 3, 2],"float32"), Tensor([715827883, 3, 2],"float16"), )
[paddle error] paddle.equal(Tensor([715827883, 3, 2],"float32"), Tensor([715827883, 3, 2],"float16"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000000GB memory on GPU 0, 78.582947GB memory has been allocated and available memory is only 616.375000MB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 15:40:33.163674 68033 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 15:40:33.164569 68033 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([715827883, 3],"float64"), 0, )
[accuracy error] paddle.equal(Tensor([715827883, 3],"float64"), 0, ) 
 
Arrays are not equal

Mismatched elements: 23 / 2147483649 (1.07e-06%)
 x: array([[False, False, False],
       [False, False, False],
       [False, False, False],...
 y: array([[False, False, False],
       [False, False, False],
       [False, False, False],...

W0211 15:41:31.397616 69948 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 15:41:31.398806 69948 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([8, 268435457],"int64"), Tensor([1],"int64"), )
[Pass] paddle.equal(Tensor([8, 268435457],"int64"), Tensor([1],"int64"), )

W0211 15:42:55.256278 70823 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 15:42:55.257153 70823 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([8, 268435457],"int64"), Tensor([8, 268435457],"int64"), )
[paddle error] paddle.equal(Tensor([8, 268435457],"int64"), Tensor([8, 268435457],"int64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 68.580994GB memory has been allocated and available memory is only 10.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 15:45:00.872417 71746 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 15:45:00.873260 71746 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([8, 268435457],"int64"), Tensor([8, 4],"int64"), )
[torch error] paddle.equal(Tensor([8, 268435457],"int64"), Tensor([8, 4],"int64"), ) 
 The size of tensor a (268435457) must match the size of tensor b (4) at non-singleton dimension 1

W0211 15:45:46.431239 72662 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 15:45:46.432454 72662 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([8, 4],"int64"), Tensor([2147483649],"int64"), )
[torch error] paddle.equal(Tensor([8, 4],"int64"), Tensor([2147483649],"int64"), ) 
 The size of tensor a (4) must match the size of tensor b (2147483649) at non-singleton dimension 1

W0211 15:46:35.031881 73261 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 15:46:35.033092 73261 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([8, 4],"int64"), Tensor([536870913, 4],"int64"), )
[torch error] paddle.equal(Tensor([8, 4],"int64"), Tensor([536870913, 4],"int64"), ) 
 The size of tensor a (8) must match the size of tensor b (536870913) at non-singleton dimension 0

W0211 15:47:29.826894 73936 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 15:47:29.828091 73936 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([8, 4],"int64"), Tensor([8, 268435457],"int64"), )
[torch error] paddle.equal(Tensor([8, 4],"int64"), Tensor([8, 268435457],"int64"), ) 
 The size of tensor a (4) must match the size of tensor b (268435457) at non-singleton dimension 1

W0211 15:48:17.821473 74508 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 15:48:17.822556 74508 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([8, 536870912],"float32"), Tensor([8, 536870912],"float32"), )
[paddle error] paddle.equal(Tensor([8, 536870912],"float32"), Tensor([8, 536870912],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 70.575134GB memory has been allocated and available memory is only 8.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 15:50:41.566475 75096 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 15:50:41.567350 75096 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([8, 536870912],"float32"), Tensor([8, 8],"float32"), )
[torch error] paddle.equal(Tensor([8, 536870912],"float32"), Tensor([8, 8],"float32"), ) 
 The size of tensor a (536870912) must match the size of tensor b (8) at non-singleton dimension 1

W0211 15:51:53.177053 76350 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 15:51:53.178181 76350 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([8, 8],"float32"), Tensor([536870912, 8],"float32"), )
[torch error] paddle.equal(Tensor([8, 8],"float32"), Tensor([536870912, 8],"float32"), ) 
 The size of tensor a (8) must match the size of tensor b (536870912) at non-singleton dimension 0

W0211 15:53:12.427285 77214 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 15:53:12.428515 77214 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([8, 8],"float32"), Tensor([8, 536870912],"float32"), )
[torch error] paddle.equal(Tensor([8, 8],"float32"), Tensor([8, 536870912],"float32"), ) 
 The size of tensor a (8) must match the size of tensor b (536870912) at non-singleton dimension 1

W0211 15:54:27.398416 77863 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 15:54:27.399703 77863 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(x=Tensor([2147483649],"int64"), y=Tensor([2147483649],"int64"), )
[paddle error] paddle.equal(x=Tensor([2147483649],"int64"), y=Tensor([2147483649],"int64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 68.580994GB memory has been allocated and available memory is only 10.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 15:56:02.642624 79151 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 15:56:02.643419 79151 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(x=Tensor([2147483649],"int64"), y=Tensor([3],"int64"), )
[torch error] paddle.equal(x=Tensor([2147483649],"int64"), y=Tensor([3],"int64"), ) 
 The size of tensor a (2147483649) must match the size of tensor b (3) at non-singleton dimension 0

W0211 15:56:48.292011 81119 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 15:56:48.293129 81119 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(x=Tensor([3],"int64"), y=Tensor([2147483649],"int64"), )
[torch error] paddle.equal(x=Tensor([3],"int64"), y=Tensor([2147483649],"int64"), ) 
 The size of tensor a (3) must match the size of tensor b (2147483649) at non-singleton dimension 0

W0211 15:57:34.348798 82070 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 15:57:34.349973 82070 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.erf(Tensor([11, 195225787],"float64"), )
[paddle error] paddle.erf(Tensor([11, 195225787],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 15:58:37.124718 83003 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 15:58:37.125613 83003 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.erf(Tensor([126322568, 17],"float64"), )
[paddle error] paddle.erf(Tensor([126322568, 17],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 15:59:42.292446 84296 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 15:59:42.293398 84296 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.erfinv(Tensor([4294967295],"float32"), )
[paddle error] paddle.erfinv(Tensor([4294967295],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:01:03.959307 85594 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:01:03.961786 85594 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([1, 1431655765, 3],"float32"), )
[paddle error] paddle.exp(Tensor([1, 1431655765, 3],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:02:31.428819 87417 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:02:31.429751 87417 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([1, 178956971, 3, 4],"float64"), )
[paddle error] paddle.exp(Tensor([1, 178956971, 3, 4],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:03:37.527413 88296 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:03:37.528345 88296 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([1, 2, 2147483648],"float32"), )
[paddle error] paddle.exp(Tensor([1, 2, 2147483648],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:04:59.667019 88939 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:04:59.667970 88939 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([1, 2, 268435457, 4],"float64"), )
[paddle error] paddle.exp(Tensor([1, 2, 268435457, 4],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:06:00.725414 89864 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:06:00.727739 89864 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([1, 2, 3, 357913942],"float64"), )
[paddle error] paddle.exp(Tensor([1, 2, 3, 357913942],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:07:02.861786 90475 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:07:02.862632 90475 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([1, 2, 3, 715827883],"float32"), )
[paddle error] paddle.exp(Tensor([1, 2, 3, 715827883],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:08:26.261549 91062 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:08:26.262437 91062 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([1, 2, 536870912, 4],"float32"), )
[paddle error] paddle.exp(Tensor([1, 2, 536870912, 4],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:09:51.679319 91977 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:09:51.680193 91977 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([1, 357913942, 3, 4],"float32"), )
[paddle error] paddle.exp(Tensor([1, 357913942, 3, 4],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:11:18.092434 92858 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:11:18.093391 92858 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([10, 10, 21474837],"float64"), )
[paddle error] paddle.exp(Tensor([10, 10, 21474837],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:12:17.611078 93680 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:12:17.613775 93680 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([10, 1431656, 300],"float32"), )
[paddle error] paddle.exp(Tensor([10, 1431656, 300],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000003GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:13:39.001595 94249 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:13:39.002496 94249 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([10, 1431656, 300],"int32"), )
[paddle error] paddle.exp(Tensor([10, 1431656, 300],"int32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000003GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:15:02.041493 94823 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:15:02.043854 94823 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([10, 200, 1073742],"int64"), )
[paddle error] paddle.exp(Tensor([10, 200, 1073742],"int64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_exp(_object*, _object*, _object*)
1   exp_ad_func(paddle::Tensor const&)
2   paddle::experimental::exp(paddle::Tensor const&)
3   void phi::ExpKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   void phi::ActivationGPUImpl<float, phi::GPUContext, phi::funcs::CudaExpFunctor<long> >(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*, phi::funcs::CudaExpFunctor<long> const&)
5   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
6   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
15  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
16  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000001GB memory on GPU 0, 74.580994GB memory has been allocated and available memory is only 4.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:15:54.224834 95588 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:15:54.225715 95588 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([10, 200, 2147484],"float32"), )
[paddle error] paddle.exp(Tensor([10, 200, 2147484],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000003GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:17:24.118018 96103 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:17:24.119078 96103 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([10, 200, 2147484],"int32"), )
[paddle error] paddle.exp(Tensor([10, 200, 2147484],"int32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000003GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:18:46.769589 96975 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:18:46.770475 96975 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([10, 214748365],"float64"), )
[paddle error] paddle.exp(Tensor([10, 214748365],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:19:52.040869 97883 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:19:52.041692 97883 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([10, 21474837, 10],"float64"), )
[paddle error] paddle.exp(Tensor([10, 21474837, 10],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:20:52.187597 98521 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:20:52.188472 98521 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([10, 429496730],"bfloat16"), )
[paddle error] paddle.exp(Tensor([10, 429496730],"bfloat16"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_cast(_object*, _object*, _object*)
1   cast_ad_func(paddle::Tensor const&, phi::DataType)
2   paddle::experimental::cast(paddle::Tensor const&, phi::DataType)
3   void phi::CastKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
4   void phi::CastCUDAKernelImpl<float, phi::dtype::bfloat16>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
5   phi::dtype::bfloat16* phi::DeviceContext::Alloc<phi::dtype::bfloat16>(phi::TensorBase*, unsigned long, bool) const
6   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
15  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
16  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000000GB memory on GPU 0, 74.580994GB memory has been allocated and available memory is only 4.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:22:08.842929 99136 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:22:08.843770 99136 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([10, 429496730],"float16"), )
[Pass] paddle.exp(Tensor([10, 429496730],"float16"), )

W0211 16:23:45.288905 100016 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:23:45.289876 100016 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([10, 429496730],"float32"), )
[paddle error] paddle.exp(Tensor([10, 429496730],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:32:39.551455 105363 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:32:39.553948 105363 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([10, 715828, 300],"int64"), )
[paddle error] paddle.exp(Tensor([10, 715828, 300],"int64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_exp(_object*, _object*, _object*)
1   exp_ad_func(paddle::Tensor const&)
2   paddle::experimental::exp(paddle::Tensor const&)
3   void phi::ExpKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   void phi::ActivationGPUImpl<float, phi::GPUContext, phi::funcs::CudaExpFunctor<long> >(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*, phi::funcs::CudaExpFunctor<long> const&)
5   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
6   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
15  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
16  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000001GB memory on GPU 0, 74.580994GB memory has been allocated and available memory is only 4.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:33:30.759620 106008 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:33:30.760496 106008 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([1000, 2147484],"float64"), )
[paddle error] paddle.exp(Tensor([1000, 2147484],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000003GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:34:40.768160 106612 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:34:40.770691 106612 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([1048576, 32, 128],"float32"), )
[paddle error] paddle.exp(Tensor([1048576, 32, 128],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:36:06.841198 107222 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:36:06.842093 107222 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([1073741824, 4],"float32"), )
[paddle error] paddle.exp(Tensor([1073741824, 4],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:37:27.464957 108109 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:37:27.465859 108109 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([1073741825, 2],"float64"), )
[paddle error] paddle.exp(Tensor([1073741825, 2],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:38:26.320557 108991 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:38:26.321434 108991 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([107374183, 20],"float64"), )
[paddle error] paddle.exp(Tensor([107374183, 20],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:39:33.375452 109619 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:39:33.376441 109619 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([10737419, 10, 20],"float64"), )
[paddle error] paddle.exp(Tensor([10737419, 10, 20],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:40:33.092407 110234 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:40:33.093330 110234 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([114, 18837576],"float64"), )
[paddle error] paddle.exp(Tensor([114, 18837576],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:41:32.456000 110767 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:41:32.456872 110767 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([1431655765, 3],"float32"), )
[paddle error] paddle.exp(Tensor([1431655765, 3],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:42:53.077215 111284 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:42:53.078107 111284 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([148, 5, 5804010],"float32"), )
[paddle error] paddle.exp(Tensor([148, 5, 5804010],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:44:21.108445 112160 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:44:21.110924 112160 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([148, 9673350, 3],"float32"), )
[paddle error] paddle.exp(Tensor([148, 9673350, 3],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:45:40.899636 113028 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:45:40.901538 113028 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([16777216, 256],"float32"), )
[paddle error] paddle.exp(Tensor([16777216, 256],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:47:09.159574 113653 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:47:09.161600 113653 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([178956971, 12],"float64"), )
[paddle error] paddle.exp(Tensor([178956971, 12],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:48:10.768072 114569 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:48:10.768893 114569 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([178956971, 2, 3, 4],"float32"), )
[paddle error] paddle.exp(Tensor([178956971, 2, 3, 4],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:49:40.537050 115183 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:49:40.538013 115183 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([1948, 2204809],"float32"), )
[paddle error] paddle.exp(Tensor([1948, 2204809],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000002GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:51:01.228498 116079 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:51:01.231055 116079 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([2, 1073741825],"float64"), )
[paddle error] paddle.exp(Tensor([2, 1073741825],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:52:07.290325 116975 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:52:07.291155 116975 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([2, 2147483648],"float32"), )
[paddle error] paddle.exp(Tensor([2, 2147483648],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:53:28.316061 117589 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:53:28.318387 117589 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([2, 3, 715827883],"float32"), )
[paddle error] paddle.exp(Tensor([2, 3, 715827883],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:54:50.161177 118480 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:54:50.162045 118480 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([2, 536870912, 4],"float32"), )
[paddle error] paddle.exp(Tensor([2, 536870912, 4],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:56:15.188697 119369 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:56:15.189496 119369 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([2147483648, 2],"bfloat16"), )
[paddle error] paddle.exp(Tensor([2147483648, 2],"bfloat16"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_cast(_object*, _object*, _object*)
1   cast_ad_func(paddle::Tensor const&, phi::DataType)
2   paddle::experimental::cast(paddle::Tensor const&, phi::DataType)
3   void phi::CastKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
4   void phi::CastCUDAKernelImpl<float, phi::dtype::bfloat16>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
5   phi::dtype::bfloat16* phi::DeviceContext::Alloc<phi::dtype::bfloat16>(phi::TensorBase*, unsigned long, bool) const
6   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
15  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
16  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000000GB memory on GPU 0, 74.575134GB memory has been allocated and available memory is only 4.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 16:57:29.687315 120457 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:57:29.688184 120457 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([2147483648, 2],"float16"), )
[Pass] paddle.exp(Tensor([2147483648, 2],"float16"), )

W0211 16:59:12.615964 122388 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 16:59:12.616982 122388 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([2147483648, 2],"float32"), )
[paddle error] paddle.exp(Tensor([2147483648, 2],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 17:08:21.281641 134547 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:08:21.282439 134547 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([2147483649, 1],"float64"), )
[paddle error] paddle.exp(Tensor([2147483649, 1],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 17:09:19.952567 136051 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:09:19.953495 136051 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([2147483649],"float64"), )
[paddle error] paddle.exp(Tensor([2147483649],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 17:10:23.142410 137174 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:10:23.145188 137174 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([214748365, 20],"float32"), )
[paddle error] paddle.exp(Tensor([214748365, 20],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 17:11:54.717730 138586 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:11:54.718672 138586 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([21474837, 10, 10],"float64"), )
[paddle error] paddle.exp(Tensor([21474837, 10, 10],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 17:12:53.511529 140435 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:12:53.512415 140435 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([286331153, 5, 3],"float32"), )
[paddle error] paddle.exp(Tensor([286331153, 5, 3],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 17:14:14.293656 141662 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:14:14.294457 141662 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([3, 1431655765],"float32"), )
[paddle error] paddle.exp(Tensor([3, 1431655765],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 17:15:36.934513 142795 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:15:36.935667 142795 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([3, 2, 715827883],"float32"), )
[paddle error] paddle.exp(Tensor([3, 2, 715827883],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 17:16:57.896824 144562 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:16:57.897841 144562 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([3, 286331153, 5],"float32"), )
[paddle error] paddle.exp(Tensor([3, 286331153, 5],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 17:18:27.062033 146326 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:18:27.062959 146326 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([3, 715827883],"float64"), )
[paddle error] paddle.exp(Tensor([3, 715827883],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 17:19:33.088027 148082 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:19:33.088940 148082 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([32, 1048576, 128],"float32"), )
[paddle error] paddle.exp(Tensor([32, 1048576, 128],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 17:20:54.909052 149388 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:20:54.911386 149388 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([32, 134217728],"float32"), )
[paddle error] paddle.exp(Tensor([32, 134217728],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 17:22:16.683321 151268 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:22:16.684233 151268 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([32, 32, 4194304],"float32"), )
[paddle error] paddle.exp(Tensor([32, 32, 4194304],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 17:23:37.742270 152885 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:23:37.744701 152885 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([357913942, 3, 2],"float64"), )
[paddle error] paddle.exp(Tensor([357913942, 3, 2],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 17:24:36.741791 154434 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:24:36.742807 154434 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([357913942, 3, 4],"float32"), )
[paddle error] paddle.exp(Tensor([357913942, 3, 4],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 17:26:06.967553 155556 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:26:06.970028 155556 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([357913942, 6],"float64"), )
[paddle error] paddle.exp(Tensor([357913942, 6],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 17:27:13.970901 157306 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:27:13.971923 157306 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([35792, 200, 300],"int64"), )
[paddle error] paddle.exp(Tensor([35792, 200, 300],"int64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_exp(_object*, _object*, _object*)
1   exp_ad_func(paddle::Tensor const&)
2   paddle::experimental::exp(paddle::Tensor const&)
3   void phi::ExpKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
4   void phi::ActivationGPUImpl<float, phi::GPUContext, phi::funcs::CudaExpFunctor<long> >(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*, phi::funcs::CudaExpFunctor<long> const&)
5   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
6   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
15  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
16  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000135GB memory on GPU 0, 74.580994GB memory has been allocated and available memory is only 4.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 17:28:05.336498 158549 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:28:05.337316 158549 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([4, 1073741824],"float32"), )
[paddle error] paddle.exp(Tensor([4, 1073741824],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 17:29:44.146148 160073 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:29:44.147042 160073 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([4, 268435457, 2],"float64"), )
[paddle error] paddle.exp(Tensor([4, 268435457, 2],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 17:30:48.776053 161489 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:30:48.776978 161489 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([4, 3, 178956971],"float64"), )
[paddle error] paddle.exp(Tensor([4, 3, 178956971],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 17:31:53.610481 162869 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:31:53.613032 162869 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([4, 3, 357913942],"bfloat16"), )
[paddle error] paddle.exp(Tensor([4, 3, 357913942],"bfloat16"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_cast(_object*, _object*, _object*)
1   cast_ad_func(paddle::Tensor const&, phi::DataType)
2   paddle::experimental::cast(paddle::Tensor const&, phi::DataType)
3   void phi::CastKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
4   void phi::CastCUDAKernelImpl<float, phi::dtype::bfloat16>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
5   phi::dtype::bfloat16* phi::DeviceContext::Alloc<phi::dtype::bfloat16>(phi::TensorBase*, unsigned long, bool) const
6   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
15  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
16  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000000GB memory on GPU 0, 74.580994GB memory has been allocated and available memory is only 4.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 17:33:09.212263   826 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:33:09.213171   826 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([4, 3, 357913942],"float16"), )
[Pass] paddle.exp(Tensor([4, 3, 357913942],"float16"), )

W0211 17:34:46.468662  2477 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:34:46.469609  2477 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([4, 3, 357913942],"float32"), )
[paddle error] paddle.exp(Tensor([4, 3, 357913942],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 17:43:33.530788 13587 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:43:33.531663 13587 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([4, 536870912, 2],"bfloat16"), )
[paddle error] paddle.exp(Tensor([4, 536870912, 2],"bfloat16"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_cast(_object*, _object*, _object*)
1   cast_ad_func(paddle::Tensor const&, phi::DataType)
2   paddle::experimental::cast(paddle::Tensor const&, phi::DataType)
3   void phi::CastKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
4   void phi::CastCUDAKernelImpl<float, phi::dtype::bfloat16>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
5   phi::dtype::bfloat16* phi::DeviceContext::Alloc<phi::dtype::bfloat16>(phi::TensorBase*, unsigned long, bool) const
6   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
15  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
16  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000000GB memory on GPU 0, 74.575134GB memory has been allocated and available memory is only 4.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 17:44:59.867729 15463 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:44:59.868785 15463 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([4, 536870912, 2],"float16"), )
[Pass] paddle.exp(Tensor([4, 536870912, 2],"float16"), )

W0211 17:46:44.751461 17417 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:46:44.752543 17417 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([4, 536870912, 2],"float32"), )
[paddle error] paddle.exp(Tensor([4, 536870912, 2],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 17:55:58.413863 29380 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:55:58.416265 29380 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([4, 536870913],"float64"), )
[paddle error] paddle.exp(Tensor([4, 536870913],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 17:57:02.462083 31241 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:57:02.464461 31241 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([400, 5368710],"float64"), )
[paddle error] paddle.exp(Tensor([400, 5368710],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000003GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 17:58:01.004630 32506 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:58:01.005728 32506 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([4294967295],"float32"), )
[paddle error] paddle.exp(Tensor([4294967295],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 17:59:22.192821 33760 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 17:59:22.193848 33760 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([429496730, 2, 5],"float32"), )
[paddle error] paddle.exp(Tensor([429496730, 2, 5],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 18:00:50.898561 35360 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:00:50.900921 35360 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([429496730, 5],"float64"), )
[paddle error] paddle.exp(Tensor([429496730, 5],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 18:01:56.542734 37241 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:01:56.543601 37241 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([44739243, 96],"float32"), )
[paddle error] paddle.exp(Tensor([44739243, 96],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 18:03:23.506147 38793 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:03:23.507207 38793 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([5, 429496730],"float64"), )
[paddle error] paddle.exp(Tensor([5, 429496730],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 18:04:30.909636 40693 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:04:30.910457 40693 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([512, 8388608],"float32"), )
[paddle error] paddle.exp(Tensor([512, 8388608],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 18:05:51.080775 42011 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:05:51.081676 42011 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([536870913, 4],"float64"), )
[paddle error] paddle.exp(Tensor([536870913, 4],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 18:06:50.104519 43614 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:06:50.105327 43614 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([64, 67108864],"float32"), )
[paddle error] paddle.exp(Tensor([64, 67108864],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 18:08:11.397794 44882 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:08:11.398737 44882 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([715827883, 2, 3],"float32"), )
[paddle error] paddle.exp(Tensor([715827883, 2, 3],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 18:09:42.430204 46503 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:09:42.431169 46503 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([715827883, 3, 2],"bfloat16"), )
[paddle error] paddle.exp(Tensor([715827883, 3, 2],"bfloat16"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_cast(_object*, _object*, _object*)
1   cast_ad_func(paddle::Tensor const&, phi::DataType)
2   paddle::experimental::cast(paddle::Tensor const&, phi::DataType)
3   void phi::CastKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
4   void phi::CastCUDAKernelImpl<float, phi::dtype::bfloat16>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
5   phi::dtype::bfloat16* phi::DeviceContext::Alloc<phi::dtype::bfloat16>(phi::TensorBase*, unsigned long, bool) const
6   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
15  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
16  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000000GB memory on GPU 0, 74.580994GB memory has been allocated and available memory is only 4.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 18:11:01.953879 48413 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:11:01.955166 48413 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([715827883, 3, 2],"float16"), )
[Pass] paddle.exp(Tensor([715827883, 3, 2],"float16"), )

W0211 18:12:38.941193 50516 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:12:38.942101 50516 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([715827883, 3, 2],"float32"), )
[paddle error] paddle.exp(Tensor([715827883, 3, 2],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 18:21:30.140966 62062 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:21:30.143479 62062 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([715827883, 3],"float64"), )
[paddle error] paddle.exp(Tensor([715827883, 3],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 18:22:32.055531 63973 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:22:32.056457 63973 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([71583, 200, 300],"float32"), )
[paddle error] paddle.exp(Tensor([71583, 200, 300],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000047GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 18:23:55.528610 65246 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:23:55.529479 65246 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([71583, 200, 300],"int32"), )
[paddle error] paddle.exp(Tensor([71583, 200, 300],"int32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000047GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 18:25:17.871519 67132 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:25:17.872362 67132 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([858993459, 5],"float32"), )
[paddle error] paddle.exp(Tensor([858993459, 5],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 18:26:42.564961 68760 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:26:42.566020 68760 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([89478486, 2, 3, 4],"float64"), )
[paddle error] paddle.exp(Tensor([89478486, 2, 3, 4],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 18:27:49.066540 70387 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:27:49.067440 70387 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([9, 10, 23860930],"float64"), )
[paddle error] paddle.exp(Tensor([9, 10, 23860930],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 18:28:53.817420 71926 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:28:53.820078 71926 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.exp(Tensor([9, 11930465, 20],"float64"), )
[paddle error] paddle.exp(Tensor([9, 11930465, 20],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 18:29:55.328533 73653 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:29:55.331089 73653 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.expm1(Tensor([1073741825, 2],"float64"), )
[paddle error] paddle.expm1(Tensor([1073741825, 2],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 18:30:57.364451 75111 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:30:57.367151 75111 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.expm1(Tensor([2, 1073741825],"float64"), )
[paddle error] paddle.expm1(Tensor([2, 1073741825],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 18:31:59.088521 76388 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:31:59.089330 76388 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.expm1(Tensor([2147483649],"float64"), )
[paddle error] paddle.expm1(Tensor([2147483649],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 18:33:02.746306 77669 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:33:02.747293 77669 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.expm1(Tensor([3, 715827883],"float64"), )
[paddle error] paddle.expm1(Tensor([3, 715827883],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 18:34:02.775290 79103 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:34:02.776175 79103 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.expm1(Tensor([4194305, 16, 32],"float64"), )
[paddle error] paddle.expm1(Tensor([4194305, 16, 32],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 18:35:06.565053 80377 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:35:06.567530 80377 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.expm1(Tensor([715827883, 3],"float64"), )
[paddle error] paddle.expm1(Tensor([715827883, 3],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 18:36:09.157104 81661 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:36:09.158174 81661 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.expm1(Tensor([8, 16, 16777217],"float64"), )
[paddle error] paddle.expm1(Tensor([8, 16, 16777217],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 18:37:18.436681 82945 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:37:18.437609 82945 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.expm1(Tensor([8, 16, 33554432],"float16"), )
[Pass] paddle.expm1(Tensor([8, 16, 33554432],"float16"), )

W0211 18:38:50.316664 84520 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:38:50.317588 84520 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.expm1(Tensor([8, 16, 33554432],"float32"), )
[paddle error] paddle.expm1(Tensor([8, 16, 33554432],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 18:47:53.982344 96130 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:47:53.983213 96130 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.expm1(Tensor([8, 16777216, 32],"float16"), )
[Pass] paddle.expm1(Tensor([8, 16777216, 32],"float16"), )

W0211 18:49:23.940147 97867 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:49:23.941056 97867 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.expm1(Tensor([8, 16777216, 32],"float32"), )
[paddle error] paddle.expm1(Tensor([8, 16777216, 32],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 18:58:23.595750 108923 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:58:23.596632 108923 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.expm1(Tensor([8, 8388609, 32],"float64"), )
[paddle error] paddle.expm1(Tensor([8, 8388609, 32],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000002GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 18:59:23.415335 110948 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 18:59:23.416276 110948 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.expm1(Tensor([8388608, 16, 32],"float16"), )
[Pass] paddle.expm1(Tensor([8388608, 16, 32],"float16"), )

W0211 19:00:52.085779 112128 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:00:52.086704 112128 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.expm1(Tensor([8388608, 16, 32],"float32"), )
[paddle error] paddle.expm1(Tensor([8388608, 16, 32],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0211 19:10:02.809293 123928 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:10:02.810158 123928 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1, 1024, 1, 4194304],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([1, 1024, 1, 4194304],"float32"), 1, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1, 1024, 1, 4194304], X's size = 4294967296, 'shape' is [1, 0], the capacity of 'shape' is 1024.
  [Hint: Expected capacity == in_size, but received capacity:1024 != in_size:4294967296.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 19:11:31.498922 125814 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:11:31.499743 125814 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1, 1024, 4194304, 1],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([1, 1024, 4194304, 1],"float32"), 1, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1, 1024, 4194304, 1], X's size = 4294967296, 'shape' is [1, 0], the capacity of 'shape' is 1024.
  [Hint: Expected capacity == in_size, but received capacity:1024 != in_size:4294967296.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 19:12:55.403957 127711 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:12:55.404886 127711 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1, 119304648, 6, 6],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([1, 119304648, 6, 6],"float32"), 1, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1, 119304648, 6, 6], X's size = 4294967328, 'shape' is [1, 32], the capacity of 'shape' is 32.
  [Hint: Expected capacity == in_size, but received capacity:32 != in_size:4294967328.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 19:14:13.124538 129578 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:14:13.125478 129578 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1, 1280, 1, 3355444],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([1, 1280, 1, 3355444],"float32"), 1, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1, 1280, 1, 3355444], X's size = 4294968320, 'shape' is [1, 1024], the capacity of 'shape' is 1024.
  [Hint: Expected capacity == in_size, but received capacity:1024 != in_size:4294968320.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 19:15:27.664976 130901 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:15:27.666049 130901 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1, 1280, 3355444, 1],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([1, 1280, 3355444, 1],"float32"), 1, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1, 1280, 3355444, 1], X's size = 4294968320, 'shape' is [1, 1024], the capacity of 'shape' is 1024.
  [Hint: Expected capacity == in_size, but received capacity:1024 != in_size:4294968320.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 19:17:01.127260 133096 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:17:01.128101 133096 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1, 16, 44739243, 6],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([1, 16, 44739243, 6],"float32"), 1, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1, 16, 44739243, 6], X's size = 4294967328, 'shape' is [1, 32], the capacity of 'shape' is 32.
  [Hint: Expected capacity == in_size, but received capacity:32 != in_size:4294967328.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 19:18:41.688131 134990 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:18:41.689133 134990 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1, 16, 5, 53687092],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([1, 16, 5, 53687092],"float32"), 1, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1, 16, 5, 53687092], X's size = 4294967360, 'shape' is [1, 64], the capacity of 'shape' is 64.
  [Hint: Expected capacity == in_size, but received capacity:64 != in_size:4294967360.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 19:19:58.717535 136929 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:19:58.718708 136929 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1, 16, 53687092, 5],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([1, 16, 53687092, 5],"float32"), 1, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1, 16, 53687092, 5], X's size = 4294967360, 'shape' is [1, 64], the capacity of 'shape' is 64.
  [Hint: Expected capacity == in_size, but received capacity:64 != in_size:4294967360.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 19:21:15.197911 138785 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:21:15.198809 138785 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1, 16, 6, 44739243],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([1, 16, 6, 44739243],"float32"), 1, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1, 16, 6, 44739243], X's size = 4294967328, 'shape' is [1, 32], the capacity of 'shape' is 32.
  [Hint: Expected capacity == in_size, but received capacity:32 != in_size:4294967328.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 19:22:35.561913 140327 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:22:35.562853 140327 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1, 171798692, 5, 5],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([1, 171798692, 5, 5],"float32"), 1, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1, 171798692, 5, 5], X's size = 4294967300, 'shape' is [1, 4], the capacity of 'shape' is 4.
  [Hint: Expected capacity == in_size, but received capacity:4 != in_size:4294967300.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 19:23:56.505053 141965 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:23:56.506002 141965 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1, 2048, 1, 2097152],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([1, 2048, 1, 2097152],"float32"), 1, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1, 2048, 1, 2097152], X's size = 4294967296, 'shape' is [1, 0], the capacity of 'shape' is 2048.
  [Hint: Expected capacity == in_size, but received capacity:2048 != in_size:4294967296.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 19:25:26.621380 143834 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:25:26.622537 143834 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1, 2048, 2097152, 1],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([1, 2048, 2097152, 1],"float32"), 1, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1, 2048, 2097152, 1], X's size = 4294967296, 'shape' is [1, 0], the capacity of 'shape' is 2048.
  [Hint: Expected capacity == in_size, but received capacity:2048 != in_size:4294967296.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 19:26:51.702147 145719 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:26:51.702971 145719 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1, 25565282, 14, 12],"float32"), start_axis=1, stop_axis=2, )
[Pass] paddle.flatten(Tensor([1, 25565282, 14, 12],"float32"), start_axis=1, stop_axis=2, )

W0211 19:28:15.961593 147346 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:28:15.962388 147346 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1, 4294967295, 1, 1],"float32"), 1, )
[Pass] paddle.flatten(Tensor([1, 4294967295, 1, 1],"float32"), 1, )

W0211 19:32:32.663123 152961 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:32:32.664062 152961 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1, 512, 1, 8388608],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([1, 512, 1, 8388608],"float32"), 1, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1, 512, 1, 8388608], X's size = 4294967296, 'shape' is [1, 0], the capacity of 'shape' is 512.
  [Hint: Expected capacity == in_size, but received capacity:512 != in_size:4294967296.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 19:36:06.964604 157445 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:36:06.965513 157445 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1, 512, 1198373, 7],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([1, 512, 1198373, 7],"float32"), 1, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1, 512, 1198373, 7], X's size = 4294968832, 'shape' is [1, 1536], the capacity of 'shape' is 1536.
  [Hint: Expected capacity == in_size, but received capacity:1536 != in_size:4294968832.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 19:37:33.432404 159004 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:37:33.433367 159004 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1, 512, 7, 1198373],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([1, 512, 7, 1198373],"float32"), 1, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1, 512, 7, 1198373], X's size = 4294968832, 'shape' is [1, 1536], the capacity of 'shape' is 1536.
  [Hint: Expected capacity == in_size, but received capacity:1536 != in_size:4294968832.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 19:38:52.892019 160909 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:38:52.892940 160909 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1, 512, 8388608, 1],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([1, 512, 8388608, 1],"float32"), 1, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1, 512, 8388608, 1], X's size = 4294967296, 'shape' is [1, 0], the capacity of 'shape' is 512.
  [Hint: Expected capacity == in_size, but received capacity:512 != in_size:4294967296.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 19:40:11.947743 162783 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:40:11.948644 162783 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1, 576, 1, 7456541],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([1, 576, 1, 7456541],"float32"), 1, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1, 576, 1, 7456541], X's size = 4294967616, 'shape' is [1, 320], the capacity of 'shape' is 320.
  [Hint: Expected capacity == in_size, but received capacity:320 != in_size:4294967616.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 19:41:26.169124   589 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:41:26.170089   589 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1, 576, 7456541, 1],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([1, 576, 7456541, 1],"float32"), 1, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1, 576, 7456541, 1], X's size = 4294967616, 'shape' is [1, 320], the capacity of 'shape' is 320.
  [Hint: Expected capacity == in_size, but received capacity:320 != in_size:4294967616.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 19:42:42.723505  2445 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:42:42.724381  2445 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1, 8, 14, 38347923],"float32"), start_axis=1, stop_axis=2, )
[Pass] paddle.flatten(Tensor([1, 8, 14, 38347923],"float32"), start_axis=1, stop_axis=2, )

W0211 19:43:57.537932  3788 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:43:57.538841  3788 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1, 8, 44739243, 12],"float32"), start_axis=1, stop_axis=2, )
[Pass] paddle.flatten(Tensor([1, 8, 44739243, 12],"float32"), start_axis=1, stop_axis=2, )

W0211 19:47:33.316921  8135 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:47:33.318239  8135 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1, 8, 7, 76695845],"float32"), start_axis=1, stop_axis=-1, )
[paddle error] paddle.flatten(Tensor([1, 8, 7, 76695845],"float32"), start_axis=1, stop_axis=-1, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1, 8, 7, 76695845], X's size = 4294967320, 'shape' is [1, 24], the capacity of 'shape' is 24.
  [Hint: Expected capacity == in_size, but received capacity:24 != in_size:4294967320.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 19:51:33.131510 13165 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:51:33.132409 13165 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1, 8, 76695845, 7],"float32"), start_axis=1, stop_axis=-1, )
[paddle error] paddle.flatten(Tensor([1, 8, 76695845, 7],"float32"), start_axis=1, stop_axis=-1, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1, 8, 76695845, 7], X's size = 4294967320, 'shape' is [1, 24], the capacity of 'shape' is 24.
  [Hint: Expected capacity == in_size, but received capacity:24 != in_size:4294967320.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 19:52:49.082556 15038 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:52:49.083417 15038 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1, 87652394, 7, 7],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([1, 87652394, 7, 7],"float32"), 1, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1, 87652394, 7, 7], X's size = 4294967306, 'shape' is [1, 10], the capacity of 'shape' is 10.
  [Hint: Expected capacity == in_size, but received capacity:10 != in_size:4294967306.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 19:54:14.153000 16612 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:54:14.154217 16612 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1, 87652394, 7, 7],"float32"), start_axis=1, stop_axis=-1, )
[paddle error] paddle.flatten(Tensor([1, 87652394, 7, 7],"float32"), start_axis=1, stop_axis=-1, ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1, 87652394, 7, 7], X's size = 4294967306, 'shape' is [1, 10], the capacity of 'shape' is 10.
  [Hint: Expected capacity == in_size, but received capacity:10 != in_size:4294967306.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 19:55:28.937361 18220 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:55:28.938241 18220 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([10, 429496730, 1, 1],"float32"), 1, )
[Pass] paddle.flatten(Tensor([10, 429496730, 1, 1],"float32"), 1, )

W0211 19:56:44.908296 20063 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 19:56:44.909138 20063 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([10, 512, 1, 838861],"float32"), 1, )
[Pass] paddle.flatten(Tensor([10, 512, 1, 838861],"float32"), 1, )

W0211 20:00:55.081719 25123 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:00:55.082621 25123 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([10, 512, 838861, 1],"float32"), 1, )
[Pass] paddle.flatten(Tensor([10, 512, 838861, 1],"float32"), 1, )

W0211 20:04:36.471349 29748 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:04:36.472820 29748 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1000, 4294968],"float32"), )
[paddle error] paddle.flatten(Tensor([1000, 4294968],"float32"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1000, 4294968], X's size = 4294968000, 'shape' is [704], the capacity of 'shape' is 704.
  [Hint: Expected capacity == in_size, but received capacity:704 != in_size:4294968000.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 20:08:16.495766 34689 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:08:16.496668 34689 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1073741824, 4],"float16"), )
[paddle error] paddle.flatten(Tensor([1073741824, 4],"float16"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1073741824, 4], X's size = 4294967296, 'shape' is [0], the capacity of 'shape' is 1073741824.
  [Hint: Expected capacity == in_size, but received capacity:1073741824 != in_size:4294967296.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 20:09:50.242046 36270 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:09:50.242982 36270 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1073741824, 4],"float32"), )
[paddle error] paddle.flatten(Tensor([1073741824, 4],"float32"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [1073741824, 4], X's size = 4294967296, 'shape' is [0], the capacity of 'shape' is 1073741824.
  [Hint: Expected capacity == in_size, but received capacity:1073741824 != in_size:4294967296.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 20:11:07.194005 38177 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:11:07.194895 38177 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([107374183, 4, 5],"float64"), )
[paddle error] paddle.flatten(Tensor([107374183, 4, 5],"float64"), ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [-2147483636], shape[0] = -2147483636.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483636 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 20:12:06.978519 39758 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:12:06.979938 39758 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([107374183, 4, 5],"int64"), )
[paddle error] paddle.flatten(Tensor([107374183, 4, 5],"int64"), ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [-2147483636], shape[0] = -2147483636.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483636 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 20:13:03.097136 41036 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:13:03.097939 41036 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([10737419, 16, 5, 5],"float16"), 1, )
[Pass] paddle.flatten(Tensor([10737419, 16, 5, 5],"float16"), 1, )

W0211 20:14:32.043280 42281 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:14:32.044162 42281 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([10737419, 16, 5, 5],"float32"), 1, )
[Pass] paddle.flatten(Tensor([10737419, 16, 5, 5],"float32"), 1, )

W0211 20:23:29.262023 53926 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:23:29.262809 53926 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([10737419, 16, 5, 5],"float32"), 1, -1, )
[Pass] paddle.flatten(Tensor([10737419, 16, 5, 5],"float32"), 1, -1, )

W0211 20:27:11.338117 58647 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:27:11.339087 58647 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([10956550, 8, 7, 7],"float32"), start_axis=1, stop_axis=-1, )
[Pass] paddle.flatten(Tensor([10956550, 8, 7, 7],"float32"), start_axis=1, stop_axis=-1, )

W0211 20:31:41.806679 63956 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:31:41.807657 63956 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1431655765, 3],"bfloat16"), )
[accuracy error] paddle.flatten(Tensor([1431655765, 3],"bfloat16"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 8217 has 33.58 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0211 20:35:47.105167 69581 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:35:47.106139 69581 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1431655765, 3],"float32"), )
[Pass] paddle.flatten(Tensor([1431655765, 3],"float32"), )

W0211 20:37:15.188351 71167 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:37:15.189318 71167 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1431655765, 3],"int32"), )
[Pass] paddle.flatten(Tensor([1431655765, 3],"int32"), )

W0211 20:41:04.677296 76534 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:41:04.678130 76534 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1597831, 2688, 1, 1],"float32"), start_axis=1, stop_axis=-1, )
[Pass] paddle.flatten(Tensor([1597831, 2688, 1, 1],"float32"), start_axis=1, stop_axis=-1, )

W0211 20:46:16.185856 82972 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:46:16.187026 82972 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([16, 10737419, 5, 5],"float32"), 1, )
[Pass] paddle.flatten(Tensor([16, 10737419, 5, 5],"float32"), 1, )

W0211 20:50:03.774507 87700 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:50:03.775542 87700 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([16, 16, 3355444, 5],"float32"), 1, )
[Pass] paddle.flatten(Tensor([16, 16, 3355444, 5],"float32"), 1, )

W0211 20:54:07.552115 92702 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:54:07.555827 92702 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([16, 16, 5, 3355444],"float32"), 1, )
[Pass] paddle.flatten(Tensor([16, 16, 5, 3355444],"float32"), 1, )

W0211 20:57:54.167976 97712 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 20:57:54.168962 97712 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([171197, 512, 7, 7],"float32"), 1, )
[Pass] paddle.flatten(Tensor([171197, 512, 7, 7],"float32"), 1, )

W0211 21:01:28.127475 102085 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:01:28.128484 102085 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([178956971, 3, 4],"float64"), 1, 2, )
[Pass] paddle.flatten(Tensor([178956971, 3, 4],"float64"), 1, 2, )

W0211 21:04:51.185878 107007 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:04:51.186810 107007 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([178957, 100, 120],"float64"), 1, 2, )
[Pass] paddle.flatten(Tensor([178957, 100, 120],"float64"), 1, 2, )

W0211 21:07:59.396337 110474 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:07:59.397209 110474 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([1945185, 2208, 1, 1],"float32"), start_axis=1, stop_axis=-1, )
[Pass] paddle.flatten(Tensor([1945185, 2208, 1, 1],"float32"), start_axis=1, stop_axis=-1, )

W0211 21:11:26.246100 114555 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:11:26.247006 114555 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 1024, 1, 2097152],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([2, 1024, 1, 2097152],"float32"), 1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483648], shape[1] = -2147483648.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483648 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 21:15:27.072132 119535 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:15:27.073906 119535 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 1024, 1, 2097152],"float32"), start_axis=1, stop_axis=-1, )
[paddle error] paddle.flatten(Tensor([2, 1024, 1, 2097152],"float32"), start_axis=1, stop_axis=-1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483648], shape[1] = -2147483648.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483648 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 21:16:48.232702 121782 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:16:48.233743 121782 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 1024, 2097152, 1],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([2, 1024, 2097152, 1],"float32"), 1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483648], shape[1] = -2147483648.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483648 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 21:18:08.823297 123385 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:18:08.824271 123385 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 1024, 2097152, 1],"float32"), start_axis=1, stop_axis=-1, )
[paddle error] paddle.flatten(Tensor([2, 1024, 2097152, 1],"float32"), start_axis=1, stop_axis=-1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483648], shape[1] = -2147483648.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483648 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 21:19:28.763515 124993 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:19:28.764394 124993 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 128, 3, 5592406],"float32"), start_axis=1, stop_axis=-1, )
[paddle error] paddle.flatten(Tensor([2, 128, 3, 5592406],"float32"), start_axis=1, stop_axis=-1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483392], shape[1] = -2147483392.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483392 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 21:20:51.259606 126848 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:20:51.260567 126848 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 128, 5592406, 3],"float32"), start_axis=1, stop_axis=-1, )
[paddle error] paddle.flatten(Tensor([2, 128, 5592406, 3],"float32"), start_axis=1, stop_axis=-1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483392], shape[1] = -2147483392.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483392 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 21:22:08.701229 128424 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:22:08.702045 128424 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 1280, 1, 1677722],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([2, 1280, 1, 1677722],"float32"), 1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483136], shape[1] = -2147483136.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483136 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 21:23:24.163838 130019 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:23:24.164829 130019 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 1280, 1677722, 1],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([2, 1280, 1677722, 1],"float32"), 1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483136], shape[1] = -2147483136.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483136 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 21:24:41.440982 131864 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:24:41.441960 131864 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 134217728, 4, 4],"float32"), start_axis=1, stop_axis=2, )
[Pass] paddle.flatten(Tensor([2, 134217728, 4, 4],"float32"), start_axis=1, stop_axis=2, )

W0211 21:25:56.843137 133492 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:25:56.844069 133492 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 134217728, 4, 4],"float32"), start_axis=-2, stop_axis=-1, )
[Pass] paddle.flatten(Tensor([2, 134217728, 4, 4],"float32"), start_axis=-2, stop_axis=-1, )

W0211 21:29:47.709898 138086 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:29:47.710896 138086 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 16, 26843546, 5],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([2, 16, 26843546, 5],"float32"), 1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483616], shape[1] = -2147483616.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483616 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 21:33:32.157859 141928 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:33:32.159011 141928 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 16, 5, 26843546],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([2, 16, 5, 26843546],"float32"), 1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483616], shape[1] = -2147483616.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483616 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 21:34:47.177043 143569 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:34:47.177896 143569 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 1664, 1, 1290556],"float32"), start_axis=1, stop_axis=-1, )
[paddle error] paddle.flatten(Tensor([2, 1664, 1, 1290556],"float32"), start_axis=1, stop_axis=-1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147482112], shape[1] = -2147482112.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147482112 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 21:36:06.280135 144923 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:36:06.281327 144923 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 1664, 1290556, 1],"float32"), start_axis=1, stop_axis=-1, )
[paddle error] paddle.flatten(Tensor([2, 1664, 1290556, 1],"float32"), start_axis=1, stop_axis=-1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147482112], shape[1] = -2147482112.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147482112 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 21:37:28.281463 146315 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:37:28.282392 146315 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 1920, 1, 1118482],"float32"), start_axis=1, stop_axis=-1, )
[paddle error] paddle.flatten(Tensor([2, 1920, 1, 1118482],"float32"), start_axis=1, stop_axis=-1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147481856], shape[1] = -2147481856.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147481856 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 21:38:45.671907 147975 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:38:45.672775 147975 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 1920, 1118482, 1],"float32"), start_axis=1, stop_axis=-1, )
[paddle error] paddle.flatten(Tensor([2, 1920, 1118482, 1],"float32"), start_axis=1, stop_axis=-1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147481856], shape[1] = -2147481856.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147481856 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 21:40:00.234092 149356 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:40:00.235149 149356 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 2048, 1, 1048576],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([2, 2048, 1, 1048576],"float32"), 1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483648], shape[1] = -2147483648.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483648 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 21:41:17.766201 150703 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:41:17.767663 150703 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 2048, 1, 1048576],"float32"), start_axis=1, stop_axis=-1, )
[paddle error] paddle.flatten(Tensor([2, 2048, 1, 1048576],"float32"), start_axis=1, stop_axis=-1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483648], shape[1] = -2147483648.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483648 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 21:42:33.599668 152086 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:42:33.600507 152086 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 2048, 1048576, 1],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([2, 2048, 1048576, 1],"float32"), 1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483648], shape[1] = -2147483648.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483648 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 21:43:51.686290 153444 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:43:51.687711 153444 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 2048, 1048576, 1],"float32"), start_axis=1, stop_axis=-1, )
[paddle error] paddle.flatten(Tensor([2, 2048, 1048576, 1],"float32"), start_axis=1, stop_axis=-1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483648], shape[1] = -2147483648.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483648 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 21:45:33.517302 154804 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:45:33.518208 154804 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 2147483648, 1, 1],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([2, 2147483648, 1, 1],"float32"), 1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483648], shape[1] = -2147483648.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483648 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 21:47:00.667141 156692 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:47:00.668002 156692 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 2147483648, 1, 1],"float32"), start_axis=1, stop_axis=-1, )
[paddle error] paddle.flatten(Tensor([2, 2147483648, 1, 1],"float32"), start_axis=1, stop_axis=-1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483648], shape[1] = -2147483648.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483648 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 21:48:24.879155 158326 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:48:24.880070 158326 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 2147483648],"bfloat16"), )
[paddle error] paddle.flatten(Tensor([2, 2147483648],"bfloat16"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [2, 2147483648], X's size = 4294967296, 'shape' is [0], the capacity of 'shape' is 2.
  [Hint: Expected capacity == in_size, but received capacity:2 != in_size:4294967296.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 21:49:48.523797 159985 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:49:48.524645 159985 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 2147483648],"float32"), )
[paddle error] paddle.flatten(Tensor([2, 2147483648],"float32"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [2, 2147483648], X's size = 4294967296, 'shape' is [0], the capacity of 'shape' is 2.
  [Hint: Expected capacity == in_size, but received capacity:2 != in_size:4294967296.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 21:51:08.081717 161360 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:51:08.082703 161360 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 2147483648],"int32"), )
[paddle error] paddle.flatten(Tensor([2, 2147483648],"int32"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [2, 2147483648], X's size = 4294967296, 'shape' is [0], the capacity of 'shape' is 2.
  [Hint: Expected capacity == in_size, but received capacity:2 != in_size:4294967296.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 21:52:27.290381 162733 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:52:27.291481 162733 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 214748365, 5],"float64"), )
[paddle error] paddle.flatten(Tensor([2, 214748365, 5],"float64"), ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [-2147483646], shape[0] = -2147483646.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483646 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 21:53:20.934839   864 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:53:20.935658   864 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 214748365, 5],"int64"), )
[paddle error] paddle.flatten(Tensor([2, 214748365, 5],"int64"), ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [-2147483646], shape[0] = -2147483646.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483646 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 21:54:16.696096  1722 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:54:16.697041  1722 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 21474837, 10, 10],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([2, 21474837, 10, 10],"float32"), 1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483596], shape[1] = -2147483596.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483596 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 21:55:35.714684  2824 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:55:35.715927  2824 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 2208, 1, 972593],"float32"), start_axis=1, stop_axis=-1, )
[paddle error] paddle.flatten(Tensor([2, 2208, 1, 972593],"float32"), start_axis=1, stop_axis=-1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147481952], shape[1] = -2147481952.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147481952 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 21:56:56.506788  4197 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:56:56.507663  4197 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 2208, 972593, 1],"float32"), start_axis=1, stop_axis=-1, )
[paddle error] paddle.flatten(Tensor([2, 2208, 972593, 1],"float32"), start_axis=1, stop_axis=-1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147481952], shape[1] = -2147481952.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147481952 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 21:58:23.282317  5843 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:58:23.283386  5843 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 238609295, 3, 3],"float32"), start_axis=1, stop_axis=-1, )
[paddle error] paddle.flatten(Tensor([2, 238609295, 3, 3],"float32"), start_axis=1, stop_axis=-1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483641], shape[1] = -2147483641.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483641 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 21:59:41.131309  7517 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 21:59:41.132809  7517 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 256, 1398102, 6],"float32"), start_axis=1, stop_axis=-1, )
[paddle error] paddle.flatten(Tensor([2, 256, 1398102, 6],"float32"), start_axis=1, stop_axis=-1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147482624], shape[1] = -2147482624.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147482624 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 22:00:55.927232  8625 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:00:55.928162  8625 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 256, 6, 1398102],"float32"), start_axis=1, stop_axis=-1, )
[paddle error] paddle.flatten(Tensor([2, 256, 6, 1398102],"float32"), start_axis=1, stop_axis=-1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147482624], shape[1] = -2147482624.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147482624 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 22:02:19.529250 10247 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:02:19.530123 10247 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 2688, 1, 798916],"float32"), start_axis=1, stop_axis=-1, )
[paddle error] paddle.flatten(Tensor([2, 2688, 1, 798916],"float32"), start_axis=1, stop_axis=-1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147481088], shape[1] = -2147481088.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147481088 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 22:03:34.323308 11609 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:03:34.324223 11609 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 2688, 798916, 1],"float32"), start_axis=1, stop_axis=-1, )
[paddle error] paddle.flatten(Tensor([2, 2688, 798916, 1],"float32"), start_axis=1, stop_axis=-1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147481088], shape[1] = -2147481088.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147481088 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 22:04:49.852313 12966 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:04:49.853225 12966 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 3, 178956971, 4],"float32"), start_axis=1, stop_axis=2, )
[Pass] paddle.flatten(Tensor([2, 3, 178956971, 4],"float32"), start_axis=1, stop_axis=2, )

W0211 22:06:04.313509 14354 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:06:04.314421 14354 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 3, 178956971, 4],"float32"), start_axis=-2, stop_axis=-1, )
[Pass] paddle.flatten(Tensor([2, 3, 178956971, 4],"float32"), start_axis=-2, stop_axis=-1, )

W0211 22:09:35.001828 18220 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:09:35.002801 18220 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 3, 4, 178956971],"float32"), start_axis=1, stop_axis=2, )
[Pass] paddle.flatten(Tensor([2, 3, 4, 178956971],"float32"), start_axis=1, stop_axis=2, )

W0211 22:13:15.067060 22334 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:13:15.068280 22334 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 3, 4, 178956971],"float32"), start_axis=-2, stop_axis=-1, )
[Pass] paddle.flatten(Tensor([2, 3, 4, 178956971],"float32"), start_axis=-2, stop_axis=-1, )

W0211 22:17:03.360611 26592 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:17:03.361419 26592 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 4, 268435457],"float64"), )
[paddle error] paddle.flatten(Tensor([2, 4, 268435457],"float64"), ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [-2147483640], shape[0] = -2147483640.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483640 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 22:20:36.469599 31027 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:20:36.470552 31027 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 4, 268435457],"int64"), )
[paddle error] paddle.flatten(Tensor([2, 4, 268435457],"int64"), ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [-2147483640], shape[0] = -2147483640.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483640 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 22:21:27.576404 32299 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:21:27.577262 32299 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 4, 536870912],"float32"), )
[paddle error] paddle.flatten(Tensor([2, 4, 536870912],"float32"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [2, 4, 536870912], X's size = 4294967296, 'shape' is [0], the capacity of 'shape' is 2.
  [Hint: Expected capacity == in_size, but received capacity:2 != in_size:4294967296.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 22:22:41.869926 33538 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:22:41.870716 33538 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 4, 536870912],"int32"), )
[paddle error] paddle.flatten(Tensor([2, 4, 536870912],"int32"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [2, 4, 536870912], X's size = 4294967296, 'shape' is [0], the capacity of 'shape' is 2.
  [Hint: Expected capacity == in_size, but received capacity:2 != in_size:4294967296.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 22:24:01.755750 34840 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:24:01.756778 34840 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 429496730, 5],"float32"), )
[paddle error] paddle.flatten(Tensor([2, 429496730, 5],"float32"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [2, 429496730, 5], X's size = 4294967300, 'shape' is [4], the capacity of 'shape' is 4.
  [Hint: Expected capacity == in_size, but received capacity:4 != in_size:4294967300.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 22:25:23.140483 36687 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:25:23.141378 36687 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 429496730, 5],"int32"), )
[paddle error] paddle.flatten(Tensor([2, 429496730, 5],"int32"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [2, 429496730, 5], X's size = 4294967300, 'shape' is [4], the capacity of 'shape' is 4.
  [Hint: Expected capacity == in_size, but received capacity:4 != in_size:4294967300.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 22:26:47.003619 38528 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:26:47.004727 38528 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 43826197, 7, 7],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([2, 43826197, 7, 7],"float32"), 1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483643], shape[1] = -2147483643.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483643 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 22:28:11.187510 40128 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:28:11.188315 40128 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 512, 1, 4194304],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([2, 512, 1, 4194304],"float32"), 1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483648], shape[1] = -2147483648.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483648 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 22:29:35.005846 41773 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:29:35.007230 41773 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 512, 1, 4194304],"float32"), start_axis=1, stop_axis=-1, )
[paddle error] paddle.flatten(Tensor([2, 512, 1, 4194304],"float32"), start_axis=1, stop_axis=-1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483648], shape[1] = -2147483648.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483648 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 22:30:51.954861 43628 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:30:51.956284 43628 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 512, 4194304, 1],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([2, 512, 4194304, 1],"float32"), 1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483648], shape[1] = -2147483648.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483648 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 22:32:08.835022 45190 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:32:08.835853 45190 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 512, 4194304, 1],"float32"), start_axis=1, stop_axis=-1, )
[paddle error] paddle.flatten(Tensor([2, 512, 4194304, 1],"float32"), start_axis=1, stop_axis=-1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483648], shape[1] = -2147483648.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483648 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 22:33:27.545780 46780 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:33:27.546924 46780 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 512, 599187, 7],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([2, 512, 599187, 7],"float32"), 1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147481088], shape[1] = -2147481088.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147481088 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 22:34:52.584856 48639 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:34:52.589253 48639 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 512, 7, 599187],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([2, 512, 7, 599187],"float32"), 1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147481088], shape[1] = -2147481088.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147481088 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 22:36:09.874296 50256 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:36:09.875164 50256 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 576, 1, 3728271],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([2, 576, 1, 3728271],"float32"), 1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483200], shape[1] = -2147483200.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483200 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 22:37:30.212718 52046 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:37:30.214206 52046 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 576, 3728271, 1],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([2, 576, 3728271, 1],"float32"), 1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483200], shape[1] = -2147483200.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483200 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 22:38:46.810622 54089 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:38:46.811465 54089 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 59652324, 6, 6],"float32"), start_axis=1, stop_axis=-1, )
[paddle error] paddle.flatten(Tensor([2, 59652324, 6, 6],"float32"), start_axis=1, stop_axis=-1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483632], shape[1] = -2147483632.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483632 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 22:40:05.900069 55691 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:40:05.900944 55691 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 6, 10, 35791395],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([2, 6, 10, 35791395],"float32"), 1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483596], shape[1] = -2147483596.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483596 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 22:41:20.710217 57273 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:41:20.711228 57273 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 6, 35791395, 10],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([2, 6, 35791395, 10],"float32"), 1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483596], shape[1] = -2147483596.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483596 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 22:42:44.672194 58882 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:42:44.673264 58882 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 85899346, 5, 5],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([2, 85899346, 5, 5],"float32"), 1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147483646], shape[1] = -2147483646.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483646 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 22:44:02.613086 60486 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:44:02.613940 60486 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 960, 1, 2236963],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([2, 960, 1, 2236963],"float32"), 1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147482816], shape[1] = -2147482816.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147482816 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 22:45:28.474977 62327 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:45:28.476006 62327 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2, 960, 2236963, 1],"float32"), 1, )
[paddle error] paddle.flatten(Tensor([2, 960, 2236963, 1],"float32"), 1, ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [2, -2147482816], shape[1] = -2147482816.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147482816 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 22:46:51.698246 64189 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:46:51.699129 64189 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2097152, 2048, 1, 1],"float32"), 1, )
[Pass] paddle.flatten(Tensor([2097152, 2048, 1, 1],"float32"), 1, )

W0211 22:48:06.945843 65770 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:48:06.946767 65770 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2097152, 2048, 1, 1],"float32"), start_axis=1, stop_axis=-1, )
[Pass] paddle.flatten(Tensor([2097152, 2048, 1, 1],"float32"), start_axis=1, stop_axis=-1, )

W0211 22:51:57.669420 70463 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:51:57.670272 70463 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([214748365, 4, 5],"float32"), )
[paddle error] paddle.flatten(Tensor([214748365, 4, 5],"float32"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [214748365, 4, 5], X's size = 4294967300, 'shape' is [4], the capacity of 'shape' is 4.
  [Hint: Expected capacity == in_size, but received capacity:4 != in_size:4294967300.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 22:55:48.153720 75757 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:55:48.154742 75757 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([214748365, 4, 5],"int32"), )
[paddle error] paddle.flatten(Tensor([214748365, 4, 5],"int32"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [214748365, 4, 5], X's size = 4294967300, 'shape' is [4], the capacity of 'shape' is 4.
  [Hint: Expected capacity == in_size, but received capacity:4 != in_size:4294967300.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 22:57:11.622740 77350 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:57:11.623549 77350 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2236963, 1920, 1, 1],"float32"), start_axis=1, stop_axis=-1, )
[Pass] paddle.flatten(Tensor([2236963, 1920, 1, 1],"float32"), start_axis=1, stop_axis=-1, )

W0211 22:58:35.441646 79124 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 22:58:35.442643 79124 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([2581111, 1664, 1, 1],"float32"), start_axis=1, stop_axis=-1, )
[Pass] paddle.flatten(Tensor([2581111, 1664, 1, 1],"float32"), start_axis=1, stop_axis=-1, )

W0211 23:02:38.119688 84085 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:02:38.120513 84085 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([268435457, 4, 2],"float64"), )
[paddle error] paddle.flatten(Tensor([268435457, 4, 2],"float64"), ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [-2147483640], shape[0] = -2147483640.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483640 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 23:06:13.552412 89366 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:06:13.553485 89366 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([268435457, 4, 2],"int64"), )
[paddle error] paddle.flatten(Tensor([268435457, 4, 2],"int64"), ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [-2147483640], shape[0] = -2147483640.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483640 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 23:07:10.723488 90324 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:07:10.724349 90324 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([272, 16, 197380, 5],"float32"), 1, )
[Pass] paddle.flatten(Tensor([272, 16, 197380, 5],"float32"), 1, )

W0211 23:08:25.411058 91597 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:08:25.411921 91597 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([272, 16, 5, 197380],"float32"), 1, )
[Pass] paddle.flatten(Tensor([272, 16, 5, 197380],"float32"), 1, )

W0211 23:12:46.743402 97158 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:12:46.744815 97158 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([272, 631613, 5, 5],"float32"), 1, )
[Pass] paddle.flatten(Tensor([272, 631613, 5, 5],"float32"), 1, )

W0211 23:16:54.807819 101854 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:16:54.808816 101854 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([3, 100, 7158279],"float64"), 1, 2, )
[Pass] paddle.flatten(Tensor([3, 100, 7158279],"float64"), 1, 2, )

W0211 23:20:34.267913 107183 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:20:34.268918 107183 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([3, 1431655765, 1, 1],"float32"), 1, )
[Pass] paddle.flatten(Tensor([3, 1431655765, 1, 1],"float32"), 1, )

W0211 23:23:55.155486 110892 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:23:55.156316 110892 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([3, 1431655765],"float16"), )
[Pass] paddle.flatten(Tensor([3, 1431655765],"float16"), )

W0211 23:28:09.582118 115918 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:28:09.583019 115918 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([3, 1431655765],"float32"), )
[Pass] paddle.flatten(Tensor([3, 1431655765],"float32"), )

W0211 23:37:32.214784 128050 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:37:32.215673 128050 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([3, 2048, 1, 699051],"float32"), 1, )
[Pass] paddle.flatten(Tensor([3, 2048, 1, 699051],"float32"), 1, )

W0211 23:41:22.950913 133401 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:41:22.951798 133401 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([3, 2048, 699051, 1],"float32"), 1, )
[Pass] paddle.flatten(Tensor([3, 2048, 699051, 1],"float32"), 1, )

W0211 23:44:56.569983 137752 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:44:56.570983 137752 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([3, 357913942, 2],"float64"), )
[paddle error] paddle.flatten(Tensor([3, 357913942, 2],"float64"), ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [-2147483644], shape[0] = -2147483644.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483644 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 23:48:14.528416 142432 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:48:14.529376 142432 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([3, 357913942, 2],"int64"), )
[paddle error] paddle.flatten(Tensor([3, 357913942, 2],"int64"), ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [-2147483644], shape[0] = -2147483644.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483644 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 23:49:09.351874 143425 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:49:09.352815 143425 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([3, 4, 178956971],"float64"), )
[paddle error] paddle.flatten(Tensor([3, 4, 178956971],"float64"), ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [-2147483644], shape[0] = -2147483644.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483644 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 23:50:07.853281 144647 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:50:07.854154 144647 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([3, 4, 178956971],"int64"), )
[paddle error] paddle.flatten(Tensor([3, 4, 178956971],"int64"), ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [-2147483644], shape[0] = -2147483644.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483644 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0211 23:51:00.678481 145880 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:51:00.679782 145880 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([3, 4, 357913942],"float32"), )
[paddle error] paddle.flatten(Tensor([3, 4, 357913942],"float32"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [3, 4, 357913942], X's size = 4294967304, 'shape' is [8], the capacity of 'shape' is 8.
  [Hint: Expected capacity == in_size, but received capacity:8 != in_size:4294967304.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 23:52:26.473510 147127 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:52:26.474561 147127 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([3, 4, 357913942],"int32"), )
[paddle error] paddle.flatten(Tensor([3, 4, 357913942],"int32"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [3, 4, 357913942], X's size = 4294967304, 'shape' is [8], the capacity of 'shape' is 8.
  [Hint: Expected capacity == in_size, but received capacity:8 != in_size:4294967304.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0211 23:53:39.587546 149012 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:53:39.588395 149012 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([3, 4, 4, 89478486],"float32"), start_axis=1, stop_axis=-1, )
[Pass] paddle.flatten(Tensor([3, 4, 4, 89478486],"float32"), start_axis=1, stop_axis=-1, )

W0211 23:54:59.939591 150321 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:54:59.940460 150321 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([3, 4, 71582789, 5],"float32"), start_axis=1, stop_axis=-1, )
[Pass] paddle.flatten(Tensor([3, 4, 71582789, 5],"float32"), start_axis=1, stop_axis=-1, )

W0211 23:58:52.471217 155287 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0211 23:58:52.472040 155287 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([3, 5965233, 120],"float64"), 1, 2, )
[Pass] paddle.flatten(Tensor([3, 5965233, 120],"float64"), 1, 2, )

W0212 00:02:16.871567 159639 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:02:16.873236 159639 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([3, 715827883, 2],"float32"), )
[paddle error] paddle.flatten(Tensor([3, 715827883, 2],"float32"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [3, 715827883, 2], X's size = 4294967298, 'shape' is [2], the capacity of 'shape' is 2.
  [Hint: Expected capacity == in_size, but received capacity:2 != in_size:4294967298.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0212 00:05:49.965782   478 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:05:49.967056   478 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([3, 715827883, 2],"int32"), )
[paddle error] paddle.flatten(Tensor([3, 715827883, 2],"int32"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [3, 715827883, 2], X's size = 4294967298, 'shape' is [2], the capacity of 'shape' is 2.
  [Hint: Expected capacity == in_size, but received capacity:2 != in_size:4294967298.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0212 00:07:08.153702  2101 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:07:08.154665  2101 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([3, 715827883],"float64"), )
[paddle error] paddle.flatten(Tensor([3, 715827883],"float64"), ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [-2147483647], shape[0] = -2147483647.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483647 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0212 00:08:05.557461  3679 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:08:05.558359  3679 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([3, 71582789, 4, 5],"float32"), start_axis=1, stop_axis=-1, )
[Pass] paddle.flatten(Tensor([3, 71582789, 4, 5],"float32"), start_axis=1, stop_axis=-1, )

W0212 00:09:26.315258  4910 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:09:26.316591  4910 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([3176751, 2, 26, 26],"float32"), start_axis=1, )
[Pass] paddle.flatten(Tensor([3176751, 2, 26, 26],"float32"), start_axis=1, )

W0212 00:13:30.814656  9892 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:13:30.815521  9892 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([3195661, 8, 14, 12],"float32"), start_axis=1, stop_axis=2, )
[Pass] paddle.flatten(Tensor([3195661, 8, 14, 12],"float32"), start_axis=1, stop_axis=2, )

W0212 00:17:12.207633 14556 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:17:12.209009 14556 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([32, 16, 1398102, 6],"float32"), 1, )
[Pass] paddle.flatten(Tensor([32, 16, 1398102, 6],"float32"), 1, )

W0212 00:20:51.296352 19236 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:20:51.297869 19236 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([32, 16, 1677722, 5],"float32"), 1, )
[Pass] paddle.flatten(Tensor([32, 16, 1677722, 5],"float32"), 1, )

W0212 00:24:32.438442 23945 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:24:32.439245 23945 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([32, 16, 5, 1677722],"float32"), 1, )
[Pass] paddle.flatten(Tensor([32, 16, 5, 1677722],"float32"), 1, )

W0212 00:28:12.222700 28476 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:28:12.223528 28476 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([32, 16, 6, 1398102],"float32"), 1, )
[Pass] paddle.flatten(Tensor([32, 16, 6, 1398102],"float32"), 1, )

W0212 00:31:47.870016 33108 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:31:47.871515 33108 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([32, 198547, 26, 26],"float32"), start_axis=1, )
[Pass] paddle.flatten(Tensor([32, 198547, 26, 26],"float32"), start_axis=1, )

W0212 00:35:41.214735 37825 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:35:41.215507 37825 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([32, 2, 2581111, 26],"float32"), start_axis=1, )
[Pass] paddle.flatten(Tensor([32, 2, 2581111, 26],"float32"), start_axis=1, )

W0212 00:39:13.155221 42452 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:39:13.156013 42452 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([32, 2, 26, 2581111],"float32"), start_axis=1, )
[Pass] paddle.flatten(Tensor([32, 2, 26, 2581111],"float32"), start_axis=1, )

W0212 00:42:50.452504 46807 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:42:50.453405 46807 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([32, 3728271, 6, 6],"float32"), 1, )
[Pass] paddle.flatten(Tensor([32, 3728271, 6, 6],"float32"), 1, )

W0212 00:46:31.570989 51447 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:46:31.571844 51447 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([32, 5368710, 5, 5],"float32"), 1, )
[Pass] paddle.flatten(Tensor([32, 5368710, 5, 5],"float32"), 1, )

W0212 00:50:12.188753 56312 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:50:12.189613 56312 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([3355444, 1280, 1, 1],"float32"), 1, )
[Pass] paddle.flatten(Tensor([3355444, 1280, 1, 1],"float32"), 1, )

W0212 00:53:45.209574 60973 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:53:45.210515 60973 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([36, 16, 1491309, 5],"float32"), 1, )
[Pass] paddle.flatten(Tensor([36, 16, 1491309, 5],"float32"), 1, )

W0212 00:57:25.738750 65349 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 00:57:25.739632 65349 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([36, 16, 5, 1491309],"float32"), 1, )
[Pass] paddle.flatten(Tensor([36, 16, 5, 1491309],"float32"), 1, )

W0212 01:01:02.430635 69589 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:01:02.431607 69589 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([36, 4772186, 5, 5],"float32"), 1, )
[Pass] paddle.flatten(Tensor([36, 4772186, 5, 5],"float32"), 1, )

W0212 01:04:33.972277 73419 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:04:33.973230 73419 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([3728271, 128, 3, 3],"float32"), start_axis=1, stop_axis=-1, )
[Pass] paddle.flatten(Tensor([3728271, 128, 3, 3],"float32"), start_axis=1, stop_axis=-1, )

W0212 01:08:27.593981 77795 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:08:27.595125 77795 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([4, 7, 76695845],"float64"), )
[paddle error] paddle.flatten(Tensor([4, 7, 76695845],"float64"), ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [-2147483636], shape[0] = -2147483636.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483636 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0212 01:11:47.697399 81767 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:11:47.698490 81767 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([4, 7, 76695845],"float64"), 1, 2, )
[Pass] paddle.flatten(Tensor([4, 7, 76695845],"float64"), 1, 2, )

W0212 01:13:01.358845 83117 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:13:01.359917 83117 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([4, 89478486, 6],"float64"), )
[paddle error] paddle.flatten(Tensor([4, 89478486, 6],"float64"), ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [-2147483632], shape[0] = -2147483632.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483632 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0212 01:15:52.643026 86616 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:15:52.643940 86616 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([4, 89478486, 6],"float64"), 1, 2, )
[Pass] paddle.flatten(Tensor([4, 89478486, 6],"float64"), 1, 2, )

W0212 01:16:45.959612 87443 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:16:45.960592 87443 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([4194304, 1024, 1, 1],"float32"), 1, )
[Pass] paddle.flatten(Tensor([4194304, 1024, 1, 1],"float32"), 1, )

W0212 01:20:04.066985 90387 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:20:04.067852 90387 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([4194304, 1024, 1, 1],"float32"), start_axis=1, stop_axis=-1, )
[Pass] paddle.flatten(Tensor([4194304, 1024, 1, 1],"float32"), start_axis=1, stop_axis=-1, )

W0212 01:23:39.052246 90415 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:23:39.053717 90415 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([4473925, 960, 1, 1],"float32"), 1, )
[Pass] paddle.flatten(Tensor([4473925, 960, 1, 1],"float32"), 1, )

W0212 01:27:21.430143 90457 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:27:21.431057 90457 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([466034, 256, 6, 6],"float32"), start_axis=1, stop_axis=-1, )
[Pass] paddle.flatten(Tensor([466034, 256, 6, 6],"float32"), start_axis=1, stop_axis=-1, )

W0212 01:31:29.472543 90485 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:31:29.473320 90485 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([5, 107374183, 4],"float64"), 1, 2, )
[Pass] paddle.flatten(Tensor([5, 107374183, 4],"float64"), 1, 2, )

W0212 01:34:51.477412 90512 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:34:51.478317 90512 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([5, 3, 143165577],"float64"), 1, 2, )
[Pass] paddle.flatten(Tensor([5, 3, 143165577],"float64"), 1, 2, )

W0212 01:37:47.656062 90527 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:37:47.657039 90527 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([5, 429496730],"float64"), )
[paddle error] paddle.flatten(Tensor([5, 429496730],"float64"), ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [-2147483646], shape[0] = -2147483646.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483646 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0212 01:40:43.642925 90569 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:40:43.643889 90569 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([5, 858993459],"float32"), )
[Pass] paddle.flatten(Tensor([5, 858993459],"float32"), )

W0212 01:42:04.623214 90596 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:42:04.624028 90596 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([51130564, 7, 6],"float64"), )
[paddle error] paddle.flatten(Tensor([51130564, 7, 6],"float64"), ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [-2147483608], shape[0] = -2147483608.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483608 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0212 01:45:21.292536 90625 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:45:21.293421 90625 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([51130564, 7, 6],"float64"), 1, 2, )
[Pass] paddle.flatten(Tensor([51130564, 7, 6],"float64"), 1, 2, )

W0212 01:46:12.896673 90652 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:46:12.897594 90652 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([512, 16, 104858, 5],"float32"), 1, )
[Pass] paddle.flatten(Tensor([512, 16, 104858, 5],"float32"), 1, )

W0212 01:49:40.451376 90680 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:49:40.452256 90680 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([512, 16, 5, 104858],"float32"), 1, )
[Pass] paddle.flatten(Tensor([512, 16, 5, 104858],"float32"), 1, )

W0212 01:53:19.761544 90722 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:53:19.762868 90722 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([512, 335545, 5, 5],"float32"), 1, )
[Pass] paddle.flatten(Tensor([512, 335545, 5, 5],"float32"), 1, )

W0212 01:57:46.438789 90764 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 01:57:46.439671 90764 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([536870912, 4, 2],"float32"), )
[paddle error] paddle.flatten(Tensor([536870912, 4, 2],"float32"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [536870912, 4, 2], X's size = 4294967296, 'shape' is [0], the capacity of 'shape' is 536870912.
  [Hint: Expected capacity == in_size, but received capacity:536870912 != in_size:4294967296.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0212 02:01:31.486459 90806 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 02:01:31.487494 90806 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([536870912, 4, 2],"int32"), )
[paddle error] paddle.flatten(Tensor([536870912, 4, 2],"int32"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [536870912, 4, 2], X's size = 4294967296, 'shape' is [0], the capacity of 'shape' is 536870912.
  [Hint: Expected capacity == in_size, but received capacity:536870912 != in_size:4294967296.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0212 02:02:46.908567 90834 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 02:02:46.909379 90834 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([536870913, 4],"float64"), )
[paddle error] paddle.flatten(Tensor([536870913, 4],"float64"), ) 
 (InvalidArgument) Each dimension value of 'shape' in ReshapeOp must not be negative except one unknown dimension. But received  shape = [-2147483644], shape[0] = -2147483644.
  [Hint: Expected shape[i] > 0, but received shape[i]:-2147483644 <= 0:0.] (at ../paddle/phi/infermeta/unary.cc:2195)


W0212 02:03:46.349779 90849 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 02:03:46.350725 90849 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([53687092, 4, 4, 5],"float32"), start_axis=1, stop_axis=-1, )
[Pass] paddle.flatten(Tensor([53687092, 4, 4, 5],"float32"), start_axis=1, stop_axis=-1, )

W0212 02:05:05.104131 90889 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 02:05:05.104983 90889 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([5478275, 784],"float32"), )
[paddle error] paddle.flatten(Tensor([5478275, 784],"float32"), ) 
 (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [5478275, 784], X's size = 4294967600, 'shape' is [304], the capacity of 'shape' is 304.
  [Hint: Expected capacity == in_size, but received capacity:304 != in_size:4294967600.] (at ../paddle/phi/infermeta/unary.cc:2254)


W0212 02:08:43.257472 90946 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 02:08:43.258358 90946 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([64, 16, 5, 838861],"float16"), 1, )
[Pass] paddle.flatten(Tensor([64, 16, 5, 838861],"float16"), 1, )

W0212 02:10:14.486917 90974 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 02:10:14.487804 90974 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([64, 16, 5, 838861],"float32"), 1, )
[Pass] paddle.flatten(Tensor([64, 16, 5, 838861],"float32"), 1, )

W0212 02:19:26.006546 91086 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 02:19:26.007648 91086 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([64, 16, 5, 838861],"float32"), 1, -1, )
[Pass] paddle.flatten(Tensor([64, 16, 5, 838861],"float32"), 1, -1, )

W0212 02:22:59.826573 91129 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 02:22:59.827709 91129 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([64, 16, 838861, 5],"float16"), 1, )
[Pass] paddle.flatten(Tensor([64, 16, 838861, 5],"float16"), 1, )

W0212 02:27:06.623667 91184 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 02:27:06.624517 91184 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([64, 16, 838861, 5],"float32"), 1, )
[Pass] paddle.flatten(Tensor([64, 16, 838861, 5],"float32"), 1, )

W0212 02:36:12.305003 91324 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 02:36:12.306053 91324 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([64, 16, 838861, 5],"float32"), 1, -1, )
[Pass] paddle.flatten(Tensor([64, 16, 838861, 5],"float32"), 1, -1, )

W0212 02:39:43.022671 91380 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 02:39:43.024049 91380 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([64, 2684355, 5, 5],"float16"), 1, )
[Pass] paddle.flatten(Tensor([64, 2684355, 5, 5],"float16"), 1, )

W0212 02:43:38.973652 91450 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 02:43:38.974790 91450 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([64, 2684355, 5, 5],"float32"), 1, )
[Pass] paddle.flatten(Tensor([64, 2684355, 5, 5],"float32"), 1, )

W0212 02:52:49.477840 91563 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 02:52:49.478681 91563 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([64, 2684355, 5, 5],"float32"), 1, -1, )
[Pass] paddle.flatten(Tensor([64, 2684355, 5, 5],"float32"), 1, -1, )

W0212 02:56:28.513332 91632 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 02:56:28.514510 91632 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([64, 512, 1, 131072],"float32"), 1, )
[Pass] paddle.flatten(Tensor([64, 512, 1, 131072],"float32"), 1, )

W0212 03:00:08.198040 91702 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:00:08.199188 91702 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([64, 512, 131072, 1],"float32"), 1, )
[Pass] paddle.flatten(Tensor([64, 512, 131072, 1],"float32"), 1, )

W0212 03:03:41.168016 91758 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:03:41.168825 91758 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([64, 67108864, 1, 1],"float32"), 1, )
[Pass] paddle.flatten(Tensor([64, 67108864, 1, 1],"float32"), 1, )

W0212 03:07:18.855898 91786 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:07:18.856985 91786 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([7, 4, 76695845],"float64"), 1, 2, )
[Pass] paddle.flatten(Tensor([7, 4, 76695845],"float64"), 1, 2, )

W0212 03:11:42.725975 91829 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:11:42.726970 91829 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([7, 51130564, 6],"float64"), 1, 2, )
[Pass] paddle.flatten(Tensor([7, 51130564, 6],"float64"), 1, 2, )

W0212 03:14:44.682505 91885 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:14:44.683537 91885 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([7158279, 6, 10, 10],"float32"), 1, )
[Pass] paddle.flatten(Tensor([7158279, 6, 10, 10],"float32"), 1, )

W0212 03:18:14.378167 91954 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:18:14.378955 91954 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([7456541, 16, 6, 6],"float32"), 1, )
[Pass] paddle.flatten(Tensor([7456541, 16, 6, 6],"float32"), 1, )

W0212 03:21:44.135046 91996 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:21:44.136065 91996 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([7456541, 576, 1, 1],"float32"), 1, )
[Pass] paddle.flatten(Tensor([7456541, 576, 1, 1],"float32"), 1, )

W0212 03:25:32.587870 92038 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:25:32.588718 92038 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([8, 16, 5, 6710887],"float32"), 1, )
[Pass] paddle.flatten(Tensor([8, 16, 5, 6710887],"float32"), 1, )

W0212 03:29:08.121629 92080 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:29:08.122525 92080 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([8, 16, 6710887, 5],"float32"), 1, )
[Pass] paddle.flatten(Tensor([8, 16, 6710887, 5],"float32"), 1, )

W0212 03:32:46.901645 92123 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:32:46.902519 92123 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([8, 21474837, 5, 5],"float32"), 1, )
[Pass] paddle.flatten(Tensor([8, 21474837, 5, 5],"float32"), 1, )

W0212 03:36:16.462092 92178 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:36:16.462899 92178 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([8388608, 512, 1, 1],"float32"), 1, )
[Pass] paddle.flatten(Tensor([8388608, 512, 1, 1],"float32"), 1, )

W0212 03:39:48.075465 92234 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:39:48.076283 92234 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([8388608, 512, 1, 1],"float32"), start_axis=1, stop_axis=-1, )
[Pass] paddle.flatten(Tensor([8388608, 512, 1, 1],"float32"), start_axis=1, stop_axis=-1, )

W0212 03:43:20.079249 92304 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:43:20.080148 92304 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([858993459, 5],"float32"), )
[Pass] paddle.flatten(Tensor([858993459, 5],"float32"), )

W0212 03:47:09.647552 92374 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:47:09.649122 92374 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([89478486, 3, 4, 4],"float32"), start_axis=1, stop_axis=2, )
[Pass] paddle.flatten(Tensor([89478486, 3, 4, 4],"float32"), start_axis=1, stop_axis=2, )

W0212 03:51:25.216475 92443 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:51:25.217578 92443 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([89478486, 3, 4, 4],"float32"), start_axis=-2, stop_axis=-1, )
[Pass] paddle.flatten(Tensor([89478486, 3, 4, 4],"float32"), start_axis=-2, stop_axis=-1, )

W0212 03:55:14.141752 92514 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:55:14.142554 92514 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flatten(Tensor([89478486, 4, 6],"float64"), 1, 2, )
[Pass] paddle.flatten(Tensor([89478486, 4, 6],"float64"), 1, 2, )

W0212 03:58:35.158600 92584 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 03:58:35.159502 92584 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flip(Tensor([1073741824, 2, 2],"float32"), list[0,1,], )
[paddle error] paddle.flip(Tensor([1073741824, 2, 2],"float32"), list[0,1,], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:02:51.592013 92654 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:02:51.592902 92654 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flip(Tensor([1073741825, 2],"float64"), tuple(-2,-1,), )
[paddle error] paddle.flip(Tensor([1073741825, 2],"float64"), tuple(-2,-1,), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:03:52.785293 92682 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:03:52.786428 92682 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flip(Tensor([1431655765, 3],"float32"), 1, )
[torch error] paddle.flip(Tensor([1431655765, 3],"float32"), 1, ) 
 flip(): argument 'dims' must be tuple of ints, not int

W0212 04:05:04.682531 92710 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:05:04.683873 92710 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flip(Tensor([1431655765, 3],"float32"), list[0,], )
[paddle error] paddle.flip(Tensor([1431655765, 3],"float32"), list[0,], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:06:30.043785 92725 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:06:30.044734 92725 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flip(Tensor([2, 1073741825],"float64"), tuple(-2,-1,), )
[paddle error] paddle.flip(Tensor([2, 1073741825],"float64"), tuple(-2,-1,), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:07:26.856660 92765 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:07:26.857518 92765 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flip(Tensor([2, 2147483648],"float32"), 1, )
[torch error] paddle.flip(Tensor([2, 2147483648],"float32"), 1, ) 
 flip(): argument 'dims' must be tuple of ints, not int

W0212 04:08:35.940831 92781 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:08:35.941921 92781 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flip(Tensor([2, 2147483648],"float32"), list[0,], )
[paddle error] paddle.flip(Tensor([2, 2147483648],"float32"), list[0,], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:10:07.804258 92809 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:10:07.805179 92809 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flip(Tensor([2, 2147483648],"float32"), tuple(-2,-1,), )
[paddle error] paddle.flip(Tensor([2, 2147483648],"float32"), tuple(-2,-1,), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:11:28.408278 92849 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:11:28.409191 92849 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flip(Tensor([2147483648, 2],"float32"), tuple(-2,-1,), )
[paddle error] paddle.flip(Tensor([2147483648, 2],"float32"), tuple(-2,-1,), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:12:57.975188 92878 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:12:57.976019 92878 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flip(Tensor([3, 2, 715827883],"float32"), list[0,1,], )
[paddle error] paddle.flip(Tensor([3, 2, 715827883],"float32"), list[0,1,], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:14:27.746855 92907 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:14:27.748901 92907 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.flip(Tensor([3, 715827883, 2],"float32"), list[0,1,], )
[paddle error] paddle.flip(Tensor([3, 715827883, 2],"float32"), list[0,1,], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:15:49.737226 92961 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:15:49.738130 92961 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([1, 2147483649],"float64"), )
[paddle error] paddle.floor(Tensor([1, 2147483649],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:16:54.648288 92990 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:16:54.649101 92990 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([1, 3, 715827883],"float64"), )
[paddle error] paddle.floor(Tensor([1, 3, 715827883],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:17:57.295013 93005 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:17:57.297314 93005 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([1, 536870913, 4],"float64"), )
[paddle error] paddle.floor(Tensor([1, 536870913, 4],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:18:53.908931 93046 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:18:53.909965 93046 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([10, 214748365],"float64"), )
[paddle error] paddle.floor(Tensor([10, 214748365],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:19:55.316310 93060 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:19:55.317245 93060 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([10, 429496730],"float32"), )
[paddle error] paddle.floor(Tensor([10, 429496730],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:21:19.330654 93089 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:21:19.331487 93089 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([100000, 14317, 3],"float32"), )
[paddle error] paddle.floor(Tensor([100000, 14317, 3],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000494GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:22:55.739162 93117 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:22:55.740059 93117 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([100000, 2, 21475],"float32"), )
[paddle error] paddle.floor(Tensor([100000, 2, 21475],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000122GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:24:21.913467 93171 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:24:21.914299 93171 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([100000, 42950],"float32"), )
[paddle error] paddle.floor(Tensor([100000, 42950],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000122GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:25:41.662098 93200 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:25:41.663044 93200 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([1073741824, 2, 2],"float32"), )
[paddle error] paddle.floor(Tensor([1073741824, 2, 2],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:27:09.475376 93228 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:27:09.477515 93228 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([10737419, 400],"float32"), )
[paddle error] paddle.floor(Tensor([10737419, 400],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:28:29.413592 93269 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:28:29.414456 93269 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([120, 35791395],"float32"), )
[paddle error] paddle.floor(Tensor([120, 35791395],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:29:50.292447 93298 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:29:50.293339 93298 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([1431655765, 3],"float32"), )
[paddle error] paddle.floor(Tensor([1431655765, 3],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:31:09.908484 93339 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:31:09.910382 93339 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([143165577, 5, 2, 3],"float32"), )
[paddle error] paddle.floor(Tensor([143165577, 5, 2, 3],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:32:42.862475 93368 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:32:42.865525 93368 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([150, 28633116],"float32"), )
[paddle error] paddle.floor(Tensor([150, 28633116],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:34:04.099256 93396 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:34:04.100157 93396 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([153391690, 28],"float32"), )
[paddle error] paddle.floor(Tensor([153391690, 28],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:35:36.209576 93437 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:35:36.210702 93437 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([16, 1, 28, 9586981],"float32"), )
[paddle error] paddle.floor(Tensor([16, 1, 28, 9586981],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:36:56.378856 93466 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:36:56.379756 93466 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([16, 1, 9586981, 28],"float32"), )
[paddle error] paddle.floor(Tensor([16, 1, 9586981, 28],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:38:15.230367 93494 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:38:15.231279 93494 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([16, 10737419, 5, 5],"float32"), )
[paddle error] paddle.floor(Tensor([16, 10737419, 5, 5],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:39:35.103724 93536 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:39:35.105660 93536 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([16, 1369569, 14, 14],"float32"), )
[paddle error] paddle.floor(Tensor([16, 1369569, 14, 14],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:41:02.105904 93565 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:41:02.106894 93565 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([16, 268435456],"float32"), )
[paddle error] paddle.floor(Tensor([16, 268435456],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:42:28.295089 93606 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:42:28.296137 93606 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([16, 342393, 28, 28],"float32"), )
[paddle error] paddle.floor(Tensor([16, 342393, 28, 28],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000039GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:43:46.933177 93648 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:43:46.934067 93648 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([16, 6, 14, 3195661],"float32"), )
[paddle error] paddle.floor(Tensor([16, 6, 14, 3195661],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:45:13.008415 93673 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:45:13.010967 93673 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([16, 6, 3195661, 14],"float32"), )
[paddle error] paddle.floor(Tensor([16, 6, 3195661, 14],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:46:45.105249 93717 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:46:45.107955 93717 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([16, 6, 5, 8947849],"float32"), )
[paddle error] paddle.floor(Tensor([16, 6, 5, 8947849],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:48:12.949235 93746 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:48:12.950095 93746 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([16, 6, 8947849, 5],"float32"), )
[paddle error] paddle.floor(Tensor([16, 6, 8947849, 5],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:49:34.171118 93787 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:49:34.171950 93787 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([178956971, 12],"float64"), )
[paddle error] paddle.floor(Tensor([178956971, 12],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:50:33.436429 93816 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:50:33.438809 93816 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([178956971, 3, 4],"float64"), )
[paddle error] paddle.floor(Tensor([178956971, 3, 4],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:51:32.010883 93844 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:51:32.011819 93844 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([2, 1073741824, 2],"float32"), )
[paddle error] paddle.floor(Tensor([2, 1073741824, 2],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:52:53.395931 93872 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:52:53.396839 93872 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([2, 2147483648],"float32"), )
[paddle error] paddle.floor(Tensor([2, 2147483648],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:54:22.980069 93913 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:54:22.980944 93913 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([2, 268435456, 8],"float32"), )
[paddle error] paddle.floor(Tensor([2, 268435456, 8],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:55:50.840397 93942 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:55:50.842221 93942 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([2, 357913942, 2, 3],"float32"), )
[paddle error] paddle.floor(Tensor([2, 357913942, 2, 3],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:57:10.065707 93983 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:57:10.066519 93983 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([2, 5, 143165577, 3],"float32"), )
[paddle error] paddle.floor(Tensor([2, 5, 143165577, 3],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 04:58:38.790839 94012 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 04:58:38.791699 94012 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([2, 5, 2, 214748365],"float32"), )
[paddle error] paddle.floor(Tensor([2, 5, 2, 214748365],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:00:07.277158 94040 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:00:07.277990 94040 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([2, 5, 429496730],"float32"), )
[paddle error] paddle.floor(Tensor([2, 5, 429496730],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:01:27.066011 94081 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:01:27.068221 94081 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([2, 8, 268435456],"float32"), )
[paddle error] paddle.floor(Tensor([2, 8, 268435456],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:02:48.956478 94110 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:02:48.957377 94110 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([2147483648, 2],"float32"), )
[paddle error] paddle.floor(Tensor([2147483648, 2],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:04:10.815151 94138 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:04:10.816051 94138 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([2147483649, 1],"float64"), )
[paddle error] paddle.floor(Tensor([2147483649, 1],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:05:17.404609 94180 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:05:17.405520 94180 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([2147483649],"float64"), )
[paddle error] paddle.floor(Tensor([2147483649],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:06:23.508316 94208 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:06:23.510651 94208 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([2147483649],"int64"), )
[paddle error] paddle.floor(Tensor([2147483649],"int64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:07:26.536669 94236 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:07:26.537480 94236 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([214748365, 5, 2],"float64"), )
[paddle error] paddle.floor(Tensor([214748365, 5, 2],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:08:32.908655 94277 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:08:32.909610 94277 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([268435456, 16],"float32"), )
[paddle error] paddle.floor(Tensor([268435456, 16],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:09:54.244962 94293 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:09:54.245959 94293 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([28, 153391690],"float32"), )
[paddle error] paddle.floor(Tensor([28, 153391690],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:11:22.609112 94334 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:11:22.611541 94334 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([28633116, 6, 5, 5],"float32"), )
[paddle error] paddle.floor(Tensor([28633116, 6, 5, 5],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:12:45.261751 94375 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:12:45.262594 94375 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([30, 200, 715828],"float32"), )
[paddle error] paddle.floor(Tensor([30, 200, 715828],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000003GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:14:19.733134 94391 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:14:19.736303 94391 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([30, 3579140, 40],"float32"), )
[paddle error] paddle.floor(Tensor([30, 3579140, 40],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000003GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:16:09.478654 94405 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:16:09.479558 94405 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([306783379, 7, 1],"float64"), )
[paddle error] paddle.floor(Tensor([306783379, 7, 1],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:17:14.733129 94446 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:17:14.734021 94446 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([32, 1, 28, 4793491],"float32"), )
[paddle error] paddle.floor(Tensor([32, 1, 28, 4793491],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000002GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:18:43.328440 94461 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:18:43.330644 94461 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([32, 1, 4793491, 28],"float32"), )
[paddle error] paddle.floor(Tensor([32, 1, 4793491, 28],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000002GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:20:11.745927 94488 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:20:11.746827 94488 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([32, 134217728],"float32"), )
[paddle error] paddle.floor(Tensor([32, 134217728],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:21:40.386739 94516 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:21:40.387645 94516 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([32, 171197, 28, 28],"float32"), )
[paddle error] paddle.floor(Tensor([32, 171197, 28, 28],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000086GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:23:10.137315 94558 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:23:10.138163 94558 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([32, 6, 14, 1597831],"float32"), )
[paddle error] paddle.floor(Tensor([32, 6, 14, 1597831],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000009GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:24:33.238513 94600 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:24:33.239487 94600 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([32, 6, 1597831, 14],"float32"), )
[paddle error] paddle.floor(Tensor([32, 6, 1597831, 14],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000009GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:25:56.427296 94641 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:25:56.429316 94641 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([32, 684785, 14, 14],"float32"), )
[paddle error] paddle.floor(Tensor([32, 684785, 14, 14],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000016GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:27:22.906008 94670 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:27:22.906875 94670 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([357913942, 1, 6],"float64"), )
[paddle error] paddle.floor(Tensor([357913942, 1, 6],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:28:29.235360 94698 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:28:29.236295 94698 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([357913942, 12],"float32"), )
[paddle error] paddle.floor(Tensor([357913942, 12],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:29:57.509413 94713 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:29:57.510308 94713 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([357913942, 2, 2, 3],"float32"), )
[paddle error] paddle.floor(Tensor([357913942, 2, 2, 3],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:31:18.739051 94740 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:31:18.740059 94740 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([35791395, 120],"float32"), )
[paddle error] paddle.floor(Tensor([35791395, 120],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:32:39.838718 94781 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:32:39.841033 94781 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([3652184, 6, 14, 14],"float32"), )
[paddle error] paddle.floor(Tensor([3652184, 6, 14, 14],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:34:01.313544 94810 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:34:01.314489 94810 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([4, 1, 536870913],"float64"), )
[paddle error] paddle.floor(Tensor([4, 1, 536870913],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:35:04.601323 94839 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:35:04.602252 94839 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([4, 1073741824],"float32"), )
[paddle error] paddle.floor(Tensor([4, 1073741824],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:36:27.112270 94879 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:36:27.113169 94879 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([4, 178956971, 2, 3],"float32"), )
[paddle error] paddle.floor(Tensor([4, 178956971, 2, 3],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:37:46.898102 94908 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:37:46.900228 94908 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([4, 2, 178956971, 3],"float32"), )
[paddle error] paddle.floor(Tensor([4, 2, 178956971, 3],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:39:09.253207 94923 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:39:09.254210 94923 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([4, 2, 2, 268435456],"float32"), )
[paddle error] paddle.floor(Tensor([4, 2, 2, 268435456],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:40:40.344739 94950 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:40:40.345675 94950 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([4, 2, 536870912],"float32"), )
[paddle error] paddle.floor(Tensor([4, 2, 536870912],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:42:01.777405 94978 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:42:01.778322 94978 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([4, 268435457, 2],"float64"), )
[paddle error] paddle.floor(Tensor([4, 268435457, 2],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:43:09.037101 94993 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:43:09.038092 94993 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([4, 5, 107374183],"float64"), )
[paddle error] paddle.floor(Tensor([4, 5, 107374183],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:44:06.654166 95007 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:44:06.655313 95007 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([4, 5, 214748365],"float32"), )
[paddle error] paddle.floor(Tensor([4, 5, 214748365],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:45:33.427234 95021 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:45:33.428174 95021 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([4, 536870912, 2],"float32"), )
[paddle error] paddle.floor(Tensor([4, 536870912, 2],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:47:04.089143 95061 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:47:04.091375 95061 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([4, 536870913, 1],"float64"), )
[paddle error] paddle.floor(Tensor([4, 536870913, 1],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:48:04.270385 95090 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:48:04.272449 95090 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([4, 536870913],"float64"), )
[paddle error] paddle.floor(Tensor([4, 536870913],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:49:08.132318 95118 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:49:08.133280 95118 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([4, 7, 76695845],"float64"), )
[paddle error] paddle.floor(Tensor([4, 7, 76695845],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:50:13.138919 95145 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:50:13.141347 95145 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([4, 89478486, 6],"float64"), )
[paddle error] paddle.floor(Tensor([4, 89478486, 6],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:51:12.657298 95174 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:51:12.658159 95174 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([400, 10737419],"float32"), )
[paddle error] paddle.floor(Tensor([400, 10737419],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:52:51.119418 95202 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:52:51.120339 95202 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([4294967295, 1],"float32"), )
[paddle error] paddle.floor(Tensor([4294967295, 1],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:54:17.055955 95243 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:54:17.057919 95243 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([4294967295],"float32"), )
[paddle error] paddle.floor(Tensor([4294967295],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:55:36.657312 95273 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:55:36.658185 95273 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([4294967295],"int16"), )
[paddle error] paddle.floor(Tensor([4294967295],"int16"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_floor(_object*, _object*, _object*)
1   floor_ad_func(paddle::Tensor const&)
2   floor_ad_func(paddle::Tensor const&)
3   paddle::experimental::floor(paddle::Tensor const&)
4   void phi::FloorKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*)
5   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
6   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
15  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
16  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 74.575134GB memory has been allocated and available memory is only 4.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:56:43.313652 95300 dygraph_functions.cc:31971] math operation got integer input data type, run type autocast, this may cause data type been changed.
W0212 05:56:43.314958 95300 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:56:43.315867 95300 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([4294967295],"int32"), )
[paddle error] paddle.floor(Tensor([4294967295],"int32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 05:58:19.848078 95342 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:58:19.848948 95342 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([4294967295],"int8"), )
[Pass] paddle.floor(Tensor([4294967295],"int8"), )

W0212 05:59:27.779716 95370 dygraph_functions.cc:31971] math operation got integer input data type, run type autocast, this may cause data type been changed.
W0212 05:59:27.780962 95370 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 05:59:27.781908 95370 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([4294967295],"uint8"), )
[Pass] paddle.floor(Tensor([4294967295],"uint8"), )

W0212 06:04:28.906608 95426 dygraph_functions.cc:31971] math operation got integer input data type, run type autocast, this may cause data type been changed.
W0212 06:04:28.907863 95426 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:04:28.908731 95426 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([429496730, 10],"float32"), )
[paddle error] paddle.floor(Tensor([429496730, 10],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:09:39.967005 95510 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:09:39.967933 95510 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([429496730, 5, 2],"float32"), )
[paddle error] paddle.floor(Tensor([429496730, 5, 2],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:11:09.338346 95553 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:11:09.340399 95553 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([477218589, 1, 3, 3],"float32"), )
[paddle error] paddle.floor(Tensor([477218589, 1, 3, 3],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:12:49.689924 95582 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:12:49.690888 95582 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([5, 1, 429496730],"float64"), )
[paddle error] paddle.floor(Tensor([5, 1, 429496730],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:13:56.926338 95623 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:13:56.928812 95623 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([5, 107374183, 4],"float64"), )
[paddle error] paddle.floor(Tensor([5, 107374183, 4],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:14:55.018395 95652 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:14:55.019413 95652 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([5, 429496730],"float64"), )
[paddle error] paddle.floor(Tensor([5, 429496730],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:15:55.189493 95680 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:15:55.190380 95680 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([51130564, 84],"float32"), )
[paddle error] paddle.floor(Tensor([51130564, 84],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:17:48.951974 95694 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:17:48.954133 95694 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([536870912, 8],"float32"), )
[paddle error] paddle.floor(Tensor([536870912, 8],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:19:12.626331 95723 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:19:12.628187 95723 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([536870913, 1, 4],"float64"), )
[paddle error] paddle.floor(Tensor([536870913, 1, 4],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:20:13.565784 95737 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:20:13.566629 95737 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([536871, 200, 40],"float32"), )
[paddle error] paddle.floor(Tensor([536871, 200, 40],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000003GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:21:34.141710 95751 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:21:34.143577 95751 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([5478275, 1, 28, 28],"float32"), )
[paddle error] paddle.floor(Tensor([5478275, 1, 28, 28],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:23:04.287441 95779 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:23:04.288415 95779 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([6, 1, 238609295, 3],"float32"), )
[paddle error] paddle.floor(Tensor([6, 1, 238609295, 3],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:24:41.392486 95793 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:24:41.393338 95793 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([6, 1, 3, 238609295],"float32"), )
[paddle error] paddle.floor(Tensor([6, 1, 3, 238609295],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:26:10.701092 95833 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:26:10.701911 95833 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([6, 79536432, 3, 3],"float32"), )
[paddle error] paddle.floor(Tensor([6, 79536432, 3, 3],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:27:31.613957 95849 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:27:31.614784 95849 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([64, 1, 2396746, 28],"float32"), )
[paddle error] paddle.floor(Tensor([64, 1, 2396746, 28],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000006GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:28:51.746546 95863 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:28:51.747429 95863 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([64, 1, 28, 2396746],"float32"), )
[paddle error] paddle.floor(Tensor([64, 1, 28, 2396746],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000006GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:30:14.897727 95904 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:30:14.898553 95904 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([64, 342393, 14, 14],"float32"), )
[paddle error] paddle.floor(Tensor([64, 342393, 14, 14],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000039GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:31:36.606575 95919 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:31:36.607481 95919 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([64, 6, 14, 798916],"float32"), )
[paddle error] paddle.floor(Tensor([64, 6, 14, 798916],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000019GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:32:57.561491 95946 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:32:57.562646 95946 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([64, 6, 798916, 14],"float32"), )
[paddle error] paddle.floor(Tensor([64, 6, 798916, 14],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000019GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:34:19.657042 95974 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:34:19.657898 95974 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([64, 67108864],"float32"), )
[paddle error] paddle.floor(Tensor([64, 67108864],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:35:49.038275 96002 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:35:49.039273 96002 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([64, 85599, 28, 28],"float32"), )
[paddle error] paddle.floor(Tensor([64, 85599, 28, 28],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000179GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:37:13.642241 96045 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:37:13.643203 96045 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([67108864, 8, 8],"float32"), )
[paddle error] paddle.floor(Tensor([67108864, 8, 8],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:38:37.644096 96059 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:38:37.646657 96059 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([7, 306783379],"float64"), )
[paddle error] paddle.floor(Tensor([7, 306783379],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:39:46.311399 96099 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:39:46.313520 96099 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([715827883, 2, 3],"float32"), )
[paddle error] paddle.floor(Tensor([715827883, 2, 3],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:41:14.143378 96115 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:41:14.144272 96115 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([715827883, 3],"float64"), )
[paddle error] paddle.floor(Tensor([715827883, 3],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:42:23.611091 96129 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:42:23.611923 96129 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([715827883, 6],"float32"), )
[paddle error] paddle.floor(Tensor([715827883, 6],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:43:53.472525 96169 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:43:53.473378 96169 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([8, 536870912],"float32"), )
[paddle error] paddle.floor(Tensor([8, 536870912],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:45:21.764379 96185 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:45:21.765246 96185 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([84, 51130564],"float32"), )
[paddle error] paddle.floor(Tensor([84, 51130564],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:46:51.010932 96199 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:46:51.011796 96199 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.floor(Tensor([9, 477218589],"float32"), )
[paddle error] paddle.floor(Tensor([9, 477218589],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 06:48:11.708730 96239 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:48:11.709702 96239 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([10, 15],"float32"), Tensor([10, 429496730],"float32"), )
[torch error] paddle.fmax(Tensor([10, 15],"float32"), Tensor([10, 429496730],"float32"), ) 
 The size of tensor a (15) must match the size of tensor b (429496730) at non-singleton dimension 1

W0212 06:49:18.085992 96255 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:49:18.087270 96255 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([10, 15],"float32"), Tensor([286331153, 15],"float32"), )
[torch error] paddle.fmax(Tensor([10, 15],"float32"), Tensor([286331153, 15],"float32"), ) 
 The size of tensor a (10) must match the size of tensor b (286331153) at non-singleton dimension 0

W0212 06:50:34.170313 96269 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:50:34.171468 96269 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([10, 15],"float32"), Tensor([4294967295],"float32"), )
[torch error] paddle.fmax(Tensor([10, 15],"float32"), Tensor([4294967295],"float32"), ) 
 The size of tensor a (15) must match the size of tensor b (4294967295) at non-singleton dimension 1

W0212 06:51:43.175885 96309 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:51:43.177053 96309 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([10, 429496730],"float32"), Tensor([10, 15],"float32"), )
[torch error] paddle.fmax(Tensor([10, 429496730],"float32"), Tensor([10, 15],"float32"), ) 
 The size of tensor a (429496730) must match the size of tensor b (15) at non-singleton dimension 1

W0212 06:53:07.254261 96338 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:53:07.255986 96338 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([10, 429496730],"float32"), Tensor([10, 429496730],"float32"), )
[torch error] paddle.fmax(Tensor([10, 429496730],"float32"), Tensor([10, 429496730],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 134082 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 06:55:44.051007 96366 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:55:44.052101 96366 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([10, 429496730],"float32"), Tensor([15],"float32"), )
[torch error] paddle.fmax(Tensor([10, 429496730],"float32"), Tensor([15],"float32"), ) 
 The size of tensor a (429496730) must match the size of tensor b (15) at non-singleton dimension 1

W0212 06:57:05.110472 96395 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:57:05.111744 96395 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([2147483649],"int64"), Tensor([2147483649],"int64"), )
[torch error] paddle.fmax(Tensor([2147483649],"int64"), Tensor([2147483649],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 52556 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 06:58:41.488102 96436 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:58:41.489204 96436 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([2147483649],"int64"), Tensor([3],"int64"), )
[torch error] paddle.fmax(Tensor([2147483649],"int64"), Tensor([3],"int64"), ) 
 The size of tensor a (2147483649) must match the size of tensor b (3) at non-singleton dimension 0

W0212 06:59:35.126672 96478 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 06:59:35.127653 96478 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([286331153, 15],"float32"), Tensor([10, 15],"float32"), )
[torch error] paddle.fmax(Tensor([286331153, 15],"float32"), Tensor([10, 15],"float32"), ) 
 The size of tensor a (286331153) must match the size of tensor b (10) at non-singleton dimension 0

W0212 07:01:01.755867 96507 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:01:01.757287 96507 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([286331153, 15],"float32"), Tensor([15],"float32"), )
[paddle error] paddle.fmax(Tensor([286331153, 15],"float32"), Tensor([15],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.577087GB memory has been allocated and available memory is only 12.607788GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 07:02:27.081725 96548 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:02:27.082561 96548 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([286331153, 15],"float32"), Tensor([286331153, 15],"float32"), )
[torch error] paddle.fmax(Tensor([286331153, 15],"float32"), Tensor([286331153, 15],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 143287 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 07:04:36.916390 96591 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:04:36.917476 96591 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([3],"int64"), Tensor([2147483649],"int64"), )
[torch error] paddle.fmax(Tensor([3],"int64"), Tensor([2147483649],"int64"), ) 
 The size of tensor a (3) must match the size of tensor b (2147483649) at non-singleton dimension 0

W0212 07:05:40.934551 96659 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:05:40.935725 96659 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([30, 200, 40],"float32"), Tensor([30, 200, 715828],"float32"), )
[torch error] paddle.fmax(Tensor([30, 200, 40],"float32"), Tensor([30, 200, 715828],"float32"), ) 
 The size of tensor a (40) must match the size of tensor b (715828) at non-singleton dimension 2

W0212 07:06:58.859059 96688 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:06:58.860617 96688 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([30, 200, 40],"float32"), Tensor([30, 3579140, 40],"float32"), )
[torch error] paddle.fmax(Tensor([30, 200, 40],"float32"), Tensor([30, 3579140, 40],"float32"), ) 
 The size of tensor a (200) must match the size of tensor b (3579140) at non-singleton dimension 1

W0212 07:08:27.192565 96703 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:08:27.194079 96703 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([30, 200, 40],"float32"), Tensor([536871, 200, 40],"float32"), )
[torch error] paddle.fmax(Tensor([30, 200, 40],"float32"), Tensor([536871, 200, 40],"float32"), ) 
 The size of tensor a (30) must match the size of tensor b (536871) at non-singleton dimension 0

W0212 07:09:38.694007 96730 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:09:38.695060 96730 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([30, 200, 715828],"float32"), Tensor([30, 200, 40],"float32"), )
[torch error] paddle.fmax(Tensor([30, 200, 715828],"float32"), Tensor([30, 200, 40],"float32"), ) 
 The size of tensor a (715828) must match the size of tensor b (40) at non-singleton dimension 2

W0212 07:10:57.169706 96759 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:10:57.170542 96759 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([30, 200, 715828],"float32"), Tensor([30, 200, 715828],"float32"), )
[torch error] paddle.fmax(Tensor([30, 200, 715828],"float32"), Tensor([30, 200, 715828],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 142170 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 07:13:09.965142 96773 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:13:09.966245 96773 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([30, 3579140, 40],"float32"), Tensor([30, 200, 40],"float32"), )
[torch error] paddle.fmax(Tensor([30, 3579140, 40],"float32"), Tensor([30, 200, 40],"float32"), ) 
 The size of tensor a (3579140) must match the size of tensor b (200) at non-singleton dimension 1

W0212 07:14:28.749336 96828 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:14:28.750128 96828 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([30, 3579140, 40],"float32"), Tensor([30, 3579140, 40],"float32"), )
[torch error] paddle.fmax(Tensor([30, 3579140, 40],"float32"), Tensor([30, 3579140, 40],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 43574 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 07:16:39.815430 96857 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:16:39.820528 96857 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([357913942, 3, 2],"float64"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.fmax(Tensor([357913942, 3, 2],"float64"), Tensor([4, 3, 2],"float16"), ) 
 The size of tensor a (357913942) must match the size of tensor b (4) at non-singleton dimension 0

W0212 07:17:33.906296 96926 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:17:33.907285 96926 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([357913942, 3, 2],"float64"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.fmax(Tensor([357913942, 3, 2],"float64"), Tensor([4, 3, 2],"float32"), ) 
 The size of tensor a (357913942) must match the size of tensor b (4) at non-singleton dimension 0

W0212 07:18:21.752290 96954 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:18:21.753466 96954 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([357913942, 3, 2],"float64"), Tensor([715827883, 3, 2],"float16"), )
[torch error] paddle.fmax(Tensor([357913942, 3, 2],"float64"), Tensor([715827883, 3, 2],"float16"), ) 
 The size of tensor a (357913942) must match the size of tensor b (715827883) at non-singleton dimension 0

W0212 07:20:30.003724 96979 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:20:30.004693 96979 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([357913942, 3, 2],"float64"), Tensor([715827883, 3, 2],"float32"), )
[torch error] paddle.fmax(Tensor([357913942, 3, 2],"float64"), Tensor([715827883, 3, 2],"float32"), ) 
 The size of tensor a (357913942) must match the size of tensor b (715827883) at non-singleton dimension 0

W0212 07:22:47.623477 97038 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:22:47.624747 97038 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 268435457, 2],"float64"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.fmax(Tensor([4, 268435457, 2],"float64"), Tensor([4, 3, 2],"float16"), ) 
 The size of tensor a (268435457) must match the size of tensor b (3) at non-singleton dimension 1

W0212 07:23:38.787031 97080 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:23:38.788226 97080 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 268435457, 2],"float64"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.fmax(Tensor([4, 268435457, 2],"float64"), Tensor([4, 3, 2],"float32"), ) 
 The size of tensor a (268435457) must match the size of tensor b (3) at non-singleton dimension 1

W0212 07:24:29.253670 97108 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:24:29.254631 97108 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 268435457, 2],"float64"), Tensor([4, 536870912, 2],"float16"), )
[torch error] paddle.fmax(Tensor([4, 268435457, 2],"float64"), Tensor([4, 536870912, 2],"float16"), ) 
 The size of tensor a (268435457) must match the size of tensor b (536870912) at non-singleton dimension 1

W0212 07:26:36.766525 97137 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:26:36.767503 97137 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 268435457, 2],"float64"), Tensor([4, 536870912, 2],"float32"), )
[torch error] paddle.fmax(Tensor([4, 268435457, 2],"float64"), Tensor([4, 536870912, 2],"float32"), ) 
 The size of tensor a (268435457) must match the size of tensor b (536870912) at non-singleton dimension 1

W0212 07:28:23.796696 97151 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:28:23.797747 97151 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.fmax(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 2],"float16"), ) 
 The size of tensor a (178956971) must match the size of tensor b (2) at non-singleton dimension 2

W0212 07:29:13.358304 97193 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:29:13.359356 97193 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.fmax(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 2],"float32"), ) 
 The size of tensor a (178956971) must match the size of tensor b (2) at non-singleton dimension 2

W0212 07:30:01.736348 97207 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:30:01.737686 97207 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 357913942],"float16"), )
[torch error] paddle.fmax(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 357913942],"float16"), ) 
 The size of tensor a (178956971) must match the size of tensor b (357913942) at non-singleton dimension 2

W0212 07:32:32.409762 97221 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:32:32.411302 97221 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 357913942],"float32"), )
[torch error] paddle.fmax(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 357913942],"float32"), ) 
 The size of tensor a (178956971) must match the size of tensor b (357913942) at non-singleton dimension 2

W0212 07:34:28.986972 97262 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:34:28.988256 97262 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 2],"float16"), Tensor([357913942, 3, 2],"float64"), )
[torch error] paddle.fmax(Tensor([4, 3, 2],"float16"), Tensor([357913942, 3, 2],"float64"), ) 
 The size of tensor a (4) must match the size of tensor b (357913942) at non-singleton dimension 0

W0212 07:35:20.520812 97304 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:35:20.522010 97304 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 2],"float16"), Tensor([4, 268435457, 2],"float64"), )
[torch error] paddle.fmax(Tensor([4, 3, 2],"float16"), Tensor([4, 268435457, 2],"float64"), ) 
 The size of tensor a (3) must match the size of tensor b (268435457) at non-singleton dimension 1

W0212 07:36:14.599370 97332 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:36:14.600476 97332 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 2],"float16"), Tensor([4, 3, 178956971],"float64"), )
[torch error] paddle.fmax(Tensor([4, 3, 2],"float16"), Tensor([4, 3, 178956971],"float64"), ) 
 The size of tensor a (2) must match the size of tensor b (178956971) at non-singleton dimension 2

W0212 07:37:09.371331 97373 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:37:09.372597 97373 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 2],"float16"), Tensor([4, 3, 357913942],"float32"), )
[torch error] paddle.fmax(Tensor([4, 3, 2],"float16"), Tensor([4, 3, 357913942],"float32"), ) 
 The size of tensor a (2) must match the size of tensor b (357913942) at non-singleton dimension 2

W0212 07:38:17.788024 97402 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:38:17.789105 97402 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 2],"float16"), Tensor([4, 536870912, 2],"float32"), )
[torch error] paddle.fmax(Tensor([4, 3, 2],"float16"), Tensor([4, 536870912, 2],"float32"), ) 
 The size of tensor a (3) must match the size of tensor b (536870912) at non-singleton dimension 1

W0212 07:39:34.918712 97430 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:39:34.919844 97430 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 2],"float16"), Tensor([715827883, 3, 2],"float32"), )
[torch error] paddle.fmax(Tensor([4, 3, 2],"float16"), Tensor([715827883, 3, 2],"float32"), ) 
 The size of tensor a (4) must match the size of tensor b (715827883) at non-singleton dimension 0

W0212 07:40:50.493865 97459 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:40:50.495376 97459 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 2],"float32"), Tensor([357913942, 3, 2],"float64"), )
[torch error] paddle.fmax(Tensor([4, 3, 2],"float32"), Tensor([357913942, 3, 2],"float64"), ) 
 The size of tensor a (4) must match the size of tensor b (357913942) at non-singleton dimension 0

W0212 07:41:39.127110 97514 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:41:39.128273 97514 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 2],"float32"), Tensor([4, 268435457, 2],"float64"), )
[torch error] paddle.fmax(Tensor([4, 3, 2],"float32"), Tensor([4, 268435457, 2],"float64"), ) 
 The size of tensor a (3) must match the size of tensor b (268435457) at non-singleton dimension 1

W0212 07:42:27.852736 97542 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:42:27.853938 97542 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 2],"float32"), Tensor([4, 3, 178956971],"float64"), )
[torch error] paddle.fmax(Tensor([4, 3, 2],"float32"), Tensor([4, 3, 178956971],"float64"), ) 
 The size of tensor a (2) must match the size of tensor b (178956971) at non-singleton dimension 2

W0212 07:43:16.299870 97570 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:43:16.301083 97570 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 2],"float32"), Tensor([4, 3, 357913942],"float16"), )
[torch error] paddle.fmax(Tensor([4, 3, 2],"float32"), Tensor([4, 3, 357913942],"float16"), ) 
 The size of tensor a (2) must match the size of tensor b (357913942) at non-singleton dimension 2

W0212 07:44:45.686872 97585 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:44:45.688073 97585 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 2],"float32"), Tensor([4, 536870912, 2],"float16"), )
[torch error] paddle.fmax(Tensor([4, 3, 2],"float32"), Tensor([4, 536870912, 2],"float16"), ) 
 The size of tensor a (3) must match the size of tensor b (536870912) at non-singleton dimension 1

W0212 07:46:19.850670 97613 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:46:19.851930 97613 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 2],"float32"), Tensor([715827883, 3, 2],"float16"), )
[torch error] paddle.fmax(Tensor([4, 3, 2],"float32"), Tensor([715827883, 3, 2],"float16"), ) 
 The size of tensor a (4) must match the size of tensor b (715827883) at non-singleton dimension 0

W0212 07:47:52.331192 97654 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:47:52.332517 97654 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 2],"float64"), Tensor([4, 3, 357913942],"float16"), )
[torch error] paddle.fmax(Tensor([4, 3, 2],"float64"), Tensor([4, 3, 357913942],"float16"), ) 
 The size of tensor a (2) must match the size of tensor b (357913942) at non-singleton dimension 2

W0212 07:49:18.038823 97701 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:49:18.039903 97701 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 2],"float64"), Tensor([4, 3, 357913942],"float32"), )
[torch error] paddle.fmax(Tensor([4, 3, 2],"float64"), Tensor([4, 3, 357913942],"float32"), ) 
 The size of tensor a (2) must match the size of tensor b (357913942) at non-singleton dimension 2

W0212 07:50:46.896674 97725 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:50:46.897930 97725 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 2],"float64"), Tensor([4, 536870912, 2],"float16"), )
[torch error] paddle.fmax(Tensor([4, 3, 2],"float64"), Tensor([4, 536870912, 2],"float16"), ) 
 The size of tensor a (3) must match the size of tensor b (536870912) at non-singleton dimension 1

W0212 07:52:16.827755 97739 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:52:16.828984 97739 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 2],"float64"), Tensor([4, 536870912, 2],"float32"), )
[torch error] paddle.fmax(Tensor([4, 3, 2],"float64"), Tensor([4, 536870912, 2],"float32"), ) 
 The size of tensor a (3) must match the size of tensor b (536870912) at non-singleton dimension 1

W0212 07:53:27.960144 97780 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:53:27.961231 97780 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 2],"float64"), Tensor([715827883, 3, 2],"float16"), )
[torch error] paddle.fmax(Tensor([4, 3, 2],"float64"), Tensor([715827883, 3, 2],"float16"), ) 
 The size of tensor a (4) must match the size of tensor b (715827883) at non-singleton dimension 0

W0212 07:54:57.802995 97808 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:54:57.804229 97808 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 2],"float64"), Tensor([715827883, 3, 2],"float32"), )
[torch error] paddle.fmax(Tensor([4, 3, 2],"float64"), Tensor([715827883, 3, 2],"float32"), ) 
 The size of tensor a (4) must match the size of tensor b (715827883) at non-singleton dimension 0

W0212 07:56:14.125388 97836 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:56:14.126592 97836 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 178956971],"float64"), )
[torch error] paddle.fmax(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 178956971],"float64"), ) 
 The size of tensor a (357913942) must match the size of tensor b (178956971) at non-singleton dimension 2

W0212 07:58:31.173326 97851 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:58:31.174659 97851 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.fmax(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 2],"float32"), ) 
 The size of tensor a (357913942) must match the size of tensor b (2) at non-singleton dimension 2

W0212 07:59:55.623154 97879 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 07:59:55.624321 97879 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.fmax(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 2],"float64"), ) 
 The size of tensor a (357913942) must match the size of tensor b (2) at non-singleton dimension 2

W0212 08:01:18.540048 97893 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:01:18.541143 97893 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 357913942],"float32"), )
[paddle error] paddle.fmax(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 357913942],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000000GB memory on GPU 0, 74.580994GB memory has been allocated and available memory is only 4.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 08:04:00.514714 97920 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:04:00.515658 97920 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 178956971],"float64"), )
[torch error] paddle.fmax(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 178956971],"float64"), ) 
 The size of tensor a (357913942) must match the size of tensor b (178956971) at non-singleton dimension 2

W0212 08:05:50.254117 97949 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:05:50.255556 97949 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.fmax(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 2],"float16"), ) 
 The size of tensor a (357913942) must match the size of tensor b (2) at non-singleton dimension 2

W0212 08:07:00.608232 97990 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:07:00.609309 97990 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.fmax(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 2],"float64"), ) 
 The size of tensor a (357913942) must match the size of tensor b (2) at non-singleton dimension 2

W0212 08:08:10.138062 98005 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:08:10.139179 98005 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 357913942],"float16"), )
[paddle error] paddle.fmax(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 357913942],"float16"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 74.580994GB memory has been allocated and available memory is only 4.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 08:10:57.679358 98019 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:10:57.680325 98019 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 536870912, 2],"float16"), Tensor([4, 268435457, 2],"float64"), )
[torch error] paddle.fmax(Tensor([4, 536870912, 2],"float16"), Tensor([4, 268435457, 2],"float64"), ) 
 The size of tensor a (536870912) must match the size of tensor b (268435457) at non-singleton dimension 1

W0212 08:13:01.054113 98060 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:13:01.055259 98060 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 536870912, 2],"float16"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.fmax(Tensor([4, 536870912, 2],"float16"), Tensor([4, 3, 2],"float32"), ) 
 The size of tensor a (536870912) must match the size of tensor b (3) at non-singleton dimension 1

W0212 08:14:26.531709 98089 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:14:26.532958 98089 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 536870912, 2],"float16"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.fmax(Tensor([4, 536870912, 2],"float16"), Tensor([4, 3, 2],"float64"), ) 
 The size of tensor a (536870912) must match the size of tensor b (3) at non-singleton dimension 1

W0212 08:15:54.532251 98116 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:15:54.533370 98116 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 536870912, 2],"float16"), Tensor([4, 536870912, 2],"float32"), )
[paddle error] paddle.fmax(Tensor([4, 536870912, 2],"float16"), Tensor([4, 536870912, 2],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000000GB memory on GPU 0, 74.575134GB memory has been allocated and available memory is only 4.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 08:18:30.971097 98144 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:18:30.972889 98144 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 536870912, 2],"float32"), Tensor([4, 268435457, 2],"float64"), )
[torch error] paddle.fmax(Tensor([4, 536870912, 2],"float32"), Tensor([4, 268435457, 2],"float64"), ) 
 The size of tensor a (536870912) must match the size of tensor b (268435457) at non-singleton dimension 1

W0212 08:20:32.129490 98159 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:20:32.130685 98159 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 536870912, 2],"float32"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.fmax(Tensor([4, 536870912, 2],"float32"), Tensor([4, 3, 2],"float16"), ) 
 The size of tensor a (536870912) must match the size of tensor b (3) at non-singleton dimension 1

W0212 08:21:50.798271 98200 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:21:50.799265 98200 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 536870912, 2],"float32"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.fmax(Tensor([4, 536870912, 2],"float32"), Tensor([4, 3, 2],"float64"), ) 
 The size of tensor a (536870912) must match the size of tensor b (3) at non-singleton dimension 1

W0212 08:23:04.040175 98228 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:23:04.041409 98228 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([4, 536870912, 2],"float32"), Tensor([4, 536870912, 2],"float16"), )
[paddle error] paddle.fmax(Tensor([4, 536870912, 2],"float32"), Tensor([4, 536870912, 2],"float16"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 74.575134GB memory has been allocated and available memory is only 4.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 08:26:00.144236 98269 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:26:00.146420 98269 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([536871, 200, 40],"float32"), Tensor([30, 200, 40],"float32"), )
[torch error] paddle.fmax(Tensor([536871, 200, 40],"float32"), Tensor([30, 200, 40],"float32"), ) 
 The size of tensor a (536871) must match the size of tensor b (30) at non-singleton dimension 0

W0212 08:27:08.855545 98312 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:27:08.856853 98312 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([536871, 200, 40],"float32"), Tensor([536871, 200, 40],"float32"), )
[torch error] paddle.fmax(Tensor([536871, 200, 40],"float32"), Tensor([536871, 200, 40],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 146024 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 08:29:15.778992 98327 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:29:15.780068 98327 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([715827883, 3, 2],"float16"), Tensor([357913942, 3, 2],"float64"), )
[torch error] paddle.fmax(Tensor([715827883, 3, 2],"float16"), Tensor([357913942, 3, 2],"float64"), ) 
 The size of tensor a (715827883) must match the size of tensor b (357913942) at non-singleton dimension 0

W0212 08:31:26.094489 98341 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:31:26.095849 98341 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([715827883, 3, 2],"float16"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.fmax(Tensor([715827883, 3, 2],"float16"), Tensor([4, 3, 2],"float32"), ) 
 The size of tensor a (715827883) must match the size of tensor b (4) at non-singleton dimension 0

W0212 08:32:56.594504 98383 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:32:56.598500 98383 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([715827883, 3, 2],"float16"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.fmax(Tensor([715827883, 3, 2],"float16"), Tensor([4, 3, 2],"float64"), ) 
 The size of tensor a (715827883) must match the size of tensor b (4) at non-singleton dimension 0

W0212 08:34:21.614758 98438 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:34:21.616159 98438 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([715827883, 3, 2],"float16"), Tensor([715827883, 3, 2],"float32"), )
[paddle error] paddle.fmax(Tensor([715827883, 3, 2],"float16"), Tensor([715827883, 3, 2],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000000GB memory on GPU 0, 74.580994GB memory has been allocated and available memory is only 4.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 08:37:05.667837 98453 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:37:05.668722 98453 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([715827883, 3, 2],"float32"), Tensor([357913942, 3, 2],"float64"), )
[torch error] paddle.fmax(Tensor([715827883, 3, 2],"float32"), Tensor([357913942, 3, 2],"float64"), ) 
 The size of tensor a (715827883) must match the size of tensor b (357913942) at non-singleton dimension 0

W0212 08:38:50.029294 98494 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:38:50.030277 98494 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([715827883, 3, 2],"float32"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.fmax(Tensor([715827883, 3, 2],"float32"), Tensor([4, 3, 2],"float16"), ) 
 The size of tensor a (715827883) must match the size of tensor b (4) at non-singleton dimension 0

W0212 08:40:09.601972 98536 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:40:09.603085 98536 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([715827883, 3, 2],"float32"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.fmax(Tensor([715827883, 3, 2],"float32"), Tensor([4, 3, 2],"float64"), ) 
 The size of tensor a (715827883) must match the size of tensor b (4) at non-singleton dimension 0

W0212 08:41:25.397874 98578 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:41:25.399017 98578 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmax(Tensor([715827883, 3, 2],"float32"), Tensor([715827883, 3, 2],"float16"), )
[paddle error] paddle.fmax(Tensor([715827883, 3, 2],"float32"), Tensor([715827883, 3, 2],"float16"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 74.580994GB memory has been allocated and available memory is only 4.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 08:44:11.621368 98606 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:44:11.622270 98606 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([1],"int64"), Tensor([2147483649],"int64"), )
[paddle error] paddle.fmin(Tensor([1],"int64"), Tensor([2147483649],"int64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 08:45:07.321385 98648 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:45:07.322350 98648 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([10, 15],"float32"), Tensor([10, 429496730],"float32"), )
[torch error] paddle.fmin(Tensor([10, 15],"float32"), Tensor([10, 429496730],"float32"), ) 
 The size of tensor a (15) must match the size of tensor b (429496730) at non-singleton dimension 1

W0212 08:46:20.670667 98689 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:46:20.671969 98689 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([10, 15],"float32"), Tensor([286331153, 15],"float32"), )
[torch error] paddle.fmin(Tensor([10, 15],"float32"), Tensor([286331153, 15],"float32"), ) 
 The size of tensor a (10) must match the size of tensor b (286331153) at non-singleton dimension 0

W0212 08:47:32.847116 98718 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:47:32.848415 98718 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([10, 15],"float32"), Tensor([4294967295],"float32"), )
[torch error] paddle.fmin(Tensor([10, 15],"float32"), Tensor([4294967295],"float32"), ) 
 The size of tensor a (15) must match the size of tensor b (4294967295) at non-singleton dimension 1

W0212 08:48:48.601316 98746 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 08:48:48.602456 98746 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

Traceback (most recent call last):
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 70, in <module>
    main()
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 65, in main
    print(str(res.stdout.read(), encoding="utf-8"), flush=True)
KeyboardInterrupt
