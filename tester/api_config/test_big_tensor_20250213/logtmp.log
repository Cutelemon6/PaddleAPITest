test begin: paddle.all(Tensor([12, 357913942],"bool"), axis=-1, )
[paddle error] paddle.all(Tensor([12, 357913942],"bool"), axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 77.389587GB memory has been allocated and available memory is only 1.795288GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:04:14.615180 89580 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:04:14.616065 89580 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.all(Tensor([12, 357913942],"bool"), axis=1, keepdim=True, )
[paddle error] paddle.all(Tensor([12, 357913942],"bool"), axis=1, keepdim=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 77.389587GB memory has been allocated and available memory is only 1.795288GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:05:28.133352 89968 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:05:28.134218 89968 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.all(Tensor([429496730, 10],"bool"), axis=0, )
[paddle error] paddle.all(Tensor([429496730, 10],"bool"), axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 77.389587GB memory has been allocated and available memory is only 1.795288GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:06:44.002887 90166 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:06:44.003809 90166 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.amax(Tensor([10, 10, 42949673],"float32"), axis=list[-1,-2,], keepdim=False, )
[torch error] paddle.amax(Tensor([10, 10, 42949673],"float32"), axis=list[-1,-2,], keepdim=False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 128181 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:07:52.923506 90463 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:07:52.924525 90463 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.amax(Tensor([10, 42949673, 10],"float32"), axis=list[0,1,], keepdim=False, )
[torch error] paddle.amax(Tensor([10, 42949673, 10],"float32"), axis=list[0,1,], keepdim=False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 6721 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:08:59.191082 90669 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:08:59.192178 90669 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.amax(Tensor([10, 42949673, 10],"float32"), axis=list[-1,-2,], keepdim=False, )
[torch error] paddle.amax(Tensor([10, 42949673, 10],"float32"), axis=list[-1,-2,], keepdim=False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 49125 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:10:06.948169 90872 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:10:06.949563 90872 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.amax(Tensor([42949673, 10, 10],"float32"), axis=list[0,1,], keepdim=False, )
[torch error] paddle.amax(Tensor([42949673, 10, 10],"float32"), axis=list[0,1,], keepdim=False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 89370 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:11:19.973284 91157 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:11:19.974512 91157 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.amax(Tensor([536870913, 4],"float64"), 0, False, )
[torch error] paddle.amax(Tensor([536870913, 4],"float64"), 0, False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 145021 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:12:08.966035 91363 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:12:08.967087 91363 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.amin(Tensor([10, 10, 42949673],"float32"), axis=list[-1,-2,], keepdim=False, )
[torch error] paddle.amin(Tensor([10, 10, 42949673],"float32"), axis=list[-1,-2,], keepdim=False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 15267 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:13:22.592417 91553 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:13:22.593398 91553 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.amin(Tensor([10, 42949673, 10],"float32"), axis=list[0,1,], keepdim=False, )
[torch error] paddle.amin(Tensor([10, 42949673, 10],"float32"), axis=list[0,1,], keepdim=False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 60133 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:14:28.333806 91758 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:14:28.335011 91758 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.amin(Tensor([10, 42949673, 10],"float32"), axis=list[-1,-2,], keepdim=False, )
[torch error] paddle.amin(Tensor([10, 42949673, 10],"float32"), axis=list[-1,-2,], keepdim=False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 101429 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:15:34.618882 91975 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:15:34.619988 91975 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.amin(Tensor([42949673, 10, 10],"float32"), axis=list[0,1,], keepdim=False, )
[torch error] paddle.amin(Tensor([42949673, 10, 10],"float32"), axis=list[0,1,], keepdim=False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 146867 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:16:48.235926 92232 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:16:48.236953 92232 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.amin(Tensor([536870913, 4],"float64"), 0, False, )
[torch error] paddle.amin(Tensor([536870913, 4],"float64"), 0, False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 45666 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:17:33.400920 92432 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:17:33.402417 92432 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.any(Tensor([12, 357913942],"bool"), axis=-1, )
[paddle error] paddle.any(Tensor([12, 357913942],"bool"), axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 77.389587GB memory has been allocated and available memory is only 1.795288GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:18:49.255764 92677 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:18:49.256775 92677 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.any(Tensor([12, 357913942],"bool"), axis=1, keepdim=True, )
[paddle error] paddle.any(Tensor([12, 357913942],"bool"), axis=1, keepdim=True, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 77.389587GB memory has been allocated and available memory is only 1.795288GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:20:04.893606 92908 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:20:04.894449 92908 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.any(Tensor([429496730, 10],"bool"), axis=0, )
[paddle error] paddle.any(Tensor([429496730, 10],"bool"), axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 77.389587GB memory has been allocated and available memory is only 1.795288GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:21:23.332140 93132 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:21:23.333132 93132 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bernoulli(Tensor([1024, 4194304],"float32"), )
[torch error] paddle.bernoulli(Tensor([1024, 4194304],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 62910 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:22:27.299909 93426 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:22:27.300930 93426 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bernoulli(Tensor([1024, 4194304],"float32"), p=0.3917133774091194, )
[torch error] paddle.bernoulli(Tensor([1024, 4194304],"float32"), p=0.3917133774091194, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 104377 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:23:33.868593 93633 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:23:33.869566 93633 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bernoulli(Tensor([2049, 1024, 1024],"float64"), )
[torch error] paddle.bernoulli(Tensor([2049, 1024, 1024],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.01 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 146796 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:24:23.829416 93922 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:24:23.830569 93922 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bernoulli(Tensor([32, 1024, 131072],"float32"), )
[torch error] paddle.bernoulli(Tensor([32, 1024, 131072],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 19377 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:25:37.329555 94036 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:25:37.330602 94036 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bernoulli(Tensor([32, 1024, 65537],"float64"), )
[torch error] paddle.bernoulli(Tensor([32, 1024, 65537],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 67105 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:26:32.228241 94315 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:26:32.229350 94315 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bernoulli(Tensor([32, 131072, 1024],"float32"), )
[torch error] paddle.bernoulli(Tensor([32, 131072, 1024],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 105508 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:27:46.376449 94455 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:27:46.377446 94455 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bernoulli(Tensor([32, 65537, 1024],"float64"), )
[torch error] paddle.bernoulli(Tensor([32, 65537, 1024],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 4060 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:28:36.319845 94754 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:28:36.320905 94754 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bernoulli(Tensor([4096, 1024, 1024],"float32"), )
[torch error] paddle.bernoulli(Tensor([4096, 1024, 1024],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 29515 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:29:49.134831 94942 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:29:49.135952 94942 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bernoulli(Tensor([4194304, 1024],"float32"), )
[torch error] paddle.bernoulli(Tensor([4194304, 1024],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 85319 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:31:01.943400 95181 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:31:01.944459 95181 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bernoulli(Tensor([4194304, 1024],"float32"), p=0.3917133774091194, )
[torch error] paddle.bernoulli(Tensor([4194304, 1024],"float32"), p=0.3917133774091194, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 127067 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:32:15.949471 95444 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:32:15.950444 95444 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bincount(Tensor([16],"int32"), weights=Tensor([4294967295],"float32"), )
[torch error] paddle.bincount(Tensor([16],"int32"), weights=Tensor([4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 16442 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:33:21.949076 95721 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:33:21.950160 95721 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bincount(Tensor([20],"int64"), minlength=Tensor([4294967295],"int32"), )
[torch error] paddle.bincount(Tensor([20],"int64"), minlength=Tensor([4294967295],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 57136 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:34:32.680668 95934 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:34:32.681777 95934 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bincount(Tensor([2147483649],"int64"), )
[torch error] paddle.bincount(Tensor([2147483649],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 99165 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:35:18.693821 96236 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:35:18.694801 96236 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bincount(Tensor([2147483649],"int64"), minlength=Tensor([1],"int32"), )
[torch error] paddle.bincount(Tensor([2147483649],"int64"), minlength=Tensor([1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 139550 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:36:06.851756 96350 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:36:06.852744 96350 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bincount(Tensor([2147483649],"int64"), minlength=Tensor([4294967295],"int32"), )
[torch error] paddle.bincount(Tensor([2147483649],"int64"), minlength=Tensor([4294967295],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 6818 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:36:53.775255 96559 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:36:53.776374 96559 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bincount(Tensor([4294967295],"int32"), weights=Tensor([16],"float32"), )
[torch error] paddle.bincount(Tensor([4294967295],"int32"), weights=Tensor([16],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 47525 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:38:01.859735 96672 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:38:01.860826 96672 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bincount(Tensor([4294967295],"int32"), weights=Tensor([4294967295],"float32"), )
[torch error] paddle.bincount(Tensor([4294967295],"int32"), weights=Tensor([4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 87367 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:39:16.004297 96880 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:39:16.005300 96880 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_and(Tensor([1073741824, 4, 1],"int32"), Tensor([1073741824, 4, 1],"int32"), )
[torch error] paddle.bitwise_and(Tensor([1073741824, 4, 1],"int32"), Tensor([1073741824, 4, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 143748 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:40:22.679899 97170 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:40:22.681305 97170 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_and(Tensor([1073741824, 4, 1],"int32"), Tensor([3, 4, 1],"int32"), )
[torch error] paddle.bitwise_and(Tensor([1073741824, 4, 1],"int32"), Tensor([3, 4, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 20573 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:41:35.544356 97389 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:41:35.545612 97389 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_and(Tensor([2, 3, 5],"int32"), Tensor([2, 3, 715827883],"int32"), )
[torch error] paddle.bitwise_and(Tensor([2, 3, 5],"int32"), Tensor([2, 3, 715827883],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 65678 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:42:41.503871 97680 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:42:41.504979 97680 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_and(Tensor([2, 3, 5],"int32"), Tensor([2, 429496730, 5],"int32"), )
[torch error] paddle.bitwise_and(Tensor([2, 3, 5],"int32"), Tensor([2, 429496730, 5],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 123691 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:43:53.598414 97889 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:43:53.599416 97889 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_and(Tensor([2, 3, 5],"int32"), Tensor([286331153, 3, 5],"int32"), )
[torch error] paddle.bitwise_and(Tensor([2, 3, 5],"int32"), Tensor([286331153, 3, 5],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 1411 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:45:04.746796 98097 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:45:04.747913 98097 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_and(Tensor([2, 3, 715827883],"int32"), Tensor([2, 3, 5],"int32"), )
[torch error] paddle.bitwise_and(Tensor([2, 3, 715827883],"int32"), Tensor([2, 3, 5],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 42436 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:46:12.647930 98374 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:46:12.679338 98374 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_and(Tensor([2, 3, 715827883],"int32"), Tensor([2, 3, 715827883],"int32"), )
[torch error] paddle.bitwise_and(Tensor([2, 3, 715827883],"int32"), Tensor([2, 3, 715827883],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 99734 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:47:24.997028 98583 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:47:24.998131 98583 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_and(Tensor([2, 429496730, 5],"int32"), Tensor([2, 3, 5],"int32"), )
[torch error] paddle.bitwise_and(Tensor([2, 429496730, 5],"int32"), Tensor([2, 3, 5],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 142249 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:48:33.287103 98806 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:48:33.288208 98806 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_and(Tensor([2, 429496730, 5],"int32"), Tensor([2, 429496730, 5],"int32"), )
[torch error] paddle.bitwise_and(Tensor([2, 429496730, 5],"int32"), Tensor([2, 429496730, 5],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 20462 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:49:42.138151 99107 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:49:42.139508 99107 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_and(Tensor([286331153, 3, 5],"int32"), Tensor([2, 3, 5],"int32"), )
[torch error] paddle.bitwise_and(Tensor([286331153, 3, 5],"int32"), Tensor([2, 3, 5],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 80220 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:50:49.063113 99305 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:50:49.064270 99305 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_and(Tensor([286331153, 3, 5],"int32"), Tensor([286331153, 3, 5],"int32"), )
[torch error] paddle.bitwise_and(Tensor([286331153, 3, 5],"int32"), Tensor([286331153, 3, 5],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 123281 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:51:56.590646 99515 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:51:56.592029 99515 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_and(Tensor([3, 1431655765, 1],"int32"), Tensor([3, 1431655765, 1],"int32"), )
[torch error] paddle.bitwise_and(Tensor([3, 1431655765, 1],"int32"), Tensor([3, 1431655765, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 4485 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:53:11.123239 99723 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:53:11.132014 99723 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_and(Tensor([3, 1431655765, 1],"int32"), Tensor([3, 4, 1],"int32"), )
[torch error] paddle.bitwise_and(Tensor([3, 1431655765, 1],"int32"), Tensor([3, 4, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 56488 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:54:22.904650 100041 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:54:22.905665 100041 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_and(Tensor([3, 4, 1],"int32"), Tensor([1073741824, 4, 1],"int32"), )
[torch error] paddle.bitwise_and(Tensor([3, 4, 1],"int32"), Tensor([1073741824, 4, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 98155 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:55:34.388290 100251 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:55:34.389288 100251 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_and(Tensor([3, 4, 1],"int32"), Tensor([3, 1431655765, 1],"int32"), )
[torch error] paddle.bitwise_and(Tensor([3, 4, 1],"int32"), Tensor([3, 1431655765, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 144692 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:56:47.455904 100541 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:56:47.456894 100541 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_and(Tensor([3, 4, 1],"int32"), Tensor([3, 4, 357913942],"int32"), )
[torch error] paddle.bitwise_and(Tensor([3, 4, 1],"int32"), Tensor([3, 4, 357913942],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 43013 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:57:54.927412 100764 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:57:54.928418 100764 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_and(Tensor([3, 4, 357913942],"int32"), Tensor([3, 4, 1],"int32"), )
[torch error] paddle.bitwise_and(Tensor([3, 4, 357913942],"int32"), Tensor([3, 4, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 84369 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:59:06.864488 100974 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:59:06.865711 100974 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_and(Tensor([3, 4, 357913942],"int32"), Tensor([3, 4, 357913942],"int32"), )
[torch error] paddle.bitwise_and(Tensor([3, 4, 357913942],"int32"), Tensor([3, 4, 357913942],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 128012 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:00:15.357465 101259 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:00:15.358608 101259 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([1],"int16"), Tensor([4294967295],"int16"), )
[torch error] paddle.bitwise_left_shift(Tensor([1],"int16"), Tensor([4294967295],"int16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 16393 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:01:23.883872 101468 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:01:23.884860 101468 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([1],"int16"), Tensor([4294967295],"int16"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([1],"int16"), Tensor([4294967295],"int16"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:01:32.220978 101687 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:01:32.221985 101687 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([1],"uint8"), Tensor([4294967295],"uint8"), )
[torch error] paddle.bitwise_left_shift(Tensor([1],"uint8"), Tensor([4294967295],"uint8"), ) 
 CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 57761 has 4.99 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:02:33.583532 101701 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:02:33.584513 101701 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([1],"uint8"), Tensor([4294967295],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([1],"uint8"), Tensor([4294967295],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:02:40.829244 102047 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:02:40.830271 102047 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([14316558, 300],"int16"), Tensor([14316558, 300],"int16"), )
[torch error] paddle.bitwise_left_shift(Tensor([14316558, 300],"int16"), Tensor([14316558, 300],"int16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 116750 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:03:50.639659 102062 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:03:50.640812 102062 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([14316558, 300],"int16"), Tensor([14316558, 300],"int16"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([14316558, 300],"int16"), Tensor([14316558, 300],"int16"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:03:58.101637 102350 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:03:58.102663 102350 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([14316558, 300],"int16"), Tensor([200, 300],"int16"), )
[torch error] paddle.bitwise_left_shift(Tensor([14316558, 300],"int16"), Tensor([200, 300],"int16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 160226 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:05:05.274451 102378 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:05:05.275470 102378 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([14316558, 300],"int16"), Tensor([200, 300],"int16"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([14316558, 300],"int16"), Tensor([200, 300],"int16"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:05:12.549654 102780 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:05:12.550594 102780 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([14316558, 300],"int16"), Tensor([300],"int16"), )
[torch error] paddle.bitwise_left_shift(Tensor([14316558, 300],"int16"), Tensor([300],"int16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 50063 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:06:17.907054 102810 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:06:17.908190 102810 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([14316558, 300],"int16"), Tensor([300],"int16"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([14316558, 300],"int16"), Tensor([300],"int16"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:06:24.953751 103076 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:06:24.954839 103076 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([14316558, 300],"int32"), Tensor([14316558, 300],"int32"), )
[torch error] paddle.bitwise_left_shift(Tensor([14316558, 300],"int32"), Tensor([14316558, 300],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 99505 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:07:34.984870 103095 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:07:34.985863 103095 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([14316558, 300],"int32"), Tensor([14316558, 300],"int32"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([14316558, 300],"int32"), Tensor([14316558, 300],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:07:42.120695 103515 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:07:42.121699 103515 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([14316558, 300],"int32"), Tensor([200, 300],"int32"), )
[torch error] paddle.bitwise_left_shift(Tensor([14316558, 300],"int32"), Tensor([200, 300],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 163722 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:08:54.978883 103548 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:08:54.979918 103548 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([14316558, 300],"int32"), Tensor([200, 300],"int32"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([14316558, 300],"int32"), Tensor([200, 300],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:09:02.169826 103858 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:09:02.170799 103858 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([14316558, 300],"int32"), Tensor([300],"int32"), )
[torch error] paddle.bitwise_left_shift(Tensor([14316558, 300],"int32"), Tensor([300],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 45820 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:10:10.608274 103888 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:10:10.609254 103888 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([14316558, 300],"int32"), Tensor([300],"int32"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([14316558, 300],"int32"), Tensor([300],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:10:17.811882 104261 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:10:17.812826 104261 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([14316558, 300],"int8"), Tensor([14316558, 300],"int8"), )
[torch error] paddle.bitwise_left_shift(Tensor([14316558, 300],"int8"), Tensor([14316558, 300],"int8"), ) 
 CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 99920 has 4.99 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:12:17.559440 104276 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:12:17.560542 104276 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([14316558, 300],"int8"), Tensor([14316558, 300],"int8"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([14316558, 300],"int8"), Tensor([14316558, 300],"int8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:12:25.239353 104682 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:12:25.240453 104682 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([14316558, 300],"int8"), Tensor([200, 300],"int8"), )
[torch error] paddle.bitwise_left_shift(Tensor([14316558, 300],"int8"), Tensor([200, 300],"int8"), ) 
 The size of tensor a (14316558) must match the size of tensor b (200) at non-singleton dimension 0

W0205 11:13:27.968673 104710 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:13:27.969802 104710 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([14316558, 300],"int8"), Tensor([200, 300],"int8"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([14316558, 300],"int8"), Tensor([200, 300],"int8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:13:35.127475 104939 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:13:35.128439 104939 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([14316558, 300],"int8"), Tensor([300],"int8"), )
[torch error] paddle.bitwise_left_shift(Tensor([14316558, 300],"int8"), Tensor([300],"int8"), ) 
 CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 58180 has 4.99 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:14:44.154973 105037 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:14:44.155961 105037 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([14316558, 300],"int8"), Tensor([300],"int8"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([14316558, 300],"int8"), Tensor([300],"int8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:14:51.363288 105249 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:14:51.364301 105249 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([14316558, 300],"uint8"), Tensor([14316558, 300],"uint8"), )
[torch error] paddle.bitwise_left_shift(Tensor([14316558, 300],"uint8"), Tensor([14316558, 300],"uint8"), ) 
 CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 120299 has 4.99 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:16:56.044296 105263 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:16:56.045253 105263 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([14316558, 300],"uint8"), Tensor([14316558, 300],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([14316558, 300],"uint8"), Tensor([14316558, 300],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:17:03.658612 105687 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:17:03.659647 105687 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([14316558, 300],"uint8"), Tensor([200, 300],"uint8"), )
[torch error] paddle.bitwise_left_shift(Tensor([14316558, 300],"uint8"), Tensor([200, 300],"uint8"), ) 
 The size of tensor a (14316558) must match the size of tensor b (200) at non-singleton dimension 0

W0205 11:18:06.902022 105795 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:18:06.903012 105795 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([14316558, 300],"uint8"), Tensor([200, 300],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([14316558, 300],"uint8"), Tensor([200, 300],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:18:14.288918 106040 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:18:14.289940 106040 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([14316558, 300],"uint8"), Tensor([300],"uint8"), )
[torch error] paddle.bitwise_left_shift(Tensor([14316558, 300],"uint8"), Tensor([300],"uint8"), ) 
 CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 98364 has 4.99 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:19:22.819561 106054 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:19:22.820618 106054 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([14316558, 300],"uint8"), Tensor([300],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([14316558, 300],"uint8"), Tensor([300],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:19:30.088492 106282 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:19:30.089501 106282 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 10737419],"int64"), Tensor([200, 10737419],"int64"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 10737419],"int64"), Tensor([200, 10737419],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 140329 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:20:16.448698 106333 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:20:16.449781 106333 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 10737419],"int64"), Tensor([200, 10737419],"int64"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 10737419],"int64"), Tensor([200, 10737419],"int64"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:20:23.952100 106541 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:20:23.953081 106541 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 10737419],"int64"), Tensor([200, 300],"int64"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 10737419],"int64"), Tensor([200, 300],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 17095 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:21:06.406086 106555 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:21:06.407060 106555 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 10737419],"int64"), Tensor([200, 300],"int64"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 10737419],"int64"), Tensor([200, 300],"int64"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:21:13.337267 106750 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:21:13.338268 106750 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 10737419],"int64"), Tensor([300],"int64"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 10737419],"int64"), Tensor([300],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 54404 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:21:54.980525 106764 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:21:54.981628 106764 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 10737419],"int64"), Tensor([300],"int64"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 10737419],"int64"), Tensor([300],"int64"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:22:02.728688 106904 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:22:02.729732 106904 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 21474837],"int16"), Tensor([200, 21474837],"int16"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 21474837],"int16"), Tensor([200, 21474837],"int16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 80128 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:23:12.963253 106918 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:23:12.970898 106918 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 21474837],"int16"), Tensor([200, 21474837],"int16"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 21474837],"int16"), Tensor([200, 21474837],"int16"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:23:20.476528 107276 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:23:20.477537 107276 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 21474837],"int16"), Tensor([200, 300],"int16"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 21474837],"int16"), Tensor([200, 300],"int16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 139273 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:24:23.811755 107294 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:24:23.812873 107294 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 21474837],"int16"), Tensor([200, 300],"int16"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 21474837],"int16"), Tensor([200, 300],"int16"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:24:31.181893 107479 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:24:31.182905 107479 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 21474837],"int16"), Tensor([300],"int16"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 21474837],"int16"), Tensor([300],"int16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 17417 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:25:41.010975 107507 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:25:41.012117 107507 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 21474837],"int16"), Tensor([300],"int16"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 21474837],"int16"), Tensor([300],"int16"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:25:48.722977 107786 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:25:48.724084 107786 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 21474837],"int32"), Tensor([200, 21474837],"int32"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 21474837],"int32"), Tensor([200, 21474837],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 85098 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:26:57.180076 107802 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:26:57.181183 107802 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 21474837],"int32"), Tensor([200, 21474837],"int32"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 21474837],"int32"), Tensor([200, 21474837],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:27:04.519731 108023 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:27:04.520750 108023 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 21474837],"int32"), Tensor([200, 300],"int32"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 21474837],"int32"), Tensor([200, 300],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 132528 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:28:19.535905 108119 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:28:19.536891 108119 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 21474837],"int32"), Tensor([200, 300],"int32"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 21474837],"int32"), Tensor([200, 300],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:28:27.181854 108328 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:28:27.182933 108328 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 21474837],"int32"), Tensor([300],"int32"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 21474837],"int32"), Tensor([300],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28342 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:29:37.055969 108348 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:29:37.057099 108348 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 21474837],"int32"), Tensor([300],"int32"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 21474837],"int32"), Tensor([300],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:29:44.687423 108636 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:29:44.688552 108636 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 21474837],"int8"), Tensor([200, 21474837],"int8"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 21474837],"int8"), Tensor([200, 21474837],"int8"), ) 
 CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 90741 has 4.99 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:31:51.476979 108651 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:31:51.477983 108651 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 21474837],"int8"), Tensor([200, 21474837],"int8"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 21474837],"int8"), Tensor([200, 21474837],"int8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:31:59.265830 109040 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:31:59.266865 109040 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 21474837],"int8"), Tensor([200, 300],"int8"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 21474837],"int8"), Tensor([200, 300],"int8"), ) 
 The size of tensor a (21474837) must match the size of tensor b (300) at non-singleton dimension 1

W0205 11:33:09.203446 109067 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:33:09.204239 109067 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 21474837],"int8"), Tensor([200, 300],"int8"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 21474837],"int8"), Tensor([200, 300],"int8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:33:16.992168 109367 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:33:16.993183 109367 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 21474837],"int8"), Tensor([300],"int8"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 21474837],"int8"), Tensor([300],"int8"), ) 
 The size of tensor a (21474837) must match the size of tensor b (300) at non-singleton dimension 1

W0205 11:34:18.475328 109385 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:34:18.481720 109385 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 21474837],"int8"), Tensor([300],"int8"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 21474837],"int8"), Tensor([300],"int8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:34:26.036149 109581 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:34:26.037127 109581 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 21474837],"uint8"), Tensor([200, 21474837],"uint8"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 21474837],"uint8"), Tensor([200, 21474837],"uint8"), ) 
 CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 115576 has 4.99 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:36:18.892797 109596 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:36:18.893919 109596 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 21474837],"uint8"), Tensor([200, 21474837],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 21474837],"uint8"), Tensor([200, 21474837],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:36:26.561259 109982 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:36:26.562285 109982 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 21474837],"uint8"), Tensor([200, 300],"uint8"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 21474837],"uint8"), Tensor([200, 300],"uint8"), ) 
 The size of tensor a (21474837) must match the size of tensor b (300) at non-singleton dimension 1

W0205 11:37:29.674705 109997 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:37:29.675742 109997 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 21474837],"uint8"), Tensor([200, 300],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 21474837],"uint8"), Tensor([200, 300],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:37:37.654345 110205 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:37:37.655385 110205 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 21474837],"uint8"), Tensor([300],"uint8"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 21474837],"uint8"), Tensor([300],"uint8"), ) 
 The size of tensor a (21474837) must match the size of tensor b (300) at non-singleton dimension 1

W0205 11:38:47.614759 110300 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:38:47.616040 110300 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 21474837],"uint8"), Tensor([300],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 21474837],"uint8"), Tensor([300],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:38:55.394272 110496 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:38:55.395283 110496 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"int16"), Tensor([14316558, 300],"int16"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 300],"int16"), Tensor([14316558, 300],"int16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 68281 has 1016.00 MiB memory in use. Of the allocated memory 117.50 KiB is allocated by PyTorch, and 1.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:40:02.008302 110511 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:40:02.009374 110511 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"int16"), Tensor([14316558, 300],"int16"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 300],"int16"), Tensor([14316558, 300],"int16"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:40:10.503768 110750 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:40:10.504839 110750 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"int16"), Tensor([200, 21474837],"int16"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 300],"int16"), Tensor([200, 21474837],"int16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 129784 has 1016.00 MiB memory in use. Of the allocated memory 117.50 KiB is allocated by PyTorch, and 1.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:41:18.874445 110804 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:41:18.875551 110804 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"int16"), Tensor([200, 21474837],"int16"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 300],"int16"), Tensor([200, 21474837],"int16"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:41:27.306385 111001 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:41:27.307355 111001 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"int16"), Tensor([4294967295],"int16"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 300],"int16"), Tensor([4294967295],"int16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 13644 has 1016.00 MiB memory in use. Of the allocated memory 117.50 KiB is allocated by PyTorch, and 1.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:42:30.231274 111029 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:42:30.232322 111029 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"int16"), Tensor([4294967295],"int16"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 300],"int16"), Tensor([4294967295],"int16"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:42:38.349027 111210 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:42:38.350088 111210 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"int32"), Tensor([14316558, 300],"int32"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 300],"int32"), Tensor([14316558, 300],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 60438 has 1016.00 MiB memory in use. Of the allocated memory 234.50 KiB is allocated by PyTorch, and 1.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:43:50.048255 111305 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:43:50.049310 111305 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"int32"), Tensor([14316558, 300],"int32"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 300],"int32"), Tensor([14316558, 300],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:43:59.318066 111513 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:43:59.319139 111513 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"int32"), Tensor([200, 21474837],"int32"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 300],"int32"), Tensor([200, 21474837],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 125781 has 1016.00 MiB memory in use. Of the allocated memory 234.50 KiB is allocated by PyTorch, and 1.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:45:11.365062 111528 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:45:11.366040 111528 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"int32"), Tensor([200, 21474837],"int32"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 300],"int32"), Tensor([200, 21474837],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:45:20.361999 111817 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:45:20.363013 111817 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"int32"), Tensor([4294967295],"int32"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 300],"int32"), Tensor([4294967295],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 20393 has 1016.00 MiB memory in use. Of the allocated memory 234.50 KiB is allocated by PyTorch, and 1.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:46:31.837004 111832 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:46:31.837980 111832 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"int32"), Tensor([4294967295],"int32"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 300],"int32"), Tensor([4294967295],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:46:40.668210 112124 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:46:40.669314 112124 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"int64"), Tensor([200, 10737419],"int64"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 300],"int64"), Tensor([200, 10737419],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 88889 has 1016.00 MiB memory in use. Of the allocated memory 469.00 KiB is allocated by PyTorch, and 1.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:47:23.898495 112139 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:47:23.899801 112139 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"int64"), Tensor([200, 10737419],"int64"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 300],"int64"), Tensor([200, 10737419],"int64"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:47:33.378988 112251 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:47:33.380015 112251 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"int64"), Tensor([2147483649],"int64"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 300],"int64"), Tensor([2147483649],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 116307 has 1016.00 MiB memory in use. Of the allocated memory 469.00 KiB is allocated by PyTorch, and 1.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:48:15.537139 112345 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:48:15.538530 112345 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"int64"), Tensor([2147483649],"int64"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 300],"int64"), Tensor([2147483649],"int64"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:48:25.273258 112460 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:48:25.274334 112460 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"int64"), Tensor([7158279, 300],"int64"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 300],"int64"), Tensor([7158279, 300],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 158960 has 1016.00 MiB memory in use. Of the allocated memory 469.00 KiB is allocated by PyTorch, and 1.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:49:08.540076 112475 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:49:08.541004 112475 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"int64"), Tensor([7158279, 300],"int64"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 300],"int64"), Tensor([7158279, 300],"int64"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:49:18.339924 112672 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:49:18.341013 112672 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"int8"), Tensor([14316558, 300],"int8"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 300],"int8"), Tensor([14316558, 300],"int8"), ) 
 The size of tensor a (200) must match the size of tensor b (14316558) at non-singleton dimension 0

W0205 11:50:26.108529 112695 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:50:26.109746 112695 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"int8"), Tensor([14316558, 300],"int8"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 300],"int8"), Tensor([14316558, 300],"int8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:50:34.124199 112887 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:50:34.125311 112887 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"int8"), Tensor([200, 21474837],"int8"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 300],"int8"), Tensor([200, 21474837],"int8"), ) 
 The size of tensor a (300) must match the size of tensor b (21474837) at non-singleton dimension 1

W0205 11:51:41.547828 112987 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:51:41.549005 112987 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"int8"), Tensor([200, 21474837],"int8"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 300],"int8"), Tensor([200, 21474837],"int8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:51:49.678851 113197 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:51:49.679992 113197 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"int8"), Tensor([4294967295],"int8"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 300],"int8"), Tensor([4294967295],"int8"), ) 
 The size of tensor a (300) must match the size of tensor b (4294967295) at non-singleton dimension 1

W0205 11:52:51.766991 113225 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:52:51.768033 113225 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"int8"), Tensor([4294967295],"int8"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 300],"int8"), Tensor([4294967295],"int8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:52:59.841068 113420 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:52:59.842124 113420 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"uint8"), Tensor([14316558, 300],"uint8"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 300],"uint8"), Tensor([14316558, 300],"uint8"), ) 
 The size of tensor a (200) must match the size of tensor b (14316558) at non-singleton dimension 0

W0205 11:54:03.189749 113435 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:54:03.190834 113435 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"uint8"), Tensor([14316558, 300],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 300],"uint8"), Tensor([14316558, 300],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:54:11.576081 113737 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:54:11.577111 113737 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"uint8"), Tensor([200, 21474837],"uint8"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 300],"uint8"), Tensor([200, 21474837],"uint8"), ) 
 The size of tensor a (300) must match the size of tensor b (21474837) at non-singleton dimension 1

W0205 11:55:20.592231 113753 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:55:20.593449 113753 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"uint8"), Tensor([200, 21474837],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 300],"uint8"), Tensor([200, 21474837],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:55:28.986440 113950 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:55:28.987545 113950 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"uint8"), Tensor([4294967295],"uint8"), )
[torch error] paddle.bitwise_left_shift(Tensor([200, 300],"uint8"), Tensor([4294967295],"uint8"), ) 
 The size of tensor a (300) must match the size of tensor b (4294967295) at non-singleton dimension 1

W0205 11:56:32.159240 113965 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:56:32.160425 113965 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([200, 300],"uint8"), Tensor([4294967295],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([200, 300],"uint8"), Tensor([4294967295],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:56:40.330271 114172 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:56:40.331665 114172 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([2147483649],"int64"), Tensor([200, 300],"int64"), )
[torch error] paddle.bitwise_left_shift(Tensor([2147483649],"int64"), Tensor([200, 300],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 34335 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:57:23.437541 114280 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:57:23.438700 114280 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([2147483649],"int64"), Tensor([200, 300],"int64"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([2147483649],"int64"), Tensor([200, 300],"int64"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:57:31.254252 114379 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:57:31.255256 114379 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([214748365, 4, 5],"int32"), Tensor([214748365, 4, 5],"int32"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([214748365, 4, 5],"int32"), Tensor([214748365, 4, 5],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:57:38.392094 114409 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:57:38.393137 114409 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([214748365, 4, 5],"int32"), Tensor([214748365, 4, 5],"int32"), True, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([214748365, 4, 5],"int32"), Tensor([214748365, 4, 5],"int32"), True, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:57:45.911664 114504 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:57:45.912726 114504 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([214748365, 4, 5],"int32"), Tensor([3, 4, 5],"int32"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([214748365, 4, 5],"int32"), Tensor([3, 4, 5],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:57:53.441231 114519 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:57:53.442322 114519 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([214748365, 4, 5],"int32"), Tensor([3, 4, 5],"int32"), True, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([214748365, 4, 5],"int32"), Tensor([3, 4, 5],"int32"), True, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:58:01.369628 114546 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:58:01.370630 114546 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([3, 286331153, 5],"int32"), Tensor([3, 286331153, 5],"int32"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([3, 286331153, 5],"int32"), Tensor([3, 286331153, 5],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:58:08.854382 114561 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:58:08.855370 114561 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([3, 286331153, 5],"int32"), Tensor([3, 286331153, 5],"int32"), True, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([3, 286331153, 5],"int32"), Tensor([3, 286331153, 5],"int32"), True, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:58:16.777663 114656 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:58:16.778635 114656 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([3, 286331153, 5],"int32"), Tensor([3, 4, 5],"int32"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([3, 286331153, 5],"int32"), Tensor([3, 4, 5],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:58:24.165781 114671 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:58:24.166759 114671 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([3, 286331153, 5],"int32"), Tensor([3, 4, 5],"int32"), True, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([3, 286331153, 5],"int32"), Tensor([3, 4, 5],"int32"), True, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:58:31.717224 114685 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:58:31.718241 114685 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([3, 4, 357913942],"int32"), Tensor([3, 4, 357913942],"int32"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([3, 4, 357913942],"int32"), Tensor([3, 4, 357913942],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:58:39.205989 114700 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:58:39.206951 114700 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([3, 4, 357913942],"int32"), Tensor([3, 4, 357913942],"int32"), True, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([3, 4, 357913942],"int32"), Tensor([3, 4, 357913942],"int32"), True, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:58:47.207442 114795 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:58:47.208456 114795 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([3, 4, 357913942],"int32"), Tensor([3, 4, 5],"int32"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([3, 4, 357913942],"int32"), Tensor([3, 4, 5],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:58:54.610868 114818 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:58:54.611867 114818 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([3, 4, 357913942],"int32"), Tensor([3, 4, 5],"int32"), True, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([3, 4, 357913942],"int32"), Tensor([3, 4, 5],"int32"), True, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:59:02.286554 114847 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:59:02.287533 114847 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([3, 4, 5],"int32"), Tensor([214748365, 4, 5],"int32"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([3, 4, 5],"int32"), Tensor([214748365, 4, 5],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:59:10.125979 114862 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:59:10.126976 114862 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([3, 4, 5],"int32"), Tensor([214748365, 4, 5],"int32"), True, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([3, 4, 5],"int32"), Tensor([214748365, 4, 5],"int32"), True, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:59:17.949939 114957 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:59:17.951006 114957 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([3, 4, 5],"int32"), Tensor([3, 286331153, 5],"int32"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([3, 4, 5],"int32"), Tensor([3, 286331153, 5],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:59:25.384428 114985 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:59:25.385447 114985 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([3, 4, 5],"int32"), Tensor([3, 286331153, 5],"int32"), True, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([3, 4, 5],"int32"), Tensor([3, 286331153, 5],"int32"), True, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:59:32.629082 115000 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:59:32.630131 115000 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([3, 4, 5],"int32"), Tensor([3, 4, 357913942],"int32"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([3, 4, 5],"int32"), Tensor([3, 4, 357913942],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:59:40.124368 115014 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:59:40.125337 115014 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([3, 4, 5],"int32"), Tensor([3, 4, 357913942],"int32"), True, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([3, 4, 5],"int32"), Tensor([3, 4, 357913942],"int32"), True, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 11:59:47.689368 115122 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:59:47.690415 115122 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([300],"int16"), Tensor([14316558, 300],"int16"), )
[torch error] paddle.bitwise_left_shift(Tensor([300],"int16"), Tensor([14316558, 300],"int16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 5895 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:00:56.203368 115137 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:00:56.204527 115137 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([300],"int16"), Tensor([14316558, 300],"int16"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([300],"int16"), Tensor([14316558, 300],"int16"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 12:01:04.682118 115348 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:01:04.683153 115348 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([300],"int16"), Tensor([200, 21474837],"int16"), )
[torch error] paddle.bitwise_left_shift(Tensor([300],"int16"), Tensor([200, 21474837],"int16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 51608 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:02:08.342159 115443 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:02:08.343245 115443 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([300],"int16"), Tensor([200, 21474837],"int16"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([300],"int16"), Tensor([200, 21474837],"int16"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 12:02:17.376562 115659 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:02:17.377565 115659 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([300],"int32"), Tensor([14316558, 300],"int32"), )
[torch error] paddle.bitwise_left_shift(Tensor([300],"int32"), Tensor([14316558, 300],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 106860 has 1016.00 MiB memory in use. Of the allocated memory 1.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:03:30.363426 115674 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:03:30.364454 115674 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([300],"int32"), Tensor([14316558, 300],"int32"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([300],"int32"), Tensor([14316558, 300],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 12:03:39.834893 115884 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:03:39.835973 115884 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([300],"int32"), Tensor([200, 21474837],"int32"), )
[torch error] paddle.bitwise_left_shift(Tensor([300],"int32"), Tensor([200, 21474837],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 4742 has 1016.00 MiB memory in use. Of the allocated memory 1.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:04:51.019134 115981 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:04:51.020328 115981 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([300],"int32"), Tensor([200, 21474837],"int32"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([300],"int32"), Tensor([200, 21474837],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 12:05:00.634279 116190 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:05:00.635552 116190 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([300],"int64"), Tensor([200, 10737419],"int64"), )
[torch error] paddle.bitwise_left_shift(Tensor([300],"int64"), Tensor([200, 10737419],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 66161 has 1016.00 MiB memory in use. Of the allocated memory 2.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:05:46.025238 116206 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:05:46.026264 116206 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([300],"int64"), Tensor([200, 10737419],"int64"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([300],"int64"), Tensor([200, 10737419],"int64"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 12:05:54.591045 116425 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:05:54.592043 116425 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([300],"int64"), Tensor([7158279, 300],"int64"), )
[torch error] paddle.bitwise_left_shift(Tensor([300],"int64"), Tensor([7158279, 300],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 116375 has 1016.00 MiB memory in use. Of the allocated memory 2.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:06:43.575912 116439 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:06:43.577049 116439 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([300],"int64"), Tensor([7158279, 300],"int64"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([300],"int64"), Tensor([7158279, 300],"int64"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 12:06:52.938468 116647 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:06:52.939666 116647 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([300],"int8"), Tensor([14316558, 300],"int8"), )
[torch error] paddle.bitwise_left_shift(Tensor([300],"int8"), Tensor([14316558, 300],"int8"), ) 
 CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 1821 has 4.99 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:07:56.949620 116662 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:07:56.950754 116662 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([300],"int8"), Tensor([14316558, 300],"int8"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([300],"int8"), Tensor([14316558, 300],"int8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 12:08:05.323326 116854 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:08:05.324362 116854 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([300],"int8"), Tensor([200, 21474837],"int8"), )
[torch error] paddle.bitwise_left_shift(Tensor([300],"int8"), Tensor([200, 21474837],"int8"), ) 
 The size of tensor a (300) must match the size of tensor b (21474837) at non-singleton dimension 1

W0205 12:09:13.595811 116966 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:09:13.597290 116966 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([300],"int8"), Tensor([200, 21474837],"int8"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([300],"int8"), Tensor([200, 21474837],"int8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 12:09:23.603292 117182 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:09:23.604321 117182 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([300],"uint8"), Tensor([14316558, 300],"uint8"), )
[torch error] paddle.bitwise_left_shift(Tensor([300],"uint8"), Tensor([14316558, 300],"uint8"), ) 
 CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 122955 has 4.99 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:10:29.434278 117204 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:10:29.435310 117204 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([300],"uint8"), Tensor([14316558, 300],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([300],"uint8"), Tensor([14316558, 300],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 12:10:37.920693 117400 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:10:37.921761 117400 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([300],"uint8"), Tensor([200, 21474837],"uint8"), )
[torch error] paddle.bitwise_left_shift(Tensor([300],"uint8"), Tensor([200, 21474837],"uint8"), ) 
 The size of tensor a (300) must match the size of tensor b (21474837) at non-singleton dimension 1

W0205 12:11:45.137537 117496 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:11:45.138762 117496 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([300],"uint8"), Tensor([200, 21474837],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([300],"uint8"), Tensor([200, 21474837],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 12:11:54.024860 117716 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:11:54.025920 117716 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([4294967295],"int16"), Tensor([1],"int16"), )
[torch error] paddle.bitwise_left_shift(Tensor([4294967295],"int16"), Tensor([1],"int16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 89181 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:12:58.520658 117732 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:12:58.521773 117732 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([4294967295],"int16"), Tensor([1],"int16"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([4294967295],"int16"), Tensor([1],"int16"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 12:13:06.403604 117955 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:13:06.404666 117955 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([4294967295],"int16"), Tensor([200, 300],"int16"), )
[torch error] paddle.bitwise_left_shift(Tensor([4294967295],"int16"), Tensor([200, 300],"int16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 142053 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:14:09.675429 118050 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:14:09.676647 118050 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([4294967295],"int16"), Tensor([200, 300],"int16"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([4294967295],"int16"), Tensor([200, 300],"int16"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 12:14:18.254426 118260 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:14:18.255434 118260 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([4294967295],"int16"), Tensor([4294967295],"int16"), )
[torch error] paddle.bitwise_left_shift(Tensor([4294967295],"int16"), Tensor([4294967295],"int16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 41103 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:15:22.409277 118275 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:15:22.410375 118275 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([4294967295],"int16"), Tensor([4294967295],"int16"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([4294967295],"int16"), Tensor([4294967295],"int16"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 12:15:30.898324 118496 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:15:30.899363 118496 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([4294967295],"int32"), Tensor([200, 300],"int32"), )
[torch error] paddle.bitwise_left_shift(Tensor([4294967295],"int32"), Tensor([200, 300],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 92636 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:16:39.021106 118511 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:16:39.022671 118511 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([4294967295],"int32"), Tensor([200, 300],"int32"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([4294967295],"int32"), Tensor([200, 300],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 12:16:47.735340 118790 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:16:47.736442 118790 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([4294967295],"int8"), Tensor([200, 300],"int8"), )
[torch error] paddle.bitwise_left_shift(Tensor([4294967295],"int8"), Tensor([200, 300],"int8"), ) 
 The size of tensor a (4294967295) must match the size of tensor b (300) at non-singleton dimension 1

W0205 12:17:50.393898 118818 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:17:50.394884 118818 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([4294967295],"int8"), Tensor([200, 300],"int8"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([4294967295],"int8"), Tensor([200, 300],"int8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 12:17:58.064512 119013 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:17:58.065549 119013 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([4294967295],"uint8"), Tensor([1],"uint8"), )
[torch error] paddle.bitwise_left_shift(Tensor([4294967295],"uint8"), Tensor([1],"uint8"), ) 
 CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 57597 has 4.99 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:19:07.582049 119028 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:19:07.583099 119028 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([4294967295],"uint8"), Tensor([1],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([4294967295],"uint8"), Tensor([1],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 12:19:16.786978 119325 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:19:16.788008 119325 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([4294967295],"uint8"), Tensor([200, 300],"uint8"), )
[torch error] paddle.bitwise_left_shift(Tensor([4294967295],"uint8"), Tensor([200, 300],"uint8"), ) 
 The size of tensor a (4294967295) must match the size of tensor b (300) at non-singleton dimension 1

W0205 12:20:19.525761 119343 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:20:19.526674 119343 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([4294967295],"uint8"), Tensor([200, 300],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([4294967295],"uint8"), Tensor([200, 300],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 12:20:27.421277 119539 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:20:27.422334 119539 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([4294967295],"uint8"), Tensor([4294967295],"uint8"), )
[torch error] paddle.bitwise_left_shift(Tensor([4294967295],"uint8"), Tensor([4294967295],"uint8"), ) 
 CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 13360 has 4.99 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:22:25.551766 119554 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:22:25.552765 119554 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([4294967295],"uint8"), Tensor([4294967295],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([4294967295],"uint8"), Tensor([4294967295],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 12:22:33.780428 119959 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:22:33.781466 119959 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([7158279, 300],"int64"), Tensor([200, 300],"int64"), )
[torch error] paddle.bitwise_left_shift(Tensor([7158279, 300],"int64"), Tensor([200, 300],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 110287 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:23:17.057010 120066 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:23:17.058034 120066 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([7158279, 300],"int64"), Tensor([200, 300],"int64"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([7158279, 300],"int64"), Tensor([200, 300],"int64"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 12:23:25.844185 120166 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:23:25.845221 120166 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([7158279, 300],"int64"), Tensor([300],"int64"), )
[torch error] paddle.bitwise_left_shift(Tensor([7158279, 300],"int64"), Tensor([300],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 155856 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:24:13.164721 120182 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:24:13.165890 120182 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([7158279, 300],"int64"), Tensor([300],"int64"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([7158279, 300],"int64"), Tensor([300],"int64"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 12:24:21.370623 120413 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:24:21.371665 120413 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([7158279, 300],"int64"), Tensor([7158279, 300],"int64"), )
[torch error] paddle.bitwise_left_shift(Tensor([7158279, 300],"int64"), Tensor([7158279, 300],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 38188 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:25:05.890906 120434 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:25:05.891909 120434 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_left_shift(Tensor([7158279, 300],"int64"), Tensor([7158279, 300],"int64"), False, )
[paddle_to_torch] paddle.bitwise_left_shift(Tensor([7158279, 300],"int64"), Tensor([7158279, 300],"int64"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 12:25:14.344861 120663 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:25:14.345835 120663 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_not(Tensor([1073741824, 4, 1],"int32"), )
[torch error] paddle.bitwise_not(Tensor([1073741824, 4, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 84465 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:26:25.996165 120681 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:26:25.997563 120681 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_not(Tensor([2, 3, 715827883],"int32"), )
[torch error] paddle.bitwise_not(Tensor([2, 3, 715827883],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 144084 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:27:36.359118 120895 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:27:36.360154 120895 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_not(Tensor([2, 429496730, 5],"int32"), )
[torch error] paddle.bitwise_not(Tensor([2, 429496730, 5],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 35363 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:28:51.617128 121172 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:28:51.618252 121172 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_not(Tensor([286331153, 3, 5],"int32"), )
[torch error] paddle.bitwise_not(Tensor([286331153, 3, 5],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 109744 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:30:07.136690 121383 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:30:07.137984 121383 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_not(Tensor([3, 1431655765, 1],"int32"), )
[torch error] paddle.bitwise_not(Tensor([3, 1431655765, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 162598 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:31:20.455076 121674 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:31:20.456259 121674 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_not(Tensor([3, 4, 357913942],"int32"), )
[torch error] paddle.bitwise_not(Tensor([3, 4, 357913942],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 63441 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:32:28.298746 121884 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:32:28.299918 121884 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_or(Tensor([1073741824, 4, 1],"int32"), Tensor([1073741824, 4, 1],"int32"), )
[torch error] paddle.bitwise_or(Tensor([1073741824, 4, 1],"int32"), Tensor([1073741824, 4, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 114111 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:33:38.322398 122065 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:33:38.323547 122065 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_or(Tensor([1073741824, 4, 1],"int32"), Tensor([3, 4, 1],"int32"), )
[torch error] paddle.bitwise_or(Tensor([1073741824, 4, 1],"int32"), Tensor([3, 4, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 7759 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:34:47.269418 122353 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:34:47.270612 122353 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_or(Tensor([2, 3, 5],"int32"), Tensor([2, 3, 715827883],"int32"), )
[torch error] paddle.bitwise_or(Tensor([2, 3, 5],"int32"), Tensor([2, 3, 715827883],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 72009 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:36:00.642014 122562 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:36:00.643127 122562 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_or(Tensor([2, 3, 5],"int32"), Tensor([2, 429496730, 5],"int32"), )
[torch error] paddle.bitwise_or(Tensor([2, 3, 5],"int32"), Tensor([2, 429496730, 5],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 128565 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:37:08.516796 122772 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:37:08.517874 122772 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_or(Tensor([2, 3, 5],"int32"), Tensor([286331153, 3, 5],"int32"), )
[torch error] paddle.bitwise_or(Tensor([2, 3, 5],"int32"), Tensor([286331153, 3, 5],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 24352 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:38:21.503916 123054 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:38:21.504988 123054 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_or(Tensor([2, 3, 715827883],"int32"), Tensor([2, 3, 5],"int32"), )
[torch error] paddle.bitwise_or(Tensor([2, 3, 715827883],"int32"), Tensor([2, 3, 5],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 78253 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:39:31.108835 123273 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:39:31.109892 123273 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_or(Tensor([2, 3, 715827883],"int32"), Tensor([2, 3, 715827883],"int32"), )
[torch error] paddle.bitwise_or(Tensor([2, 3, 715827883],"int32"), Tensor([2, 3, 715827883],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 133166 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:40:38.168186 123472 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:40:38.169299 123472 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_or(Tensor([2, 429496730, 5],"int32"), Tensor([2, 3, 5],"int32"), )
[torch error] paddle.bitwise_or(Tensor([2, 429496730, 5],"int32"), Tensor([2, 3, 5],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 26154 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:41:52.702265 123762 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:41:52.703326 123762 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_or(Tensor([2, 429496730, 5],"int32"), Tensor([2, 429496730, 5],"int32"), )
[torch error] paddle.bitwise_or(Tensor([2, 429496730, 5],"int32"), Tensor([2, 429496730, 5],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 92772 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:43:05.092934 123984 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:43:05.093932 123984 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_or(Tensor([286331153, 3, 5],"int32"), Tensor([2, 3, 5],"int32"), )
[torch error] paddle.bitwise_or(Tensor([286331153, 3, 5],"int32"), Tensor([2, 3, 5],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 147055 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:44:12.338567 124275 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:44:12.339566 124275 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_or(Tensor([286331153, 3, 5],"int32"), Tensor([286331153, 3, 5],"int32"), )
[torch error] paddle.bitwise_or(Tensor([286331153, 3, 5],"int32"), Tensor([286331153, 3, 5],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 43187 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:45:27.450850 124497 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:45:27.451818 124497 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_or(Tensor([3, 1431655765, 1],"int32"), Tensor([3, 1431655765, 1],"int32"), )
[torch error] paddle.bitwise_or(Tensor([3, 1431655765, 1],"int32"), Tensor([3, 1431655765, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 94401 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:46:34.801968 124708 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:46:34.803000 124708 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_or(Tensor([3, 1431655765, 1],"int32"), Tensor([3, 4, 1],"int32"), )
[torch error] paddle.bitwise_or(Tensor([3, 1431655765, 1],"int32"), Tensor([3, 4, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 152647 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:47:43.506891 124971 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:47:43.508144 124971 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_or(Tensor([3, 4, 1],"int32"), Tensor([1073741824, 4, 1],"int32"), )
[torch error] paddle.bitwise_or(Tensor([3, 4, 1],"int32"), Tensor([1073741824, 4, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 58677 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:48:57.602209 125177 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:48:57.603271 125177 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_or(Tensor([3, 4, 1],"int32"), Tensor([3, 1431655765, 1],"int32"), )
[torch error] paddle.bitwise_or(Tensor([3, 4, 1],"int32"), Tensor([3, 1431655765, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 122048 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:50:11.417337 125374 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:50:11.418375 125374 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_or(Tensor([3, 4, 1],"int32"), Tensor([3, 4, 357913942],"int32"), )
[torch error] paddle.bitwise_or(Tensor([3, 4, 1],"int32"), Tensor([3, 4, 357913942],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 22070 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:51:21.579630 125675 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:51:21.580763 125675 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_or(Tensor([3, 4, 357913942],"int32"), Tensor([3, 4, 1],"int32"), )
[torch error] paddle.bitwise_or(Tensor([3, 4, 357913942],"int32"), Tensor([3, 4, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 69586 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:52:46.845116 125861 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:52:46.846207 125861 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_or(Tensor([3, 4, 357913942],"int32"), Tensor([3, 4, 357913942],"int32"), )
[torch error] paddle.bitwise_or(Tensor([3, 4, 357913942],"int32"), Tensor([3, 4, 357913942],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 143792 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:54:02.238085 126124 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:54:02.239173 126124 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([1],"int8"), Tensor([4294967295],"int8"), )
[torch error] paddle.bitwise_right_shift(Tensor([1],"int8"), Tensor([4294967295],"int8"), ) 
 CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 30733 has 4.99 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:55:04.696748 126332 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:55:04.697772 126332 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([1],"int8"), Tensor([4294967295],"int8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([1],"int8"), Tensor([4294967295],"int8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 12:55:12.645627 126607 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:55:12.646579 126607 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([1],"uint8"), Tensor([4294967295],"uint8"), )
[torch error] paddle.bitwise_right_shift(Tensor([1],"uint8"), Tensor([4294967295],"uint8"), ) 
 CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 90504 has 4.99 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:56:20.744362 126621 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:56:20.745515 126621 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([1],"uint8"), Tensor([4294967295],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([1],"uint8"), Tensor([4294967295],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 12:56:28.733191 126816 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:56:28.734237 126816 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([14316558, 300],"int16"), Tensor([14316558, 300],"int16"), )
[torch error] paddle.bitwise_right_shift(Tensor([14316558, 300],"int16"), Tensor([14316558, 300],"int16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 151200 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:57:54.759063 126832 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:57:54.760231 126832 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([14316558, 300],"int16"), Tensor([14316558, 300],"int16"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([14316558, 300],"int16"), Tensor([14316558, 300],"int16"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 12:58:02.866844 127122 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:58:02.867852 127122 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([14316558, 300],"int16"), Tensor([200, 300],"int16"), )
[torch error] paddle.bitwise_right_shift(Tensor([14316558, 300],"int16"), Tensor([200, 300],"int16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 68418 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:59:12.367885 127136 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:59:12.380874 127136 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([14316558, 300],"int16"), Tensor([200, 300],"int16"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([14316558, 300],"int16"), Tensor([200, 300],"int16"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 12:59:20.484264 127421 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:59:20.485272 127421 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([14316558, 300],"int16"), Tensor([300],"int16"), )
[torch error] paddle.bitwise_right_shift(Tensor([14316558, 300],"int16"), Tensor([300],"int16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 141509 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:00:31.426512 127436 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:00:31.427636 127436 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([14316558, 300],"int16"), Tensor([300],"int16"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([14316558, 300],"int16"), Tensor([300],"int16"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:00:40.211566 127657 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:00:40.212599 127657 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([14316558, 300],"int32"), Tensor([14316558, 300],"int32"), )
[torch error] paddle.bitwise_right_shift(Tensor([14316558, 300],"int32"), Tensor([14316558, 300],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 43887 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:01:51.235776 127752 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:01:51.236739 127752 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([14316558, 300],"int32"), Tensor([14316558, 300],"int32"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([14316558, 300],"int32"), Tensor([14316558, 300],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:01:58.605577 127957 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:01:58.606621 127957 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([14316558, 300],"int32"), Tensor([200, 300],"int32"), )
[torch error] paddle.bitwise_right_shift(Tensor([14316558, 300],"int32"), Tensor([200, 300],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 105540 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:03:09.526934 127972 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:03:09.528095 127972 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([14316558, 300],"int32"), Tensor([200, 300],"int32"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([14316558, 300],"int32"), Tensor([200, 300],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:03:17.383272 128248 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:03:17.384232 128248 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([14316558, 300],"int32"), Tensor([300],"int32"), )
[torch error] paddle.bitwise_right_shift(Tensor([14316558, 300],"int32"), Tensor([300],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 8785 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:04:28.709517 128263 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:04:28.710489 128263 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([14316558, 300],"int32"), Tensor([300],"int32"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([14316558, 300],"int32"), Tensor([300],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:04:36.352751 128485 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:04:36.353696 128485 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([14316558, 300],"int8"), Tensor([14316558, 300],"int8"), )
[torch error] paddle.bitwise_right_shift(Tensor([14316558, 300],"int8"), Tensor([14316558, 300],"int8"), ) 
 CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 59936 has 4.99 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:06:30.366406 128580 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:06:30.367398 128580 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([14316558, 300],"int8"), Tensor([14316558, 300],"int8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([14316558, 300],"int8"), Tensor([14316558, 300],"int8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:06:38.273777 128874 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:06:38.274863 128874 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([14316558, 300],"int8"), Tensor([200, 300],"int8"), )
[torch error] paddle.bitwise_right_shift(Tensor([14316558, 300],"int8"), Tensor([200, 300],"int8"), ) 
 The size of tensor a (14316558) must match the size of tensor b (200) at non-singleton dimension 0

W0205 13:07:47.175683 128969 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:07:47.176694 128969 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([14316558, 300],"int8"), Tensor([200, 300],"int8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([14316558, 300],"int8"), Tensor([200, 300],"int8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:07:55.049625 129177 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:07:55.050647 129177 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([14316558, 300],"int8"), Tensor([300],"int8"), )
[torch error] paddle.bitwise_right_shift(Tensor([14316558, 300],"int8"), Tensor([300],"int8"), ) 
 CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 74152 has 4.99 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:09:08.864084 129193 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:09:08.865056 129193 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([14316558, 300],"int8"), Tensor([300],"int8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([14316558, 300],"int8"), Tensor([300],"int8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:09:16.639035 129467 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:09:16.640034 129467 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([14316558, 300],"uint8"), Tensor([14316558, 300],"uint8"), )
[torch error] paddle.bitwise_right_shift(Tensor([14316558, 300],"uint8"), Tensor([14316558, 300],"uint8"), ) 
 CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 144112 has 4.99 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:11:31.383713 129482 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:11:31.384847 129482 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([14316558, 300],"uint8"), Tensor([14316558, 300],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([14316558, 300],"uint8"), Tensor([14316558, 300],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:11:40.897250 129968 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:11:40.898306 129968 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([14316558, 300],"uint8"), Tensor([200, 300],"uint8"), )
[torch error] paddle.bitwise_right_shift(Tensor([14316558, 300],"uint8"), Tensor([200, 300],"uint8"), ) 
 The size of tensor a (14316558) must match the size of tensor b (200) at non-singleton dimension 0

W0205 13:12:49.750783 129983 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:12:49.751612 129983 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([14316558, 300],"uint8"), Tensor([200, 300],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([14316558, 300],"uint8"), Tensor([200, 300],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:12:57.291826 130168 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:12:57.292879 130168 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([14316558, 300],"uint8"), Tensor([300],"uint8"), )
[torch error] paddle.bitwise_right_shift(Tensor([14316558, 300],"uint8"), Tensor([300],"uint8"), ) 
 CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 160583 has 4.99 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:14:01.301399 130196 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:14:01.302529 130196 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([14316558, 300],"uint8"), Tensor([300],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([14316558, 300],"uint8"), Tensor([300],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:14:08.796074 130390 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:14:08.797170 130390 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 10737419],"int64"), Tensor([200, 10737419],"int64"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 10737419],"int64"), Tensor([200, 10737419],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 52031 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:14:53.894466 130487 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:14:53.895601 130487 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 10737419],"int64"), Tensor([200, 10737419],"int64"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 10737419],"int64"), Tensor([200, 10737419],"int64"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:15:01.267843 130599 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:15:01.268816 130599 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 10737419],"int64"), Tensor([200, 300],"int64"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 10737419],"int64"), Tensor([200, 300],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 96975 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:15:46.562121 130627 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:15:46.563305 130627 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 10737419],"int64"), Tensor([200, 300],"int64"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 10737419],"int64"), Tensor([200, 300],"int64"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:15:54.242911 130820 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:15:54.243834 130820 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 10737419],"int64"), Tensor([300],"int64"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 10737419],"int64"), Tensor([300],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 147569 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:16:38.617780 130834 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:16:38.618863 130834 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 10737419],"int64"), Tensor([300],"int64"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 10737419],"int64"), Tensor([300],"int64"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:16:46.660080 131014 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:16:46.661075 131014 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 21474837],"int16"), Tensor([200, 21474837],"int16"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 21474837],"int16"), Tensor([200, 21474837],"int16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 31213 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:17:57.806372 131042 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:17:57.807366 131042 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 21474837],"int16"), Tensor([200, 21474837],"int16"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 21474837],"int16"), Tensor([200, 21474837],"int16"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:18:05.339780 131238 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:18:05.340817 131238 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 21474837],"int16"), Tensor([200, 300],"int16"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 21474837],"int16"), Tensor([200, 300],"int16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 85455 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:19:14.831045 131333 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:19:14.832115 131333 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 21474837],"int16"), Tensor([200, 300],"int16"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 21474837],"int16"), Tensor([200, 300],"int16"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:19:22.444622 131541 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:19:22.445680 131541 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 21474837],"int16"), Tensor([300],"int16"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 21474837],"int16"), Tensor([300],"int16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 151440 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:20:26.252821 131555 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:20:26.253913 131555 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 21474837],"int16"), Tensor([300],"int16"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 21474837],"int16"), Tensor([300],"int16"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:20:33.521234 131750 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:20:33.522349 131750 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 21474837],"int32"), Tensor([200, 21474837],"int32"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 21474837],"int32"), Tensor([200, 21474837],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 40475 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:21:48.622035 131823 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:21:48.623102 131823 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 21474837],"int32"), Tensor([200, 21474837],"int32"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 21474837],"int32"), Tensor([200, 21474837],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:21:56.188438 132029 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:21:56.189383 132029 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 21474837],"int32"), Tensor([200, 300],"int32"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 21474837],"int32"), Tensor([200, 300],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 114637 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:23:04.262260 132044 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:23:04.263391 132044 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 21474837],"int32"), Tensor([200, 300],"int32"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 21474837],"int32"), Tensor([200, 300],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:23:11.808836 132333 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:23:11.809813 132333 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 21474837],"int32"), Tensor([300],"int32"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 21474837],"int32"), Tensor([300],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 15972 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:24:20.486971 132347 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:24:20.488006 132347 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 21474837],"int32"), Tensor([300],"int32"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 21474837],"int32"), Tensor([300],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:24:27.915920 132528 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:24:27.916925 132528 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 21474837],"int8"), Tensor([200, 21474837],"int8"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 21474837],"int8"), Tensor([200, 21474837],"int8"), ) 
 CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 66319 has 4.99 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:26:32.850811 132543 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:26:32.851816 132543 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 21474837],"int8"), Tensor([200, 21474837],"int8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 21474837],"int8"), Tensor([200, 21474837],"int8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:26:40.661245 132996 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:26:40.662227 132996 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 21474837],"int8"), Tensor([200, 300],"int8"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 21474837],"int8"), Tensor([200, 300],"int8"), ) 
 The size of tensor a (21474837) must match the size of tensor b (300) at non-singleton dimension 1

W0205 13:27:49.728557 133011 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:27:49.729493 133011 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 21474837],"int8"), Tensor([200, 300],"int8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 21474837],"int8"), Tensor([200, 300],"int8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:27:57.518569 133193 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:27:57.519671 133193 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 21474837],"int8"), Tensor([300],"int8"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 21474837],"int8"), Tensor([300],"int8"), ) 
 The size of tensor a (21474837) must match the size of tensor b (300) at non-singleton dimension 1

W0205 13:29:07.479800 133208 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:29:07.480952 133208 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 21474837],"int8"), Tensor([300],"int8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 21474837],"int8"), Tensor([300],"int8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:29:15.042695 133485 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:29:15.043715 133485 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 21474837],"uint8"), Tensor([200, 21474837],"uint8"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 21474837],"uint8"), Tensor([200, 21474837],"uint8"), ) 
 CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 145976 has 4.99 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:31:17.153723 133513 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:31:17.154860 133513 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 21474837],"uint8"), Tensor([200, 21474837],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 21474837],"uint8"), Tensor([200, 21474837],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:31:25.071961 133873 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:31:25.072990 133873 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 21474837],"uint8"), Tensor([200, 300],"uint8"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 21474837],"uint8"), Tensor([200, 300],"uint8"), ) 
 The size of tensor a (21474837) must match the size of tensor b (300) at non-singleton dimension 1

W0205 13:32:27.647372 133911 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:32:27.648366 133911 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 21474837],"uint8"), Tensor([200, 300],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 21474837],"uint8"), Tensor([200, 300],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:32:35.383394 134110 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:32:35.384519 134110 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 21474837],"uint8"), Tensor([300],"uint8"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 21474837],"uint8"), Tensor([300],"uint8"), ) 
 The size of tensor a (21474837) must match the size of tensor b (300) at non-singleton dimension 1

W0205 13:33:45.067296 134205 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:33:45.068290 134205 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 21474837],"uint8"), Tensor([300],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 21474837],"uint8"), Tensor([300],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:33:52.939144 134400 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:33:52.940161 134400 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"int16"), Tensor([14316558, 300],"int16"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 300],"int16"), Tensor([14316558, 300],"int16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 46849 has 1016.00 MiB memory in use. Of the allocated memory 117.50 KiB is allocated by PyTorch, and 1.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:34:57.709605 134414 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:34:57.710752 134414 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"int16"), Tensor([14316558, 300],"int16"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 300],"int16"), Tensor([14316558, 300],"int16"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:35:07.106627 134609 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:35:07.107736 134609 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"int16"), Tensor([200, 21474837],"int16"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 300],"int16"), Tensor([200, 21474837],"int16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 97644 has 1016.00 MiB memory in use. Of the allocated memory 117.50 KiB is allocated by PyTorch, and 1.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:36:11.824517 134704 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:36:11.825502 134704 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"int16"), Tensor([200, 21474837],"int16"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 300],"int16"), Tensor([200, 21474837],"int16"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:36:20.133257 134898 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:36:20.134334 134898 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"int16"), Tensor([4294967295],"int16"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 300],"int16"), Tensor([4294967295],"int16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 6336 has 1016.00 MiB memory in use. Of the allocated memory 117.50 KiB is allocated by PyTorch, and 1.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:37:29.148386 134913 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:37:29.149516 134913 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"int16"), Tensor([4294967295],"int16"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 300],"int16"), Tensor([4294967295],"int16"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:37:37.213188 135122 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:37:37.214156 135122 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"int32"), Tensor([14316558, 300],"int32"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 300],"int32"), Tensor([14316558, 300],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 67057 has 1016.00 MiB memory in use. Of the allocated memory 234.50 KiB is allocated by PyTorch, and 1.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:38:47.619632 135217 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:38:47.620746 135217 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"int32"), Tensor([14316558, 300],"int32"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 300],"int32"), Tensor([14316558, 300],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:38:56.788687 135428 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:38:56.789808 135428 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"int32"), Tensor([200, 21474837],"int32"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 300],"int32"), Tensor([200, 21474837],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 143847 has 1016.00 MiB memory in use. Of the allocated memory 234.50 KiB is allocated by PyTorch, and 1.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:40:03.453893 135443 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:40:03.454874 135443 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"int32"), Tensor([200, 21474837],"int32"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 300],"int32"), Tensor([200, 21474837],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:40:11.698946 135731 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:40:11.699935 135731 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"int32"), Tensor([4294967295],"int32"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 300],"int32"), Tensor([4294967295],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 45869 has 1016.00 MiB memory in use. Of the allocated memory 234.50 KiB is allocated by PyTorch, and 1.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:41:23.399392 135746 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:41:23.400508 135746 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"int32"), Tensor([4294967295],"int32"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 300],"int32"), Tensor([4294967295],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:41:32.411677 135943 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:41:32.412671 135943 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"int64"), Tensor([200, 10737419],"int64"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 300],"int64"), Tensor([200, 10737419],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 102234 has 1016.00 MiB memory in use. Of the allocated memory 469.00 KiB is allocated by PyTorch, and 1.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:42:14.549329 135957 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:42:14.550155 135957 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"int64"), Tensor([200, 10737419],"int64"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 300],"int64"), Tensor([200, 10737419],"int64"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:42:23.025840 136178 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:42:23.026845 136178 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"int64"), Tensor([2147483649],"int64"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 300],"int64"), Tensor([2147483649],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 146214 has 1016.00 MiB memory in use. Of the allocated memory 469.00 KiB is allocated by PyTorch, and 1.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:43:05.206277 136192 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:43:05.207665 136192 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"int64"), Tensor([2147483649],"int64"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 300],"int64"), Tensor([2147483649],"int64"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:43:14.536459 136376 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:43:14.537513 136376 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"int64"), Tensor([7158279, 300],"int64"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 300],"int64"), Tensor([7158279, 300],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 27037 has 1016.00 MiB memory in use. Of the allocated memory 469.00 KiB is allocated by PyTorch, and 1.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:43:58.830753 136391 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:43:58.831743 136391 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"int64"), Tensor([7158279, 300],"int64"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 300],"int64"), Tensor([7158279, 300],"int64"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:44:07.700604 136502 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:44:07.701687 136502 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"int8"), Tensor([14316558, 300],"int8"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 300],"int8"), Tensor([14316558, 300],"int8"), ) 
 The size of tensor a (200) must match the size of tensor b (14316558) at non-singleton dimension 0

W0205 13:45:09.390182 136597 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:45:09.391358 136597 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"int8"), Tensor([14316558, 300],"int8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 300],"int8"), Tensor([14316558, 300],"int8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:45:17.590724 136804 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:45:17.591746 136804 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"int8"), Tensor([200, 21474837],"int8"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 300],"int8"), Tensor([200, 21474837],"int8"), ) 
 The size of tensor a (300) must match the size of tensor b (21474837) at non-singleton dimension 1

W0205 13:46:19.715201 136819 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:46:19.716265 136819 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"int8"), Tensor([200, 21474837],"int8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 300],"int8"), Tensor([200, 21474837],"int8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:46:27.610013 137029 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:46:27.610986 137029 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"int8"), Tensor([4294967295],"int8"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 300],"int8"), Tensor([4294967295],"int8"), ) 
 The size of tensor a (300) must match the size of tensor b (4294967295) at non-singleton dimension 1

W0205 13:47:30.254798 137044 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:47:30.255831 137044 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"int8"), Tensor([4294967295],"int8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 300],"int8"), Tensor([4294967295],"int8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:47:38.191536 137226 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:47:38.192521 137226 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"uint8"), Tensor([14316558, 300],"uint8"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 300],"uint8"), Tensor([14316558, 300],"uint8"), ) 
 The size of tensor a (200) must match the size of tensor b (14316558) at non-singleton dimension 0

W0205 13:48:40.467186 137321 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:48:40.468380 137321 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"uint8"), Tensor([14316558, 300],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 300],"uint8"), Tensor([14316558, 300],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:48:48.549173 137528 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:48:48.550206 137528 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"uint8"), Tensor([200, 21474837],"uint8"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 300],"uint8"), Tensor([200, 21474837],"uint8"), ) 
 The size of tensor a (300) must match the size of tensor b (21474837) at non-singleton dimension 1

W0205 13:49:56.791821 137543 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:49:56.792887 137543 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"uint8"), Tensor([200, 21474837],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 300],"uint8"), Tensor([200, 21474837],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:50:04.548790 137754 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:50:04.549813 137754 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"uint8"), Tensor([4294967295],"uint8"), )
[torch error] paddle.bitwise_right_shift(Tensor([200, 300],"uint8"), Tensor([4294967295],"uint8"), ) 
 The size of tensor a (300) must match the size of tensor b (4294967295) at non-singleton dimension 1

W0205 13:51:07.906863 137849 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:51:07.907933 137849 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([200, 300],"uint8"), Tensor([4294967295],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([200, 300],"uint8"), Tensor([4294967295],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:51:15.745306 138046 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:51:15.746368 138046 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([2147483649],"int64"), Tensor([200, 300],"int64"), )
[torch error] paddle.bitwise_right_shift(Tensor([2147483649],"int64"), Tensor([200, 300],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 84089 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:51:58.978113 138061 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:51:58.979223 138061 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([2147483649],"int64"), Tensor([200, 300],"int64"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([2147483649],"int64"), Tensor([200, 300],"int64"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:52:06.775022 138187 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:52:06.776027 138187 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([300],"int16"), Tensor([14316558, 300],"int16"), )
[torch error] paddle.bitwise_right_shift(Tensor([300],"int16"), Tensor([14316558, 300],"int16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 116843 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:53:10.519713 138283 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:53:10.520735 138283 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([300],"int16"), Tensor([14316558, 300],"int16"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([300],"int16"), Tensor([14316558, 300],"int16"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:53:19.518363 138478 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:53:19.519474 138478 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([300],"int16"), Tensor([200, 21474837],"int16"), )
[torch error] paddle.bitwise_right_shift(Tensor([300],"int16"), Tensor([200, 21474837],"int16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 14115 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:54:22.445464 138506 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:54:22.446498 138506 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([300],"int16"), Tensor([200, 21474837],"int16"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([300],"int16"), Tensor([200, 21474837],"int16"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:54:31.581224 138688 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:54:31.582685 138688 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([300],"int32"), Tensor([14316558, 300],"int32"), )
[torch error] paddle.bitwise_right_shift(Tensor([300],"int32"), Tensor([14316558, 300],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 62974 has 1016.00 MiB memory in use. Of the allocated memory 1.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:55:36.527998 138703 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:55:36.529103 138703 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([300],"int32"), Tensor([14316558, 300],"int32"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([300],"int32"), Tensor([14316558, 300],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:55:45.553927 138990 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:55:45.555049 138990 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([300],"int32"), Tensor([200, 21474837],"int32"), )
[torch error] paddle.bitwise_right_shift(Tensor([300],"int32"), Tensor([200, 21474837],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 132288 has 1016.00 MiB memory in use. Of the allocated memory 1.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:57:02.223462 139005 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:57:02.224592 139005 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([300],"int32"), Tensor([200, 21474837],"int32"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([300],"int32"), Tensor([200, 21474837],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:57:11.435187 139281 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:57:11.436281 139281 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([300],"int64"), Tensor([200, 10737419],"int64"), )
[torch error] paddle.bitwise_right_shift(Tensor([300],"int64"), Tensor([200, 10737419],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 39387 has 1016.00 MiB memory in use. Of the allocated memory 2.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:57:56.632179 139310 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:57:56.634104 139310 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([300],"int64"), Tensor([200, 10737419],"int64"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([300],"int64"), Tensor([200, 10737419],"int64"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:58:05.453521 139409 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:58:05.454504 139409 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([300],"int64"), Tensor([7158279, 300],"int64"), )
[torch error] paddle.bitwise_right_shift(Tensor([300],"int64"), Tensor([7158279, 300],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 72168 has 1016.00 MiB memory in use. Of the allocated memory 2.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:58:53.296243 139506 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:58:53.297253 139506 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([300],"int64"), Tensor([7158279, 300],"int64"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([300],"int64"), Tensor([7158279, 300],"int64"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 13:59:03.168265 139614 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:59:03.169384 139614 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([300],"int8"), Tensor([14316558, 300],"int8"), )
[torch error] paddle.bitwise_right_shift(Tensor([300],"int8"), Tensor([14316558, 300],"int8"), ) 
 CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 122001 has 4.99 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:00:12.432471 139628 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:00:12.433449 139628 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([300],"int8"), Tensor([14316558, 300],"int8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([300],"int8"), Tensor([14316558, 300],"int8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 14:00:20.946772 139917 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:00:20.947819 139917 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([300],"int8"), Tensor([200, 21474837],"int8"), )
[torch error] paddle.bitwise_right_shift(Tensor([300],"int8"), Tensor([200, 21474837],"int8"), ) 
 The size of tensor a (300) must match the size of tensor b (21474837) at non-singleton dimension 1

W0205 14:01:24.769302 139933 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:01:24.770512 139933 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([300],"int8"), Tensor([200, 21474837],"int8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([300],"int8"), Tensor([200, 21474837],"int8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 14:01:33.660460 140149 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:01:33.661571 140149 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([300],"uint8"), Tensor([14316558, 300],"uint8"), )
[torch error] paddle.bitwise_right_shift(Tensor([300],"uint8"), Tensor([14316558, 300],"uint8"), ) 
 CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 69447 has 4.99 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:02:36.968396 140244 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:02:36.969460 140244 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([300],"uint8"), Tensor([14316558, 300],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([300],"uint8"), Tensor([14316558, 300],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 14:02:44.828761 140441 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:02:44.829866 140441 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([300],"uint8"), Tensor([200, 21474837],"uint8"), )
[torch error] paddle.bitwise_right_shift(Tensor([300],"uint8"), Tensor([200, 21474837],"uint8"), ) 
 The size of tensor a (300) must match the size of tensor b (21474837) at non-singleton dimension 1

W0205 14:03:48.287055 140455 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:03:48.288192 140455 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([300],"uint8"), Tensor([200, 21474837],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([300],"uint8"), Tensor([200, 21474837],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 14:03:56.821903 140676 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:03:56.822876 140676 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([4294967295],"int16"), Tensor([200, 300],"int16"), )
[torch error] paddle.bitwise_right_shift(Tensor([4294967295],"int16"), Tensor([200, 300],"int16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28431 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:04:59.949571 140691 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:04:59.950661 140691 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([4294967295],"int16"), Tensor([200, 300],"int16"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([4294967295],"int16"), Tensor([200, 300],"int16"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 14:05:07.536314 140887 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:05:07.537302 140887 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([4294967295],"int32"), Tensor([200, 300],"int32"), )
[torch error] paddle.bitwise_right_shift(Tensor([4294967295],"int32"), Tensor([200, 300],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 75534 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:06:18.880914 140982 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:06:18.881911 140982 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([4294967295],"int32"), Tensor([200, 300],"int32"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([4294967295],"int32"), Tensor([200, 300],"int32"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 14:06:26.281980 141177 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:06:26.282980 141177 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([4294967295],"int8"), Tensor([1],"int8"), )
[torch error] paddle.bitwise_right_shift(Tensor([4294967295],"int8"), Tensor([1],"int8"), ) 
 CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 145250 has 4.99 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:07:28.325502 141192 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:07:28.326534 141192 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([4294967295],"int8"), Tensor([1],"int8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([4294967295],"int8"), Tensor([1],"int8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 14:07:35.668355 141386 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:07:35.669332 141386 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([4294967295],"int8"), Tensor([200, 300],"int8"), )
[torch error] paddle.bitwise_right_shift(Tensor([4294967295],"int8"), Tensor([200, 300],"int8"), ) 
 The size of tensor a (4294967295) must match the size of tensor b (300) at non-singleton dimension 1

W0205 14:08:38.720094 141481 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:08:38.721235 141481 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([4294967295],"int8"), Tensor([200, 300],"int8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([4294967295],"int8"), Tensor([200, 300],"int8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 14:08:46.111112 141675 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:08:46.112485 141675 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([4294967295],"int8"), Tensor([4294967295],"int8"), )
[torch error] paddle.bitwise_right_shift(Tensor([4294967295],"int8"), Tensor([4294967295],"int8"), ) 
 CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 92772 has 4.99 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:10:48.030113 141690 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:10:48.031114 141690 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([4294967295],"int8"), Tensor([4294967295],"int8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([4294967295],"int8"), Tensor([4294967295],"int8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 14:10:55.697486 142052 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:10:55.698491 142052 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([4294967295],"uint8"), Tensor([1],"uint8"), )
[torch error] paddle.bitwise_right_shift(Tensor([4294967295],"uint8"), Tensor([1],"uint8"), ) 
 CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 29427 has 4.99 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:12:02.614513 142067 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:12:02.615532 142067 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([4294967295],"uint8"), Tensor([1],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([4294967295],"uint8"), Tensor([1],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 14:12:10.118239 142324 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:12:10.119251 142324 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([4294967295],"uint8"), Tensor([200, 300],"uint8"), )
[torch error] paddle.bitwise_right_shift(Tensor([4294967295],"uint8"), Tensor([200, 300],"uint8"), ) 
 The size of tensor a (4294967295) must match the size of tensor b (300) at non-singleton dimension 1

W0205 14:13:16.431188 142420 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:13:16.445572 142420 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([4294967295],"uint8"), Tensor([200, 300],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([4294967295],"uint8"), Tensor([200, 300],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 14:13:24.375722 142604 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:13:24.376730 142604 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([4294967295],"uint8"), Tensor([4294967295],"uint8"), )
[torch error] paddle.bitwise_right_shift(Tensor([4294967295],"uint8"), Tensor([4294967295],"uint8"), ) 
 CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 139989 has 4.99 GiB memory in use. Of the allocated memory 4.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:15:23.025465 142631 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:15:23.026451 142631 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([4294967295],"uint8"), Tensor([4294967295],"uint8"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([4294967295],"uint8"), Tensor([4294967295],"uint8"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 14:15:30.613960 143004 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:15:30.614964 143004 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([7158279, 300],"int64"), Tensor([200, 300],"int64"), )
[torch error] paddle.bitwise_right_shift(Tensor([7158279, 300],"int64"), Tensor([200, 300],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 69230 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:16:16.787983 143019 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:16:16.789090 143019 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([7158279, 300],"int64"), Tensor([200, 300],"int64"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([7158279, 300],"int64"), Tensor([200, 300],"int64"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 14:16:24.612267 143213 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:16:24.613250 143213 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([7158279, 300],"int64"), Tensor([300],"int64"), )
[torch error] paddle.bitwise_right_shift(Tensor([7158279, 300],"int64"), Tensor([300],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 121177 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:17:10.330628 143227 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:17:10.331624 143227 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([7158279, 300],"int64"), Tensor([300],"int64"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([7158279, 300],"int64"), Tensor([300],"int64"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 14:17:17.518112 143421 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:17:17.519114 143421 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([7158279, 300],"int64"), Tensor([7158279, 300],"int64"), )
[torch error] paddle.bitwise_right_shift(Tensor([7158279, 300],"int64"), Tensor([7158279, 300],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 163577 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:18:00.420238 143436 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:18:00.421278 143436 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_right_shift(Tensor([7158279, 300],"int64"), Tensor([7158279, 300],"int64"), False, )
[paddle_to_torch] paddle.bitwise_right_shift(Tensor([7158279, 300],"int64"), Tensor([7158279, 300],"int64"), False, ) 
  is_arithmetic not in paddle_to_torch_args_map, can not call torch

W0205 14:18:08.024470 143548 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:18:08.025477 143548 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_xor(Tensor([1073741824, 4, 1],"int32"), Tensor([1073741824, 4, 1],"int32"), )
[torch error] paddle.bitwise_xor(Tensor([1073741824, 4, 1],"int32"), Tensor([1073741824, 4, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 32605 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:19:14.811779 143643 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:19:14.813202 143643 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_xor(Tensor([1073741824, 4, 1],"int32"), Tensor([3, 4, 1],"int32"), )
[torch error] paddle.bitwise_xor(Tensor([1073741824, 4, 1],"int32"), Tensor([3, 4, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 97781 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:20:22.396237 143852 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:20:22.397253 143852 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_xor(Tensor([2, 3, 5],"int32"), Tensor([2, 3, 715827883],"int32"), )
[torch error] paddle.bitwise_xor(Tensor([2, 3, 5],"int32"), Tensor([2, 3, 715827883],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 145193 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:21:28.486596 144034 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:21:28.487555 144034 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_xor(Tensor([2, 3, 5],"int32"), Tensor([2, 429496730, 5],"int32"), )
[torch error] paddle.bitwise_xor(Tensor([2, 3, 5],"int32"), Tensor([2, 429496730, 5],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 29427 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:22:47.939790 144229 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:22:47.940877 144229 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_xor(Tensor([2, 3, 5],"int32"), Tensor([286331153, 3, 5],"int32"), )
[torch error] paddle.bitwise_xor(Tensor([2, 3, 5],"int32"), Tensor([286331153, 3, 5],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 96415 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:24:00.601676 144518 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:24:00.602794 144518 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_xor(Tensor([2, 3, 715827883],"int32"), Tensor([2, 3, 5],"int32"), )
[torch error] paddle.bitwise_xor(Tensor([2, 3, 715827883],"int32"), Tensor([2, 3, 5],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 147007 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:25:14.513676 144714 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:25:14.514897 144714 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_xor(Tensor([2, 3, 715827883],"int32"), Tensor([2, 3, 715827883],"int32"), )
[torch error] paddle.bitwise_xor(Tensor([2, 3, 715827883],"int32"), Tensor([2, 3, 715827883],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 44586 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:26:27.820765 144990 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:26:27.821738 144990 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_xor(Tensor([2, 429496730, 5],"int32"), Tensor([2, 3, 5],"int32"), )
[torch error] paddle.bitwise_xor(Tensor([2, 429496730, 5],"int32"), Tensor([2, 3, 5],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 98561 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:27:34.392226 145199 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:27:34.393318 145199 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_xor(Tensor([2, 429496730, 5],"int32"), Tensor([2, 429496730, 5],"int32"), )
[torch error] paddle.bitwise_xor(Tensor([2, 429496730, 5],"int32"), Tensor([2, 429496730, 5],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 146187 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:28:46.742211 145474 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:28:46.743212 145474 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_xor(Tensor([286331153, 3, 5],"int32"), Tensor([2, 3, 5],"int32"), )
[torch error] paddle.bitwise_xor(Tensor([286331153, 3, 5],"int32"), Tensor([2, 3, 5],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 48842 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:29:53.832509 145657 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:29:53.833544 145657 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_xor(Tensor([286331153, 3, 5],"int32"), Tensor([286331153, 3, 5],"int32"), )
[torch error] paddle.bitwise_xor(Tensor([286331153, 3, 5],"int32"), Tensor([286331153, 3, 5],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 101408 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:31:07.637740 145865 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:31:07.638952 145865 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_xor(Tensor([3, 1431655765, 1],"int32"), Tensor([3, 1431655765, 1],"int32"), )
[torch error] paddle.bitwise_xor(Tensor([3, 1431655765, 1],"int32"), Tensor([3, 1431655765, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 152650 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:32:14.157788 146161 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:32:14.158795 146161 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_xor(Tensor([3, 1431655765, 1],"int32"), Tensor([3, 4, 1],"int32"), )
[torch error] paddle.bitwise_xor(Tensor([3, 1431655765, 1],"int32"), Tensor([3, 4, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 48469 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:33:26.320942 146358 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:33:26.322096 146358 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_xor(Tensor([3, 4, 1],"int32"), Tensor([1073741824, 4, 1],"int32"), )
[torch error] paddle.bitwise_xor(Tensor([3, 4, 1],"int32"), Tensor([1073741824, 4, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 95910 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:34:42.267024 146684 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:34:42.268194 146684 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_xor(Tensor([3, 4, 1],"int32"), Tensor([3, 1431655765, 1],"int32"), )
[torch error] paddle.bitwise_xor(Tensor([3, 4, 1],"int32"), Tensor([3, 1431655765, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 159521 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:35:54.568261 147610 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:35:54.569249 147610 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_xor(Tensor([3, 4, 1],"int32"), Tensor([3, 4, 357913942],"int32"), )
[torch error] paddle.bitwise_xor(Tensor([3, 4, 1],"int32"), Tensor([3, 4, 357913942],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 54430 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:37:04.726444 147910 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:37:04.727454 147910 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_xor(Tensor([3, 4, 357913942],"int32"), Tensor([3, 4, 1],"int32"), )
[torch error] paddle.bitwise_xor(Tensor([3, 4, 357913942],"int32"), Tensor([3, 4, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 103622 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:38:12.879660 148374 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:38:12.893457 148374 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bitwise_xor(Tensor([3, 4, 357913942],"int32"), Tensor([3, 4, 357913942],"int32"), )
[torch error] paddle.bitwise_xor(Tensor([3, 4, 357913942],"int32"), Tensor([3, 4, 357913942],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 161150 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:39:20.569031 149278 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:39:20.570158 149278 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bmm(Tensor([2, 2, 1073741824],"float32"), Tensor([2, 3, 1073741824],"float32"), )
[torch error] paddle.bmm(Tensor([2, 2, 1073741824],"float32"), Tensor([2, 3, 1073741824],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 41269 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:40:32.434737 150133 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:40:32.435843 150133 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bmm(Tensor([2, 2, 1073741824],"float32"), Tensor([2, 3, 2],"float32"), )
[torch error] paddle.bmm(Tensor([2, 2, 1073741824],"float32"), Tensor([2, 3, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 84264 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:41:42.062942 150421 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:41:42.064057 150421 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bmm(Tensor([2, 2, 3],"float32"), Tensor([2, 1073741824, 2],"float32"), )
[torch error] paddle.bmm(Tensor([2, 2, 3],"float32"), Tensor([2, 1073741824, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 137507 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:42:51.236703 150712 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:42:51.237787 150712 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bmm(Tensor([2, 2, 3],"float32"), Tensor([2, 3, 715827883],"float32"), )
[torch error] paddle.bmm(Tensor([2, 2, 3],"float32"), Tensor([2, 3, 715827883],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 24609 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:44:03.495072 150910 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:44:03.496205 150910 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bmm(Tensor([2, 2, 3],"float32"), Tensor([715827883, 3, 2],"float32"), )
[torch error] paddle.bmm(Tensor([2, 2, 3],"float32"), Tensor([715827883, 3, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 65418 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:45:13.305567 151201 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:45:13.306672 151201 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bmm(Tensor([2, 715827883, 3],"float32"), Tensor([2, 3, 2],"float32"), )
[torch error] paddle.bmm(Tensor([2, 715827883, 3],"float32"), Tensor([2, 3, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 120197 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:46:23.659356 151410 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:46:23.660432 151410 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bmm(Tensor([2, 715827883, 3],"float32"), Tensor([2, 715827883, 2],"float32"), )
[torch error] paddle.bmm(Tensor([2, 715827883, 3],"float32"), Tensor([2, 715827883, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 5011 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:47:35.789439 151606 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:47:35.790472 151606 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bmm(Tensor([2147484, 40, 50],"float32"), Tensor([2147484, 50, 60],"float32"), )
[torch error] paddle.bmm(Tensor([2147484, 40, 50],"float32"), Tensor([2147484, 50, 60],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 45501 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:48:46.385946 151882 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:48:46.387023 151882 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bmm(Tensor([2147484, 40, 50],"float32"), Tensor([30, 50, 60],"float32"), )
[torch error] paddle.bmm(Tensor([2147484, 40, 50],"float32"), Tensor([30, 50, 60],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 103279 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:49:54.242027 152082 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:49:54.243088 152082 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bmm(Tensor([30, 2863312, 50],"float32"), Tensor([30, 2863312, 60],"float32"), )
[torch error] paddle.bmm(Tensor([30, 2863312, 50],"float32"), Tensor([30, 2863312, 60],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 151097 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:51:05.328881 152272 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:51:05.329964 152272 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bmm(Tensor([30, 2863312, 50],"float32"), Tensor([30, 50, 60],"float32"), )
[torch error] paddle.bmm(Tensor([30, 2863312, 50],"float32"), Tensor([30, 50, 60],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 34046 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:52:12.199076 152547 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:52:12.200155 152547 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bmm(Tensor([30, 40, 3579140],"float32"), Tensor([30, 50, 3579140],"float32"), )
[torch error] paddle.bmm(Tensor([30, 40, 3579140],"float32"), Tensor([30, 50, 3579140],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 86391 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:53:25.176498 152756 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:53:25.177703 152756 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bmm(Tensor([30, 40, 3579140],"float32"), Tensor([30, 50, 60],"float32"), )
[torch error] paddle.bmm(Tensor([30, 40, 3579140],"float32"), Tensor([30, 50, 60],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 129058 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:54:31.980079 152953 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:54:31.981082 152953 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bmm(Tensor([30, 40, 50],"float32"), Tensor([1431656, 50, 60],"float32"), )
[torch error] paddle.bmm(Tensor([30, 40, 50],"float32"), Tensor([1431656, 50, 60],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 6436 has 1016.00 MiB memory in use. Of the allocated memory 234.50 KiB is allocated by PyTorch, and 1.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:55:42.642064 153148 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:55:42.643170 153148 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bmm(Tensor([30, 40, 50],"float32"), Tensor([30, 2386093, 60],"float32"), )
[torch error] paddle.bmm(Tensor([30, 40, 50],"float32"), Tensor([30, 2386093, 60],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 62857 has 1016.00 MiB memory in use. Of the allocated memory 234.50 KiB is allocated by PyTorch, and 1.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:56:49.016666 153437 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:56:49.020586 153437 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bmm(Tensor([30, 40, 50],"float32"), Tensor([30, 50, 2863312],"float32"), )
[torch error] paddle.bmm(Tensor([30, 40, 50],"float32"), Tensor([30, 50, 2863312],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 112877 has 1016.00 MiB memory in use. Of the allocated memory 234.50 KiB is allocated by PyTorch, and 1.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:58:01.102851 153620 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:58:01.105926 153620 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bmm(Tensor([715827883, 2, 3],"float32"), Tensor([2, 3, 2],"float32"), )
[torch error] paddle.bmm(Tensor([715827883, 2, 3],"float32"), Tensor([2, 3, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 157359 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:59:09.722786 153828 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:59:09.723922 153828 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.bmm(Tensor([715827883, 2, 3],"float32"), Tensor([715827883, 3, 2],"float32"), )
[torch error] paddle.bmm(Tensor([715827883, 2, 3],"float32"), Tensor([715827883, 3, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 48352 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:00:23.399143 154112 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:00:23.400156 154112 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1, 1, 1, 4294967295],"int32"), tuple(10,10,1,10,), )
[torch error] paddle.broadcast_to(Tensor([1, 1, 1, 4294967295],"int32"), tuple(10,10,1,10,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 91762 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:01:31.329831 154319 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:01:31.331229 154319 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1, 1, 2147483649],"float64"), list[4,5,6,], )
[torch error] paddle.broadcast_to(Tensor([1, 1, 2147483649],"float64"), list[4,5,6,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 132742 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:02:21.041676 154538 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:02:21.042690 154538 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1, 1, 2147483649],"int64"), tuple(3,2,3,), )
[torch error] paddle.broadcast_to(Tensor([1, 1, 2147483649],"int64"), tuple(3,2,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 7820 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:03:04.379063 154721 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:03:04.380235 154721 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1, 1, 4294967295, 1],"int32"), tuple(10,10,1,10,), )
[torch error] paddle.broadcast_to(Tensor([1, 1, 4294967295, 1],"int32"), tuple(10,10,1,10,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 33529 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:04:11.087905 154912 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:04:11.088958 154912 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1, 1, 4294967295],"bool"), list[4,5,6,], )
[torch error] paddle.broadcast_to(Tensor([1, 1, 4294967295],"bool"), list[4,5,6,], ) 
 The expanded size of the tensor (6) must match the existing size (4294967295) at non-singleton dimension 2.  Target sizes: [4, 5, 6].  Tensor sizes: [1, 1, 4294967295]

W0205 15:05:15.945118 155122 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:05:15.946306 155122 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1, 1073741824, 4],"int32"), tuple(1,3,4,), )
[torch error] paddle.broadcast_to(Tensor([1, 1073741824, 4],"int32"), tuple(1,3,4,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 127915 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:06:25.953269 155307 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:06:25.954475 155307 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1, 1073741825, 2],"int64"), tuple(4,3,2,), )
[torch error] paddle.broadcast_to(Tensor([1, 1073741825, 2],"int64"), tuple(4,3,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 17499 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:07:10.149706 155503 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:07:10.150823 155503 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1, 2147483649, 1],"float64"), list[4,5,6,], )
[torch error] paddle.broadcast_to(Tensor([1, 2147483649, 1],"float64"), list[4,5,6,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 54124 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:08:00.431317 155694 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:08:00.432411 155694 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1, 2147483649],"int64"), tuple(1,3,), )
[torch error] paddle.broadcast_to(Tensor([1, 2147483649],"int64"), tuple(1,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 81480 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:08:46.193303 155808 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:08:46.194289 155808 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1, 2147483649],"int64"), tuple(3,3,), )
[torch error] paddle.broadcast_to(Tensor([1, 2147483649],"int64"), tuple(3,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 114509 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:09:38.299854 155991 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:09:38.300925 155991 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1, 3, 1431655765],"int32"), tuple(1,3,4,), )
[torch error] paddle.broadcast_to(Tensor([1, 3, 1431655765],"int32"), tuple(1,3,4,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 146616 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:10:54.111092 156197 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:10:54.112124 156197 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1, 3, 715827883],"int64"), tuple(4,3,2,), )
[torch error] paddle.broadcast_to(Tensor([1, 3, 715827883],"int64"), tuple(4,3,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 41090 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:11:42.317456 156392 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:11:42.318532 156392 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1, 357913942, 6],"float64"), list[4,5,6,], )
[torch error] paddle.broadcast_to(Tensor([1, 357913942, 6],"float64"), list[4,5,6,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 71160 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:12:27.064642 156585 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:12:27.065857 156585 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1, 4294967295, 1, 1],"int32"), tuple(10,10,1,10,), )
[torch error] paddle.broadcast_to(Tensor([1, 4294967295, 1, 1],"int32"), tuple(10,10,1,10,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 98683 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:13:34.320387 156710 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:13:34.321336 156710 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1, 4294967295],"bool"), list[3,3,], )
[torch error] paddle.broadcast_to(Tensor([1, 4294967295],"bool"), list[3,3,], ) 
 The expanded size of the tensor (3) must match the existing size (4294967295) at non-singleton dimension 1.  Target sizes: [3, 3].  Tensor sizes: [1, 4294967295]

W0205 15:14:44.088578 156988 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:14:44.089764 156988 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1, 4294967295],"float32"), tuple(1,3,), )
[torch error] paddle.broadcast_to(Tensor([1, 4294967295],"float32"), tuple(1,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 30045 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:15:59.545397 157182 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:15:59.546471 157182 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1, 4294967295],"int32"), tuple(1,3,), )
[torch error] paddle.broadcast_to(Tensor([1, 4294967295],"int32"), tuple(1,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 84051 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:17:13.123149 157391 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:17:13.124150 157391 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1, 5, 429496730],"float64"), list[4,5,6,], )
[torch error] paddle.broadcast_to(Tensor([1, 5, 429496730],"float64"), list[4,5,6,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 141168 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:17:58.137918 157654 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:17:58.139122 157654 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1, 5, 858993459],"int32"), tuple(1,5,5,), )
[torch error] paddle.broadcast_to(Tensor([1, 5, 858993459],"int32"), tuple(1,5,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 3917 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:19:11.042057 157766 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:19:11.043056 157766 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1, 715827883, 3],"int64"), tuple(3,2,3,), )
[torch error] paddle.broadcast_to(Tensor([1, 715827883, 3],"int64"), tuple(3,2,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 58721 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:19:56.600972 158073 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:19:56.601913 158073 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1, 715827883, 6],"bool"), list[4,5,6,], )
[torch error] paddle.broadcast_to(Tensor([1, 715827883, 6],"bool"), list[4,5,6,], ) 
 The expanded size of the tensor (5) must match the existing size (715827883) at non-singleton dimension 1.  Target sizes: [4, 5, 6].  Tensor sizes: [1, 715827883, 6]

W0205 15:21:09.745481 158176 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:21:09.746686 158176 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1, 858993459, 5],"int32"), tuple(1,5,5,), )
[torch error] paddle.broadcast_to(Tensor([1, 858993459, 5],"int32"), tuple(1,5,5,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 138829 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:22:30.888825 158466 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:22:30.889843 158466 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([10, 1, 214748365],"float64"), tuple(10,1,10,), )
[torch error] paddle.broadcast_to(Tensor([10, 1, 214748365],"float64"), tuple(10,1,10,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 24298 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:23:15.882798 158665 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:23:15.883846 158665 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([10, 1, 214748365],"int64"), tuple(10,1,10,), )
[torch error] paddle.broadcast_to(Tensor([10, 1, 214748365],"int64"), tuple(10,1,10,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 61627 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:24:00.181944 158858 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:24:00.182971 158858 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([10, 1, 429496730],"float16"), tuple(10,1,10,), )
[torch error] paddle.broadcast_to(Tensor([10, 1, 429496730],"float16"), tuple(10,1,10,), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 87918 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:25:27.343519 158982 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:25:27.344517 158982 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([10, 1, 429496730],"float32"), list[10,20,1,], )
[torch error] paddle.broadcast_to(Tensor([10, 1, 429496730],"float32"), list[10,20,1,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 144502 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:26:33.787012 159275 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:26:33.788399 159275 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([10, 1, 429496730],"float32"), tuple(10,1,10,), )
[torch error] paddle.broadcast_to(Tensor([10, 1, 429496730],"float32"), tuple(10,1,10,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 28680 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:27:42.382455 159551 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:27:42.383455 159551 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([10, 1, 429496730],"int32"), tuple(10,1,10,), )
[torch error] paddle.broadcast_to(Tensor([10, 1, 429496730],"int32"), tuple(10,1,10,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 79406 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:28:56.178155 159759 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:28:56.179102 159759 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([10, 21474837, 10],"float64"), tuple(10,1,10,), )
[torch error] paddle.broadcast_to(Tensor([10, 21474837, 10],"float64"), tuple(10,1,10,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 133763 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:29:46.149338 159968 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:29:46.150292 159968 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([10, 21474837, 10],"int64"), tuple(10,1,10,), )
[torch error] paddle.broadcast_to(Tensor([10, 21474837, 10],"int64"), tuple(10,1,10,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 163359 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:30:34.449865 160164 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:30:34.450876 160164 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([10, 42949673, 10],"float16"), tuple(10,1,10,), )
[torch error] paddle.broadcast_to(Tensor([10, 42949673, 10],"float16"), tuple(10,1,10,), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 27490 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:31:55.188900 160376 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:31:55.190037 160376 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([10, 42949673, 10],"float32"), tuple(10,1,10,), )
[torch error] paddle.broadcast_to(Tensor([10, 42949673, 10],"float32"), tuple(10,1,10,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 90491 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:33:05.880306 160604 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:33:05.885475 160604 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([10, 42949673, 10],"int32"), tuple(10,1,10,), )
[torch error] paddle.broadcast_to(Tensor([10, 42949673, 10],"int32"), tuple(10,1,10,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 132695 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:34:24.322908 160907 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:34:24.323901 160907 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([10, 429496730, 1],"float32"), list[10,20,1,], )
[torch error] paddle.broadcast_to(Tensor([10, 429496730, 1],"float32"), list[10,20,1,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 23059 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:35:31.976147 161119 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:35:31.977298 161119 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([10, 429496730],"int32"), list[10,20,], )
[torch error] paddle.broadcast_to(Tensor([10, 429496730],"int32"), list[10,20,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 65706 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:36:39.233597 161320 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:36:39.234645 161320 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([100, 21474837],"float64"), list[100,100,], )
[torch error] paddle.broadcast_to(Tensor([100, 21474837],"float64"), list[100,100,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 125995 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:37:29.089977 161595 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:37:29.090986 161595 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([102261127, 6, 7],"float32"), tuple(5,6,7,), )
[torch error] paddle.broadcast_to(Tensor([102261127, 6, 7],"float32"), tuple(5,6,7,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 6.39 GiB is free. Process 112603 has 418.00 MiB memory in use. Process 4110 has 71.38 GiB memory in use. Process 160321 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:38:37.119066 161698 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:38:37.120064 161698 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.broadcast_to(Tensor([1073741824, 1, 4],"bool"), list[2,2,4,], )
[torch error] paddle.broadcast_to(Tensor([1073741824, 1, 4],"bool"), list[2,2,4,], ) 
 The expanded size of the tensor (2) must match the existing size (1073741824) at non-singleton dimension 0.  Target sizes: [2, 2, 4].  Tensor sizes: [1073741824, 1, 4]

W0205 15:39:43.468051 162023 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:39:43.469141 162023 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

Traceback (most recent call last):
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 70, in <module>
    main()
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 65, in main
    print(str(res.stdout.read(), encoding="utf-8"), flush=True)
KeyboardInterrupt
