test begin: paddle.fmin(Tensor([10, 15],"float32"), Tensor([4294967295],"float32"), )
[torch error] paddle.fmin(Tensor([10, 15],"float32"), Tensor([4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 40164 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:07:13.604380 102014 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:07:13.605454 102014 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.poisson(Tensor([10, 429496730],"float32"), )
[torch error] paddle.poisson(Tensor([10, 429496730],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 105495 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:08:27.012913 102908 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:08:27.013948 102908 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.poisson(Tensor([16, 1024, 262144],"float32"), )
[torch error] paddle.poisson(Tensor([16, 1024, 262144],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 1719 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:09:40.879324 103551 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:09:40.880463 103551 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.poisson(Tensor([16, 262144, 1024],"float32"), )
[torch error] paddle.poisson(Tensor([16, 262144, 1024],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 50944 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:10:56.931738 104435 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:10:56.932718 104435 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.poisson(Tensor([1821, 3, 1024, 768],"float32"), )
[torch error] paddle.poisson(Tensor([1821, 3, 1024, 768],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.01 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 117598 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:12:10.262671 105114 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:12:10.263856 105114 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.poisson(Tensor([2147483648, 2],"float32"), )
[torch error] paddle.poisson(Tensor([2147483648, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 14795 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:13:23.455276 106024 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:13:23.456357 106024 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.poisson(Tensor([2147483649, 1],"float64"), )
[torch error] paddle.poisson(Tensor([2147483649, 1],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 76254 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:14:12.470863 106676 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:14:12.471938 106676 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.poisson(Tensor([2147483649],"float64"), )
[torch error] paddle.poisson(Tensor([2147483649],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 112412 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:15:03.778281 107296 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:15:03.779724 107296 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.poisson(Tensor([32, 171, 1024, 768],"float32"), )
[torch error] paddle.poisson(Tensor([32, 171, 1024, 768],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.03 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 152407 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:16:16.896224 107916 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:16:16.897292 107916 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.poisson(Tensor([32, 3, 1024, 43691],"float32"), )
[torch error] paddle.poisson(Tensor([32, 3, 1024, 43691],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 61972 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:17:27.941188 108574 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:17:27.942222 108574 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.poisson(Tensor([32, 3, 58255, 768],"float32"), )
[torch error] paddle.poisson(Tensor([32, 3, 58255, 768],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 116405 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:18:40.087833 109197 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:18:40.088909 109197 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.poisson(Tensor([4096, 1024, 1024],"float32"), )
[torch error] paddle.poisson(Tensor([4096, 1024, 1024],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 1001 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:19:51.583750 110117 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:19:51.584767 110117 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.poisson(Tensor([4294967295],"float32"), )
[torch error] paddle.poisson(Tensor([4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 62341 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:21:05.834672 110791 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:21:05.835668 110791 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.poisson(Tensor([429496730, 10],"float32"), )
[torch error] paddle.poisson(Tensor([429496730, 10],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 122719 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:22:17.392884 111700 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:22:17.393965 111700 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.poisson(Tensor([5000, 429497],"float64"), )
[torch error] paddle.poisson(Tensor([5000, 429497],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 28183 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:23:09.630847 112345 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:23:09.631965 112345 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.poisson(Tensor([5000, 858994],"float32"), )
[torch error] paddle.poisson(Tensor([5000, 858994],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 61488 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:24:28.512568 112984 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:24:28.513700 112984 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.polygamma(Tensor([10, 20, 21474837],"float32"), 1, )
[torch error] paddle.polygamma(Tensor([10, 20, 21474837],"float32"), 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 131278 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:25:40.218391 113657 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:25:40.219468 113657 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.polygamma(Tensor([10, 429496730, 1],"float32"), 1, )
[torch error] paddle.polygamma(Tensor([10, 429496730, 1],"float32"), 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 20594 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:26:52.569288 114577 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:26:52.570405 114577 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.polygamma(Tensor([178956971, 2, 6],"float64"), 2, )
[torch error] paddle.polygamma(Tensor([178956971, 2, 6],"float64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 86839 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:27:42.808498 115237 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:27:42.809641 115237 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.polygamma(Tensor([2, 1073741825],"float64"), 1, )
[torch error] paddle.polygamma(Tensor([2, 1073741825],"float64"), 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 120010 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:28:33.756006 115851 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:28:33.757010 115851 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.polygamma(Tensor([2, 178956971, 6],"float64"), 2, )
[torch error] paddle.polygamma(Tensor([2, 178956971, 6],"float64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 3010 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:29:23.964875 116477 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:29:23.965975 116477 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.polygamma(Tensor([2, 2, 536870913],"float64"), 2, )
[torch error] paddle.polygamma(Tensor([2, 2, 536870913],"float64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 47237 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:30:16.605120 116849 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:30:16.606177 116849 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.polygamma(Tensor([2147483649],"float64"), 1, )
[torch error] paddle.polygamma(Tensor([2147483649],"float64"), 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 94296 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:31:07.037875 117463 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:31:07.038949 117463 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.polygamma(Tensor([2147483649],"float64"), 2, )
[torch error] paddle.polygamma(Tensor([2147483649],"float64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 127361 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:32:00.115509 118092 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:32:00.116524 118092 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.polygamma(Tensor([2147483649],"float64"), 3, )
[torch error] paddle.polygamma(Tensor([2147483649],"float64"), 3, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 3331 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:32:50.497669 118724 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:32:50.498749 118724 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.polygamma(Tensor([214748365, 20, 1],"float32"), 1, )
[torch error] paddle.polygamma(Tensor([214748365, 20, 1],"float32"), 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 47640 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:34:10.628564 119100 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:34:10.629645 119100 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.polygamma(Tensor([357913942, 6],"float64"), 1, )
[torch error] paddle.polygamma(Tensor([357913942, 6],"float64"), 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 111384 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:35:00.565834 120204 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:35:00.566903 120204 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.polygamma(Tensor([4294967295],"float32"), 1, )
[torch error] paddle.polygamma(Tensor([4294967295],"float32"), 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 148829 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:36:14.661592 120830 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:36:14.662693 120830 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.polygamma(Tensor([4294967295],"float32"), 2, )
[torch error] paddle.polygamma(Tensor([4294967295],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 55881 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:37:27.550675 121673 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:37:27.551712 121673 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.polygamma(Tensor([4294967295],"float32"), 3, )
[torch error] paddle.polygamma(Tensor([4294967295],"float32"), 3, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 118018 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:38:37.564106 122342 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:38:37.565291 122342 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1, 1025, 4190212],"float32"), 2.0, )
[torch error] paddle.pow(Tensor([1, 1025, 4190212],"float32"), 2.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 8144 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:39:49.576915 123256 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:39:49.577924 123256 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1, 10250519, 419],"float32"), 2.0, )
[torch error] paddle.pow(Tensor([1, 10250519, 419],"float32"), 2.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 69611 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:41:05.478600 123934 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:41:05.479689 123934 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1, 107374183, 4, 10],"float32"), 2, )
[torch error] paddle.pow(Tensor([1, 107374183, 4, 10],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 129454 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:42:17.963101 124865 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:42:17.964217 124865 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1, 14608733, 294],"float32"), 2.0, )
[torch error] paddle.pow(Tensor([1, 14608733, 294],"float32"), 2.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 32055 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:43:30.629746 125538 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:43:30.630750 125538 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1, 21, 204522253],"float32"), 1.0, )
[torch error] paddle.pow(Tensor([1, 21, 204522253],"float32"), 1.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 84809 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:44:49.026643 126458 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:44:49.027669 126458 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1, 2492727, 1723],"float32"), 2.0, )
[torch error] paddle.pow(Tensor([1, 2492727, 1723],"float32"), 2.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 150048 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:45:59.673985 127130 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:45:59.675041 127130 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1, 257, 16711935],"float32"), 2.0, )
[torch error] paddle.pow(Tensor([1, 257, 16711935],"float32"), 2.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 43135 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:47:11.849623 127789 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:47:11.850683 127789 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1, 3, 143165577, 10],"float32"), 2, )
[torch error] paddle.pow(Tensor([1, 3, 143165577, 10],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 104722 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:48:29.318439 128712 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:48:29.319412 128712 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1, 3, 4, 178956971],"float64"), 2, )
[torch error] paddle.pow(Tensor([1, 3, 4, 178956971],"float64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 7501 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:49:19.897162 129397 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:49:19.898257 129397 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1, 3, 4, 357913942],"float32"), 2, )
[torch error] paddle.pow(Tensor([1, 3, 4, 357913942],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 51578 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:50:32.945978 130005 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:50:32.947005 130005 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1, 3, 71582789, 10],"float64"), 2, )
[torch error] paddle.pow(Tensor([1, 3, 71582789, 10],"float64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 103365 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:51:24.695851 130926 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:51:24.696919 130926 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1, 32292988, 133],"float32"), 1.0, )
[torch error] paddle.pow(Tensor([1, 32292988, 133],"float32"), 1.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 149595 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:52:36.272370 131305 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:52:36.273527 131305 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1, 33, 130150525],"float32"), 1.0, )
[torch error] paddle.pow(Tensor([1, 33, 130150525],"float32"), 1.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 36419 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:53:49.523874 132254 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:53:49.524891 132254 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1, 34636834, 124],"float32"), 1.0, )
[torch error] paddle.pow(Tensor([1, 34636834, 124],"float32"), 1.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 105839 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:55:02.413156 133261 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:55:02.414268 133261 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1, 35791395, 120],"float32"), 1.0, )
[torch error] paddle.pow(Tensor([1, 35791395, 120],"float32"), 1.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 158948 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:56:14.636427 134193 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:56:14.637535 134193 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1, 35791395, 120],"float32"), 2.0, )
[torch error] paddle.pow(Tensor([1, 35791395, 120],"float32"), 2.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 64500 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:57:27.706252 134872 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:57:27.707265 134872 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1, 38347923, 112],"float32"), 1.0, )
[torch error] paddle.pow(Tensor([1, 38347923, 112],"float32"), 1.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 127139 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:58:45.188746 135551 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:58:45.189823 135551 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1, 38347923, 112],"float32"), 2.0, )
[torch error] paddle.pow(Tensor([1, 38347923, 112],"float32"), 2.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 22026 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 14:59:59.925190 136474 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 14:59:59.926294 136474 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1, 40904451, 105],"float32"), 2.0, )
[torch error] paddle.pow(Tensor([1, 40904451, 105],"float32"), 2.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 77772 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:01:09.903251 137142 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:01:09.904332 137142 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1, 53687092, 4, 10],"float64"), 2, )
[torch error] paddle.pow(Tensor([1, 53687092, 4, 10],"float64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 134719 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:02:03.625772 138044 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:02:03.626744 138044 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1, 58040099, 74],"float32"), 2.0, )
[torch error] paddle.pow(Tensor([1, 58040099, 74],"float32"), 2.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 14047 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:03:20.064873 138677 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:03:20.065847 138677 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1, 8103712, 530],"float32"), 2.0, )
[torch error] paddle.pow(Tensor([1, 8103712, 530],"float32"), 2.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 84160 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:04:36.947007 139356 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:04:36.947973 139356 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1, 8711902, 493],"float32"), 2.0, )
[torch error] paddle.pow(Tensor([1, 8711902, 493],"float32"), 2.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 139406 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:05:53.172729 140295 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:05:53.173697 140295 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1, 8947849, 480],"float32"), 2.0, )
[torch error] paddle.pow(Tensor([1, 8947849, 480],"float32"), 2.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 43974 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:07:04.803226 140948 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:07:04.804239 140948 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1, 9586981, 448],"float32"), 2.0, )
[torch error] paddle.pow(Tensor([1, 9586981, 448],"float32"), 2.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 98625 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:08:21.606761 141881 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:08:21.607754 141881 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1, 9965122, 431],"float32"), 1.0, )
[torch error] paddle.pow(Tensor([1, 9965122, 431],"float32"), 1.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 7796 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:09:32.075136 142533 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:09:32.076200 142533 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1, 9965122, 431],"float32"), 2.0, )
[torch error] paddle.pow(Tensor([1, 9965122, 431],"float32"), 2.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 58999 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:10:53.935286 143433 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:10:53.936324 143433 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([10, 20, 21474837],"float32"), 2, )
[torch error] paddle.pow(Tensor([10, 20, 21474837],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 129147 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:12:13.865366 144105 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:12:13.866459 144105 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([10, 429496730, 1],"float32"), 2, )
[torch error] paddle.pow(Tensor([10, 429496730, 1],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 30630 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:13:24.653702 145032 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:13:24.654695 145032 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([10, 429496730],"float32"), 2, )
[torch error] paddle.pow(Tensor([10, 429496730],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 91240 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:14:42.130858 145691 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:14:42.131932 145691 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([10, 429496730],"float32"), 2.7, )
[torch error] paddle.pow(Tensor([10, 429496730],"float32"), 2.7, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 145433 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:15:53.581950 146657 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:15:53.583019 146657 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1000, 4294968],"float32"), 2, )
[torch error] paddle.pow(Tensor([1000, 4294968],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 50000 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:17:04.118455 147328 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:17:04.119879 147328 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([10000, 143166, 3],"float32"), 2, )
[torch error] paddle.pow(Tensor([10000, 143166, 3],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 103862 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:18:15.548593 148226 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:18:15.549687 148226 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([10000, 2, 107375],"float64"), 2, )
[torch error] paddle.pow(Tensor([10000, 2, 107375],"float64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 10674 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:19:08.019260 148902 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:19:08.020771 148902 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([10000, 2, 214749],"float32"), 2, )
[torch error] paddle.pow(Tensor([10000, 2, 214749],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 42369 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:20:26.522703 149516 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:20:26.523691 149516 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([10000, 71583, 3],"float64"), 2, )
[torch error] paddle.pow(Tensor([10000, 71583, 3],"float64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 112189 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:21:20.548445 150175 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:21:20.549449 150175 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([100000, 21475],"float64"), 2, )
[torch error] paddle.pow(Tensor([100000, 21475],"float64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 159856 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:22:19.031903 150809 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:22:19.032989 150809 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1000000, 2148],"float64"), 2, )
[torch error] paddle.pow(Tensor([1000000, 2148],"float64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 44052 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:23:12.751969 151438 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:23:12.753098 151438 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1024, 1024, 2049],"float64"), 2, )
[torch error] paddle.pow(Tensor([1024, 1024, 2049],"float64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.01 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 76630 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:24:02.685427 152056 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:24:02.686625 152056 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1024, 1024, 4096],"float32"), 2, )
[torch error] paddle.pow(Tensor([1024, 1024, 4096],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 123894 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:25:22.991580 152669 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:25:22.992667 152669 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1024, 262145, 8],"float64"), 2, )
[torch error] paddle.pow(Tensor([1024, 262145, 8],"float64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 33539 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:26:12.461911 153340 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:26:12.462880 153340 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1024, 524288, 8],"float32"), 2, )
[torch error] paddle.pow(Tensor([1024, 524288, 8],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 71546 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:27:23.906656 153967 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:27:23.907789 153967 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1073741824, 2, 2],"float32"), 5, )
[torch error] paddle.pow(Tensor([1073741824, 2, 2],"float32"), 5, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 142483 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:28:40.166392 154613 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:28:40.167413 154613 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1073741824, 2, 2],"float32"), 6, )
[torch error] paddle.pow(Tensor([1073741824, 2, 2],"float32"), 6, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 31909 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:29:53.022518 155533 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:29:53.031412 155533 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1073741825, 2],"float64"), 1, )
[torch error] paddle.pow(Tensor([1073741825, 2],"float64"), 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 97785 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:30:42.901127 156185 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:30:42.902110 156185 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1073741825, 2],"float64"), 2, )
[torch error] paddle.pow(Tensor([1073741825, 2],"float64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 131712 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:31:31.064985 156792 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:31:31.066058 156792 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1162059, 33, 112],"float32"), 1.0, )
[torch error] paddle.pow(Tensor([1162059, 33, 112],"float32"), 1.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 15617 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:32:48.406453 157405 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:32:48.407534 157405 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([120, 35791395],"float32"), 2, )
[torch error] paddle.pow(Tensor([120, 35791395],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 80196 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:34:08.165511 158046 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:34:08.166559 158046 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1431655765, 3],"float32"), 2, )
[torch error] paddle.pow(Tensor([1431655765, 3],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 141063 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:35:25.453707 158927 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:35:25.454687 158927 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1431655765, 3],"float32"), Tensor([1431655765, 3],"float32"), )
[torch error] paddle.pow(Tensor([1431655765, 3],"float32"), Tensor([1431655765, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 48777 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:36:36.840169 159608 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:36:36.841233 159608 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1431655765, 3],"float32"), Tensor([3, 3],"float32"), )
[torch error] paddle.pow(Tensor([1431655765, 3],"float32"), Tensor([3, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 116477 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:37:49.797886 160509 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:37:49.798866 160509 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([16, 134217729],"float64"), 2, )
[torch error] paddle.pow(Tensor([16, 134217729],"float64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 21113 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:38:43.539992 161167 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:38:43.540942 161167 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([16, 268435456],"float32"), 2, )
[torch error] paddle.pow(Tensor([16, 268435456],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 57268 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:40:03.830945 161795 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:40:03.832016 161795 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1649374, 21, 124],"float32"), 1.0, )
[torch error] paddle.pow(Tensor([1649374, 21, 124],"float32"), 1.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 125894 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:41:20.393492 162709 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:41:20.394471 162709 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([16777216, 256],"float32"), 2, )
[torch error] paddle.pow(Tensor([16777216, 256],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 40404 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:42:37.622383 163378 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:42:37.623353 163378 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([1704353, 21, 120],"float32"), 1.0, )
[torch error] paddle.pow(Tensor([1704353, 21, 120],"float32"), 1.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 99425 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:43:47.909652   791 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:43:47.910763   791 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([17895698, 3, 4, 10],"float64"), 2, )
[torch error] paddle.pow(Tensor([17895698, 3, 4, 10],"float64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 3010 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:44:41.243033  1441 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:44:41.244021  1441 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([2, 1073741824, 2],"float32"), 5, )
[torch error] paddle.pow(Tensor([2, 1073741824, 2],"float32"), 5, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 38762 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:46:01.697979  2059 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:46:01.699047  2059 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([2, 1073741824, 2],"float32"), 6, )
[torch error] paddle.pow(Tensor([2, 1073741824, 2],"float32"), 6, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 112983 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:47:20.108727  2974 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:47:20.110067  2974 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([2, 2, 1073741824],"float32"), 5, )
[torch error] paddle.pow(Tensor([2, 2, 1073741824],"float32"), 5, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 27083 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:48:37.499539  3660 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:48:37.500646  3660 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([2, 2, 1073741824],"float32"), 6, )
[torch error] paddle.pow(Tensor([2, 2, 1073741824],"float32"), 6, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 81815 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:49:50.602317  4613 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:49:50.603404  4613 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([2, 2147483648],"float32"), 2, )
[torch error] paddle.pow(Tensor([2, 2147483648],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 148047 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:51:16.060174  5272 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:51:16.061240  5272 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([2, 2147483648],"float32"), 5, )
[torch error] paddle.pow(Tensor([2, 2147483648],"float32"), 5, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 61660 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:52:32.839880  6222 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:52:32.840865  6222 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([2, 2147483648],"float32"), 6, )
[torch error] paddle.pow(Tensor([2, 2147483648],"float32"), 6, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 119648 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:53:43.799027  7158 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:53:43.800091  7158 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([2147483648, 2],"float32"), 2, )
[torch error] paddle.pow(Tensor([2147483648, 2],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 9655 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:54:58.300617  7825 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:54:58.301687  7825 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([2147483648, 2],"float32"), 5, )
[torch error] paddle.pow(Tensor([2147483648, 2],"float32"), 5, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 77200 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:56:13.553251  8479 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:56:13.554239  8479 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([2147483648, 2],"float32"), 6, )
[torch error] paddle.pow(Tensor([2147483648, 2],"float32"), 6, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 140883 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:57:24.798166  9387 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:57:24.799161  9387 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([2147483649, 1],"float64"), 2, )
[torch error] paddle.pow(Tensor([2147483649, 1],"float64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 49471 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:58:14.150604 10042 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:58:14.151576 10042 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([2147483649],"float64"), 2, )
[torch error] paddle.pow(Tensor([2147483649],"float64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 90366 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:59:03.190124 10660 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:59:03.191345 10660 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([2147483649],"float64"), 3, )
[torch error] paddle.pow(Tensor([2147483649],"float64"), 3, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 127403 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 15:59:57.073648 11282 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 15:59:57.074561 11282 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([2147483649],"float64"), 8.902181874411676, )
[torch error] paddle.pow(Tensor([2147483649],"float64"), 8.902181874411676, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 13185 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:00:45.337831 11654 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:00:45.338994 11654 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([2147483649],"float64"), Tensor([2147483649],"float64"), )
[torch error] paddle.pow(Tensor([2147483649],"float64"), Tensor([2147483649],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 54829 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:01:33.371084 12261 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:01:33.372048 12261 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([2147483649],"float64"), Tensor([267],"float64"), )
[torch error] paddle.pow(Tensor([2147483649],"float64"), Tensor([267],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 94156 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:02:21.960665 12882 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:02:21.961629 12882 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([2147483649],"int64"), 6, )
[torch error] paddle.pow(Tensor([2147483649],"int64"), 6, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 140638 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:03:22.855115 13228 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:03:22.864908 13228 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([2147483649],"int64"), Tensor([2147483649],"int64"), )
[torch error] paddle.pow(Tensor([2147483649],"int64"), Tensor([2147483649],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 27324 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:04:13.463315 13881 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:04:13.464267 13881 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([2147483649],"int64"), Tensor([282],"int64"), )
[torch error] paddle.pow(Tensor([2147483649],"int64"), Tensor([282],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 63114 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:05:03.084710 14514 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:05:03.085803 14514 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([214748365, 20, 1],"float32"), 2, )
[torch error] paddle.pow(Tensor([214748365, 20, 1],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 103328 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:06:20.212317 15122 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:06:20.228103 15122 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([214748365, 20],"float32"), 2, )
[torch error] paddle.pow(Tensor([214748365, 20],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 20275 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:07:30.842856 15829 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:07:30.843950 15829 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([216],"int32"), Tensor([4294967295],"int32"), )
[torch error] paddle.pow(Tensor([216],"int32"), Tensor([4294967295],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 75500 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:08:42.398380 16932 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:08:42.399360 16932 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([262145, 1024, 8],"float64"), 2, )
[torch error] paddle.pow(Tensor([262145, 1024, 8],"float64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 128275 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:09:32.361320 17647 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:09:32.362356 17647 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([267],"float64"), Tensor([2147483649],"float64"), )
[torch error] paddle.pow(Tensor([267],"float64"), Tensor([2147483649],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 13539 has 1016.00 MiB memory in use. Of the allocated memory 2.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:10:20.973050 18296 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:10:20.974009 18296 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([268435456, 16],"float32"), 2, )
[torch error] paddle.pow(Tensor([268435456, 16],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 59719 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:11:33.417878 18677 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:11:33.418906 18677 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([2684355, 40, 40],"float32"), 0.75, )
[torch error] paddle.pow(Tensor([2684355, 40, 40],"float32"), 0.75, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 116639 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:12:46.382870 19618 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:12:46.383958 19618 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([280],"float32"), Tensor([4294967295],"float32"), )
[torch error] paddle.pow(Tensor([280],"float32"), Tensor([4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 16500 has 1016.00 MiB memory in use. Of the allocated memory 1.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:13:56.608354 20299 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:13:56.609364 20299 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([282],"int64"), Tensor([2147483649],"int64"), )
[torch error] paddle.pow(Tensor([282],"int64"), Tensor([2147483649],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 78292 has 1016.00 MiB memory in use. Of the allocated memory 2.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:14:47.765031 20978 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:14:47.766028 20978 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([28633116, 150],"float32"), 2, )
[torch error] paddle.pow(Tensor([28633116, 150],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 125541 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:15:59.950624 21650 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:15:59.951594 21650 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([298262, 3, 3, 40, 40],"float32"), 0.75, )
[torch error] paddle.pow(Tensor([298262, 3, 3, 40, 40],"float32"), 0.75, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 20775 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:17:10.860249 22346 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:17:10.861346 22346 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([298262, 3, 40, 40, 3],"float32"), 0.75, )
[torch error] paddle.pow(Tensor([298262, 3, 40, 40, 3],"float32"), 0.75, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 78125 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:18:22.012236 23323 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:18:22.013336 23323 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([3, 11930465, 40, 3],"float32"), 0.75, )
[torch error] paddle.pow(Tensor([3, 11930465, 40, 3],"float32"), 0.75, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 150226 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:19:35.488021 24013 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:19:35.489156 24013 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([3, 1431655765],"float32"), 2, )
[torch error] paddle.pow(Tensor([3, 1431655765],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 40589 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:20:46.820564 24963 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:20:46.821684 24963 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([3, 1431655765],"float32"), Tensor([3, 1431655765],"float32"), )
[torch error] paddle.pow(Tensor([3, 1431655765],"float32"), Tensor([3, 1431655765],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 105219 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:22:05.340188 25655 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:22:05.341178 25655 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([3, 1431655765],"float32"), Tensor([3, 3],"float32"), )
[torch error] paddle.pow(Tensor([3, 1431655765],"float32"), Tensor([3, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 161240 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:23:17.062479 26774 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:23:17.063448 26774 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([3, 298262, 3, 40, 40],"float32"), 0.75, )
[torch error] paddle.pow(Tensor([3, 298262, 3, 40, 40],"float32"), 0.75, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 70673 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:24:31.048672 27481 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:24:31.049667 27481 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([3, 298262, 40, 40, 3],"float32"), 0.75, )
[torch error] paddle.pow(Tensor([3, 298262, 40, 40, 3],"float32"), 0.75, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 129637 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:25:49.600521 28434 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:25:49.601619 28434 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([3, 3, 11930465, 40],"float32"), 0.75, )
[torch error] paddle.pow(Tensor([3, 3, 11930465, 40],"float32"), 0.75, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 36292 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:27:00.322428 29123 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:27:00.323426 29123 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([3, 3, 298262, 40, 40],"float32"), 0.75, )
[torch error] paddle.pow(Tensor([3, 3, 298262, 40, 40],"float32"), 0.75, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 92990 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:28:19.046514 29802 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:28:19.047463 29802 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([3, 3, 3, 3976822, 40],"float32"), 0.75, )
[torch error] paddle.pow(Tensor([3, 3, 3, 3976822, 40],"float32"), 0.75, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 5455 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:29:30.932958 30778 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:29:30.934000 30778 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([3, 3, 3, 40, 3976822],"float32"), 0.75, )
[torch error] paddle.pow(Tensor([3, 3, 3, 40, 3976822],"float32"), 0.75, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 63523 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:30:41.966421 31458 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:30:41.967437 31458 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([3, 3, 3976822, 40, 3],"float32"), 0.75, )
[torch error] paddle.pow(Tensor([3, 3, 3976822, 40, 3],"float32"), 0.75, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 117051 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:31:57.769299 32415 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:31:57.770365 32415 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([3, 3, 40, 11930465],"float32"), 0.75, )
[torch error] paddle.pow(Tensor([3, 3, 40, 11930465],"float32"), 0.75, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 21403 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:33:08.652417 33094 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:33:08.653429 33094 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([3, 3, 40, 3976822, 3],"float32"), 0.75, )
[torch error] paddle.pow(Tensor([3, 3, 40, 3976822, 3],"float32"), 0.75, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 73642 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:34:28.006521 34026 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:34:28.007506 34026 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([3, 3, 40, 40, 298262],"float32"), 0.75, )
[torch error] paddle.pow(Tensor([3, 3, 40, 40, 298262],"float32"), 0.75, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 153996 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:35:39.673307 34714 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:35:39.674437 34714 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([3, 3],"float32"), Tensor([1431655765, 3],"float32"), )
[torch error] paddle.pow(Tensor([3, 3],"float32"), Tensor([1431655765, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 44056 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:36:49.172317 35660 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:36:49.173332 35660 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([3, 3],"float32"), Tensor([3, 1431655765],"float32"), )
[torch error] paddle.pow(Tensor([3, 3],"float32"), Tensor([3, 1431655765],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 114156 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:38:03.511821 36329 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:38:03.512967 36329 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([3, 35791395, 40],"float32"), 0.75, )
[torch error] paddle.pow(Tensor([3, 35791395, 40],"float32"), 0.75, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 6092 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:39:20.645006 37298 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:39:20.646202 37298 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([3, 40, 11930465, 3],"float32"), 0.75, )
[torch error] paddle.pow(Tensor([3, 40, 11930465, 3],"float32"), 0.75, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 81104 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:40:37.288187 37995 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:40:37.289273 37995 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([3, 40, 35791395],"float32"), 0.75, )
[torch error] paddle.pow(Tensor([3, 40, 35791395],"float32"), 0.75, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 136391 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:41:47.690287 38976 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:41:47.691417 38976 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([3, 40, 40, 894785],"float32"), 0.75, )
[torch error] paddle.pow(Tensor([3, 40, 40, 894785],"float32"), 0.75, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 38554 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:42:58.149763 39662 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:42:58.150880 39662 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([3, 894785, 40, 40],"float32"), 0.75, )
[torch error] paddle.pow(Tensor([3, 894785, 40, 40],"float32"), 0.75, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 93156 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:44:10.011408 40331 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:44:10.012382 40331 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([3],"float32"), Tensor([4294967295],"float32"), )
[torch error] paddle.pow(Tensor([3],"float32"), Tensor([4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 149461 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:45:20.545323 41282 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:45:20.546277 41282 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([301974, 33, 431],"float32"), 1.0, )
[torch error] paddle.pow(Tensor([301974, 33, 431],"float32"), 1.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 62293 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:46:36.828791 41965 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:46:36.829943 41965 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([31532, 257, 530],"float32"), 2.0, )
[torch error] paddle.pow(Tensor([31532, 257, 530],"float32"), 2.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 125557 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:47:48.562455 42929 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:47:48.563463 42929 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([33899, 257, 493],"float32"), 2.0, )
[torch error] paddle.pow(Tensor([33899, 257, 493],"float32"), 2.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 27160 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:49:02.914669 43614 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:49:02.915840 43614 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([34087043, 9, 7],"float64"), Tensor([7],"float64"), )
[torch error] paddle.pow(Tensor([34087043, 9, 7],"float64"), Tensor([7],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 81819 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:49:52.393265 44575 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:49:52.394610 44575 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([34817, 257, 480],"float32"), 2.0, )
[torch error] paddle.pow(Tensor([34817, 257, 480],"float32"), 2.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 129598 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:51:08.846652 44948 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:51:08.847747 44948 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([34919, 1025, 120],"float32"), 2.0, )
[torch error] paddle.pow(Tensor([34919, 1025, 120],"float32"), 2.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 20272 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:52:25.548905 45904 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:52:25.550033 45904 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([357913942, 2, 3],"float64"), 2, )
[torch error] paddle.pow(Tensor([357913942, 2, 3],"float64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 96411 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:53:16.314795 46598 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:53:16.315822 46598 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([357913942, 3, 2],"float64"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.pow(Tensor([357913942, 3, 2],"float64"), Tensor([4, 3, 2],"float16"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 141950 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:54:09.828198 47251 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:54:09.829190 47251 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([357913942, 3, 2],"float64"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.pow(Tensor([357913942, 3, 2],"float64"), Tensor([4, 3, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 10082 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:55:02.952006 47909 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:55:02.953210 47909 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([357913942, 3, 2],"float64"), Tensor([715827883, 3, 2],"float16"), )
[torch error] paddle.pow(Tensor([357913942, 3, 2],"float64"), Tensor([715827883, 3, 2],"float16"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 56962 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:55:57.047628 48548 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:55:57.048624 48548 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([357913942, 3, 2],"float64"), Tensor([715827883, 3, 2],"float32"), )
[torch error] paddle.pow(Tensor([357913942, 3, 2],"float64"), Tensor([715827883, 3, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 112130 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:56:47.254393 48941 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:56:47.255421 48941 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([35791395, 120],"float32"), 2, )
[torch error] paddle.pow(Tensor([35791395, 120],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 159829 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:57:58.766176 49592 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:57:58.767174 49592 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([35791395, 3, 4, 10],"float32"), 2, )
[torch error] paddle.pow(Tensor([35791395, 3, 4, 10],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 50369 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:59:15.656849 50277 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:59:15.657938 50277 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([37304, 257, 448],"float32"), 2.0, )
[torch error] paddle.pow(Tensor([37304, 257, 448],"float32"), 2.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 122550 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:00:27.136368 51402 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:00:27.137501 51402 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([37413, 1025, 112],"float32"), 2.0, )
[torch error] paddle.pow(Tensor([37413, 1025, 112],"float32"), 2.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 18050 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:01:38.412227 52080 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:01:38.413234 52080 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([39886, 257, 419],"float32"), 2.0, )
[torch error] paddle.pow(Tensor([39886, 257, 419],"float32"), 2.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 72845 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:02:48.986754 53199 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:02:48.987860 53199 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([39907, 1025, 105],"float32"), 2.0, )
[torch error] paddle.pow(Tensor([39907, 1025, 105],"float32"), 2.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 139457 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:04:11.335359 53881 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:04:11.336357 53881 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 268435457, 2],"float64"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.pow(Tensor([4, 268435457, 2],"float64"), Tensor([4, 3, 2],"float16"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 34746 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:05:11.984349 54855 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:05:11.985332 54855 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 268435457, 2],"float64"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.pow(Tensor([4, 268435457, 2],"float64"), Tensor([4, 3, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 86388 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:06:04.118836 55512 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:06:04.119846 55512 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 268435457, 2],"float64"), Tensor([4, 536870912, 2],"float16"), )
[torch error] paddle.pow(Tensor([4, 268435457, 2],"float64"), Tensor([4, 536870912, 2],"float16"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 137191 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:06:53.651474 56163 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:06:53.652477 56163 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 268435457, 2],"float64"), Tensor([4, 536870912, 2],"float32"), )
[torch error] paddle.pow(Tensor([4, 268435457, 2],"float64"), Tensor([4, 536870912, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 23976 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:07:44.042505 56545 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:07:44.043607 56545 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.pow(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 2],"float16"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 61302 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:08:35.046208 57196 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:08:35.047345 57196 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.pow(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 106567 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:09:24.514762 57847 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:09:24.515766 57847 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 357913942],"float16"), )
[torch error] paddle.pow(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 357913942],"float16"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 153472 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:10:16.301308 58215 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:10:16.302359 58215 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 357913942],"float32"), )
[torch error] paddle.pow(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 357913942],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 32781 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:11:10.123661 58886 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:11:10.124647 58886 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 2],"float16"), Tensor([357913942, 3, 2],"float64"), )
[torch error] paddle.pow(Tensor([4, 3, 2],"float16"), Tensor([357913942, 3, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 65153 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:12:02.288056 59511 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:12:02.289145 59511 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 2],"float16"), Tensor([4, 268435457, 2],"float64"), )
[torch error] paddle.pow(Tensor([4, 3, 2],"float16"), Tensor([4, 268435457, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 116537 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:12:56.412294 60159 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:12:56.413311 60159 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 2],"float16"), Tensor([4, 3, 178956971],"float64"), )
[torch error] paddle.pow(Tensor([4, 3, 2],"float16"), Tensor([4, 3, 178956971],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 2137 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:13:48.777365 60539 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:13:48.778429 60539 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 2],"float16"), Tensor([4, 3, 357913942],"float32"), )
[torch error] paddle.pow(Tensor([4, 3, 2],"float16"), Tensor([4, 3, 357913942],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 49370 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:14:59.848273 61186 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:14:59.849356 61186 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 2],"float16"), Tensor([4, 536870912, 2],"float32"), )
[torch error] paddle.pow(Tensor([4, 3, 2],"float16"), Tensor([4, 536870912, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 105063 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:16:10.736438 62157 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:16:10.740288 62157 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 2],"float16"), Tensor([715827883, 3, 2],"float32"), )
[torch error] paddle.pow(Tensor([4, 3, 2],"float16"), Tensor([715827883, 3, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 160244 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:17:30.526594 62827 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:17:30.527698 62827 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 2],"float32"), Tensor([357913942, 3, 2],"float64"), )
[torch error] paddle.pow(Tensor([4, 3, 2],"float32"), Tensor([357913942, 3, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 82822 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:18:24.087858 63790 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:18:24.089090 63790 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 2],"float32"), Tensor([4, 268435457, 2],"float64"), )
[torch error] paddle.pow(Tensor([4, 3, 2],"float32"), Tensor([4, 268435457, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 131303 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:19:15.017014 64160 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:19:15.018004 64160 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 2],"float32"), Tensor([4, 3, 178956971],"float64"), )
[torch error] paddle.pow(Tensor([4, 3, 2],"float32"), Tensor([4, 3, 178956971],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 8272 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:20:08.933627 64792 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:20:08.934630 64792 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 2],"float32"), Tensor([4, 3, 357913942],"float16"), )
[torch error] paddle.pow(Tensor([4, 3, 2],"float32"), Tensor([4, 3, 357913942],"float16"), ) 
 The size of tensor a (2) must match the size of tensor b (357913942) at non-singleton dimension 2

W0212 17:21:54.749555 65428 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:21:54.750744 65428 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 2],"float32"), Tensor([4, 536870912, 2],"float16"), )
[torch error] paddle.pow(Tensor([4, 3, 2],"float32"), Tensor([4, 536870912, 2],"float16"), ) 
 The size of tensor a (3) must match the size of tensor b (536870912) at non-singleton dimension 1

W0212 17:23:29.202970 66414 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:23:29.204192 66414 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 2],"float32"), Tensor([715827883, 3, 2],"float16"), )
[torch error] paddle.pow(Tensor([4, 3, 2],"float32"), Tensor([715827883, 3, 2],"float16"), ) 
 The size of tensor a (4) must match the size of tensor b (715827883) at non-singleton dimension 0

W0212 17:24:58.949425 67366 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:24:58.950678 67366 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 2],"float64"), Tensor([4, 3, 357913942],"float16"), )
[torch error] paddle.pow(Tensor([4, 3, 2],"float64"), Tensor([4, 3, 357913942],"float16"), ) 
 The size of tensor a (2) must match the size of tensor b (357913942) at non-singleton dimension 2

W0212 17:26:34.177819 68342 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:26:34.179068 68342 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 2],"float64"), Tensor([4, 3, 357913942],"float32"), )
[torch error] paddle.pow(Tensor([4, 3, 2],"float64"), Tensor([4, 3, 357913942],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 65781 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:27:50.542022 69585 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:27:50.543128 69585 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 2],"float64"), Tensor([4, 536870912, 2],"float16"), )
[torch error] paddle.pow(Tensor([4, 3, 2],"float64"), Tensor([4, 536870912, 2],"float16"), ) 
 The size of tensor a (3) must match the size of tensor b (536870912) at non-singleton dimension 1

W0212 17:29:19.699369 70275 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:29:19.700701 70275 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 2],"float64"), Tensor([4, 536870912, 2],"float32"), )
[torch error] paddle.pow(Tensor([4, 3, 2],"float64"), Tensor([4, 536870912, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 43732 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:30:36.965641 71261 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:30:36.966718 71261 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 2],"float64"), Tensor([715827883, 3, 2],"float16"), )
[torch error] paddle.pow(Tensor([4, 3, 2],"float64"), Tensor([715827883, 3, 2],"float16"), ) 
 The size of tensor a (4) must match the size of tensor b (715827883) at non-singleton dimension 0

W0212 17:32:11.606679 72224 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:32:11.607978 72224 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 2],"float64"), Tensor([715827883, 3, 2],"float32"), )
[torch error] paddle.pow(Tensor([4, 3, 2],"float64"), Tensor([715827883, 3, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 13211 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:33:23.367069 73207 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:33:23.368078 73207 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 178956971],"float64"), )
[torch error] paddle.pow(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 178956971],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 89002 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:35:31.930756 74240 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:35:31.931872 74240 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.pow(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 2],"float32"), ) 
 The size of tensor a (357913942) must match the size of tensor b (2) at non-singleton dimension 2

W0212 17:37:08.453632 75817 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:37:08.455403 75817 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.pow(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 2],"float64"), ) 
 The size of tensor a (357913942) must match the size of tensor b (2) at non-singleton dimension 2

W0212 17:38:43.202482 76797 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:38:43.203863 76797 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 357913942],"float32"), )
[torch error] paddle.pow(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 357913942],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 41637 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:41:07.673810 77794 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:41:07.674908 77794 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 178956971],"float64"), )
[torch error] paddle.pow(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 178956971],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 1043 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:42:24.995076 79559 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:42:24.996143 79559 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.pow(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 2],"float16"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 71134 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:43:49.684057 80260 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:43:49.685134 80260 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.pow(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 146796 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:45:00.555707 81250 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:45:00.556741 81250 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 357913942],"float16"), )
[torch error] paddle.pow(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 357913942],"float16"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 38880 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:46:17.162580 82217 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:46:17.163548 82217 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 536870912, 2],"float16"), Tensor([4, 268435457, 2],"float64"), )
[torch error] paddle.pow(Tensor([4, 536870912, 2],"float16"), Tensor([4, 268435457, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 108978 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:48:28.609305 82906 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:48:28.610394 82906 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 536870912, 2],"float16"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.pow(Tensor([4, 536870912, 2],"float16"), Tensor([4, 3, 2],"float32"), ) 
 The size of tensor a (536870912) must match the size of tensor b (3) at non-singleton dimension 1

W0212 17:50:06.109153 84242 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:50:06.110248 84242 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 536870912, 2],"float16"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.pow(Tensor([4, 536870912, 2],"float16"), Tensor([4, 3, 2],"float64"), ) 
 The size of tensor a (536870912) must match the size of tensor b (3) at non-singleton dimension 1

W0212 17:51:42.328356 85535 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:51:42.330153 85535 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 536870912, 2],"float16"), Tensor([4, 536870912, 2],"float32"), )
[torch error] paddle.pow(Tensor([4, 536870912, 2],"float16"), Tensor([4, 536870912, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 56918 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:54:12.975911 86547 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:54:12.977042 86547 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 536870912, 2],"float32"), Tensor([4, 268435457, 2],"float64"), )
[torch error] paddle.pow(Tensor([4, 536870912, 2],"float32"), Tensor([4, 268435457, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 17937 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:55:26.744678 88186 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:55:26.746120 88186 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 536870912, 2],"float32"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.pow(Tensor([4, 536870912, 2],"float32"), Tensor([4, 3, 2],"float16"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 89527 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:56:44.887610 88857 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:56:44.888626 88857 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 536870912, 2],"float32"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.pow(Tensor([4, 536870912, 2],"float32"), Tensor([4, 3, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 161648 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:58:02.102064 89804 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:58:02.106571 89804 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4, 536870912, 2],"float32"), Tensor([4, 536870912, 2],"float16"), )
[torch error] paddle.pow(Tensor([4, 536870912, 2],"float32"), Tensor([4, 536870912, 2],"float16"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 59964 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:59:14.247720 90763 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:59:14.248792 90763 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([400, 10737419],"float32"), 2, )
[torch error] paddle.pow(Tensor([400, 10737419],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 117099 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:00:30.606073 91469 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:00:30.607175 91469 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4194304, 1024],"float32"), 2, )
[torch error] paddle.pow(Tensor([4194304, 1024],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 25841 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:01:43.474586 92408 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:01:43.493659 92408 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4294967295, 1],"float32"), 2, )
[torch error] paddle.pow(Tensor([4294967295, 1],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 78826 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:02:54.222366 93100 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:02:54.223569 93100 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4294967295],"float32"), 2, )
[torch error] paddle.pow(Tensor([4294967295],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 144944 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:04:11.335829 93780 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:04:11.336920 93780 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4294967295],"float32"), 4.0, )
[torch error] paddle.pow(Tensor([4294967295],"float32"), 4.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 38657 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:05:22.900540 94746 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:05:22.908222 94746 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4294967295],"float32"), 5, )
[torch error] paddle.pow(Tensor([4294967295],"float32"), 5, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 111026 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:06:34.369835 95426 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:06:34.370908 95426 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4294967295],"float32"), 6, )
[torch error] paddle.pow(Tensor([4294967295],"float32"), 6, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 16086 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:07:45.239266 96368 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:07:45.240367 96368 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4294967295],"float32"), Tensor([280],"float32"), )
[torch error] paddle.pow(Tensor([4294967295],"float32"), Tensor([280],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 79937 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:08:57.351122 96979 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:08:57.352274 96979 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4294967295],"float32"), Tensor([3],"float32"), )
[torch error] paddle.pow(Tensor([4294967295],"float32"), Tensor([3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 141486 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:10:09.424106 97655 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:10:09.425333 97655 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4294967295],"float32"), Tensor([4294967295],"float32"), )
[torch error] paddle.pow(Tensor([4294967295],"float32"), Tensor([4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 32802 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:11:27.609027 98616 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:11:27.610006 98616 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4294967295],"int32"), Tensor([216],"int32"), )
[torch error] paddle.pow(Tensor([4294967295],"int32"), Tensor([216],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 113475 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:12:43.247771 99323 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:12:43.248808 99323 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([4294967295],"int32"), Tensor([4294967295],"int32"), )
[torch error] paddle.pow(Tensor([4294967295],"int32"), Tensor([4294967295],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 8537 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:13:54.877521 100489 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:13:54.878531 100489 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([429496730, 10],"float32"), 2, )
[torch error] paddle.pow(Tensor([429496730, 10],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 78453 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:15:07.223757 101184 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:15:07.224834 101184 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([429496730, 10],"float32"), 2.7, )
[torch error] paddle.pow(Tensor([429496730, 10],"float32"), 2.7, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 136186 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:16:18.023245 102161 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:16:18.024459 102161 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([474530, 21, 431],"float32"), 1.0, )
[torch error] paddle.pow(Tensor([474530, 21, 431],"float32"), 1.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 45352 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:17:29.944783 102857 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:17:29.945863 102857 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([477218589, 9],"float32"), 2, )
[torch error] paddle.pow(Tensor([477218589, 9],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 114144 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:18:45.660908 103527 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:18:45.661957 103527 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([5, 429496730],"float64"), 1, )
[torch error] paddle.pow(Tensor([5, 429496730],"float64"), 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 17333 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:19:37.534032 104482 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:19:37.535030 104482 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([5, 429496730],"float64"), 2, )
[torch error] paddle.pow(Tensor([5, 429496730],"float64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 56765 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:20:28.642788 105139 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:20:28.643949 105139 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([5, 61356676, 7],"float64"), Tensor([7],"float64"), )
[torch error] paddle.pow(Tensor([5, 61356676, 7],"float64"), Tensor([7],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 105861 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:21:20.215553 105516 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:21:20.216614 105516 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([5, 858993459],"float32"), 6.996091978980955, )
[torch error] paddle.pow(Tensor([5, 858993459],"float32"), 6.996091978980955, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 153669 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:22:36.523516 106167 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:22:36.524498 106167 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([5, 9, 47721859],"float64"), Tensor([7],"float64"), )
[torch error] paddle.pow(Tensor([5, 9, 47721859],"float64"), Tensor([7],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 55989 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:23:31.388829 107162 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:23:31.389864 107162 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([5, 9, 7],"float64"), Tensor([2147483649],"float64"), )
[torch error] paddle.pow(Tensor([5, 9, 7],"float64"), Tensor([2147483649],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 107395 has 1016.00 MiB memory in use. Of the allocated memory 2.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:24:22.413738 107818 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:24:22.416396 107818 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([5000, 429497],"float64"), 2, )
[torch error] paddle.pow(Tensor([5000, 429497],"float64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 150402 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:25:15.426220 108212 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:25:15.427332 108212 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([5000, 858994],"float32"), 2, )
[torch error] paddle.pow(Tensor([5000, 858994],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 34228 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:26:33.053284 108859 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:26:33.054376 108859 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([50000, 14317, 3],"float64"), 2, )
[torch error] paddle.pow(Tensor([50000, 14317, 3],"float64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 110555 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:27:22.377229 109837 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:27:22.378302 109837 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([50000, 2, 21475],"float64"), 2, )
[torch error] paddle.pow(Tensor([50000, 2, 21475],"float64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 151005 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:28:11.114686 110207 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:28:11.115640 110207 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([50000, 85900],"float32"), 2, )
[torch error] paddle.pow(Tensor([50000, 85900],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 24296 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:29:23.677755 110853 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:29:23.678861 110853 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([51130564, 84],"float32"), 2, )
[torch error] paddle.pow(Tensor([51130564, 84],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 92974 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:30:35.086431 111553 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:30:35.087393 111553 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([524288, 1024, 8],"float32"), 2, )
[torch error] paddle.pow(Tensor([524288, 1024, 8],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 157884 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:31:46.826345 112507 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:31:46.827431 112507 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([536870913, 4],"float64"), 2, )
[torch error] paddle.pow(Tensor([536870913, 4],"float64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 62137 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:32:40.330340 113204 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:32:40.331281 113204 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([5478275, 784],"float32"), 2, )
[torch error] paddle.pow(Tensor([5478275, 784],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 101281 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:33:51.618042 113842 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:33:51.619124 113842 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([56625, 1025, 74],"float32"), 2.0, )
[torch error] paddle.pow(Tensor([56625, 1025, 74],"float32"), 2.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 7933 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:35:03.371233 114511 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:35:03.372225 114511 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([56844, 257, 294],"float32"), 2.0, )
[torch error] paddle.pow(Tensor([56844, 257, 294],"float32"), 2.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 63545 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:36:19.338466 115451 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:36:19.339457 115451 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([6, 715827883],"float32"), 2, )
[torch error] paddle.pow(Tensor([6, 715827883],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 140716 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:37:34.568626 116130 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:37:34.569706 116130 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([715827883, 2, 3],"float32"), 2, )
[torch error] paddle.pow(Tensor([715827883, 2, 3],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 47992 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:38:46.036276 117078 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:38:46.037246 117078 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([715827883, 3, 2],"float16"), Tensor([357913942, 3, 2],"float64"), )
[torch error] paddle.pow(Tensor([715827883, 3, 2],"float16"), Tensor([357913942, 3, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 115957 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:40:46.515571 117763 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:40:46.516655 117763 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([715827883, 3, 2],"float16"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.pow(Tensor([715827883, 3, 2],"float16"), Tensor([4, 3, 2],"float32"), ) 
 The size of tensor a (715827883) must match the size of tensor b (4) at non-singleton dimension 0

W0212 18:42:23.081552 119088 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:42:23.082643 119088 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([715827883, 3, 2],"float16"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.pow(Tensor([715827883, 3, 2],"float16"), Tensor([4, 3, 2],"float64"), ) 
 The size of tensor a (715827883) must match the size of tensor b (4) at non-singleton dimension 0

W0212 18:43:51.761023 120243 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:43:51.762121 120243 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([715827883, 3, 2],"float16"), Tensor([715827883, 3, 2],"float32"), )
[torch error] paddle.pow(Tensor([715827883, 3, 2],"float16"), Tensor([715827883, 3, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 56478 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:46:40.960947 121243 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:46:40.961942 121243 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([715827883, 3, 2],"float32"), Tensor([357913942, 3, 2],"float64"), )
[torch error] paddle.pow(Tensor([715827883, 3, 2],"float32"), Tensor([357913942, 3, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 42016 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:47:52.793609 123292 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:47:52.794649 123292 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([715827883, 3, 2],"float32"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.pow(Tensor([715827883, 3, 2],"float32"), Tensor([4, 3, 2],"float16"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 110797 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:49:03.295322 123981 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:49:03.296478 123981 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([715827883, 3, 2],"float32"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.pow(Tensor([715827883, 3, 2],"float32"), Tensor([4, 3, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 3351 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:50:19.561970 124937 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:50:19.562947 124937 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([715827883, 3, 2],"float32"), Tensor([715827883, 3, 2],"float16"), )
[torch error] paddle.pow(Tensor([715827883, 3, 2],"float32"), Tensor([715827883, 3, 2],"float16"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 72096 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:51:38.518124 125626 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:51:38.519227 125626 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([715827883, 3],"float64"), 2, )
[torch error] paddle.pow(Tensor([715827883, 3],"float64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 140348 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:52:32.850970 126608 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:52:32.852012 126608 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([8, 16, 33554432],"float32"), 3, )
[torch error] paddle.pow(Tensor([8, 16, 33554432],"float32"), 3, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 29117 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:53:42.991680 127260 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:53:42.992806 127260 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([8, 16777216, 32],"float32"), 3, )
[torch error] paddle.pow(Tensor([8, 16777216, 32],"float32"), 3, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 87226 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:55:00.378870 127959 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:55:00.380079 127959 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([8388608, 16, 32],"float32"), 3, )
[torch error] paddle.pow(Tensor([8388608, 16, 32],"float32"), 3, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 160545 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:56:11.793285 128752 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:56:11.794351 128752 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([8388609, 256],"float64"), 2, )
[torch error] paddle.pow(Tensor([8388609, 256],"float64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 56576 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:57:00.801679 129598 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:57:00.802657 129598 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([84, 51130564],"float32"), 2, )
[torch error] paddle.pow(Tensor([84, 51130564],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 109498 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:58:17.674793 130244 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:58:17.675809 130244 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([858993459, 5],"float32"), 2, )
[torch error] paddle.pow(Tensor([858993459, 5],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 15110 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:59:34.299254 130954 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:59:34.300312 130954 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([858993459, 5],"float32"), 6.996091978980955, )
[torch error] paddle.pow(Tensor([858993459, 5],"float32"), 6.996091978980955, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 82044 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:00:50.337704 131908 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:00:50.338755 131908 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([894785, 3, 40, 40],"float32"), 0.75, )
[torch error] paddle.pow(Tensor([894785, 3, 40, 40],"float32"), 0.75, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 151363 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:02:07.020335 132919 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:02:07.021807 132919 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([894785, 40, 40, 3],"float32"), 0.75, )
[torch error] paddle.pow(Tensor([894785, 40, 40, 3],"float32"), 0.75, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 45997 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:03:19.218243 133879 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:03:19.219200 133879 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([9700, 257, 1723],"float32"), 2.0, )
[torch error] paddle.pow(Tensor([9700, 257, 1723],"float32"), 2.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 115825 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:04:31.798101 134557 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:04:31.799135 134557 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([9723, 1025, 431],"float32"), 2.0, )
[torch error] paddle.pow(Tensor([9723, 1025, 431],"float32"), 2.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 18781 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:05:51.208940 135517 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:05:51.209894 135517 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.pow(Tensor([978576, 33, 133],"float32"), 1.0, )
[torch error] paddle.pow(Tensor([978576, 33, 133],"float32"), 1.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 94927 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:07:07.681529 136221 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:07:07.682459 136221 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([10, 10, 42949673],"float32"), )
[torch error] paddle.prod(Tensor([10, 10, 42949673],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 153839 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:08:19.563910 137168 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:08:19.565021 137168 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([10, 10, 42949673],"float32"), axis=1, )
[torch error] paddle.prod(Tensor([10, 10, 42949673],"float32"), axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 59347 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:09:38.872675 137837 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:09:38.873631 137837 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([10, 10, 42949673],"float32"), axis=-1, )
[torch error] paddle.prod(Tensor([10, 10, 42949673],"float32"), axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 130895 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:10:54.509472 138819 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:10:54.510382 138819 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([10, 10, 42949673],"float32"), axis=1, dtype="int64", )
[torch error] paddle.prod(Tensor([10, 10, 42949673],"float32"), axis=1, dtype="int64", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 38056 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:12:12.655485 139491 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:12:12.656503 139491 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([10, 10, 42949673],"float32"), axis=1, keepdim=True, )
[torch error] paddle.prod(Tensor([10, 10, 42949673],"float32"), axis=1, keepdim=True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 97332 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:13:23.973557 140441 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:13:23.974547 140441 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([10, 10, 42949673],"float32"), axis=1, keepdim=True, dtype="int64", )
[torch error] paddle.prod(Tensor([10, 10, 42949673],"float32"), axis=1, keepdim=True, dtype="int64", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 2107 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:14:49.502699 141139 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:14:49.503863 141139 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([10, 10, 42949673],"float32"), axis=list[0,1,], )
[torch error] paddle.prod(Tensor([10, 10, 42949673],"float32"), axis=list[0,1,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 85531 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:16:00.803314 142099 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:16:00.804522 142099 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([10, 2651215, 9, 9],"float64"), Tensor([2],"int64"), )
[torch error] paddle.prod(Tensor([10, 2651215, 9, 9],"float64"), Tensor([2],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 146663 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:16:51.954950 143039 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:16:51.955953 143039 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([10, 5, 4772186, 9],"float64"), Tensor([2],"int64"), )
[torch error] paddle.prod(Tensor([10, 5, 4772186, 9],"float64"), Tensor([2],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 31877 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:17:40.180702 143415 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:17:40.181649 143415 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([10, 5, 9, 4772186],"float64"), Tensor([2],"int64"), )
[torch error] paddle.prod(Tensor([10, 5, 9, 4772186],"float64"), Tensor([2],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 65420 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:18:33.011639 144042 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:18:33.012697 144042 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([10, 5, 9, 9],"float64"), Tensor([2147483649],"int64"), )
[torch error] paddle.prod(Tensor([10, 5, 9, 9],"float64"), Tensor([2147483649],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 113330 has 1016.00 MiB memory in use. Of the allocated memory 32.00 KiB is allocated by PyTorch, and 1.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:19:18.714406 144679 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:19:18.715476 144679 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([10, 85899346, 5],"float32"), )
[torch error] paddle.prod(Tensor([10, 85899346, 5],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 149445 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:20:30.921830 145040 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:20:30.922921 145040 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([10, 85899346, 5],"float32"), axis=1, )
[torch error] paddle.prod(Tensor([10, 85899346, 5],"float32"), axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 45581 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:21:45.578444 145995 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:21:45.588069 145995 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([10, 85899346, 5],"float32"), axis=-1, )
[torch error] paddle.prod(Tensor([10, 85899346, 5],"float32"), axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 104559 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:22:56.928730 146669 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:22:56.929883 146669 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([10, 85899346, 5],"float32"), axis=1, dtype="int64", )
[torch error] paddle.prod(Tensor([10, 85899346, 5],"float32"), axis=1, dtype="int64", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 2689 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:24:13.187279 147334 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:24:13.188388 147334 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([10, 85899346, 5],"float32"), axis=1, keepdim=True, )
[torch error] paddle.prod(Tensor([10, 85899346, 5],"float32"), axis=1, keepdim=True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 58289 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:25:31.189956 148312 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:25:31.191054 148312 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([10, 85899346, 5],"float32"), axis=1, keepdim=True, dtype="int64", )
[torch error] paddle.prod(Tensor([10, 85899346, 5],"float32"), axis=1, keepdim=True, dtype="int64", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 132930 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:26:47.741912 149275 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:26:47.742853 149275 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([10, 85899346, 5],"float32"), axis=list[0,1,], )
[torch error] paddle.prod(Tensor([10, 85899346, 5],"float32"), axis=list[0,1,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 47079 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:28:01.633190 149960 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:28:01.634296 149960 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([14913081, 6, 2, 3, 4, 2],"float16"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([14913081, 6, 2, 3, 4, 2],"float16"), list[2,3,4,], False, ) 
 prod() received an invalid combination of arguments - got (keepdim=bool, input=Tensor, dim=list, ), but expected one of:
 * (Tensor input, *, torch.dtype dtype = None)
      didn't match because some of the keywords were incorrect: keepdim, dim
 * (Tensor input, int dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, name dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)


W0212 19:29:29.356802 150932 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:29:29.357955 150932 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([14913081, 6, 2, 3, 4, 2],"float32"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([14913081, 6, 2, 3, 4, 2],"float32"), list[2,3,4,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 9920 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:30:46.168536 151630 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:30:46.169648 151630 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([1491309, 5, 3, 2, 2, 3, 4, 2],"float64"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([1491309, 5, 3, 2, 2, 3, 4, 2],"float64"), list[2,3,4,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 81526 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:31:34.754470 152577 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:31:34.755594 152577 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([2, 3728271, 3, 2, 2, 3, 4, 2],"float64"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([2, 3728271, 3, 2, 2, 3, 4, 2],"float64"), list[2,3,4,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 116822 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:32:24.230441 153235 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:32:24.231828 153235 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([2, 5, 2236963, 2, 2, 3, 4, 2],"float64"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([2, 5, 2236963, 2, 2, 3, 4, 2],"float64"), list[2,3,4,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 153027 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:33:13.987664 153617 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:33:13.988667 153617 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([2, 5, 3, 1491309, 2, 3, 4, 2],"float64"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([2, 5, 3, 1491309, 2, 3, 4, 2],"float64"), list[2,3,4,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 26083 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:34:05.733016 154235 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:34:05.734146 154235 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([2, 5, 3, 2, 1491309, 3, 4, 2],"float64"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([2, 5, 3, 2, 1491309, 3, 4, 2],"float64"), list[2,3,4,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 72978 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:35:00.444012 154880 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:35:00.445055 154880 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([2, 5, 3, 2, 2, 2236963, 4, 2],"float64"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([2, 5, 3, 2, 2, 2236963, 4, 2],"float64"), list[2,3,4,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 122734 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:35:53.703317 155368 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:35:53.704293 155368 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([2, 5, 3, 2, 2, 3, 2982617, 2],"float64"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([2, 5, 3, 2, 2, 3, 2982617, 2],"float64"), list[2,3,4,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 9095 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:36:46.613844 155915 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:36:46.614809 155915 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([2, 5, 3, 2, 2, 3, 4, 1491309],"float64"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([2, 5, 3, 2, 2, 3, 4, 1491309],"float64"), list[2,3,4,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 66172 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:37:40.652323 156552 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:37:40.653296 156552 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([2, 5, 3, 2, 2, 3, 4, 2982617],"float16"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([2, 5, 3, 2, 2, 3, 4, 2982617],"float16"), list[2,3,4,], False, ) 
 prod() received an invalid combination of arguments - got (keepdim=bool, input=Tensor, dim=list, ), but expected one of:
 * (Tensor input, *, torch.dtype dtype = None)
      didn't match because some of the keywords were incorrect: keepdim, dim
 * (Tensor input, int dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, name dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)


W0212 19:39:10.137681 157190 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:39:10.138897 157190 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([2, 5, 3, 2, 2, 3, 4, 2982617],"float32"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([2, 5, 3, 2, 2, 3, 4, 2982617],"float32"), list[2,3,4,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 12015 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:40:21.489521 158175 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:40:21.490495 158175 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([2, 5, 3, 2, 2, 3, 5965233, 2],"float16"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([2, 5, 3, 2, 2, 3, 5965233, 2],"float16"), list[2,3,4,], False, ) 
 prod() received an invalid combination of arguments - got (keepdim=bool, input=Tensor, dim=list, ), but expected one of:
 * (Tensor input, *, torch.dtype dtype = None)
      didn't match because some of the keywords were incorrect: keepdim, dim
 * (Tensor input, int dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, name dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)


W0212 19:41:58.019011 158852 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:41:58.019999 158852 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([2, 5, 3, 2, 2, 3, 5965233, 2],"float32"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([2, 5, 3, 2, 2, 3, 5965233, 2],"float32"), list[2,3,4,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 1700 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:43:09.197289 159853 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:43:09.198354 159853 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([2, 5, 3, 2, 2, 4473925, 4, 2],"float16"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([2, 5, 3, 2, 2, 4473925, 4, 2],"float16"), list[2,3,4,], False, ) 
 prod() received an invalid combination of arguments - got (keepdim=bool, input=Tensor, dim=list, ), but expected one of:
 * (Tensor input, *, torch.dtype dtype = None)
      didn't match because some of the keywords were incorrect: keepdim, dim
 * (Tensor input, int dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, name dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)


W0212 19:44:41.307941 160770 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:44:41.309080 160770 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([2, 5, 3, 2, 2, 4473925, 4, 2],"float32"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([2, 5, 3, 2, 2, 4473925, 4, 2],"float32"), list[2,3,4,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 140495 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:45:52.575578 161747 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:45:52.577167 161747 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([2, 5, 3, 2, 2982617, 3, 4, 2],"float16"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([2, 5, 3, 2, 2982617, 3, 4, 2],"float16"), list[2,3,4,], False, ) 
 prod() received an invalid combination of arguments - got (keepdim=bool, input=Tensor, dim=list, ), but expected one of:
 * (Tensor input, *, torch.dtype dtype = None)
      didn't match because some of the keywords were incorrect: keepdim, dim
 * (Tensor input, int dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, name dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)


W0212 19:47:29.229460 162329 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:47:29.230758 162329 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([2, 5, 3, 2, 2982617, 3, 4, 2],"float32"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([2, 5, 3, 2, 2982617, 3, 4, 2],"float32"), list[2,3,4,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 127176 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:48:40.717118 163271 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:48:40.718132 163271 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([2, 5, 3, 2982617, 2, 3, 4, 2],"float16"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([2, 5, 3, 2982617, 2, 3, 4, 2],"float16"), list[2,3,4,], False, ) 
 prod() received an invalid combination of arguments - got (keepdim=bool, input=Tensor, dim=list, ), but expected one of:
 * (Tensor input, *, torch.dtype dtype = None)
      didn't match because some of the keywords were incorrect: keepdim, dim
 * (Tensor input, int dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, name dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)


W0212 19:50:11.915663   707 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:50:11.917443   707 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([2, 5, 3, 2982617, 2, 3, 4, 2],"float32"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([2, 5, 3, 2982617, 2, 3, 4, 2],"float32"), list[2,3,4,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 101006 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:51:27.754351  1685 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:51:27.760823  1685 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([2, 5, 4473925, 2, 2, 3, 4, 2],"float16"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([2, 5, 4473925, 2, 2, 3, 4, 2],"float16"), list[2,3,4,], False, ) 
 prod() received an invalid combination of arguments - got (keepdim=bool, input=Tensor, dim=list, ), but expected one of:
 * (Tensor input, *, torch.dtype dtype = None)
      didn't match because some of the keywords were incorrect: keepdim, dim
 * (Tensor input, int dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, name dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)


W0212 19:53:04.964694  2368 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:53:04.965956  2368 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([2, 5, 4473925, 2, 2, 3, 4, 2],"float32"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([2, 5, 4473925, 2, 2, 3, 4, 2],"float32"), list[2,3,4,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 90363 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:54:31.127305  3647 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:54:31.128373  3647 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([2, 7456541, 3, 2, 2, 3, 4, 2],"float16"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([2, 7456541, 3, 2, 2, 3, 4, 2],"float16"), list[2,3,4,], False, ) 
 prod() received an invalid combination of arguments - got (keepdim=bool, input=Tensor, dim=list, ), but expected one of:
 * (Tensor input, *, torch.dtype dtype = None)
      didn't match because some of the keywords were incorrect: keepdim, dim
 * (Tensor input, int dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, name dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)


W0212 19:56:06.000766  4595 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:56:06.002116  4595 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([2, 7456541, 3, 2, 2, 3, 4, 2],"float32"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([2, 7456541, 3, 2, 2, 3, 4, 2],"float32"), list[2,3,4,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 89785 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:57:18.108700  5590 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:57:18.109615  5590 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([2982617, 5, 3, 2, 2, 3, 4, 2],"float16"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([2982617, 5, 3, 2, 2, 3, 4, 2],"float16"), list[2,3,4,], False, ) 
 prod() received an invalid combination of arguments - got (keepdim=bool, input=Tensor, dim=list, ), but expected one of:
 * (Tensor input, *, torch.dtype dtype = None)
      didn't match because some of the keywords were incorrect: keepdim, dim
 * (Tensor input, int dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, name dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)


W0212 19:58:52.927408  6249 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:58:52.928772  6249 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([2982617, 5, 3, 2, 2, 3, 4, 2],"float32"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([2982617, 5, 3, 2, 2, 3, 4, 2],"float32"), list[2,3,4,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 84678 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:00:06.686568  7219 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:00:06.687670  7219 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([3, 1431655765],"float32"), axis=None, )
[torch error] paddle.prod(Tensor([3, 1431655765],"float32"), axis=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 141536 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:01:26.305521  8177 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:01:26.306649  8177 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([3, 1431655765],"float32"), keepdim=True, )
[torch error] paddle.prod(Tensor([3, 1431655765],"float32"), keepdim=True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 47392 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:02:42.801298  8868 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:02:42.802402  8868 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([35791395, 6, 10],"float64"), list[0,], False, )
[torch error] paddle.prod(Tensor([35791395, 6, 10],"float64"), list[0,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 113804 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:03:36.481124  9824 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:03:36.483685  9824 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([4294967295],"float32"), axis=0, )
[torch error] paddle.prod(Tensor([4294967295],"float32"), axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 162684 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:04:48.558017 10470 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:04:48.558950 10470 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([5, 17895698, 2, 3, 4, 2],"float16"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([5, 17895698, 2, 3, 4, 2],"float16"), list[2,3,4,], False, ) 
 prod() received an invalid combination of arguments - got (keepdim=bool, input=Tensor, dim=list, ), but expected one of:
 * (Tensor input, *, torch.dtype dtype = None)
      didn't match because some of the keywords were incorrect: keepdim, dim
 * (Tensor input, int dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, name dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)


W0212 20:06:17.576723 11135 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:06:17.577924 11135 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([5, 17895698, 2, 3, 4, 2],"float32"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([5, 17895698, 2, 3, 4, 2],"float32"), list[2,3,4,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 147912 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:07:29.239907 12109 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:07:29.241011 12109 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([5, 42949673, 10],"float64"), list[0,], False, )
[torch error] paddle.prod(Tensor([5, 42949673, 10],"float64"), list[0,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 42818 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:08:23.101189 12799 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:08:23.102126 12799 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([5, 6, 143165577],"float16"), list[0,], False, )
[torch error] paddle.prod(Tensor([5, 6, 143165577],"float16"), list[0,], False, ) 
 prod() received an invalid combination of arguments - got (keepdim=bool, input=Tensor, dim=list, ), but expected one of:
 * (Tensor input, *, torch.dtype dtype = None)
      didn't match because some of the keywords were incorrect: keepdim, dim
 * (Tensor input, int dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, name dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)


W0212 20:09:58.495002 13432 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:09:58.496769 13432 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([5, 6, 143165577],"float32"), list[0,], False, )
[torch error] paddle.prod(Tensor([5, 6, 143165577],"float32"), list[0,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 12887 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:11:28.603480 14399 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:11:28.604494 14399 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([5, 6, 2, 3, 11930465, 2],"float16"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([5, 6, 2, 3, 11930465, 2],"float16"), list[2,3,4,], False, ) 
 prod() received an invalid combination of arguments - got (keepdim=bool, input=Tensor, dim=list, ), but expected one of:
 * (Tensor input, *, torch.dtype dtype = None)
      didn't match because some of the keywords were incorrect: keepdim, dim
 * (Tensor input, int dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, name dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)


W0212 20:12:57.844317 15377 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:12:57.845571 15377 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([5, 6, 2, 3, 11930465, 2],"float32"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([5, 6, 2, 3, 11930465, 2],"float32"), list[2,3,4,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 11743 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:14:16.749787 16354 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:14:16.750768 16354 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([5, 6, 2, 3, 4, 2982617],"float64"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([5, 6, 2, 3, 4, 2982617],"float64"), list[2,3,4,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 84045 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:15:10.096751 17293 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:15:10.097853 17293 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([5, 6, 2, 3, 4, 5965233],"float16"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([5, 6, 2, 3, 4, 5965233],"float16"), list[2,3,4,], False, ) 
 prod() received an invalid combination of arguments - got (keepdim=bool, input=Tensor, dim=list, ), but expected one of:
 * (Tensor input, *, torch.dtype dtype = None)
      didn't match because some of the keywords were incorrect: keepdim, dim
 * (Tensor input, int dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, name dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)


W0212 20:16:39.773514 17936 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:16:39.774775 17936 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([5, 6, 2, 3, 4, 5965233],"float32"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([5, 6, 2, 3, 4, 5965233],"float32"), list[2,3,4,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 46494 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:17:48.867020 18917 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:17:48.868531 18917 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([5, 6, 2, 3, 5965233, 2],"float64"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([5, 6, 2, 3, 5965233, 2],"float64"), list[2,3,4,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 114299 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:18:38.479607 19606 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:18:38.480764 19606 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([5, 6, 2, 4473925, 4, 2],"float64"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([5, 6, 2, 4473925, 4, 2],"float64"), list[2,3,4,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 150258 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:19:29.049453 20253 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:19:29.050410 20253 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([5, 6, 2, 8947849, 4, 2],"float16"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([5, 6, 2, 8947849, 4, 2],"float16"), list[2,3,4,], False, ) 
 prod() received an invalid combination of arguments - got (keepdim=bool, input=Tensor, dim=list, ), but expected one of:
 * (Tensor input, *, torch.dtype dtype = None)
      didn't match because some of the keywords were incorrect: keepdim, dim
 * (Tensor input, int dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, name dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)


W0212 20:21:03.604079 20622 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:21:03.605062 20622 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([5, 6, 2, 8947849, 4, 2],"float32"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([5, 6, 2, 8947849, 4, 2],"float32"), list[2,3,4,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 111195 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:22:24.352417 21891 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:22:24.353367 21891 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([5, 6, 2982617, 3, 4, 2],"float64"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([5, 6, 2982617, 3, 4, 2],"float64"), list[2,3,4,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 18043 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:23:14.072624 22592 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:23:14.073655 22592 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([5, 6, 5965233, 3, 4, 2],"float16"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([5, 6, 5965233, 3, 4, 2],"float16"), list[2,3,4,], False, ) 
 prod() received an invalid combination of arguments - got (keepdim=bool, input=Tensor, dim=list, ), but expected one of:
 * (Tensor input, *, torch.dtype dtype = None)
      didn't match because some of the keywords were incorrect: keepdim, dim
 * (Tensor input, int dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, name dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)


W0212 20:24:43.445050 23223 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:24:43.446309 23223 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([5, 6, 5965233, 3, 4, 2],"float32"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([5, 6, 5965233, 3, 4, 2],"float32"), list[2,3,4,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 139212 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:25:59.146139 24202 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:25:59.147272 24202 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([5, 6, 71582789],"float64"), list[0,], False, )
[torch error] paddle.prod(Tensor([5, 6, 71582789],"float64"), list[0,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 49024 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:26:52.543079 24902 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:26:52.544139 24902 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([5, 85899346, 10],"float16"), list[0,], False, )
[torch error] paddle.prod(Tensor([5, 85899346, 10],"float16"), list[0,], False, ) 
 prod() received an invalid combination of arguments - got (keepdim=bool, input=Tensor, dim=list, ), but expected one of:
 * (Tensor input, *, torch.dtype dtype = None)
      didn't match because some of the keywords were incorrect: keepdim, dim
 * (Tensor input, int dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, name dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)


W0212 20:28:28.592310 25537 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:28:28.593318 25537 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([5, 85899346, 10],"float32"), list[0,], False, )
[torch error] paddle.prod(Tensor([5, 85899346, 10],"float32"), list[0,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 13397 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:29:39.720842 26638 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:29:39.721935 26638 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([5, 8947849, 2, 3, 4, 2],"float64"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([5, 8947849, 2, 3, 4, 2],"float64"), list[2,3,4,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 73567 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:30:30.300969 27594 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:30:30.301956 27594 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([5302429, 5, 9, 9],"float64"), Tensor([2],"int64"), )
[torch error] paddle.prod(Tensor([5302429, 5, 9, 9],"float64"), Tensor([2],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 116359 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:31:25.981492 27973 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:31:25.982614 27973 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([71582789, 6, 10],"float16"), list[0,], False, )
[torch error] paddle.prod(Tensor([71582789, 6, 10],"float16"), list[0,], False, ) 
 prod() received an invalid combination of arguments - got (keepdim=bool, input=Tensor, dim=list, ), but expected one of:
 * (Tensor input, *, torch.dtype dtype = None)
      didn't match because some of the keywords were incorrect: keepdim, dim
 * (Tensor input, int dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, name dim, bool keepdim = False, *, torch.dtype dtype = None, Tensor out = None)


W0212 20:32:56.553776 28611 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:32:56.554948 28611 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([71582789, 6, 10],"float32"), list[0,], False, )
[torch error] paddle.prod(Tensor([71582789, 6, 10],"float32"), list[0,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 77411 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:34:11.958235 29604 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:34:11.959237 29604 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([7456541, 6, 2, 3, 4, 2],"float64"), list[2,3,4,], False, )
[torch error] paddle.prod(Tensor([7456541, 6, 2, 3, 4, 2],"float64"), list[2,3,4,], False, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 135148 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:35:03.831585 30549 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:35:03.832670 30549 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([858993459, 5],"float32"), axis=None, )
[torch error] paddle.prod(Tensor([858993459, 5],"float32"), axis=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 18645 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:36:13.593885 31166 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:36:13.595095 31166 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([858993459, 5],"float32"), keepdim=True, )
[torch error] paddle.prod(Tensor([858993459, 5],"float32"), keepdim=True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 75286 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:37:24.061410 31836 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:37:24.062523 31836 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([85899346, 10, 5],"float32"), )
[torch error] paddle.prod(Tensor([85899346, 10, 5],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 143278 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:38:41.160729 32522 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:38:41.161760 32522 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([85899346, 10, 5],"float32"), axis=1, )
[torch error] paddle.prod(Tensor([85899346, 10, 5],"float32"), axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 43225 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:39:58.408977 33477 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:39:58.410077 33477 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([85899346, 10, 5],"float32"), axis=-1, )
[torch error] paddle.prod(Tensor([85899346, 10, 5],"float32"), axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 111664 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:41:14.698567 34179 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:41:14.699587 34179 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([85899346, 10, 5],"float32"), axis=1, dtype="int64", )
[torch error] paddle.prod(Tensor([85899346, 10, 5],"float32"), axis=1, dtype="int64", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 7978 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:42:25.549163 35129 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:42:25.550276 35129 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([85899346, 10, 5],"float32"), axis=1, keepdim=True, )
[torch error] paddle.prod(Tensor([85899346, 10, 5],"float32"), axis=1, keepdim=True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 66917 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:43:42.161263 35813 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:43:42.162281 35813 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([85899346, 10, 5],"float32"), axis=1, keepdim=True, dtype="int64", )
[torch error] paddle.prod(Tensor([85899346, 10, 5],"float32"), axis=1, keepdim=True, dtype="int64", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 134992 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:44:54.023268 36719 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:44:54.024365 36719 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.prod(Tensor([85899346, 10, 5],"float32"), axis=list[0,1,], )
[torch error] paddle.prod(Tensor([85899346, 10, 5],"float32"), axis=list[0,1,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 45375 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:46:10.948757 37382 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:46:10.949738 37382 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([1431655765, 3],"float32"), 0.5, axis=None, )
[torch error] paddle.quantile(Tensor([1431655765, 3],"float32"), 0.5, axis=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 108975 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:47:21.891805 38316 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:47:21.892869 38316 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([1431655765, 3],"float32"), list[0.3,0.7,], 1, )
[torch error] paddle.quantile(Tensor([1431655765, 3],"float32"), list[0.3,0.7,], 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 16368 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:48:34.426640 38999 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:48:34.427561 38999 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([178956971, 3, 4],"float64"), q=0.35, axis=0, )
[torch error] paddle.quantile(Tensor([178956971, 3, 4],"float64"), q=0.35, axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 75984 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:49:24.642608 39950 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:49:24.643600 39950 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([178956971, 3, 4],"float64"), q=0.35, axis=0, interpolation="higher", )
[torch error] paddle.quantile(Tensor([178956971, 3, 4],"float64"), q=0.35, axis=0, interpolation="higher", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 122879 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:50:23.577471 40319 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:50:23.578379 40319 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([178956971, 3, 4],"float64"), q=0.35, axis=0, interpolation="lower", )
[torch error] paddle.quantile(Tensor([178956971, 3, 4],"float64"), q=0.35, axis=0, interpolation="lower", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 11619 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:51:15.294735 40962 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:51:15.295677 40962 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([178956971, 3, 4],"float64"), q=0.35, axis=0, interpolation="midpoint", )
[torch error] paddle.quantile(Tensor([178956971, 3, 4],"float64"), q=0.35, axis=0, interpolation="midpoint", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 55938 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:52:03.727502 41621 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:52:03.728518 41621 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([178956971, 3, 4],"float64"), q=0.35, axis=0, interpolation="nearest", )
[torch error] paddle.quantile(Tensor([178956971, 3, 4],"float64"), q=0.35, axis=0, interpolation="nearest", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 98764 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:52:57.167762 42245 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:52:57.168872 42245 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([178956971, 3, 4],"float64"), q=list[0.1,0.2,0.3,], axis=list[1,2,], keepdim=True, )
[torch error] paddle.quantile(Tensor([178956971, 3, 4],"float64"), q=list[0.1,0.2,0.3,], axis=list[1,2,], keepdim=True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 148691 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:53:50.498566 42619 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:53:50.499706 42619 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([178956971, 3, 4],"float64"), q=list[0.2,0.67,], axis=list[1,-1,], )
[torch error] paddle.quantile(Tensor([178956971, 3, 4],"float64"), q=list[0.2,0.67,], axis=list[1,-1,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 36264 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:54:41.872671 43250 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:54:41.873646 43250 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([178956971, 3, 4],"float64"), q=list[0.3,0.44,], axis=-2, )
[torch error] paddle.quantile(Tensor([178956971, 3, 4],"float64"), q=list[0.3,0.44,], axis=-2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 74042 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:55:32.318034 43891 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:55:32.319005 43891 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([178956971, 3, 4],"float64"), q=Tensor([2],"float32"), axis=list[1,2,], keepdim=True, )
[torch error] paddle.quantile(Tensor([178956971, 3, 4],"float64"), q=Tensor([2],"float32"), axis=list[1,2,], keepdim=True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 118849 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:56:24.857615 44522 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:56:24.858816 44522 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([2, 2147483648],"float32"), 0.5, axis=None, )
[torch error] paddle.quantile(Tensor([2, 2147483648],"float32"), 0.5, axis=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 9763 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:57:37.485548 44890 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:57:37.486460 44890 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([2, 2147483648],"float32"), list[0.3,0.7,], 1, )
[torch error] paddle.quantile(Tensor([2, 2147483648],"float32"), list[0.3,0.7,], 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 73180 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:58:50.424305 45839 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:58:50.425247 45839 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([2, 268435457, 4],"float64"), q=0.35, axis=0, )
[torch error] paddle.quantile(Tensor([2, 268435457, 4],"float64"), q=0.35, axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 143720 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:59:38.568284 46503 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:59:38.569262 46503 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([2, 268435457, 4],"float64"), q=0.35, axis=0, interpolation="higher", )
[torch error] paddle.quantile(Tensor([2, 268435457, 4],"float64"), q=0.35, axis=0, interpolation="higher", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 15983 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:00:30.240347 47127 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:00:30.241428 47127 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([2, 268435457, 4],"float64"), q=0.35, axis=0, interpolation="lower", )
[torch error] paddle.quantile(Tensor([2, 268435457, 4],"float64"), q=0.35, axis=0, interpolation="lower", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 63802 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:01:22.670948 47496 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:01:22.672097 47496 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([2, 268435457, 4],"float64"), q=0.35, axis=0, interpolation="midpoint", )
[torch error] paddle.quantile(Tensor([2, 268435457, 4],"float64"), q=0.35, axis=0, interpolation="midpoint", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 115727 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:02:19.830060 48126 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:02:19.831122 48126 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([2, 268435457, 4],"float64"), q=0.35, axis=0, interpolation="nearest", )
[torch error] paddle.quantile(Tensor([2, 268435457, 4],"float64"), q=0.35, axis=0, interpolation="nearest", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 2507 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:03:09.218261 48770 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:03:09.219291 48770 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([2, 3, 357913942],"float64"), q=0.35, axis=0, )
[torch error] paddle.quantile(Tensor([2, 3, 357913942],"float64"), q=0.35, axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 38853 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:04:02.152959 49403 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:04:02.153976 49403 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([2, 3, 357913942],"float64"), q=0.35, axis=0, interpolation="higher", )
[torch error] paddle.quantile(Tensor([2, 3, 357913942],"float64"), q=0.35, axis=0, interpolation="higher", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 94163 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:04:56.126255 50042 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:04:56.127396 50042 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([2, 3, 357913942],"float64"), q=0.35, axis=0, interpolation="lower", )
[torch error] paddle.quantile(Tensor([2, 3, 357913942],"float64"), q=0.35, axis=0, interpolation="lower", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 143181 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:05:46.605321 50588 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:05:46.606355 50588 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([2, 3, 357913942],"float64"), q=0.35, axis=0, interpolation="midpoint", )
[torch error] paddle.quantile(Tensor([2, 3, 357913942],"float64"), q=0.35, axis=0, interpolation="midpoint", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 33067 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:06:39.604590 51219 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:06:39.605707 51219 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([2, 3, 357913942],"float64"), q=0.35, axis=0, interpolation="nearest", )
[torch error] paddle.quantile(Tensor([2, 3, 357913942],"float64"), q=0.35, axis=0, interpolation="nearest", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 72841 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:07:32.322744 51849 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:07:32.323911 51849 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([306783379, 7],"float64"), q=0.5, axis=1, )
[torch error] paddle.quantile(Tensor([306783379, 7],"float64"), q=0.5, axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 116664 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:08:26.483449 52487 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:08:26.484453 52487 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([4, 1073741824],"float32"), q=0.5, axis=1, )
[torch error] paddle.quantile(Tensor([4, 1073741824],"float32"), q=0.5, axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 1997 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:09:37.467695 53039 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:09:37.468950 53039 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([4, 536870913],"float64"), q=0.5, axis=1, )
[torch error] paddle.quantile(Tensor([4, 536870913],"float64"), q=0.5, axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 64278 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:10:29.504079 53985 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:10:29.505249 53985 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([4, 7, 76695845],"float64"), q=0, axis=1, )
[torch error] paddle.quantile(Tensor([4, 7, 76695845],"float64"), q=0, axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 108969 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:11:18.518769 54366 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:11:18.519743 54366 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([4, 7, 76695845],"float64"), q=0.1, axis=list[1,2,], keepdim=True, )
[torch error] paddle.quantile(Tensor([4, 7, 76695845],"float64"), q=0.1, axis=list[1,2,], keepdim=True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 158415 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:12:10.336488 54978 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:12:10.337509 54978 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([4, 7, 76695845],"float64"), q=0.35, )
[torch error] paddle.quantile(Tensor([4, 7, 76695845],"float64"), q=0.35, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 31810 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:13:00.478016 55609 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:13:00.478978 55609 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([4, 7, 76695845],"float64"), q=0.35, axis=2, keepdim=True, )
[torch error] paddle.quantile(Tensor([4, 7, 76695845],"float64"), q=0.35, axis=2, keepdim=True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 81889 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:13:52.467361 55987 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:13:52.468410 55987 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([4, 7, 76695845],"float64"), q=0.5, axis=2, )
[torch error] paddle.quantile(Tensor([4, 7, 76695845],"float64"), q=0.5, axis=2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 135339 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:14:47.214998 56651 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:14:47.216094 56651 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([4, 7, 76695845],"float64"), q=0.75, axis=list[0,2,], )
[torch error] paddle.quantile(Tensor([4, 7, 76695845],"float64"), q=0.75, axis=list[0,2,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 22541 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:15:41.897884 57289 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:15:41.898983 57289 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([4, 89478486, 6],"float64"), q=0, axis=1, )
[torch error] paddle.quantile(Tensor([4, 89478486, 6],"float64"), q=0, axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 64113 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:16:31.077829 57913 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:16:31.078902 57913 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([4, 89478486, 6],"float64"), q=0.1, axis=list[1,2,], keepdim=True, )
[torch error] paddle.quantile(Tensor([4, 89478486, 6],"float64"), q=0.1, axis=list[1,2,], keepdim=True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 112760 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:17:20.581719 58551 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:17:20.582870 58551 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([4, 89478486, 6],"float64"), q=0.35, )
[torch error] paddle.quantile(Tensor([4, 89478486, 6],"float64"), q=0.35, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 160846 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:18:09.904076 58927 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:18:09.905284 58927 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([4, 89478486, 6],"float64"), q=0.35, axis=2, keepdim=True, )
[torch error] paddle.quantile(Tensor([4, 89478486, 6],"float64"), q=0.35, axis=2, keepdim=True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 34986 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:18:58.936172 59574 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:18:58.945986 59574 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([4, 89478486, 6],"float64"), q=0.5, axis=2, )
[torch error] paddle.quantile(Tensor([4, 89478486, 6],"float64"), q=0.5, axis=2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 84947 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:19:52.040760 59924 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:19:52.041859 59924 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([4, 89478486, 6],"float64"), q=0.75, axis=list[0,2,], )
[torch error] paddle.quantile(Tensor([4, 89478486, 6],"float64"), q=0.75, axis=list[0,2,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 135529 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:20:41.544509 60564 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:20:41.545570 60564 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([4294967295],"float32"), 0.5, 0, )
[torch error] paddle.quantile(Tensor([4294967295],"float32"), 0.5, 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 9848 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:21:52.847070 61202 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:21:52.848163 61202 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([4294967295],"float32"), list[0.55,0.7,], 0, )
[torch error] paddle.quantile(Tensor([4294967295],"float32"), list[0.55,0.7,], 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 77159 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:23:09.942526 61881 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:23:09.943639 61881 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([5, 107374183, 4],"float64"), q=list[0.1,0.2,0.3,], axis=list[1,2,], keepdim=True, )
[torch error] paddle.quantile(Tensor([5, 107374183, 4],"float64"), q=list[0.1,0.2,0.3,], axis=list[1,2,], keepdim=True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 135006 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:23:58.202625 62828 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:23:58.203567 62828 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([5, 107374183, 4],"float64"), q=list[0.2,0.67,], axis=list[1,-1,], )
[torch error] paddle.quantile(Tensor([5, 107374183, 4],"float64"), q=list[0.2,0.67,], axis=list[1,-1,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 22882 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:24:48.778630 63177 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:24:48.793514 63177 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([5, 107374183, 4],"float64"), q=list[0.3,0.44,], axis=-2, )
[torch error] paddle.quantile(Tensor([5, 107374183, 4],"float64"), q=list[0.3,0.44,], axis=-2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 72176 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:25:38.041822 63821 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:25:38.042906 63821 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([5, 107374183, 4],"float64"), q=Tensor([2],"float32"), axis=list[1,2,], keepdim=True, )
[torch error] paddle.quantile(Tensor([5, 107374183, 4],"float64"), q=Tensor([2],"float32"), axis=list[1,2,], keepdim=True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 108135 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:26:27.871141 64466 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:26:27.872181 64466 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([5, 3, 143165577],"float64"), q=list[0.1,0.2,0.3,], axis=list[1,2,], keepdim=True, )
[torch error] paddle.quantile(Tensor([5, 3, 143165577],"float64"), q=list[0.1,0.2,0.3,], axis=list[1,2,], keepdim=True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 157811 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:27:16.735001 64820 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:27:16.736001 64820 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([5, 3, 143165577],"float64"), q=list[0.2,0.67,], axis=list[1,-1,], )
[torch error] paddle.quantile(Tensor([5, 3, 143165577],"float64"), q=list[0.2,0.67,], axis=list[1,-1,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 42192 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:28:10.502158 65481 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:28:10.503300 65481 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([5, 3, 143165577],"float64"), q=list[0.3,0.44,], axis=-2, )
[torch error] paddle.quantile(Tensor([5, 3, 143165577],"float64"), q=list[0.3,0.44,], axis=-2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 79940 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:29:02.695561 66133 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:29:02.696522 66133 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([5, 3, 143165577],"float64"), q=Tensor([2],"float32"), axis=list[1,2,], keepdim=True, )
[torch error] paddle.quantile(Tensor([5, 3, 143165577],"float64"), q=Tensor([2],"float32"), axis=list[1,2,], keepdim=True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 130830 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:29:57.210415 66751 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:29:57.211454 66751 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([5, 3, 4],"float64"), q=Tensor([4294967295],"float32"), axis=list[1,2,], keepdim=True, )
[torch error] paddle.quantile(Tensor([5, 3, 4],"float64"), q=Tensor([4294967295],"float32"), axis=list[1,2,], keepdim=True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 19601 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:31:12.659487 67156 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:31:12.660547 67156 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([51130564, 7, 6],"float64"), q=0, axis=1, )
[torch error] paddle.quantile(Tensor([51130564, 7, 6],"float64"), q=0, axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 75387 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:32:06.485985 68115 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:32:06.487208 68115 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([51130564, 7, 6],"float64"), q=0.1, axis=list[1,2,], keepdim=True, )
[torch error] paddle.quantile(Tensor([51130564, 7, 6],"float64"), q=0.1, axis=list[1,2,], keepdim=True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 128049 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:33:00.200867 68750 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:33:00.201825 68750 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([51130564, 7, 6],"float64"), q=0.35, )
[torch error] paddle.quantile(Tensor([51130564, 7, 6],"float64"), q=0.35, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 19313 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:33:49.717594 69131 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:33:49.718669 69131 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([51130564, 7, 6],"float64"), q=0.35, axis=2, keepdim=True, )
[torch error] paddle.quantile(Tensor([51130564, 7, 6],"float64"), q=0.35, axis=2, keepdim=True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 69031 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:34:43.866339 69772 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:34:43.867306 69772 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([51130564, 7, 6],"float64"), q=0.5, axis=2, )
[torch error] paddle.quantile(Tensor([51130564, 7, 6],"float64"), q=0.5, axis=2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 109108 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:35:37.316159 70408 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:35:37.317287 70408 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([51130564, 7, 6],"float64"), q=0.75, axis=list[0,2,], )
[torch error] paddle.quantile(Tensor([51130564, 7, 6],"float64"), q=0.75, axis=list[0,2,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 143907 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:36:30.507360 71060 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:36:30.508327 71060 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.quantile(Tensor([613566757, 7],"float32"), q=0.5, axis=1, )
[torch error] paddle.quantile(Tensor([613566757, 7],"float32"), q=0.5, axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 10686 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:37:40.969797 71429 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:37:40.970979 71429 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rad2deg(Tensor([2147483649],"int64"), )
[torch error] paddle.rad2deg(Tensor([2147483649],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 57007 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:38:32.320108 72373 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:38:32.321195 72373 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rad2deg(Tensor([4294967295],"float32"), )
[torch error] paddle.rad2deg(Tensor([4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 72154 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:39:43.268334 73030 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:39:43.269286 73030 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rad2deg(Tensor([8, 16, 33554432],"float32"), )
[torch error] paddle.rad2deg(Tensor([8, 16, 33554432],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 114258 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:40:53.327841 74034 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:40:53.329233 74034 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rad2deg(Tensor([8, 16777216, 32],"float32"), )
[torch error] paddle.rad2deg(Tensor([8, 16777216, 32],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 146092 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:42:10.548537 74691 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:42:10.549646 74691 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.rad2deg(Tensor([8388608, 16, 32],"float32"), )
[torch error] paddle.rad2deg(Tensor([8388608, 16, 32],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 16680 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:43:23.939905 75666 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:43:23.941015 75666 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 214748365],"float64"), low=-100, high=100, dtype="bool", )
[torch error] paddle.randint_like(Tensor([10, 214748365],"float64"), low=-100, high=100, dtype="bool", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 48674 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:44:13.348212 76330 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:44:13.349290 76330 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 214748365],"float64"), low=-100, high=100, dtype="float16", )
[torch error] paddle.randint_like(Tensor([10, 214748365],"float64"), low=-100, high=100, dtype="float16", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 75186 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:45:07.449561 76955 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:45:07.450544 76955 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 214748365],"float64"), low=-100, high=100, dtype="float32", )
[torch error] paddle.randint_like(Tensor([10, 214748365],"float64"), low=-100, high=100, dtype="float32", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 102506 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:46:01.293136 77593 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:46:01.294113 77593 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 214748365],"float64"), low=-100, high=100, dtype="float64", )
[torch error] paddle.randint_like(Tensor([10, 214748365],"float64"), low=-100, high=100, dtype="float64", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 133921 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:46:54.410045 78246 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:46:54.411037 78246 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 214748365],"float64"), low=-100, high=100, dtype="int32", )
[torch error] paddle.randint_like(Tensor([10, 214748365],"float64"), low=-100, high=100, dtype="int32", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 160864 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:47:43.267791 78615 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:47:43.269088 78615 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 214748365],"float64"), low=-100, high=100, dtype="int64", )
[torch error] paddle.randint_like(Tensor([10, 214748365],"float64"), low=-100, high=100, dtype="int64", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 22776 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:48:36.492835 79442 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:48:36.493801 79442 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 214748365],"int64"), low=-100, high=100, dtype="bool", )
[torch error] paddle.randint_like(Tensor([10, 214748365],"int64"), low=-100, high=100, dtype="bool", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 46521 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:49:24.906554 80096 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:49:24.907625 80096 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 214748365],"int64"), low=-100, high=100, dtype="float16", )
[torch error] paddle.randint_like(Tensor([10, 214748365],"int64"), low=-100, high=100, dtype="float16", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 66446 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:50:15.434988 80477 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:50:15.435956 80477 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 214748365],"int64"), low=-100, high=100, dtype="float32", )
[torch error] paddle.randint_like(Tensor([10, 214748365],"int64"), low=-100, high=100, dtype="float32", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 93004 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:51:02.703454 81115 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:51:02.704566 81115 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 214748365],"int64"), low=-100, high=100, dtype="float64", )
[torch error] paddle.randint_like(Tensor([10, 214748365],"int64"), low=-100, high=100, dtype="float64", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 119075 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:51:53.061578 81753 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:51:53.062621 81753 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 214748365],"int64"), low=-100, high=100, dtype="int32", )
[torch error] paddle.randint_like(Tensor([10, 214748365],"int64"), low=-100, high=100, dtype="int32", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 143852 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:52:44.577214 82122 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:52:44.578311 82122 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 214748365],"int64"), low=-100, high=100, dtype="int64", )
[torch error] paddle.randint_like(Tensor([10, 214748365],"int64"), low=-100, high=100, dtype="int64", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 5125 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:53:31.075456 82763 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:53:31.076367 82763 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 429496730],"bool"), low=-100, high=100, dtype="bool", )
[torch error] paddle.randint_like(Tensor([10, 429496730],"bool"), low=-100, high=100, dtype="bool", ) 
 randint_like() received an invalid combination of arguments - got (dtype=str, input=Tensor, high=int, low=int, ), but expected one of:
 * (Tensor input, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (Tensor input, int low, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0212 21:54:49.870867 83400 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:54:49.872083 83400 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 429496730],"bool"), low=-100, high=100, dtype="float16", )
[torch error] paddle.randint_like(Tensor([10, 429496730],"bool"), low=-100, high=100, dtype="float16", ) 
 randint_like() received an invalid combination of arguments - got (dtype=str, input=Tensor, high=int, low=int, ), but expected one of:
 * (Tensor input, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (Tensor input, int low, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0212 21:56:00.117352 84084 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:56:00.119374 84084 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 429496730],"bool"), low=-100, high=100, dtype="float32", )
[torch error] paddle.randint_like(Tensor([10, 429496730],"bool"), low=-100, high=100, dtype="float32", ) 
 randint_like() received an invalid combination of arguments - got (dtype=str, input=Tensor, high=int, low=int, ), but expected one of:
 * (Tensor input, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (Tensor input, int low, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0212 21:57:07.773754 84749 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:57:07.774997 84749 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 429496730],"bool"), low=-100, high=100, dtype="float64", )
[torch error] paddle.randint_like(Tensor([10, 429496730],"bool"), low=-100, high=100, dtype="float64", ) 
 randint_like() received an invalid combination of arguments - got (dtype=str, input=Tensor, high=int, low=int, ), but expected one of:
 * (Tensor input, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (Tensor input, int low, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0212 21:58:21.111161 85676 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:58:21.112408 85676 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 429496730],"bool"), low=-100, high=100, dtype="int32", )
[torch error] paddle.randint_like(Tensor([10, 429496730],"bool"), low=-100, high=100, dtype="int32", ) 
 randint_like() received an invalid combination of arguments - got (dtype=str, input=Tensor, high=int, low=int, ), but expected one of:
 * (Tensor input, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (Tensor input, int low, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0212 21:59:35.018170 86353 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:59:35.019132 86353 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 429496730],"bool"), low=-100, high=100, dtype="int64", )
[torch error] paddle.randint_like(Tensor([10, 429496730],"bool"), low=-100, high=100, dtype="int64", ) 
 randint_like() received an invalid combination of arguments - got (dtype=str, input=Tensor, high=int, low=int, ), but expected one of:
 * (Tensor input, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (Tensor input, int low, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0212 22:00:49.243969 87308 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:00:49.245767 87308 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 429496730],"float16"), low=-100, high=100, dtype="bool", )
[torch error] paddle.randint_like(Tensor([10, 429496730],"float16"), low=-100, high=100, dtype="bool", ) 
 randint_like() received an invalid combination of arguments - got (dtype=str, input=Tensor, high=int, low=int, ), but expected one of:
 * (Tensor input, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (Tensor input, int low, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0212 22:02:24.447701 87972 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:02:24.449048 87972 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 429496730],"float16"), low=-100, high=100, dtype="float16", )
[torch error] paddle.randint_like(Tensor([10, 429496730],"float16"), low=-100, high=100, dtype="float16", ) 
 randint_like() received an invalid combination of arguments - got (dtype=str, input=Tensor, high=int, low=int, ), but expected one of:
 * (Tensor input, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (Tensor input, int low, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0212 22:04:01.122082 88906 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:04:01.123147 88906 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 429496730],"float16"), low=-100, high=100, dtype="float32", )
[torch error] paddle.randint_like(Tensor([10, 429496730],"float16"), low=-100, high=100, dtype="float32", ) 
 randint_like() received an invalid combination of arguments - got (dtype=str, input=Tensor, high=int, low=int, ), but expected one of:
 * (Tensor input, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (Tensor input, int low, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0212 22:05:39.259686 90038 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:05:39.260645 90038 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 429496730],"float16"), low=-100, high=100, dtype="float64", )
[torch error] paddle.randint_like(Tensor([10, 429496730],"float16"), low=-100, high=100, dtype="float64", ) 
 randint_like() received an invalid combination of arguments - got (dtype=str, input=Tensor, high=int, low=int, ), but expected one of:
 * (Tensor input, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (Tensor input, int low, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0212 22:07:06.524716 90893 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:07:06.525898 90893 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 429496730],"float16"), low=-100, high=100, dtype="int32", )
[torch error] paddle.randint_like(Tensor([10, 429496730],"float16"), low=-100, high=100, dtype="int32", ) 
 randint_like() received an invalid combination of arguments - got (dtype=str, input=Tensor, high=int, low=int, ), but expected one of:
 * (Tensor input, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (Tensor input, int low, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0212 22:08:43.787810 91742 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:08:43.788945 91742 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 429496730],"float16"), low=-100, high=100, dtype="int64", )
[torch error] paddle.randint_like(Tensor([10, 429496730],"float16"), low=-100, high=100, dtype="int64", ) 
 randint_like() received an invalid combination of arguments - got (dtype=str, input=Tensor, high=int, low=int, ), but expected one of:
 * (Tensor input, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (Tensor input, int low, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0212 22:10:19.450322 92611 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:10:19.451627 92611 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 429496730],"float32"), low=-100, high=100, dtype="bool", )
[torch error] paddle.randint_like(Tensor([10, 429496730],"float32"), low=-100, high=100, dtype="bool", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 39398 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:11:38.809149 93459 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:11:38.810297 93459 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 429496730],"float32"), low=-100, high=100, dtype="float16", )
[torch error] paddle.randint_like(Tensor([10, 429496730],"float32"), low=-100, high=100, dtype="float16", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 82022 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:12:56.050403 94311 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:12:56.051522 94311 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 429496730],"float32"), low=-100, high=100, dtype="float32", )
[torch error] paddle.randint_like(Tensor([10, 429496730],"float32"), low=-100, high=100, dtype="float32", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 123319 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:14:09.266326 94888 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:14:09.267436 94888 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 429496730],"float32"), low=-100, high=100, dtype="float64", )
[torch error] paddle.randint_like(Tensor([10, 429496730],"float32"), low=-100, high=100, dtype="float64", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 158222 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:15:20.477222 95727 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:15:20.478264 95727 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 429496730],"float32"), low=-100, high=100, dtype="int32", )
[torch error] paddle.randint_like(Tensor([10, 429496730],"float32"), low=-100, high=100, dtype="int32", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 28578 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:16:31.262738 96324 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:16:31.263718 96324 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 429496730],"float32"), low=-100, high=100, dtype="int64", )
[torch error] paddle.randint_like(Tensor([10, 429496730],"float32"), low=-100, high=100, dtype="int64", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 67812 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:17:48.159271 97163 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:17:48.160367 97163 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 429496730],"int32"), low=-100, high=100, dtype="bool", )
[torch error] paddle.randint_like(Tensor([10, 429496730],"int32"), low=-100, high=100, dtype="bool", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 113855 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:18:59.243999 97726 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:18:59.245067 97726 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 429496730],"int32"), low=-100, high=100, dtype="float16", )
[torch error] paddle.randint_like(Tensor([10, 429496730],"int32"), low=-100, high=100, dtype="float16", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 147819 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:20:11.512041 98315 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:20:11.513195 98315 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 429496730],"int32"), low=-100, high=100, dtype="float32", )
[torch error] paddle.randint_like(Tensor([10, 429496730],"int32"), low=-100, high=100, dtype="float32", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 22831 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:21:25.612690 99167 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:21:25.613742 99167 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 429496730],"int32"), low=-100, high=100, dtype="float64", )
[torch error] paddle.randint_like(Tensor([10, 429496730],"int32"), low=-100, high=100, dtype="float64", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 55923 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:22:39.932330 99972 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:22:39.933725 99972 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 429496730],"int32"), low=-100, high=100, dtype="int32", )
[torch error] paddle.randint_like(Tensor([10, 429496730],"int32"), low=-100, high=100, dtype="int32", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 96663 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:24:16.613735 100836 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:24:16.614867 100836 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([10, 429496730],"int32"), low=-100, high=100, dtype="int64", )
[torch error] paddle.randint_like(Tensor([10, 429496730],"int32"), low=-100, high=100, dtype="int64", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 145980 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:25:33.446970 101684 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:25:33.448045 101684 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([178956971, 12],"float64"), low=-100, high=100, dtype="bool", )
[torch error] paddle.randint_like(Tensor([178956971, 12],"float64"), low=-100, high=100, dtype="bool", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 18473 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:26:25.971181 102543 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:26:25.972172 102543 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([178956971, 12],"float64"), low=-100, high=100, dtype="float16", )
[torch error] paddle.randint_like(Tensor([178956971, 12],"float64"), low=-100, high=100, dtype="float16", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 50334 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:27:15.495456 102842 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:27:15.496896 102842 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([178956971, 12],"float64"), low=-100, high=100, dtype="float32", )
[torch error] paddle.randint_like(Tensor([178956971, 12],"float64"), low=-100, high=100, dtype="float32", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 75978 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:28:04.284615 103397 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:28:04.285907 103397 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([178956971, 12],"float64"), low=-100, high=100, dtype="float64", )
[torch error] paddle.randint_like(Tensor([178956971, 12],"float64"), low=-100, high=100, dtype="float64", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 102886 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:28:58.379243 103960 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:28:58.380183 103960 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([178956971, 12],"float64"), low=-100, high=100, dtype="int32", )
[torch error] paddle.randint_like(Tensor([178956971, 12],"float64"), low=-100, high=100, dtype="int32", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 132277 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:29:51.794061 104257 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:29:51.794998 104257 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([178956971, 12],"float64"), low=-100, high=100, dtype="int64", )
[torch error] paddle.randint_like(Tensor([178956971, 12],"float64"), low=-100, high=100, dtype="int64", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 158378 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:30:42.028983 104805 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:30:42.030154 104805 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([178956971, 12],"int64"), low=-100, high=100, dtype="bool", )
[torch error] paddle.randint_like(Tensor([178956971, 12],"int64"), low=-100, high=100, dtype="bool", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 19450 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:31:32.700898 105386 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:31:32.701953 105386 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([178956971, 12],"int64"), low=-100, high=100, dtype="float16", )
[torch error] paddle.randint_like(Tensor([178956971, 12],"int64"), low=-100, high=100, dtype="float16", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 38058 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:32:18.709790 105948 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:32:18.710954 105948 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([178956971, 12],"int64"), low=-100, high=100, dtype="float32", )
[torch error] paddle.randint_like(Tensor([178956971, 12],"int64"), low=-100, high=100, dtype="float32", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 62300 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:33:06.088366 106231 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:33:06.089478 106231 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([178956971, 12],"int64"), low=-100, high=100, dtype="float64", )
[torch error] paddle.randint_like(Tensor([178956971, 12],"int64"), low=-100, high=100, dtype="float64", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 88140 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:33:54.187099 106789 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:33:54.188081 106789 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([178956971, 12],"int64"), low=-100, high=100, dtype="int32", )
[torch error] paddle.randint_like(Tensor([178956971, 12],"int64"), low=-100, high=100, dtype="int32", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 114532 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:34:44.120786 107097 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:34:44.121757 107097 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([178956971, 12],"int64"), low=-100, high=100, dtype="int64", )
[torch error] paddle.randint_like(Tensor([178956971, 12],"int64"), low=-100, high=100, dtype="int64", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 138483 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:35:34.083616 107670 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:35:34.084679 107670 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([357913942, 12],"bool"), low=-100, high=100, dtype="bool", )
[torch error] paddle.randint_like(Tensor([357913942, 12],"bool"), low=-100, high=100, dtype="bool", ) 
 randint_like() received an invalid combination of arguments - got (dtype=str, input=Tensor, high=int, low=int, ), but expected one of:
 * (Tensor input, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (Tensor input, int low, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0212 22:36:42.476215 108239 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:36:42.477887 108239 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([357913942, 12],"bool"), low=-100, high=100, dtype="float16", )
[torch error] paddle.randint_like(Tensor([357913942, 12],"bool"), low=-100, high=100, dtype="float16", ) 
 randint_like() received an invalid combination of arguments - got (dtype=str, input=Tensor, high=int, low=int, ), but expected one of:
 * (Tensor input, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (Tensor input, int low, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0212 22:37:58.631790 108823 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:37:58.632993 108823 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([357913942, 12],"bool"), low=-100, high=100, dtype="float32", )
[torch error] paddle.randint_like(Tensor([357913942, 12],"bool"), low=-100, high=100, dtype="float32", ) 
 randint_like() received an invalid combination of arguments - got (dtype=str, input=Tensor, high=int, low=int, ), but expected one of:
 * (Tensor input, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (Tensor input, int low, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0212 22:39:20.868348 109399 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:39:20.869520 109399 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([357913942, 12],"bool"), low=-100, high=100, dtype="float64", )
[torch error] paddle.randint_like(Tensor([357913942, 12],"bool"), low=-100, high=100, dtype="float64", ) 
 randint_like() received an invalid combination of arguments - got (dtype=str, input=Tensor, high=int, low=int, ), but expected one of:
 * (Tensor input, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (Tensor input, int low, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0212 22:40:35.606554 110252 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:40:35.607681 110252 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([357913942, 12],"bool"), low=-100, high=100, dtype="int32", )
[torch error] paddle.randint_like(Tensor([357913942, 12],"bool"), low=-100, high=100, dtype="int32", ) 
 randint_like() received an invalid combination of arguments - got (dtype=str, input=Tensor, high=int, low=int, ), but expected one of:
 * (Tensor input, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (Tensor input, int low, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0212 22:41:52.940037 111091 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:41:52.941218 111091 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([357913942, 12],"bool"), low=-100, high=100, dtype="int64", )
[torch error] paddle.randint_like(Tensor([357913942, 12],"bool"), low=-100, high=100, dtype="int64", ) 
 randint_like() received an invalid combination of arguments - got (dtype=str, input=Tensor, high=int, low=int, ), but expected one of:
 * (Tensor input, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (Tensor input, int low, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0212 22:43:16.760622 111660 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:43:16.761874 111660 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([357913942, 12],"float16"), low=-100, high=100, dtype="bool", )
[torch error] paddle.randint_like(Tensor([357913942, 12],"float16"), low=-100, high=100, dtype="bool", ) 
 randint_like() received an invalid combination of arguments - got (dtype=str, input=Tensor, high=int, low=int, ), but expected one of:
 * (Tensor input, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (Tensor input, int low, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0212 22:44:52.737392 112525 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:44:52.738739 112525 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([357913942, 12],"float16"), low=-100, high=100, dtype="float16", )
[torch error] paddle.randint_like(Tensor([357913942, 12],"float16"), low=-100, high=100, dtype="float16", ) 
 randint_like() received an invalid combination of arguments - got (dtype=str, input=Tensor, high=int, low=int, ), but expected one of:
 * (Tensor input, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (Tensor input, int low, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0212 22:46:22.938824 113365 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:46:22.940006 113365 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([357913942, 12],"float16"), low=-100, high=100, dtype="float32", )
[torch error] paddle.randint_like(Tensor([357913942, 12],"float16"), low=-100, high=100, dtype="float32", ) 
 randint_like() received an invalid combination of arguments - got (dtype=str, input=Tensor, high=int, low=int, ), but expected one of:
 * (Tensor input, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (Tensor input, int low, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0212 22:47:51.568799 114206 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:47:51.569895 114206 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([357913942, 12],"float16"), low=-100, high=100, dtype="float64", )
[torch error] paddle.randint_like(Tensor([357913942, 12],"float16"), low=-100, high=100, dtype="float64", ) 
 randint_like() received an invalid combination of arguments - got (dtype=str, input=Tensor, high=int, low=int, ), but expected one of:
 * (Tensor input, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (Tensor input, int low, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0212 22:49:29.781929 115050 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:49:29.783167 115050 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([357913942, 12],"float16"), low=-100, high=100, dtype="int32", )
[torch error] paddle.randint_like(Tensor([357913942, 12],"float16"), low=-100, high=100, dtype="int32", ) 
 randint_like() received an invalid combination of arguments - got (dtype=str, input=Tensor, high=int, low=int, ), but expected one of:
 * (Tensor input, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (Tensor input, int low, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0212 22:51:05.890270 115905 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:51:05.891225 115905 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([357913942, 12],"float16"), low=-100, high=100, dtype="int64", )
[torch error] paddle.randint_like(Tensor([357913942, 12],"float16"), low=-100, high=100, dtype="int64", ) 
 randint_like() received an invalid combination of arguments - got (dtype=str, input=Tensor, high=int, low=int, ), but expected one of:
 * (Tensor input, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (Tensor input, int low, int high, *, torch.memory_format memory_format = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0212 22:52:42.149472 117018 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:52:42.150815 117018 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([357913942, 12],"float32"), low=-100, high=100, dtype="bool", )
[torch error] paddle.randint_like(Tensor([357913942, 12],"float32"), low=-100, high=100, dtype="bool", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 157874 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:53:54.688201 117872 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:53:54.689152 117872 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([357913942, 12],"float32"), low=-100, high=100, dtype="float16", )
[torch error] paddle.randint_like(Tensor([357913942, 12],"float32"), low=-100, high=100, dtype="float16", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 34355 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:55:07.245640 118434 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:55:07.246634 118434 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([357913942, 12],"float32"), low=-100, high=100, dtype="float32", )
[torch error] paddle.randint_like(Tensor([357913942, 12],"float32"), low=-100, high=100, dtype="float32", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 66486 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:56:18.294451 119293 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:56:18.295446 119293 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([357913942, 12],"float32"), low=-100, high=100, dtype="float64", )
[torch error] paddle.randint_like(Tensor([357913942, 12],"float32"), low=-100, high=100, dtype="float64", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 101424 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:57:33.033938 119856 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:57:33.035108 119856 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([357913942, 12],"float32"), low=-100, high=100, dtype="int32", )
[torch error] paddle.randint_like(Tensor([357913942, 12],"float32"), low=-100, high=100, dtype="int32", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 137572 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:58:43.723692 120856 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:58:43.724740 120856 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([357913942, 12],"float32"), low=-100, high=100, dtype="int64", )
[torch error] paddle.randint_like(Tensor([357913942, 12],"float32"), low=-100, high=100, dtype="int64", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 9327 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:59:55.921178 121594 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:59:55.922178 121594 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([357913942, 12],"int32"), low=-100, high=100, dtype="bool", )
[torch error] paddle.randint_like(Tensor([357913942, 12],"int32"), low=-100, high=100, dtype="bool", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 41722 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:01:09.004979 122157 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:01:09.006032 122157 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([357913942, 12],"int32"), low=-100, high=100, dtype="float16", )
[torch error] paddle.randint_like(Tensor([357913942, 12],"int32"), low=-100, high=100, dtype="float16", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 73335 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:02:19.228087 122982 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:02:19.229185 122982 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([357913942, 12],"int32"), low=-100, high=100, dtype="float32", )
[torch error] paddle.randint_like(Tensor([357913942, 12],"int32"), low=-100, high=100, dtype="float32", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 104818 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:03:35.706530 123557 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:03:35.707506 123557 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([357913942, 12],"int32"), low=-100, high=100, dtype="float64", )
[torch error] paddle.randint_like(Tensor([357913942, 12],"int32"), low=-100, high=100, dtype="float64", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 137678 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:04:50.557250 124395 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:04:50.558326 124395 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([357913942, 12],"int32"), low=-100, high=100, dtype="int32", )
[torch error] paddle.randint_like(Tensor([357913942, 12],"int32"), low=-100, high=100, dtype="int32", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 16336 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:06:03.588241 124970 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:06:03.589354 124970 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.randint_like(Tensor([357913942, 12],"int32"), low=-100, high=100, dtype="int64", )
[torch error] paddle.randint_like(Tensor([357913942, 12],"int32"), low=-100, high=100, dtype="int64", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 52535 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:07:19.946817 125795 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:07:19.947937 125795 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reciprocal(Tensor([1431655765, 3],"float32"), )
[torch error] paddle.reciprocal(Tensor([1431655765, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 86592 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:08:36.241518 126357 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:08:36.242460 126357 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reciprocal(Tensor([2, 1048576, 2048],"float32"), )
[torch error] paddle.reciprocal(Tensor([2, 1048576, 2048],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 124833 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:09:46.222577 127209 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:09:46.223718 127209 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reciprocal(Tensor([2, 2147483648],"float32"), )
[torch error] paddle.reciprocal(Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 163225 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:11:01.980536 127785 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:11:01.981532 127785 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reciprocal(Tensor([2, 300, 7158279],"float32"), )
[torch error] paddle.reciprocal(Tensor([2, 300, 7158279],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 33531 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:12:22.318573 128622 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:12:22.319661 128622 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.reciprocal(Tensor([6991, 300, 2048],"float32"), )
[torch error] paddle.reciprocal(Tensor([6991, 300, 2048],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 65581 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:13:32.606698 129202 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:13:32.607681 129202 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.renorm(Tensor([10, 20, 21474837],"float32"), 1.0, -1, 2.05, )
[torch error] paddle.renorm(Tensor([10, 20, 21474837],"float32"), 1.0, -1, 2.05, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 97150 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:14:51.522106 130004 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:14:51.523020 130004 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.renorm(Tensor([10, 429496730, 1],"float32"), 1.0, -1, 2.05, )
[torch error] paddle.renorm(Tensor([10, 429496730, 1],"float32"), 1.0, -1, 2.05, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 142340 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:16:03.779628 130556 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:16:03.780609 130556 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.renorm(Tensor([2, 2, 1073741824],"float32"), 1.0, -1, 2.05, )
[torch error] paddle.renorm(Tensor([2, 2, 1073741824],"float32"), 1.0, -1, 2.05, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 13669 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:17:14.089190 131344 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:17:14.090339 131344 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.renorm(Tensor([2, 2, 1073741824],"float32"), 1.0, 2, 2.05, )
[torch error] paddle.renorm(Tensor([2, 2, 1073741824],"float32"), 1.0, 2, 2.05, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 44341 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:18:25.626624 131894 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:18:25.627792 131894 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.renorm(Tensor([2, 715827883, 3],"float32"), 1.0, -1, 2.05, )
[torch error] paddle.renorm(Tensor([2, 715827883, 3],"float32"), 1.0, -1, 2.05, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 76195 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:19:37.325110 132433 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:19:37.326124 132433 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.renorm(Tensor([2, 715827883, 3],"float32"), 1.0, 2, 2.05, )
[torch error] paddle.renorm(Tensor([2, 715827883, 3],"float32"), 1.0, 2, 2.05, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 52666 has 32.99 GiB memory in use. Process 55939 has 32.99 GiB memory in use. Process 108232 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:20:48.531220 133549 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:20:48.532568 133549 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

