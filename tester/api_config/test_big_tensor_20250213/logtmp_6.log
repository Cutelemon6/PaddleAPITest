test begin: paddle.cumprod(Tensor([4294967295],"float32"), dim=0, )
[torch error] paddle.cumprod(Tensor([4294967295],"float32"), dim=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 50760 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:08:20.417227 16605 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:08:20.418176 16605 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([429496730, 10],"float32"), dim=0, )
[torch error] paddle.cumprod(Tensor([429496730, 10],"float32"), dim=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 121275 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:09:31.692806 17325 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:09:31.693933 17325 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([429496730, 10],"float32"), dim=1, )
[torch error] paddle.cumprod(Tensor([429496730, 10],"float32"), dim=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 12951 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:10:40.024053 18014 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:10:40.025040 18014 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([5, 858993459],"float32"), dim=-1, )
[torch error] paddle.cumprod(Tensor([5, 858993459],"float32"), dim=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 63584 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:11:52.368011 18980 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:11:52.368973 18980 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([613566757, 7],"float32"), dim=-1, )
[torch error] paddle.cumprod(Tensor([613566757, 7],"float32"), dim=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 131594 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:13:04.422163 19657 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:13:04.423332 19657 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([715827883, 6],"float32"), dim=-1, )
[torch error] paddle.cumprod(Tensor([715827883, 6],"float32"), dim=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 23481 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:14:12.578847 20596 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:14:12.579842 20596 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([7158279, 3, 10, 10],"float64"), 1, )
[torch error] paddle.cumprod(Tensor([7158279, 3, 10, 10],"float64"), 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 84522 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:14:59.521270 21284 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:14:59.522244 21284 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([858993459, 5],"float32"), dim=-1, )
[torch error] paddle.cumprod(Tensor([858993459, 5],"float32"), dim=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 127760 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:16:11.404557 21678 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:16:11.405699 21678 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([1, 4294967295],"float32"), axis=0, )
[torch error] paddle.cumsum(Tensor([1, 4294967295],"float32"), axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 23555 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:17:22.735538 22645 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:17:22.736672 22645 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([10, 20, 21474837],"float32"), dtype="float32", )
[torch error] paddle.cumsum(Tensor([10, 20, 21474837],"float32"), dtype="float32", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 100383 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:18:32.120033 23356 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:18:32.121168 23356 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([10, 429496730, 1],"float32"), dtype="float32", )
[torch error] paddle.cumsum(Tensor([10, 429496730, 1],"float32"), dtype="float32", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 152422 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:19:40.128468 24034 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:19:40.129480 24034 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([10, 429496730],"float16"), dtype="float16", )
[torch error] paddle.cumsum(Tensor([10, 429496730],"float16"), dtype="float16", ) 
 cumsum() received an invalid combination of arguments - got (dtype=str, input=Tensor, ), but expected one of:
 * (Tensor input, int dim, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, name dim, *, torch.dtype dtype = None, Tensor out = None)


W0212 16:21:05.605973 24976 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:21:05.607158 24976 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([10, 429496730],"float32"), dtype="float32", )
[torch error] paddle.cumsum(Tensor([10, 429496730],"float32"), dtype="float32", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 111200 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:22:16.698247 26122 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:22:16.699369 26122 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([1073741825, 2],"float64"), axis=1, )
[torch error] paddle.cumsum(Tensor([1073741825, 2],"float64"), axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 11821 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:23:02.581087 26804 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:23:02.582304 26804 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([1431655765, 3],"float16"), axis=1, )
[torch error] paddle.cumsum(Tensor([1431655765, 3],"float16"), axis=1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 46437 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:24:27.003410 27152 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:24:27.004415 27152 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([1431655765, 3],"float32"), 1, )
[torch error] paddle.cumsum(Tensor([1431655765, 3],"float32"), 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 127559 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:25:38.674357 28139 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:25:38.675323 28139 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([1431655765, 3],"float32"), axis=0, )
[torch error] paddle.cumsum(Tensor([1431655765, 3],"float32"), axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 17934 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:26:46.803920 29084 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:26:46.804953 29084 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([16777217, 128],"int64"), axis=-1, )
[torch error] paddle.cumsum(Tensor([16777217, 128],"int64"), axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 74759 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:27:30.945701 29753 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:27:30.946745 29753 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([2, 1073741825],"float64"), axis=1, )
[torch error] paddle.cumsum(Tensor([2, 1073741825],"float64"), axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 123022 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:28:20.054019 30127 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:28:20.055136 30127 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([2, 1073741825],"int64"), axis=-1, )
[torch error] paddle.cumsum(Tensor([2, 1073741825],"int64"), axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 4435 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:29:03.859870 30765 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:29:03.861042 30765 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([2, 2147483648],"float32"), 1, )
[torch error] paddle.cumsum(Tensor([2, 2147483648],"float32"), 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 30555 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:30:11.794934 31388 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:30:11.795946 31388 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([2, 2147483648],"float32"), axis=1, )
[torch error] paddle.cumsum(Tensor([2, 2147483648],"float32"), axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 88312 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:31:23.610435 32061 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:31:23.630738 32061 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([2147483648, 2],"float32"), axis=1, )
[torch error] paddle.cumsum(Tensor([2147483648, 2],"float32"), axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 161202 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:32:35.441246 32756 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:32:35.442370 32756 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([214748365, 20, 1],"float32"), dtype="float32", )
[torch error] paddle.cumsum(Tensor([214748365, 20, 1],"float32"), dtype="float32", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 51741 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:33:45.125710 33692 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:33:45.126718 33692 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([3, 1431655765],"float32"), axis=-1, )
[torch error] paddle.cumsum(Tensor([3, 1431655765],"float32"), axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 103800 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:34:58.493515 34360 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:34:58.494614 34360 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([3, 2, 715827883],"float32"), axis=1, )
[torch error] paddle.cumsum(Tensor([3, 2, 715827883],"float32"), axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 9172 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:36:09.084396 35049 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:36:09.085563 35049 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([3, 357913942, 4],"float32"), axis=1, )
[torch error] paddle.cumsum(Tensor([3, 357913942, 4],"float32"), axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 65714 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:37:17.879961 35983 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:37:17.881165 35983 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([3, 715827883],"int64"), )
[torch error] paddle.cumsum(Tensor([3, 715827883],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 141319 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:38:03.306816 36652 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:38:03.307907 36652 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([3, 715827883],"int64"), axis=0, )
[torch error] paddle.cumsum(Tensor([3, 715827883],"int64"), axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 5049 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:38:47.936359 37278 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:38:47.937489 37278 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([3, 715827883],"int64"), axis=-1, )
[torch error] paddle.cumsum(Tensor([3, 715827883],"int64"), axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 44461 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:39:32.918871 37659 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:39:32.920020 37659 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([3, 715827883],"int64"), axis=-2, )
[torch error] paddle.cumsum(Tensor([3, 715827883],"int64"), axis=-2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 84059 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:40:15.316005 38035 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:40:15.317055 38035 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([3, 715827883],"int64"), dtype="float64", )
[torch error] paddle.cumsum(Tensor([3, 715827883],"int64"), dtype="float64", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 111696 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:41:00.045135 38645 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:41:00.046339 38645 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([3, 715827883],"int64"), dtype=type(numpy.int32), )
[torch error] paddle.cumsum(Tensor([3, 715827883],"int64"), dtype=type(numpy.int32), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 154204 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:41:43.183869 39020 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:41:43.185142 39020 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([357913942, 12],"float16"), dtype="float16", )
[torch error] paddle.cumsum(Tensor([357913942, 12],"float16"), dtype="float16", ) 
 cumsum() received an invalid combination of arguments - got (dtype=str, input=Tensor, ), but expected one of:
 * (Tensor input, int dim, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, name dim, *, torch.dtype dtype = None, Tensor out = None)


W0212 16:43:10.562341 39636 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:43:10.563514 39636 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([357913942, 12],"float32"), dtype="float32", )
[torch error] paddle.cumsum(Tensor([357913942, 12],"float32"), dtype="float32", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 94636 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:44:19.611234 40628 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:44:19.612231 40628 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([357913942, 6],"float64"), axis=Tensor([1],"int32"), )
[torch error] paddle.cumsum(Tensor([357913942, 6],"float64"), axis=Tensor([1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 7891 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:45:09.333756 41310 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:45:09.334717 41310 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([4, 1073741824],"float16"), axis=1, )
[torch error] paddle.cumsum(Tensor([4, 1073741824],"float16"), axis=1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 34170 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:46:36.911489 41927 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:46:36.912429 41927 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([4294967295],"float32"), dtype="float32", )
[torch error] paddle.cumsum(Tensor([4294967295],"float32"), dtype="float32", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 124862 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:47:47.699177 42916 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:47:47.700335 42916 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([4294967295],"int32"), )
[torch error] paddle.cumsum(Tensor([4294967295],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 20125 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:48:55.521759 43595 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:48:55.522858 43595 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([429497, 10000],"float32"), axis=-1, )
[torch error] paddle.cumsum(Tensor([429497, 10000],"float32"), axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 78032 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:50:09.678898 44269 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:50:09.680006 44269 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([5, 429496730],"float64"), axis=Tensor([1],"int32"), )
[torch error] paddle.cumsum(Tensor([5, 429496730],"float64"), axis=Tensor([1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 133518 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:50:57.692848 45245 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:50:57.693945 45245 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([5, 6],"float64"), axis=Tensor([4294967295],"int32"), )
[torch error] paddle.cumsum(Tensor([5, 6],"float64"), axis=Tensor([4294967295],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 16768 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:52:05.807246 45601 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:52:05.808274 45601 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([536870912, 2, 4],"float32"), axis=1, )
[torch error] paddle.cumsum(Tensor([536870912, 2, 4],"float32"), axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 68119 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:53:14.218288 46533 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:53:14.219806 46533 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([536870913, 4],"int64"), )
[torch error] paddle.cumsum(Tensor([536870913, 4],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 123583 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:54:00.331820 47231 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:54:00.332809 47231 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([536870913, 4],"int64"), axis=0, )
[torch error] paddle.cumsum(Tensor([536870913, 4],"int64"), axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 7685 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:54:49.252331 47614 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:54:49.253643 47614 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([536870913, 4],"int64"), axis=-1, )
[torch error] paddle.cumsum(Tensor([536870913, 4],"int64"), axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 51682 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:55:35.619387 48244 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:55:35.620465 48244 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([536870913, 4],"int64"), axis=-2, )
[torch error] paddle.cumsum(Tensor([536870913, 4],"int64"), axis=-2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 88047 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:56:27.253157 48889 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:56:27.254129 48889 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([536870913, 4],"int64"), dtype="float64", )
[torch error] paddle.cumsum(Tensor([536870913, 4],"int64"), dtype="float64", ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 141656 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:57:09.843967 49264 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:57:09.844977 49264 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumsum(Tensor([536870913, 4],"int64"), dtype=type(numpy.int32), )
[torch error] paddle.cumsum(Tensor([536870913, 4],"int64"), dtype=type(numpy.int32), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 2753 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 16:57:56.927340 49901 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 16:57:56.928280 49901 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumulative_trapezoid(y=Tensor([1073741824, 4],"float16"), x=Tensor([1073741824, 4],"float16"), )
[torch error] paddle.cumulative_trapezoid(y=Tensor([1073741824, 4],"float16"), x=Tensor([1073741824, 4],"float16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 48172 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:00:33.108258 50258 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:00:33.109376 50258 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumulative_trapezoid(y=Tensor([1073741824, 4],"float16"), x=Tensor([4, 4],"float16"), )
[torch error] paddle.cumulative_trapezoid(y=Tensor([1073741824, 4],"float16"), x=Tensor([4, 4],"float16"), ) 
 CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 18640 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:01:58.486294 52361 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:01:58.487284 52361 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumulative_trapezoid(y=Tensor([1431655765, 3],"float32"), x=None, dx=None, axis=-1, )
[torch error] paddle.cumulative_trapezoid(y=Tensor([1431655765, 3],"float32"), x=None, dx=None, axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 91722 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:03:11.477010 53258 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:03:11.478013 53258 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumulative_trapezoid(y=Tensor([1431655765, 3],"float32"), x=Tensor([1431655765, 3],"float32"), dx=None, axis=-1, )
[torch error] paddle.cumulative_trapezoid(y=Tensor([1431655765, 3],"float32"), x=Tensor([1431655765, 3],"float32"), dx=None, axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 144398 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:04:21.340415 54200 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:04:21.341470 54200 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumulative_trapezoid(y=Tensor([1431655765, 3],"float32"), x=Tensor([2, 3],"float32"), dx=None, axis=-1, )
[torch error] paddle.cumulative_trapezoid(y=Tensor([1431655765, 3],"float32"), x=Tensor([2, 3],"float32"), dx=None, axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 56161 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:05:36.566668 54882 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:05:36.567665 54882 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumulative_trapezoid(y=Tensor([2, 1073741825],"float64"), x=None, dx=None, axis=-1, )
[torch error] paddle.cumulative_trapezoid(y=Tensor([2, 1073741825],"float64"), x=None, dx=None, axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 113372 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:06:22.233434 55822 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:06:22.234396 55822 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumulative_trapezoid(y=Tensor([2, 1073741825],"float64"), x=Tensor([2, 1073741825],"float64"), dx=None, axis=-1, )
[torch error] paddle.cumulative_trapezoid(y=Tensor([2, 1073741825],"float64"), x=Tensor([2, 1073741825],"float64"), dx=None, axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 162086 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:07:11.985009 56202 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:07:11.985986 56202 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumulative_trapezoid(y=Tensor([2, 1073741825],"float64"), x=Tensor([2, 3],"float64"), dx=None, axis=-1, )
[torch error] paddle.cumulative_trapezoid(y=Tensor([2, 1073741825],"float64"), x=Tensor([2, 3],"float64"), dx=None, axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 27717 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:08:00.629521 56860 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:08:00.630527 56860 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumulative_trapezoid(y=Tensor([2, 2147483648],"float32"), x=None, dx=None, axis=-1, )
[torch error] paddle.cumulative_trapezoid(y=Tensor([2, 2147483648],"float32"), x=None, dx=None, axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 75046 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:09:09.648912 57229 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:09:09.649891 57229 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumulative_trapezoid(y=Tensor([2, 2147483648],"float32"), x=Tensor([2, 2147483648],"float32"), dx=None, axis=-1, )
[torch error] paddle.cumulative_trapezoid(y=Tensor([2, 2147483648],"float32"), x=Tensor([2, 2147483648],"float32"), dx=None, axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 128121 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:10:15.817545 58169 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:10:15.818766 58169 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumulative_trapezoid(y=Tensor([2, 2147483648],"float32"), x=Tensor([2, 3],"float32"), dx=None, axis=-1, )
[torch error] paddle.cumulative_trapezoid(y=Tensor([2, 2147483648],"float32"), x=Tensor([2, 3],"float32"), dx=None, axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 16639 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:11:29.099794 58866 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:11:29.100813 58866 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumulative_trapezoid(y=Tensor([2, 3],"float32"), x=Tensor([1431655765, 3],"float32"), dx=None, axis=-1, )
[torch error] paddle.cumulative_trapezoid(y=Tensor([2, 3],"float32"), x=Tensor([1431655765, 3],"float32"), dx=None, axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 94166 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:12:40.779989 59558 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:12:40.783735 59558 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumulative_trapezoid(y=Tensor([2, 3],"float32"), x=Tensor([2, 2147483648],"float32"), dx=None, axis=-1, )
[torch error] paddle.cumulative_trapezoid(y=Tensor([2, 3],"float32"), x=Tensor([2, 2147483648],"float32"), dx=None, axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 145956 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:13:52.757109 60493 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:13:52.758190 60493 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumulative_trapezoid(y=Tensor([2, 3],"float64"), x=Tensor([2, 1073741825],"float64"), dx=None, axis=-1, )
[torch error] paddle.cumulative_trapezoid(y=Tensor([2, 3],"float64"), x=Tensor([2, 1073741825],"float64"), dx=None, axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 50254 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:14:37.590817 61197 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:14:37.591828 61197 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumulative_trapezoid(y=Tensor([2, 3],"float64"), x=Tensor([715827883, 3],"float64"), dx=None, axis=-1, )
[torch error] paddle.cumulative_trapezoid(y=Tensor([2, 3],"float64"), x=Tensor([715827883, 3],"float64"), dx=None, axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 84853 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:15:26.995432 61827 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:15:26.996414 61827 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumulative_trapezoid(y=Tensor([3, 3, 4],"float32"), x=Tensor([4294967295],"float32"), dx=None, axis=1, )
[torch error] paddle.cumulative_trapezoid(y=Tensor([3, 3, 4],"float32"), x=Tensor([4294967295],"float32"), dx=None, axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 132231 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:16:33.464536 62216 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:16:33.465631 62216 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumulative_trapezoid(y=Tensor([3, 3, 477218589],"float32"), x=Tensor([3],"float32"), dx=None, axis=1, )
[torch error] paddle.cumulative_trapezoid(y=Tensor([3, 3, 477218589],"float32"), x=Tensor([3],"float32"), dx=None, axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 28250 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:17:45.456404 63136 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:17:45.457459 63136 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumulative_trapezoid(y=Tensor([3, 357913942, 4],"float32"), x=Tensor([3],"float32"), dx=None, axis=1, )
[torch error] paddle.cumulative_trapezoid(y=Tensor([3, 357913942, 4],"float32"), x=Tensor([3],"float32"), dx=None, axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 83874 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:18:55.522895 63818 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:18:55.524083 63818 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumulative_trapezoid(y=Tensor([357913942, 3, 4],"float32"), x=Tensor([3],"float32"), dx=None, axis=1, )
[torch error] paddle.cumulative_trapezoid(y=Tensor([357913942, 3, 4],"float32"), x=Tensor([3],"float32"), dx=None, axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 151887 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:20:12.594599 64477 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:20:12.595566 64477 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumulative_trapezoid(y=Tensor([4, 1073741824],"float16"), x=Tensor([4, 1073741824],"float16"), )
[torch error] paddle.cumulative_trapezoid(y=Tensor([4, 1073741824],"float16"), x=Tensor([4, 1073741824],"float16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 46423 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:22:47.605624 65423 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:22:47.606846 65423 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumulative_trapezoid(y=Tensor([4, 1073741824],"float16"), x=Tensor([4, 4],"float16"), )
[torch error] paddle.cumulative_trapezoid(y=Tensor([4, 1073741824],"float16"), x=Tensor([4, 4],"float16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 31308 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:24:13.730897 67037 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:24:13.731938 67037 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumulative_trapezoid(y=Tensor([4, 4],"float16"), x=Tensor([1073741824, 4],"float16"), )
[torch error] paddle.cumulative_trapezoid(y=Tensor([4, 4],"float16"), x=Tensor([1073741824, 4],"float16"), ) 
 CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 94652 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:25:58.158937 67988 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:25:58.159929 67988 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumulative_trapezoid(y=Tensor([4, 4],"float16"), x=Tensor([4, 1073741824],"float16"), )
[torch error] paddle.cumulative_trapezoid(y=Tensor([4, 4],"float16"), x=Tensor([4, 1073741824],"float16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 32156 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:27:22.643179 68972 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:27:22.644152 68972 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumulative_trapezoid(y=Tensor([715827883, 3],"float64"), x=None, dx=None, axis=-1, )
[torch error] paddle.cumulative_trapezoid(y=Tensor([715827883, 3],"float64"), x=None, dx=None, axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 105900 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:28:18.222517 69948 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:28:18.223608 69948 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumulative_trapezoid(y=Tensor([715827883, 3],"float64"), x=Tensor([2, 3],"float64"), dx=None, axis=-1, )
[torch error] paddle.cumulative_trapezoid(y=Tensor([715827883, 3],"float64"), x=Tensor([2, 3],"float64"), dx=None, axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 150659 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:29:06.349794 70605 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:29:06.350948 70605 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumulative_trapezoid(y=Tensor([715827883, 3],"float64"), x=Tensor([715827883, 3],"float64"), dx=None, axis=-1, )
[torch error] paddle.cumulative_trapezoid(y=Tensor([715827883, 3],"float64"), x=Tensor([715827883, 3],"float64"), dx=None, axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 24378 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:29:53.923835 71222 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:29:53.924998 71222 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.deg2rad(Tensor([2147483649],"int64"), )
[torch error] paddle.deg2rad(Tensor([2147483649],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 69965 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:30:41.644533 71597 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:30:41.645547 71597 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.deg2rad(Tensor([4294967295],"float32"), )
[torch error] paddle.deg2rad(Tensor([4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 105672 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:31:54.634555 72229 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:31:54.635643 72229 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.deg2rad(Tensor([8, 16, 33554432],"float32"), )
[torch error] paddle.deg2rad(Tensor([8, 16, 33554432],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 8099 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:33:00.694797 72899 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:33:00.695878 72899 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.deg2rad(Tensor([8, 16777216, 32],"float32"), )
[torch error] paddle.deg2rad(Tensor([8, 16777216, 32],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 61248 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:34:12.387933 73742 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:34:12.388921 73742 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.deg2rad(Tensor([8388608, 16, 32],"float32"), )
[torch error] paddle.deg2rad(Tensor([8388608, 16, 32],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 120272 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:35:18.089413 74852 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:35:18.090487 74852 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag(Tensor([10, 429496730],"float32"), )
[torch error] paddle.diag(Tensor([10, 429496730],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 16491 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:36:30.402482 75516 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:36:30.403627 75516 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag(Tensor([10, 429496730],"float32"), offset=1, )
[torch error] paddle.diag(Tensor([10, 429496730],"float32"), offset=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 91680 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:37:43.199383 76193 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:37:43.200380 76193 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag(Tensor([10, 429496730],"float32"), offset=-1, )
[torch error] paddle.diag(Tensor([10, 429496730],"float32"), offset=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 150535 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:38:58.304420 77125 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:38:58.305523 77125 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag(Tensor([1073741824, 4],"float32"), )
[torch error] paddle.diag(Tensor([1073741824, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 57629 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:40:10.661294 77827 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:40:10.662389 77827 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag(Tensor([2000, 2147484],"float32"), )
[torch error] paddle.diag(Tensor([2000, 2147484],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 111221 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:41:23.269204 78749 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:41:23.286235 78749 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag(Tensor([2000, 2147484],"float32"), offset=1, )
[torch error] paddle.diag(Tensor([2000, 2147484],"float32"), offset=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 16505 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:42:33.227780 79592 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:42:33.228768 79592 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag(Tensor([2000, 2147484],"float32"), offset=-1, )
[torch error] paddle.diag(Tensor([2000, 2147484],"float32"), offset=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 77129 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:43:40.748884 80279 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:43:40.750037 80279 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag(Tensor([2147483649],"float64"), )
[torch error] paddle.diag(Tensor([2147483649],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 130311 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:44:26.047395 81216 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:44:26.048518 81216 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag(Tensor([2147483649],"float64"), padding_value=8, )
[paddle_to_torch] paddle.diag(Tensor([2147483649],"float64"), padding_value=8, ) 
  padding_value not in paddle_to_torch_args_map, can not call torch

W0212 17:44:33.839404 81579 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:44:33.840420 81579 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag(Tensor([2147483649],"int64"), padding_value=-8, )
[paddle_to_torch] paddle.diag(Tensor([2147483649],"int64"), padding_value=-8, ) 
  padding_value not in paddle_to_torch_args_map, can not call torch

W0212 17:44:40.577332 81612 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:44:40.578684 81612 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag(Tensor([2147483649],"int64"), padding_value=8.0, )
[paddle_to_torch] paddle.diag(Tensor([2147483649],"int64"), padding_value=8.0, ) 
  padding_value not in paddle_to_torch_args_map, can not call torch

W0212 17:44:48.166539 81894 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:44:48.167516 81894 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag(Tensor([2147484, 2000],"float32"), )
[torch error] paddle.diag(Tensor([2147484, 2000],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 26743 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:45:55.280772 81921 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:45:55.281862 81921 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag(Tensor([2147484, 2000],"float32"), offset=1, )
[torch error] paddle.diag(Tensor([2147484, 2000],"float32"), offset=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 90573 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:47:04.068179 82577 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:47:04.069363 82577 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag(Tensor([2147484, 2000],"float32"), offset=-1, )
[torch error] paddle.diag(Tensor([2147484, 2000],"float32"), offset=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 146358 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:48:17.877058 83532 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:48:17.878144 83532 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag(Tensor([2863312, 1500],"float32"), offset=-1, )
[torch error] paddle.diag(Tensor([2863312, 1500],"float32"), offset=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 43489 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:49:27.056702 84204 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:49:27.057629 84204 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag(Tensor([4, 1073741824],"float32"), )
[torch error] paddle.diag(Tensor([4, 1073741824],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 108599 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:50:40.124910 84889 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:50:40.126645 84889 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag(Tensor([4, 536870913],"float64"), )
[torch error] paddle.diag(Tensor([4, 536870913],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 7541 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:51:30.061074 85872 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:51:30.095109 85872 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag(Tensor([4294967295],"float32"), )
[torch error] paddle.diag(Tensor([4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 51140 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:52:36.884018 86239 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:52:36.885290 86239 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag(Tensor([4294967295],"float32"), offset=1, )
[torch error] paddle.diag(Tensor([4294967295],"float32"), offset=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 106131 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:53:48.117317 87171 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:53:48.118299 87171 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag(Tensor([4294967295],"float32"), offset=-1, )
[torch error] paddle.diag(Tensor([4294967295],"float32"), offset=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 4651 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:55:01.311048 87849 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:55:01.312146 87849 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag(Tensor([429496730, 10],"float32"), )
[torch error] paddle.diag(Tensor([429496730, 10],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 64330 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:56:09.317592 88535 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:56:09.318715 88535 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag(Tensor([429496730, 10],"float32"), offset=1, )
[torch error] paddle.diag(Tensor([429496730, 10],"float32"), offset=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 121690 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:57:21.757001 89463 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:57:21.758180 89463 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag(Tensor([429496730, 10],"float32"), offset=-1, )
[torch error] paddle.diag(Tensor([429496730, 10],"float32"), offset=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 26588 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:58:29.075196 90139 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:58:29.076165 90139 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag(Tensor([429496730, 5],"float64"), )
[torch error] paddle.diag(Tensor([429496730, 5],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 83936 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 17:59:14.717720 90829 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 17:59:14.718878 90829 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag(Tensor([5, 429496730],"float64"), )
[torch error] paddle.diag(Tensor([5, 429496730],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 111622 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:00:04.389765 91455 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:00:04.390717 91455 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag(Tensor([5, 858993459],"float32"), )
[torch error] paddle.diag(Tensor([5, 858993459],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 160270 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:01:16.595099 92086 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:01:16.596302 92086 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag(Tensor([536870913, 4],"float64"), )
[torch error] paddle.diag(Tensor([536870913, 4],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 49140 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:02:09.012302 92756 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:02:09.013350 92756 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag(Tensor([858993459, 5],"float32"), )
[torch error] paddle.diag(Tensor([858993459, 5],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 98715 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:03:15.544574 93416 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:03:15.545764 93416 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag_embed(Tensor([1, 2147483649],"float64"), )
[torch error] paddle.diag_embed(Tensor([1, 2147483649],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 149643 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:03:59.894974 94089 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:03:59.896013 94089 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag_embed(Tensor([1, 4294967295],"float32"), )
[torch error] paddle.diag_embed(Tensor([1, 4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 35708 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:05:07.296960 94437 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:05:07.298018 94437 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag_embed(Tensor([1073741825, 2],"float64"), )
[torch error] paddle.diag_embed(Tensor([1073741825, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 91302 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:05:56.278963 95379 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:05:56.280016 95379 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag_embed(Tensor([119304648, 3, 6],"float64"), )
[torch error] paddle.diag_embed(Tensor([119304648, 3, 6],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 143526 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:06:45.747076 95763 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:06:45.748019 95763 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag_embed(Tensor([178956971, 12],"float64"), )
[torch error] paddle.diag_embed(Tensor([178956971, 12],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 18334 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:07:32.127382 96388 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:07:32.128595 96388 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag_embed(Tensor([178956971, 3, 4],"float64"), )
[torch error] paddle.diag_embed(Tensor([178956971, 3, 4],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 62469 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:08:22.283946 96676 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:08:22.284967 96676 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag_embed(Tensor([2, 134217729, 8],"float64"), )
[torch error] paddle.diag_embed(Tensor([2, 134217729, 8],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 106815 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:09:08.330113 97320 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:09:08.331248 97320 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag_embed(Tensor([2, 178956971, 6],"float64"), )
[torch error] paddle.diag_embed(Tensor([2, 178956971, 6],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 142426 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:09:56.610132 97946 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:09:56.611557 97946 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag_embed(Tensor([2, 2147483648],"float32"), )
[torch error] paddle.diag_embed(Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 28338 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:11:06.846325 98313 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:11:06.847468 98313 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag_embed(Tensor([2, 268435457, 4],"float64"), )
[torch error] paddle.diag_embed(Tensor([2, 268435457, 4],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 85567 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:12:00.528266 99247 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:12:00.529242 99247 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag_embed(Tensor([2, 3, 357913942],"float64"), )
[torch error] paddle.diag_embed(Tensor([2, 3, 357913942],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 137921 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:12:45.918680 99850 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:12:45.919821 99850 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag_embed(Tensor([2, 536870913, 2],"float64"), )
[torch error] paddle.diag_embed(Tensor([2, 536870913, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 8526 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:13:31.177505 100483 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:13:31.178524 100483 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag_embed(Tensor([2, 89478486, 12],"float64"), )
[torch error] paddle.diag_embed(Tensor([2, 89478486, 12],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 55563 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:14:20.938189 100866 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:14:20.939232 100866 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag_embed(Tensor([2147483648, 2],"float32"), )
[torch error] paddle.diag_embed(Tensor([2147483648, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 99056 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:15:27.294404 101513 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:15:27.295442 101513 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag_embed(Tensor([2147483649],"float64"), )
[torch error] paddle.diag_embed(Tensor([2147483649],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 154450 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:16:16.805512 102202 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:16:16.806569 102202 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag_embed(Tensor([268435457, 8],"float64"), )
[torch error] paddle.diag_embed(Tensor([268435457, 8],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 33156 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:17:06.220678 102838 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:17:06.221698 102838 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag_embed(Tensor([3, 715827883],"float64"), )
[torch error] paddle.diag_embed(Tensor([3, 715827883],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 84129 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:17:51.890470 103469 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:17:51.891805 103469 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag_embed(Tensor([357913942, 3, 2],"float64"), )
[torch error] paddle.diag_embed(Tensor([357913942, 3, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 132652 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:18:38.297341 103838 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:18:38.298323 103838 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag_embed(Tensor([357913942, 6],"float64"), )
[torch error] paddle.diag_embed(Tensor([357913942, 6],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 4946 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:19:23.713351 104449 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:19:23.715735 104449 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag_embed(Tensor([4294967295],"float32"), )
[torch error] paddle.diag_embed(Tensor([4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 43954 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:20:36.203509 104826 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:20:36.204537 104826 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag_embed(Tensor([536870913, 4],"float64"), )
[torch error] paddle.diag_embed(Tensor([536870913, 4],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 110332 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:21:25.859656 105798 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:21:25.860827 105798 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag_embed(Tensor([59652324, 3, 12],"float64"), )
[torch error] paddle.diag_embed(Tensor([59652324, 3, 12],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 154725 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:22:15.298141 106181 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:22:15.299110 106181 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diag_embed(Tensor([89478486, 3, 8],"float64"), )
[torch error] paddle.diag_embed(Tensor([89478486, 3, 8],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 27535 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:23:00.186342 106833 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:23:00.187402 106833 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagflat(Tensor([10, 214748365],"float64"), )
[torch error] paddle.diagflat(Tensor([10, 214748365],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 76296 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:23:45.687250 107209 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:23:45.688689 107209 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagflat(Tensor([10, 214748365],"float64"), offset=1, )
[torch error] paddle.diagflat(Tensor([10, 214748365],"float64"), offset=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 110776 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:24:33.611289 107852 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:24:33.622267 107852 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagflat(Tensor([10, 214748365],"float64"), offset=-1, )
[torch error] paddle.diagflat(Tensor([10, 214748365],"float64"), offset=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 159202 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:25:23.741381 108502 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:25:23.742491 108502 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagflat(Tensor([2147483649],"float64"), )
[torch error] paddle.diagflat(Tensor([2147483649],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 39553 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:26:08.517838 108878 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:26:08.518868 108878 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagflat(Tensor([2147483649],"float64"), offset=1, )
[torch error] paddle.diagflat(Tensor([2147483649],"float64"), offset=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 77486 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:26:55.503705 109516 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:26:55.504722 109516 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagflat(Tensor([2147483649],"float64"), offset=-1, )
[torch error] paddle.diagflat(Tensor([2147483649],"float64"), offset=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 129768 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:27:42.444814 109878 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:27:42.445837 109878 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagflat(Tensor([214748365, 10],"float64"), )
[torch error] paddle.diagflat(Tensor([214748365, 10],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 2711 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:28:31.237784 110523 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:28:31.238852 110523 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagflat(Tensor([214748365, 10],"float64"), offset=1, )
[torch error] paddle.diagflat(Tensor([214748365, 10],"float64"), offset=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 48207 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:29:17.831653 110893 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:29:17.832715 110893 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagflat(Tensor([214748365, 10],"float64"), offset=-1, )
[torch error] paddle.diagflat(Tensor([214748365, 10],"float64"), offset=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 82482 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:30:03.096810 111527 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:30:03.097950 111527 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal(Tensor([1, 2, 2147483648],"float32"), offset=0, axis1=-1, axis2=-2, )
[torch error] paddle.diagonal(Tensor([1, 2, 2147483648],"float32"), offset=0, axis1=-1, axis2=-2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 126287 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:31:09.587706 111914 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:31:09.588835 111914 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal(Tensor([1, 2147483648, 2],"float32"), offset=0, axis1=-1, axis2=-2, )
[torch error] paddle.diagonal(Tensor([1, 2147483648, 2],"float32"), offset=0, axis1=-1, axis2=-2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 17249 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:32:18.633000 112849 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:32:18.634101 112849 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal(Tensor([10, 107374183, 4],"float32"), )
[torch error] paddle.diagonal(Tensor([10, 107374183, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 81506 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:33:27.127537 113527 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:33:27.128635 113527 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal(Tensor([10, 107374183, 4],"float32"), offset=0, axis1=1, axis2=2, )
[torch error] paddle.diagonal(Tensor([10, 107374183, 4],"float32"), offset=0, axis1=1, axis2=2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 139835 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:34:33.578912 114190 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:34:33.580071 114190 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal(Tensor([10, 107374183, 4],"float32"), offset=0, axis1=2, axis2=1, )
[torch error] paddle.diagonal(Tensor([10, 107374183, 4],"float32"), offset=0, axis1=2, axis2=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 41770 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:35:40.757249 115109 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:35:40.758415 115109 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal(Tensor([10, 107374183, 4],"float32"), offset=1, axis1=0, axis2=1, )
[torch error] paddle.diagonal(Tensor([10, 107374183, 4],"float32"), offset=1, axis1=0, axis2=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 97108 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:36:47.715292 115789 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:36:47.716385 115789 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal(Tensor([10, 3, 143165577],"float32"), )
[torch error] paddle.diagonal(Tensor([10, 3, 143165577],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 163505 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:37:56.064366 116455 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:37:56.065397 116455 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal(Tensor([10, 3, 143165577],"float32"), offset=0, axis1=1, axis2=2, )
[torch error] paddle.diagonal(Tensor([10, 3, 143165577],"float32"), offset=0, axis1=1, axis2=2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 65938 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:39:09.559492 117117 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:39:09.570153 117117 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal(Tensor([10, 3, 143165577],"float32"), offset=0, axis1=2, axis2=1, )
[torch error] paddle.diagonal(Tensor([10, 3, 143165577],"float32"), offset=0, axis1=2, axis2=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 123487 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:40:16.346329 118085 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:40:16.347404 118085 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal(Tensor([10, 3, 143165577],"float32"), offset=1, axis1=0, axis2=1, )
[torch error] paddle.diagonal(Tensor([10, 3, 143165577],"float32"), offset=1, axis1=0, axis2=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 13238 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:41:25.889600 118756 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:41:25.890681 118756 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal(Tensor([1073741824, 2, 2],"float32"), offset=0, axis1=-1, axis2=-2, )
[torch error] paddle.diagonal(Tensor([1073741824, 2, 2],"float32"), offset=0, axis1=-1, axis2=-2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 84091 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:42:40.863301 119422 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:42:40.864313 119422 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal(Tensor([2, 3, 715827883],"float32"), )
[torch error] paddle.diagonal(Tensor([2, 3, 715827883],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 149424 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:43:47.525053 120548 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:43:47.526137 120548 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal(Tensor([2, 3, 715827883],"float32"), offset=0, axis1=1, axis2=2, )
[torch error] paddle.diagonal(Tensor([2, 3, 715827883],"float32"), offset=0, axis1=1, axis2=2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 46064 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:44:57.274571 121218 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:44:57.275723 121218 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal(Tensor([2, 3, 715827883],"float32"), offset=0, axis1=2, axis2=1, )
[torch error] paddle.diagonal(Tensor([2, 3, 715827883],"float32"), offset=0, axis1=2, axis2=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 110930 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:46:06.158489 122046 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:46:06.159613 122046 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal(Tensor([2, 3, 715827883],"float32"), offset=1, axis1=0, axis2=1, )
[torch error] paddle.diagonal(Tensor([2, 3, 715827883],"float32"), offset=1, axis1=0, axis2=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 6612 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:47:13.709488 122958 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:47:13.710462 122958 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal(Tensor([2, 536870912, 4],"float32"), )
[torch error] paddle.diagonal(Tensor([2, 536870912, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 63096 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:48:22.657424 123614 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:48:22.658505 123614 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal(Tensor([2, 536870912, 4],"float32"), offset=0, axis1=1, axis2=2, )
[torch error] paddle.diagonal(Tensor([2, 536870912, 4],"float32"), offset=0, axis1=1, axis2=2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 130786 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:49:29.741189 124311 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:49:29.742331 124311 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal(Tensor([2, 536870912, 4],"float32"), offset=0, axis1=2, axis2=1, )
[torch error] paddle.diagonal(Tensor([2, 536870912, 4],"float32"), offset=0, axis1=2, axis2=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 27881 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:50:43.720753 124989 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:50:43.721899 124989 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal(Tensor([2, 536870912, 4],"float32"), offset=1, axis1=0, axis2=1, )
[torch error] paddle.diagonal(Tensor([2, 536870912, 4],"float32"), offset=1, axis1=0, axis2=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 88604 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:51:51.157833 125936 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:51:51.158938 125936 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal(Tensor([357913942, 3, 4],"float32"), )
[torch error] paddle.diagonal(Tensor([357913942, 3, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 154959 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:52:59.839025 126648 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:52:59.840138 126648 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal(Tensor([357913942, 3, 4],"float32"), offset=0, axis1=1, axis2=2, )
[torch error] paddle.diagonal(Tensor([357913942, 3, 4],"float32"), offset=0, axis1=1, axis2=2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 51472 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:54:09.241262 127326 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:54:09.242273 127326 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal(Tensor([357913942, 3, 4],"float32"), offset=0, axis1=2, axis2=1, )
[torch error] paddle.diagonal(Tensor([357913942, 3, 4],"float32"), offset=0, axis1=2, axis2=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 110019 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:55:16.663028 128269 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:55:16.664167 128269 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal(Tensor([357913942, 3, 4],"float32"), offset=1, axis1=0, axis2=1, )
[torch error] paddle.diagonal(Tensor([357913942, 3, 4],"float32"), offset=1, axis1=0, axis2=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 1713 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 18:56:25.824692 128954 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:56:25.825825 128954 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([10, 10],"bool"), Tensor([4294967295],"bool"), offset=0, axis1=0, axis2=1, )
[torch error] paddle.diagonal_scatter(Tensor([10, 10],"bool"), Tensor([4294967295],"bool"), offset=0, axis1=0, axis2=1, ) 
 expected src to have a size equal to the slice of self. src size = [4294967295], slice size = [10]

W0212 18:57:32.277289 129644 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:57:32.278466 129644 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([10, 10],"float16"), Tensor([4294967295],"float16"), offset=0, axis1=0, axis2=1, )
[torch error] paddle.diagonal_scatter(Tensor([10, 10],"float16"), Tensor([4294967295],"float16"), offset=0, axis1=0, axis2=1, ) 
 expected src to have a size equal to the slice of self. src size = [4294967295], slice size = [10]

W0212 18:59:03.599227 130315 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 18:59:03.600364 130315 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([10, 10],"float32"), Tensor([4294967295],"float32"), offset=0, axis1=0, axis2=1, )
[torch error] paddle.diagonal_scatter(Tensor([10, 10],"float32"), Tensor([4294967295],"float32"), offset=0, axis1=0, axis2=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 51142 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:00:10.086961 131577 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:00:10.087913 131577 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([10, 10],"float32"), Tensor([4294967295],"float32"), offset=0, axis1=1, axis2=0, )
[torch error] paddle.diagonal_scatter(Tensor([10, 10],"float32"), Tensor([4294967295],"float32"), offset=0, axis1=1, axis2=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 104421 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:01:22.449326 132249 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:01:22.450394 132249 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([10, 10],"float32"), Tensor([4294967295],"float32"), offset=1, axis1=0, axis2=1, )
[torch error] paddle.diagonal_scatter(Tensor([10, 10],"float32"), Tensor([4294967295],"float32"), offset=1, axis1=0, axis2=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 10618 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:02:28.353896 133241 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:02:28.354925 133241 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([10, 10],"float32"), Tensor([4294967295],"float32"), offset=-2, axis1=0, axis2=1, )
[torch error] paddle.diagonal_scatter(Tensor([10, 10],"float32"), Tensor([4294967295],"float32"), offset=-2, axis1=0, axis2=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 64675 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:03:34.150806 133924 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:03:34.151857 133924 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([10, 10],"float64"), Tensor([2147483649],"float64"), offset=0, axis1=0, axis2=1, )
[torch error] paddle.diagonal_scatter(Tensor([10, 10],"float64"), Tensor([2147483649],"float64"), offset=0, axis1=0, axis2=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 127573 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:04:22.398736 134852 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:04:22.400090 134852 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([10, 10],"int16"), Tensor([4294967295],"int16"), offset=0, axis1=0, axis2=1, )
[torch error] paddle.diagonal_scatter(Tensor([10, 10],"int16"), Tensor([4294967295],"int16"), offset=0, axis1=0, axis2=1, ) 
 expected src to have a size equal to the slice of self. src size = [4294967295], slice size = [10]

W0212 19:05:27.975245 135220 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:05:27.976534 135220 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([10, 10],"int32"), Tensor([4294967295],"int32"), offset=0, axis1=0, axis2=1, )
[torch error] paddle.diagonal_scatter(Tensor([10, 10],"int32"), Tensor([4294967295],"int32"), offset=0, axis1=0, axis2=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 61652 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:06:41.187197 135904 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:06:41.188371 135904 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([10, 10],"int64"), Tensor([2147483649],"int64"), offset=0, axis1=0, axis2=1, )
[torch error] paddle.diagonal_scatter(Tensor([10, 10],"int64"), Tensor([2147483649],"int64"), offset=0, axis1=0, axis2=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 133562 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:07:27.620514 136842 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:07:27.621644 136842 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([10, 10],"int8"), Tensor([4294967295],"int8"), offset=0, axis1=0, axis2=1, )
[torch error] paddle.diagonal_scatter(Tensor([10, 10],"int8"), Tensor([4294967295],"int8"), offset=0, axis1=0, axis2=1, ) 
 expected src to have a size equal to the slice of self. src size = [4294967295], slice size = [10]

W0212 19:08:35.065812 137207 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:08:35.067082 137207 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([10, 10],"uint8"), Tensor([4294967295],"uint8"), offset=0, axis1=0, axis2=1, )
[torch error] paddle.diagonal_scatter(Tensor([10, 10],"uint8"), Tensor([4294967295],"uint8"), offset=0, axis1=0, axis2=1, ) 
 expected src to have a size equal to the slice of self. src size = [4294967295], slice size = [10]

W0212 19:09:38.838948 138132 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:09:38.840143 138132 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([10, 214748365],"float64"), Tensor([10],"float64"), offset=0, axis1=0, axis2=1, )
[torch error] paddle.diagonal_scatter(Tensor([10, 214748365],"float64"), Tensor([10],"float64"), offset=0, axis1=0, axis2=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 130125 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:10:24.048550 138800 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:10:24.049621 138800 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([10, 214748365],"int64"), Tensor([10],"int64"), offset=0, axis1=0, axis2=1, )
[torch error] paddle.diagonal_scatter(Tensor([10, 214748365],"int64"), Tensor([10],"int64"), offset=0, axis1=0, axis2=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 6568 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:11:08.086082 139162 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:11:08.087277 139162 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([10, 429496730],"bool"), Tensor([10],"bool"), offset=0, axis1=0, axis2=1, )
[paddle error] paddle.diagonal_scatter(Tensor([10, 429496730],"bool"), Tensor([10],"bool"), offset=0, axis1=0, axis2=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 75.571228GB memory has been allocated and available memory is only 3.613647GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 19:12:24.070684 139787 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:12:24.071549 139787 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([10, 429496730],"float16"), Tensor([10],"float16"), offset=0, axis1=0, axis2=1, )
[torch error] paddle.diagonal_scatter(Tensor([10, 429496730],"float16"), Tensor([10],"float16"), offset=0, axis1=0, axis2=1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 111684 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:13:52.635035 140467 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:13:52.636157 140467 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([10, 429496730],"float32"), Tensor([10],"float32"), offset=0, axis1=0, axis2=1, )
[torch error] paddle.diagonal_scatter(Tensor([10, 429496730],"float32"), Tensor([10],"float32"), offset=0, axis1=0, axis2=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 33158 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:14:59.133283 141456 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:14:59.134377 141456 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([10, 429496730],"float32"), Tensor([10],"float32"), offset=0, axis1=1, axis2=0, )
[torch error] paddle.diagonal_scatter(Tensor([10, 429496730],"float32"), Tensor([10],"float32"), offset=0, axis1=1, axis2=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 87722 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:16:14.016244 142123 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:16:14.017306 142123 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([10, 429496730],"float32"), Tensor([8],"float32"), offset=-2, axis1=0, axis2=1, )
[torch error] paddle.diagonal_scatter(Tensor([10, 429496730],"float32"), Tensor([8],"float32"), offset=-2, axis1=0, axis2=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 148476 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:17:25.439935 143066 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:17:25.440945 143066 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([10, 429496730],"float32"), Tensor([9],"float32"), offset=1, axis1=0, axis2=1, )
[torch error] paddle.diagonal_scatter(Tensor([10, 429496730],"float32"), Tensor([9],"float32"), offset=1, axis1=0, axis2=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 52521 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:18:34.363257 143739 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:18:34.364354 143739 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([10, 429496730],"int16"), Tensor([10],"int16"), offset=0, axis1=0, axis2=1, )
[torch error] paddle.diagonal_scatter(Tensor([10, 429496730],"int16"), Tensor([10],"int16"), offset=0, axis1=0, axis2=1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 111256 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:19:39.856015 144660 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:19:39.856971 144660 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([10, 429496730],"int32"), Tensor([10],"int32"), offset=0, axis1=0, axis2=1, )
[torch error] paddle.diagonal_scatter(Tensor([10, 429496730],"int32"), Tensor([10],"int32"), offset=0, axis1=0, axis2=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 985 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:20:48.304383 145357 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:20:48.305509 145357 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([10, 429496730],"int8"), Tensor([10],"int8"), offset=0, axis1=0, axis2=1, )
[paddle error] paddle.diagonal_scatter(Tensor([10, 429496730],"int8"), Tensor([10],"int8"), offset=0, axis1=0, axis2=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 75.571228GB memory has been allocated and available memory is only 3.613647GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 19:22:07.900452 146030 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:22:07.901253 146030 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([10, 429496730],"uint8"), Tensor([10],"uint8"), offset=0, axis1=0, axis2=1, )
[paddle error] paddle.diagonal_scatter(Tensor([10, 429496730],"uint8"), Tensor([10],"uint8"), offset=0, axis1=0, axis2=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 75.571228GB memory has been allocated and available memory is only 3.613647GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 19:23:30.235144 146973 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:23:30.236146 146973 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([214748365, 10],"float64"), Tensor([10],"float64"), offset=0, axis1=0, axis2=1, )
[torch error] paddle.diagonal_scatter(Tensor([214748365, 10],"float64"), Tensor([10],"float64"), offset=0, axis1=0, axis2=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 21883 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:24:15.402065 147671 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:24:15.403162 147671 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([214748365, 10],"int64"), Tensor([10],"int64"), offset=0, axis1=0, axis2=1, )
[torch error] paddle.diagonal_scatter(Tensor([214748365, 10],"int64"), Tensor([10],"int64"), offset=0, axis1=0, axis2=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 57955 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:24:58.148025 148307 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:24:58.149057 148307 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([429496730, 10],"bool"), Tensor([10],"bool"), offset=0, axis1=0, axis2=1, )
[paddle error] paddle.diagonal_scatter(Tensor([429496730, 10],"bool"), Tensor([10],"bool"), offset=0, axis1=0, axis2=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 75.571228GB memory has been allocated and available memory is only 3.613647GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 19:26:13.803699 148675 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:26:13.804533 148675 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([429496730, 10],"float16"), Tensor([10],"float16"), offset=0, axis1=0, axis2=1, )
[torch error] paddle.diagonal_scatter(Tensor([429496730, 10],"float16"), Tensor([10],"float16"), offset=0, axis1=0, axis2=1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 1491 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:27:34.361361 149624 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:27:34.362342 149624 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([429496730, 10],"float32"), Tensor([10],"float32"), offset=0, axis1=0, axis2=1, )
[torch error] paddle.diagonal_scatter(Tensor([429496730, 10],"float32"), Tensor([10],"float32"), offset=0, axis1=0, axis2=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 75218 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:28:47.001375 150409 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:28:47.002389 150409 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([429496730, 10],"float32"), Tensor([10],"float32"), offset=0, axis1=1, axis2=0, )
[torch error] paddle.diagonal_scatter(Tensor([429496730, 10],"float32"), Tensor([10],"float32"), offset=0, axis1=1, axis2=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 135669 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:29:59.338594 151288 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:29:59.339792 151288 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([429496730, 10],"float32"), Tensor([8],"float32"), offset=-2, axis1=0, axis2=1, )
[torch error] paddle.diagonal_scatter(Tensor([429496730, 10],"float32"), Tensor([8],"float32"), offset=-2, axis1=0, axis2=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 34759 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:31:14.831761 151960 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:31:14.832808 151960 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([429496730, 10],"float32"), Tensor([9],"float32"), offset=1, axis1=0, axis2=1, )
[torch error] paddle.diagonal_scatter(Tensor([429496730, 10],"float32"), Tensor([9],"float32"), offset=1, axis1=0, axis2=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 88139 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:32:22.108062 152919 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:32:22.109140 152919 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([429496730, 10],"int16"), Tensor([10],"int16"), offset=0, axis1=0, axis2=1, )
[torch error] paddle.diagonal_scatter(Tensor([429496730, 10],"int16"), Tensor([10],"int16"), offset=0, axis1=0, axis2=1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 151672 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:33:27.911916 153591 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:33:27.913048 153591 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([429496730, 10],"int32"), Tensor([10],"int32"), offset=0, axis1=0, axis2=1, )
[torch error] paddle.diagonal_scatter(Tensor([429496730, 10],"int32"), Tensor([10],"int32"), offset=0, axis1=0, axis2=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 38714 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:34:40.942394 154263 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:34:40.943488 154263 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([429496730, 10],"int8"), Tensor([10],"int8"), offset=0, axis1=0, axis2=1, )
[paddle error] paddle.diagonal_scatter(Tensor([429496730, 10],"int8"), Tensor([10],"int8"), offset=0, axis1=0, axis2=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 75.571228GB memory has been allocated and available memory is only 3.613647GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 19:35:57.004900 155217 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:35:57.006213 155217 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diagonal_scatter(Tensor([429496730, 10],"uint8"), Tensor([10],"uint8"), offset=0, axis1=0, axis2=1, )
[paddle error] paddle.diagonal_scatter(Tensor([429496730, 10],"uint8"), Tensor([10],"uint8"), offset=0, axis1=0, axis2=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 75.571228GB memory has been allocated and available memory is only 3.613647GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 19:37:15.351389 155901 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:37:15.352528 155901 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([10, 429496730],"float32"), n=1, axis=-1, prepend=None, append=None, )
[torch error] paddle.diff(Tensor([10, 429496730],"float32"), n=1, axis=-1, prepend=None, append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 72013 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:38:25.732986 156867 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:38:25.733983 156867 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([1073741824, 4],"float16"), axis=1, )
[torch error] paddle.diff(Tensor([1073741824, 4],"float16"), axis=1, ) 
 CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 141692 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:39:48.586620 157544 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:39:48.587680 157544 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([1073741824, 4],"float32"), n=1, axis=0, prepend=None, append=None, )
[torch error] paddle.diff(Tensor([1073741824, 4],"float32"), n=1, axis=0, prepend=None, append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 51584 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:40:59.908154 158504 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:40:59.909140 158504 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([1073741824, 4],"float32"), n=1, axis=0, prepend=None, append=Tensor([1, 4],"float32"), )
[torch error] paddle.diff(Tensor([1073741824, 4],"float32"), n=1, axis=0, prepend=None, append=Tensor([1, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 112252 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:42:06.961143 159191 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:42:06.962168 159191 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([1073741824, 4],"float32"), n=1, axis=0, prepend=None, append=Tensor([1073741824, 4],"float32"), )
[torch error] paddle.diff(Tensor([1073741824, 4],"float32"), n=1, axis=0, prepend=None, append=Tensor([1073741824, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 2694 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:43:17.123103 160137 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:43:17.124289 160137 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([1073741824, 4],"float32"), n=1, axis=0, prepend=Tensor([1073741824, 4],"float32"), append=None, )
[torch error] paddle.diff(Tensor([1073741824, 4],"float32"), n=1, axis=0, prepend=Tensor([1073741824, 4],"float32"), append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 57886 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:44:29.057168 160790 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:44:29.058283 160790 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([1073741824, 4],"float32"), n=1, axis=0, prepend=Tensor([1073741824, 4],"float32"), append=Tensor([1073741824, 4],"float32"), )
[torch error] paddle.diff(Tensor([1073741824, 4],"float32"), n=1, axis=0, prepend=Tensor([1073741824, 4],"float32"), append=Tensor([1073741824, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 127265 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:45:41.007680 161440 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:45:41.008731 161440 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([1073741824, 4],"float32"), n=1, axis=0, prepend=Tensor([2, 4],"float32"), append=Tensor([2, 4],"float32"), )
[torch error] paddle.diff(Tensor([1073741824, 4],"float32"), n=1, axis=0, prepend=Tensor([2, 4],"float32"), append=Tensor([2, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 26049 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:46:55.690665 162314 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:46:55.691773 162314 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([1073741824, 4],"float32"), n=1, axis=0, prepend=Tensor([3, 4],"float32"), append=None, )
[torch error] paddle.diff(Tensor([1073741824, 4],"float32"), n=1, axis=0, prepend=Tensor([3, 4],"float32"), append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 101259 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:48:02.966985 162924 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:48:02.968007 162924 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([1073741824, 4],"float32"), n=1, axis=-1, prepend=None, append=Tensor([1073741824, 3],"float32"), )
[torch error] paddle.diff(Tensor([1073741824, 4],"float32"), n=1, axis=-1, prepend=None, append=Tensor([1073741824, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 156094 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:49:14.788821 163607 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:49:14.789752 163607 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([1073741824, 4],"float32"), n=1, axis=-1, prepend=None, append=Tensor([2, 3],"float32"), )
[torch error] paddle.diff(Tensor([1073741824, 4],"float32"), n=1, axis=-1, prepend=None, append=Tensor([2, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 48270 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:50:22.622728  1036 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:50:22.623868  1036 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([1073741824, 4],"float32"), n=1, axis=-1, prepend=Tensor([1073741824, 2],"float32"), append=Tensor([1073741824, 3],"float32"), )
[torch error] paddle.diff(Tensor([1073741824, 4],"float32"), n=1, axis=-1, prepend=Tensor([1073741824, 2],"float32"), append=Tensor([1073741824, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 115377 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:51:36.077036  1710 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:51:36.077966  1710 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([1073741824, 4],"float32"), n=1, axis=-1, prepend=Tensor([1073741824, 3],"float32"), append=None, )
[torch error] paddle.diff(Tensor([1073741824, 4],"float32"), n=1, axis=-1, prepend=Tensor([1073741824, 3],"float32"), append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 13838 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:52:48.144052  2671 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:52:48.145176  2671 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([1073741824, 4],"float32"), n=1, axis=-1, prepend=Tensor([2, 2],"float32"), append=Tensor([2, 3],"float32"), )
[torch error] paddle.diff(Tensor([1073741824, 4],"float32"), n=1, axis=-1, prepend=Tensor([2, 2],"float32"), append=Tensor([2, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 80915 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:54:01.360251  3337 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:54:01.361406  3337 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([1073741824, 4],"float32"), n=1, axis=-1, prepend=Tensor([2, 3],"float32"), append=None, )
[torch error] paddle.diff(Tensor([1073741824, 4],"float32"), n=1, axis=-1, prepend=Tensor([2, 3],"float32"), append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 144028 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:55:16.290709  4272 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:55:16.291821  4272 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([1073741824, 4],"float32"), n=2, axis=0, prepend=None, append=Tensor([1073741824, 4],"float32"), )
[torch error] paddle.diff(Tensor([1073741824, 4],"float32"), n=2, axis=0, prepend=None, append=Tensor([1073741824, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 35429 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:56:25.520896  4949 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:56:25.521932  4949 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([1073741824, 4],"float32"), n=2, axis=0, prepend=None, append=Tensor([2, 4],"float32"), )
[torch error] paddle.diff(Tensor([1073741824, 4],"float32"), n=2, axis=0, prepend=None, append=Tensor([2, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 110667 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:57:38.977484  5629 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:57:38.978448  5629 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([1073741824, 4],"float32"), n=2, axis=0, prepend=Tensor([1073741824, 4],"float32"), append=None, )
[torch error] paddle.diff(Tensor([1073741824, 4],"float32"), n=2, axis=0, prepend=Tensor([1073741824, 4],"float32"), append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 15048 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 19:58:55.266813  6552 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 19:58:55.267933  6552 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([1073741824, 4],"float32"), n=2, axis=0, prepend=Tensor([1073741824, 4],"float32"), append=Tensor([1073741824, 4],"float32"), )
[torch error] paddle.diff(Tensor([1073741824, 4],"float32"), n=2, axis=0, prepend=Tensor([1073741824, 4],"float32"), append=Tensor([1073741824, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 84664 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:00:05.180907  7208 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:00:05.182001  7208 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([1073741824, 4],"float32"), n=2, axis=0, prepend=Tensor([2, 4],"float32"), append=None, )
[torch error] paddle.diff(Tensor([1073741824, 4],"float32"), n=2, axis=0, prepend=Tensor([2, 4],"float32"), append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 139674 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:01:13.743348  8157 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:01:13.744465  8157 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([1073741824, 4],"float32"), n=2, axis=0, prepend=Tensor([2, 4],"float32"), append=Tensor([2, 4],"float32"), )
[torch error] paddle.diff(Tensor([1073741824, 4],"float32"), n=2, axis=0, prepend=Tensor([2, 4],"float32"), append=Tensor([2, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 31409 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:02:21.673453  8828 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:02:21.674882  8828 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([1073741824, 4],"float32"), n=2, axis=1, prepend=None, append=None, )
[torch error] paddle.diff(Tensor([1073741824, 4],"float32"), n=2, axis=1, prepend=None, append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 98060 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:03:33.254117  9500 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:03:33.255240  9500 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([1073741824, 4],"float32"), n=2, axis=-1, prepend=None, append=Tensor([1073741824, 4],"float32"), )
[torch error] paddle.diff(Tensor([1073741824, 4],"float32"), n=2, axis=-1, prepend=None, append=Tensor([1073741824, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 154919 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:04:43.629511 10194 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:04:43.630610 10194 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([1073741824, 4],"float32"), n=2, axis=-1, prepend=None, append=Tensor([2, 4],"float32"), )
[torch error] paddle.diff(Tensor([1073741824, 4],"float32"), n=2, axis=-1, prepend=None, append=Tensor([2, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 55678 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:05:54.722474 11109 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:05:54.723626 11109 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([1073741824, 4],"float32"), n=2, axis=-1, prepend=Tensor([1073741824, 4],"float32"), append=None, )
[torch error] paddle.diff(Tensor([1073741824, 4],"float32"), n=2, axis=-1, prepend=Tensor([1073741824, 4],"float32"), append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 128288 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:07:06.489315 11784 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:07:06.490507 11784 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([1073741824, 4],"float32"), n=2, axis=-1, prepend=Tensor([1073741824, 4],"float32"), append=Tensor([1073741824, 4],"float32"), )
[torch error] paddle.diff(Tensor([1073741824, 4],"float32"), n=2, axis=-1, prepend=Tensor([1073741824, 4],"float32"), append=Tensor([1073741824, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 21793 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:08:23.843869 12733 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:08:23.844993 12733 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([1073741824, 4],"float32"), n=2, axis=-1, prepend=Tensor([2, 4],"float32"), append=None, )
[torch error] paddle.diff(Tensor([1073741824, 4],"float32"), n=2, axis=-1, prepend=Tensor([2, 4],"float32"), append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 91661 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:09:33.145884 13413 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:09:33.147068 13413 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([1073741824, 4],"float32"), n=2, axis=-1, prepend=Tensor([2, 4],"float32"), append=Tensor([2, 4],"float32"), )
[torch error] paddle.diff(Tensor([1073741824, 4],"float32"), n=2, axis=-1, prepend=Tensor([2, 4],"float32"), append=Tensor([2, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 147795 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:10:49.232482 14075 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:10:49.233458 14075 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([1431655765, 3],"float32"), axis=1, )
[torch error] paddle.diff(Tensor([1431655765, 3],"float32"), axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 59950 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:12:07.520767 15036 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:12:07.521822 15036 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 1073741825],"float64"), axis=1, )
[torch error] paddle.diff(Tensor([2, 1073741825],"float64"), axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 120773 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:12:55.340428 15980 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:12:55.341542 15980 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 2147483648],"float32"), axis=1, )
[torch error] paddle.diff(Tensor([2, 2147483648],"float32"), axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 9734 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:14:10.106611 16328 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:14:10.107633 16328 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 2147483648],"float32"), n=1, axis=0, prepend=None, append=None, )
[torch error] paddle.diff(Tensor([2, 2147483648],"float32"), n=1, axis=0, prepend=None, append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 67827 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:15:23.569432 17267 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:15:23.570547 17267 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 2147483648],"float32"), n=1, axis=0, prepend=None, append=Tensor([1, 2147483648],"float32"), )
[torch error] paddle.diff(Tensor([2, 2147483648],"float32"), n=1, axis=0, prepend=None, append=Tensor([1, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 137663 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:16:35.754367 17963 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:16:35.755313 17963 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 2147483648],"float32"), n=1, axis=0, prepend=None, append=Tensor([1, 4],"float32"), )
[torch error] paddle.diff(Tensor([2, 2147483648],"float32"), n=1, axis=0, prepend=None, append=Tensor([1, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 40231 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:17:40.897922 18891 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:17:40.898947 18891 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 2147483648],"float32"), n=1, axis=0, prepend=Tensor([2, 2147483648],"float32"), append=Tensor([2, 2147483648],"float32"), )
[torch error] paddle.diff(Tensor([2, 2147483648],"float32"), n=1, axis=0, prepend=Tensor([2, 2147483648],"float32"), append=Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 98288 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:18:55.065905 19573 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:18:55.067005 19573 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 2147483648],"float32"), n=1, axis=0, prepend=Tensor([2, 4],"float32"), append=Tensor([2, 4],"float32"), )
[torch error] paddle.diff(Tensor([2, 2147483648],"float32"), n=1, axis=0, prepend=Tensor([2, 4],"float32"), append=Tensor([2, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 3932 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:20:01.585161 20286 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:20:01.586119 20286 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 2147483648],"float32"), n=1, axis=0, prepend=Tensor([3, 2147483648],"float32"), append=None, )
[torch error] paddle.diff(Tensor([2, 2147483648],"float32"), n=1, axis=0, prepend=Tensor([3, 2147483648],"float32"), append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 58226 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:21:12.544091 20959 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:21:12.545195 20959 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 2147483648],"float32"), n=1, axis=0, prepend=Tensor([3, 4],"float32"), append=None, )
[torch error] paddle.diff(Tensor([2, 2147483648],"float32"), n=1, axis=0, prepend=Tensor([3, 4],"float32"), append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 112957 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:22:20.216877 21914 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:22:20.217968 21914 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 2147483648],"float32"), n=1, axis=-1, prepend=None, append=Tensor([2, 2147483648],"float32"), )
[torch error] paddle.diff(Tensor([2, 2147483648],"float32"), n=1, axis=-1, prepend=None, append=Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 16607 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:23:31.826392 22566 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:23:31.827339 22566 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 2147483648],"float32"), n=1, axis=-1, prepend=None, append=Tensor([2, 3],"float32"), )
[torch error] paddle.diff(Tensor([2, 2147483648],"float32"), n=1, axis=-1, prepend=None, append=Tensor([2, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 70714 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:24:43.423486 23257 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:24:43.424443 23257 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 2147483648],"float32"), n=1, axis=-1, prepend=Tensor([2, 2],"float32"), append=Tensor([2, 3],"float32"), )
[torch error] paddle.diff(Tensor([2, 2147483648],"float32"), n=1, axis=-1, prepend=Tensor([2, 2],"float32"), append=Tensor([2, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 138265 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:26:01.317255 24183 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:26:01.318356 24183 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 2147483648],"float32"), n=1, axis=-1, prepend=Tensor([2, 2147483648],"float32"), append=None, )
[torch error] paddle.diff(Tensor([2, 2147483648],"float32"), n=1, axis=-1, prepend=Tensor([2, 2147483648],"float32"), append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 48988 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:27:07.635607 24892 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:27:07.636656 24892 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 2147483648],"float32"), n=1, axis=-1, prepend=Tensor([2, 2147483648],"float32"), append=Tensor([2, 2147483648],"float32"), )
[torch error] paddle.diff(Tensor([2, 2147483648],"float32"), n=1, axis=-1, prepend=Tensor([2, 2147483648],"float32"), append=Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 103807 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:28:13.926245 25844 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:28:13.927326 25844 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 2147483648],"float32"), n=1, axis=-1, prepend=Tensor([2, 3],"float32"), append=None, )
[torch error] paddle.diff(Tensor([2, 2147483648],"float32"), n=1, axis=-1, prepend=Tensor([2, 3],"float32"), append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 157229 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:29:27.401621 26616 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:29:27.402698 26616 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 2147483648],"float32"), n=2, axis=0, prepend=None, append=Tensor([2, 2147483648],"float32"), )
[torch error] paddle.diff(Tensor([2, 2147483648],"float32"), n=2, axis=0, prepend=None, append=Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 61368 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:30:36.115967 27298 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:30:36.117066 27298 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 2147483648],"float32"), n=2, axis=0, prepend=None, append=Tensor([2, 4],"float32"), )
[torch error] paddle.diff(Tensor([2, 2147483648],"float32"), n=2, axis=0, prepend=None, append=Tensor([2, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 120209 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:31:49.322059 28249 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:31:49.323031 28249 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 2147483648],"float32"), n=2, axis=0, prepend=Tensor([2, 2147483648],"float32"), append=None, )
[torch error] paddle.diff(Tensor([2, 2147483648],"float32"), n=2, axis=0, prepend=Tensor([2, 2147483648],"float32"), append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 25532 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:32:58.168936 28927 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:32:58.170011 28927 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 2147483648],"float32"), n=2, axis=0, prepend=Tensor([2, 2147483648],"float32"), append=Tensor([2, 2147483648],"float32"), )
[torch error] paddle.diff(Tensor([2, 2147483648],"float32"), n=2, axis=0, prepend=Tensor([2, 2147483648],"float32"), append=Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 76658 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:34:11.647096 29594 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:34:11.648129 29594 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 2147483648],"float32"), n=2, axis=0, prepend=Tensor([2, 4],"float32"), append=None, )
[torch error] paddle.diff(Tensor([2, 2147483648],"float32"), n=2, axis=0, prepend=Tensor([2, 4],"float32"), append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 134009 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:35:22.159364 30530 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:35:22.160439 30530 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 2147483648],"float32"), n=2, axis=0, prepend=Tensor([2, 4],"float32"), append=Tensor([2, 4],"float32"), )
[torch error] paddle.diff(Tensor([2, 2147483648],"float32"), n=2, axis=0, prepend=Tensor([2, 4],"float32"), append=Tensor([2, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 33899 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:36:28.928839 31200 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:36:28.929935 31200 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 2147483648],"float32"), n=2, axis=1, prepend=None, append=None, )
[torch error] paddle.diff(Tensor([2, 2147483648],"float32"), n=2, axis=1, prepend=None, append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 94385 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:37:36.938151 31871 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:37:36.939579 31871 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 2147483648],"float32"), n=2, axis=-1, prepend=None, append=Tensor([2, 2147483648],"float32"), )
[torch error] paddle.diff(Tensor([2, 2147483648],"float32"), n=2, axis=-1, prepend=None, append=Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 150507 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:38:49.118029 32812 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:38:49.119019 32812 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 2147483648],"float32"), n=2, axis=-1, prepend=None, append=Tensor([2, 4],"float32"), )
[torch error] paddle.diff(Tensor([2, 2147483648],"float32"), n=2, axis=-1, prepend=None, append=Tensor([2, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 55985 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:40:00.736958 33497 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:40:00.738083 33497 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 2147483648],"float32"), n=2, axis=-1, prepend=Tensor([2, 2147483648],"float32"), append=None, )
[torch error] paddle.diff(Tensor([2, 2147483648],"float32"), n=2, axis=-1, prepend=Tensor([2, 2147483648],"float32"), append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 111646 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:41:06.716225 34174 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:41:06.717968 34174 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 2147483648],"float32"), n=2, axis=-1, prepend=Tensor([2, 2147483648],"float32"), append=Tensor([2, 2147483648],"float32"), )
[torch error] paddle.diff(Tensor([2, 2147483648],"float32"), n=2, axis=-1, prepend=Tensor([2, 2147483648],"float32"), append=Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 163231 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:42:18.957764 35100 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:42:18.958738 35100 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 2147483648],"float32"), n=2, axis=-1, prepend=Tensor([2, 4],"float32"), append=None, )
[torch error] paddle.diff(Tensor([2, 2147483648],"float32"), n=2, axis=-1, prepend=Tensor([2, 4],"float32"), append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 61029 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:43:26.164681 35787 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:43:26.165781 35787 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 2147483648],"float32"), n=2, axis=-1, prepend=Tensor([2, 4],"float32"), append=Tensor([2, 4],"float32"), )
[torch error] paddle.diff(Tensor([2, 2147483648],"float32"), n=2, axis=-1, prepend=Tensor([2, 4],"float32"), append=Tensor([2, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 119343 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:44:38.530213 36385 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:44:38.531203 36385 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=1, axis=0, prepend=None, append=Tensor([1, 4294967295],"float32"), )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=1, axis=0, prepend=None, append=Tensor([1, 4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 25766 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:45:51.508973 37341 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:45:51.510092 37341 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=1, axis=0, prepend=None, append=Tensor([1073741824, 4],"float32"), )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=1, axis=0, prepend=None, append=Tensor([1073741824, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 102224 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:47:03.652932 38006 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:47:03.654009 38006 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=1, axis=0, prepend=Tensor([1073741824, 4],"float32"), append=None, )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=1, axis=0, prepend=Tensor([1073741824, 4],"float32"), append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 160491 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:48:09.761767 38945 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:48:09.762880 38945 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=1, axis=0, prepend=Tensor([1073741824, 4],"float32"), append=Tensor([2, 4],"float32"), )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=1, axis=0, prepend=Tensor([1073741824, 4],"float32"), append=Tensor([2, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 51603 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:49:21.598819 39620 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:49:21.599785 39620 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=1, axis=0, prepend=Tensor([2, 2147483648],"float32"), append=Tensor([2, 4],"float32"), )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=1, axis=0, prepend=Tensor([2, 2147483648],"float32"), append=Tensor([2, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 120478 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:50:42.969388 40295 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:50:42.970361 40295 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=1, axis=0, prepend=Tensor([2, 4],"float32"), append=Tensor([1073741824, 4],"float32"), )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=1, axis=0, prepend=Tensor([2, 4],"float32"), append=Tensor([1073741824, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 25654 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:51:50.316571 41289 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:51:50.320688 41289 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=1, axis=0, prepend=Tensor([2, 4],"float32"), append=Tensor([2, 2147483648],"float32"), )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=1, axis=0, prepend=Tensor([2, 4],"float32"), append=Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 93616 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:52:57.288997 41942 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:52:57.289978 41942 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=1, axis=0, prepend=Tensor([3, 1431655765],"float32"), append=None, )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=1, axis=0, prepend=Tensor([3, 1431655765],"float32"), append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 146895 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:54:03.577657 42600 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:54:03.578593 42600 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=1, axis=-1, prepend=None, append=Tensor([1431655765, 3],"float32"), )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=1, axis=-1, prepend=None, append=Tensor([1431655765, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 42663 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:55:12.553128 43554 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:55:12.554150 43554 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=1, axis=-1, prepend=None, append=Tensor([2, 2147483648],"float32"), )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=1, axis=-1, prepend=None, append=Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 96464 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:56:23.998200 44212 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:56:23.999236 44212 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=1, axis=-1, prepend=Tensor([1431655765, 3],"float32"), append=None, )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=1, axis=-1, prepend=Tensor([1431655765, 3],"float32"), append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 7157 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:57:32.485795 44870 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:57:32.486838 44870 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=1, axis=-1, prepend=Tensor([2, 2],"float32"), append=Tensor([1431655765, 3],"float32"), )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=1, axis=-1, prepend=Tensor([2, 2],"float32"), append=Tensor([1431655765, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 63982 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:58:40.068409 45540 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:58:40.069337 45540 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=1, axis=-1, prepend=Tensor([2, 2],"float32"), append=Tensor([2, 2147483648],"float32"), )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=1, axis=-1, prepend=Tensor([2, 2],"float32"), append=Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 128066 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 20:59:50.659547 46469 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 20:59:50.660645 46469 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=1, axis=-1, prepend=Tensor([2, 2147483648],"float32"), append=None, )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=1, axis=-1, prepend=Tensor([2, 2147483648],"float32"), append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 32727 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:01:02.023978 47159 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:01:02.025035 47159 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=1, axis=-1, prepend=Tensor([2, 2147483648],"float32"), append=Tensor([2, 3],"float32"), )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=1, axis=-1, prepend=Tensor([2, 2147483648],"float32"), append=Tensor([2, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 95201 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:02:12.920862 47823 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:02:12.921900 47823 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=1, axis=-1, prepend=Tensor([2147483648, 2],"float32"), append=Tensor([2, 3],"float32"), )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=1, axis=-1, prepend=Tensor([2147483648, 2],"float32"), append=Tensor([2, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 151469 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:03:18.858938 48743 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:03:18.859916 48743 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=2, axis=0, prepend=None, append=Tensor([1073741824, 4],"float32"), )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=2, axis=0, prepend=None, append=Tensor([1073741824, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 53286 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:04:29.899292 49429 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:04:29.900422 49429 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=2, axis=0, prepend=None, append=Tensor([2, 2147483648],"float32"), )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=2, axis=0, prepend=None, append=Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 113599 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:05:35.850373 50087 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:05:35.854032 50087 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=2, axis=0, prepend=Tensor([1073741824, 4],"float32"), append=None, )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=2, axis=0, prepend=Tensor([1073741824, 4],"float32"), append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 6787 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:06:42.294008 51185 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:06:42.295080 51185 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=2, axis=0, prepend=Tensor([1073741824, 4],"float32"), append=Tensor([2, 4],"float32"), )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=2, axis=0, prepend=Tensor([1073741824, 4],"float32"), append=Tensor([2, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 72850 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:07:53.885406 51857 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:07:53.886435 51857 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=2, axis=0, prepend=Tensor([2, 2147483648],"float32"), append=None, )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=2, axis=0, prepend=Tensor([2, 2147483648],"float32"), append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 143223 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:09:00.658490 52529 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:09:00.659543 52529 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=2, axis=0, prepend=Tensor([2, 2147483648],"float32"), append=Tensor([2, 4],"float32"), )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=2, axis=0, prepend=Tensor([2, 2147483648],"float32"), append=Tensor([2, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 33338 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:10:14.114041 53369 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:10:14.115087 53369 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=2, axis=0, prepend=Tensor([2, 4],"float32"), append=Tensor([1073741824, 4],"float32"), )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=2, axis=0, prepend=Tensor([2, 4],"float32"), append=Tensor([1073741824, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 91097 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:11:21.380240 54317 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:11:21.381319 54317 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=2, axis=0, prepend=Tensor([2, 4],"float32"), append=Tensor([2, 2147483648],"float32"), )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=2, axis=0, prepend=Tensor([2, 4],"float32"), append=Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 158558 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:12:28.387658 54988 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:12:28.388696 54988 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=2, axis=-1, prepend=None, append=Tensor([1073741824, 4],"float32"), )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=2, axis=-1, prepend=None, append=Tensor([1073741824, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 49929 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:13:40.036355 55661 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:13:40.040032 55661 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=2, axis=-1, prepend=None, append=Tensor([2, 2147483648],"float32"), )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=2, axis=-1, prepend=None, append=Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 114189 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:14:47.250952 56617 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:14:47.252096 56617 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=2, axis=-1, prepend=Tensor([1073741824, 4],"float32"), append=None, )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=2, axis=-1, prepend=Tensor([1073741824, 4],"float32"), append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 17028 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:15:57.258419 57270 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:15:57.259482 57270 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=2, axis=-1, prepend=Tensor([1073741824, 4],"float32"), append=Tensor([2, 4],"float32"), )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=2, axis=-1, prepend=Tensor([1073741824, 4],"float32"), append=Tensor([2, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 81305 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:17:03.579164 57953 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:17:03.580286 57953 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=2, axis=-1, prepend=Tensor([2, 2147483648],"float32"), append=None, )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=2, axis=-1, prepend=Tensor([2, 2147483648],"float32"), append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 143928 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:18:09.337321 58885 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:18:09.338469 58885 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=2, axis=-1, prepend=Tensor([2, 2147483648],"float32"), append=Tensor([2, 4],"float32"), )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=2, axis=-1, prepend=Tensor([2, 2147483648],"float32"), append=Tensor([2, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 33938 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:19:20.750157 59555 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:19:20.751314 59555 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=2, axis=-1, prepend=Tensor([2, 4],"float32"), append=Tensor([1073741824, 4],"float32"), )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=2, axis=-1, prepend=Tensor([2, 4],"float32"), append=Tensor([1073741824, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 102775 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:20:27.679826 60232 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:20:27.683218 60232 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([2, 4],"float32"), n=2, axis=-1, prepend=Tensor([2, 4],"float32"), append=Tensor([2, 2147483648],"float32"), )
[torch error] paddle.diff(Tensor([2, 4],"float32"), n=2, axis=-1, prepend=Tensor([2, 4],"float32"), append=Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 157933 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:21:34.593250 60892 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:21:34.594331 60892 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([4, 1073741824],"float16"), axis=1, )
[torch error] paddle.diff(Tensor([4, 1073741824],"float16"), axis=1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 49369 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:22:59.490902 61841 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:22:59.491873 61841 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([4294967295],"bool"), n=1, axis=-1, prepend=None, append=None, )
[paddle error] paddle.diff(Tensor([4294967295],"bool"), n=1, axis=-1, prepend=None, append=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 75.565369GB memory has been allocated and available memory is only 3.619507GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0212 21:24:23.790488 62532 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:24:23.791528 62532 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([4294967295],"float32"), )
[torch error] paddle.diff(Tensor([4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 41569 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:25:35.593626 63499 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:25:35.594573 63499 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([4294967295],"float32"), n=1, axis=-1, prepend=None, append=None, )
[torch error] paddle.diff(Tensor([4294967295],"float32"), n=1, axis=-1, prepend=None, append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 100250 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:26:41.919515 64446 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:26:41.920473 64446 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([4294967295],"float32"), n=2, axis=0, prepend=None, append=None, )
[torch error] paddle.diff(Tensor([4294967295],"float32"), n=2, axis=0, prepend=None, append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 4964 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:27:54.748232 65133 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:27:54.749325 65133 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([429496730, 10],"float32"), n=1, axis=-1, prepend=None, append=None, )
[torch error] paddle.diff(Tensor([429496730, 10],"float32"), n=1, axis=-1, prepend=None, append=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 74322 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:29:06.838033 65811 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:29:06.839133 65811 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.diff(Tensor([715827883, 3],"float64"), axis=1, )
[torch error] paddle.diff(Tensor([715827883, 3],"float64"), axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 131784 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:29:52.157330 66761 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:29:52.158438 66761 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([1, 2, 2147483648],"float32"), )
[torch error] paddle.digamma(Tensor([1, 2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 15030 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:31:05.169050 67130 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:31:05.170020 67130 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([1, 2147483648, 2],"float32"), )
[torch error] paddle.digamma(Tensor([1, 2147483648, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 71989 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:32:11.571812 68075 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:32:11.572873 68075 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([1, 4294967295],"float32"), )
[torch error] paddle.digamma(Tensor([1, 4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 128561 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:33:24.354055 68773 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:33:24.355011 68773 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([10, 10, 10, 2147484],"float64"), )
[torch error] paddle.digamma(Tensor([10, 10, 10, 2147484],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 37443 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:34:14.416965 69440 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:34:14.417917 69440 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([10, 10, 10737419, 2],"float64"), )
[torch error] paddle.digamma(Tensor([10, 10, 10737419, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 76581 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:35:06.079080 70086 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:35:06.080040 70086 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([10, 10, 21474837],"float64"), )
[torch error] paddle.digamma(Tensor([10, 10, 21474837],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 128138 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:35:56.105736 70718 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:35:56.106905 70718 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([10, 10737419, 10, 2],"float64"), )
[torch error] paddle.digamma(Tensor([10, 10737419, 10, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 155476 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:36:41.426852 71093 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:36:41.428221 71093 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([10, 20, 21474837],"float32"), )
[torch error] paddle.digamma(Tensor([10, 20, 21474837],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 20835 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:37:50.208964 71741 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:37:50.209964 71741 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([10, 21474837, 10],"float64"), )
[torch error] paddle.digamma(Tensor([10, 21474837, 10],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 58524 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:38:39.908473 72406 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:38:39.909375 72406 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([10, 429496730, 1],"float32"), )
[torch error] paddle.digamma(Tensor([10, 429496730, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 77889 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:39:52.161239 73050 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:39:52.162213 73050 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([10, 429496730],"float32"), )
[torch error] paddle.digamma(Tensor([10, 429496730],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 116422 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:40:57.840857 74054 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:40:57.842483 74054 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([1073741824, 2, 2],"float32"), )
[torch error] paddle.digamma(Tensor([1073741824, 2, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 146223 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:42:04.497840 74702 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:42:04.498854 74702 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([10737419, 10, 10, 2],"float64"), )
[torch error] paddle.digamma(Tensor([10737419, 10, 10, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 14367 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:42:51.143865 75640 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:42:51.144872 75640 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([1398102, 3, 32, 32],"float32"), )
[torch error] paddle.digamma(Tensor([1398102, 3, 32, 32],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 37609 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:43:57.615619 75996 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:43:57.616663 75996 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([1431655765, 3],"float32"), )
[torch error] paddle.digamma(Tensor([1431655765, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 69161 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:45:09.282146 76653 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:45:09.283215 76653 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([2, 1073741825],"float64"), )
[torch error] paddle.digamma(Tensor([2, 1073741825],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 102386 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:45:58.080080 77583 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:45:58.081125 77583 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([2, 2147483648],"float32"), )
[torch error] paddle.digamma(Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 131149 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:47:08.846634 77958 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:47:08.847600 77958 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([2, 5, 214748365],"float64"), )
[torch error] paddle.digamma(Tensor([2, 5, 214748365],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 1605 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:47:58.538406 79108 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:47:58.539553 79108 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([2, 536870913, 2],"float64"), )
[torch error] paddle.digamma(Tensor([2, 536870913, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 25950 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:48:47.313506 79477 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:48:47.316183 79477 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([2147483648, 2],"float32"), )
[torch error] paddle.digamma(Tensor([2147483648, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 53840 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:49:56.904147 80123 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:49:56.905113 80123 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([2147483649],"float64"), )
[torch error] paddle.digamma(Tensor([2147483649],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 86170 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:50:43.792846 80798 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:50:43.793793 80798 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([214748365, 20, 1],"float32"), )
[torch error] paddle.digamma(Tensor([214748365, 20, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 110297 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:51:53.458910 81431 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:51:53.460041 81431 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([214748365, 5, 2],"float64"), )
[torch error] paddle.digamma(Tensor([214748365, 5, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 142177 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:52:40.194720 82103 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:52:40.195680 82103 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([21474837, 10, 10],"float64"), )
[torch error] paddle.digamma(Tensor([21474837, 10, 10],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 161213 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:53:28.206393 82737 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:53:28.207333 82737 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([357913942, 12],"float32"), )
[torch error] paddle.digamma(Tensor([357913942, 12],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 17531 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:54:37.031742 83112 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:54:37.032903 83112 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([4, 1073741824],"float32"), )
[torch error] paddle.digamma(Tensor([4, 1073741824],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 51350 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:55:47.739120 84044 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:55:47.740072 84044 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([4294967295, 1],"float32"), )
[torch error] paddle.digamma(Tensor([4294967295, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 95608 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:56:56.168354 84710 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:56:56.169473 84710 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([4294967295],"float32"), )
[torch error] paddle.digamma(Tensor([4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 129570 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:58:02.673898 85379 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:58:02.674939 85379 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([429496730, 5],"float64"), )
[torch error] paddle.digamma(Tensor([429496730, 5],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 159066 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:58:49.312750 86044 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:58:49.313858 86044 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([699051, 3, 32, 32],"float64"), )
[torch error] paddle.digamma(Tensor([699051, 3, 32, 32],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 19290 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 21:59:36.456699 86670 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 21:59:36.457705 86670 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([715827883, 3],"float64"), )
[torch error] paddle.digamma(Tensor([715827883, 3],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 33919 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:00:22.299397 87294 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:00:22.300525 87294 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([8, 262145, 32, 32],"float64"), )
[torch error] paddle.digamma(Tensor([8, 262145, 32, 32],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 56468 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:01:07.931285 87656 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:01:07.932363 87656 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([8, 3, 2796203, 32],"float64"), )
[torch error] paddle.digamma(Tensor([8, 3, 2796203, 32],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 81657 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:01:55.839799 88284 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:01:55.840896 88284 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([8, 3, 32, 2796203],"float64"), )
[torch error] paddle.digamma(Tensor([8, 3, 32, 2796203],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 106098 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:02:43.284940 88625 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:02:43.285885 88625 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([8, 3, 32, 5592406],"float32"), )
[torch error] paddle.digamma(Tensor([8, 3, 32, 5592406],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 127735 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:03:53.745074 89186 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:03:53.746168 89186 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([8, 3, 5592406, 32],"float32"), )
[torch error] paddle.digamma(Tensor([8, 3, 5592406, 32],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 5151 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:05:02.720789 89761 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:05:02.721843 89761 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.digamma(Tensor([8, 524288, 32, 32],"float32"), )
[torch error] paddle.digamma(Tensor([8, 524288, 32, 32],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 41789 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:06:11.969738 90335 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:06:11.970872 90335 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dist(Tensor([1431655765, 3],"float32"), Tensor([1431655765, 3],"float32"), )
[torch error] paddle.dist(Tensor([1431655765, 3],"float32"), Tensor([1431655765, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 77059 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:07:20.291172 91182 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:07:20.292236 91182 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dist(Tensor([1431655765, 3],"float32"), Tensor([2, 3],"float32"), )
[torch error] paddle.dist(Tensor([1431655765, 3],"float32"), Tensor([2, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 114444 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:08:33.873015 91757 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:08:33.873981 91757 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dist(Tensor([2, 2, 3, 2],"float32"), Tensor([1, 1, 3, 1431655765],"float32"), 2, )
[torch error] paddle.dist(Tensor([2, 2, 3, 2],"float32"), Tensor([1, 1, 3, 1431655765],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 148621 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:09:41.294370 92596 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:09:41.297745 92596 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dist(Tensor([2, 2, 3, 2],"float32"), Tensor([1, 1, 4294967295, 1],"float32"), 2, )
[torch error] paddle.dist(Tensor([2, 2, 3, 2],"float32"), Tensor([1, 1, 4294967295, 1],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 21352 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:10:57.782332 93176 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:10:57.783423 93176 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dist(Tensor([2, 2, 3, 2],"float32"), Tensor([1, 1431655765, 3, 1],"float32"), 2, )
[torch error] paddle.dist(Tensor([2, 2, 3, 2],"float32"), Tensor([1, 1431655765, 3, 1],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 60363 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:12:06.240113 93766 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:12:06.241132 93766 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dist(Tensor([2, 2, 3, 2],"float32"), Tensor([1431655765, 1, 3, 1],"float32"), 2, )
[torch error] paddle.dist(Tensor([2, 2, 3, 2],"float32"), Tensor([1431655765, 1, 3, 1],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 95644 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:13:17.097018 94591 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:13:17.100437 94591 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dist(Tensor([2, 2, 3, 357913942],"float32"), Tensor([1, 1, 3, 1],"float32"), 2, )
[torch error] paddle.dist(Tensor([2, 2, 3, 357913942],"float32"), Tensor([1, 1, 3, 1],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 128781 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:14:30.049291 95166 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:14:30.050382 95166 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dist(Tensor([2, 2, 3, 357913942],"float32"), Tensor([1, 1, 3, 357913942],"float32"), 2, )
[torch error] paddle.dist(Tensor([2, 2, 3, 357913942],"float32"), Tensor([1, 1, 3, 357913942],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 3617 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:15:40.313972 95743 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:15:40.314952 95743 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dist(Tensor([2, 2, 536870912, 2],"float32"), Tensor([1, 1, 3, 1],"float32"), 2, )
[torch error] paddle.dist(Tensor([2, 2, 536870912, 2],"float32"), Tensor([1, 1, 3, 1],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 38079 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:16:50.157970 96604 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:16:50.159089 96604 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dist(Tensor([2, 2, 536870912, 2],"float32"), Tensor([1, 1, 536870912, 1],"float32"), 2, )
[torch error] paddle.dist(Tensor([2, 2, 536870912, 2],"float32"), Tensor([1, 1, 536870912, 1],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 83828 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:18:00.004325 97179 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:18:00.005393 97179 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dist(Tensor([2, 2],"float32"), Tensor([2, 2147483648],"float32"), 0, )
[torch error] paddle.dist(Tensor([2, 2],"float32"), Tensor([2, 2147483648],"float32"), 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 117710 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:19:10.675832 97754 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:19:10.676975 97754 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dist(Tensor([2, 2],"float32"), Tensor([2147483648, 2],"float32"), 0, )
[torch error] paddle.dist(Tensor([2, 2],"float32"), Tensor([2147483648, 2],"float32"), 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 150185 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:20:19.476366 98614 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:20:19.477422 98614 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dist(Tensor([2, 2147483648],"float32"), Tensor([2, 2],"float32"), 0, )
[torch error] paddle.dist(Tensor([2, 2147483648],"float32"), Tensor([2, 2],"float32"), 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 25274 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:21:29.465973 99181 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:21:29.467140 99181 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dist(Tensor([2, 2147483648],"float32"), Tensor([2, 2147483648],"float32"), )
[torch error] paddle.dist(Tensor([2, 2147483648],"float32"), Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 56936 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:22:39.096199 99982 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:22:39.097159 99982 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dist(Tensor([2, 2147483648],"float32"), Tensor([2, 2147483648],"float32"), 0, )
[torch error] paddle.dist(Tensor([2, 2147483648],"float32"), Tensor([2, 2147483648],"float32"), 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 91003 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:23:49.449339 100823 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:23:49.450315 100823 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dist(Tensor([2, 2147483648],"float32"), Tensor([2, 3],"float32"), )
[torch error] paddle.dist(Tensor([2, 2147483648],"float32"), Tensor([2, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 134833 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:25:01.939414 101398 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:25:01.940547 101398 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dist(Tensor([2, 3],"float32"), Tensor([1431655765, 3],"float32"), )
[torch error] paddle.dist(Tensor([2, 3],"float32"), Tensor([1431655765, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 6223 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:26:12.742121 101991 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:26:12.743213 101991 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dist(Tensor([2, 3],"float32"), Tensor([2, 2147483648],"float32"), )
[torch error] paddle.dist(Tensor([2, 3],"float32"), Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 42443 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:27:27.854166 102824 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:27:27.855145 102824 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dist(Tensor([2, 357913942, 3, 2],"float32"), Tensor([1, 1, 3, 1],"float32"), 2, )
[torch error] paddle.dist(Tensor([2, 357913942, 3, 2],"float32"), Tensor([1, 1, 3, 1],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 79380 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:28:56.420495 103414 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:28:56.421545 103414 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dist(Tensor([2, 357913942, 3, 2],"float32"), Tensor([1, 357913942, 3, 1],"float32"), 2, )
[torch error] paddle.dist(Tensor([2, 357913942, 3, 2],"float32"), Tensor([1, 357913942, 3, 1],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 129138 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:30:08.205366 104243 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:30:08.206430 104243 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dist(Tensor([2147483648, 2],"float32"), Tensor([2, 2],"float32"), 0, )
[torch error] paddle.dist(Tensor([2147483648, 2],"float32"), Tensor([2, 2],"float32"), 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 162912 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:31:16.544718 105093 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:31:16.545828 105093 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dist(Tensor([2147483648, 2],"float32"), Tensor([2147483648, 2],"float32"), 0, )
[torch error] paddle.dist(Tensor([2147483648, 2],"float32"), Tensor([2147483648, 2],"float32"), 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 31151 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:32:27.674225 105669 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:32:27.675299 105669 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dist(Tensor([357913942, 2, 3, 2],"float32"), Tensor([1, 1, 3, 1],"float32"), 2, )
[torch error] paddle.dist(Tensor([357913942, 2, 3, 2],"float32"), Tensor([1, 1, 3, 1],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 63822 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:33:39.208587 106245 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:33:39.209610 106245 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dist(Tensor([357913942, 2, 3, 2],"float32"), Tensor([357913942, 1, 3, 1],"float32"), 2, )
[torch error] paddle.dist(Tensor([357913942, 2, 3, 2],"float32"), Tensor([357913942, 1, 3, 1],"float32"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 99670 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:34:48.964553 107082 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:34:48.965651 107082 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dot(Tensor([1, 1],"float32"), Tensor([1, 4294967295],"float32"), )
[torch error] paddle.dot(Tensor([1, 1],"float32"), Tensor([1, 4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 139927 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:35:54.248018 107684 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:35:54.249123 107684 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dot(Tensor([1, 1],"float32"), Tensor([4294967295, 1],"float32"), )
[torch error] paddle.dot(Tensor([1, 1],"float32"), Tensor([4294967295, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 7893 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:37:05.674711 108268 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:37:05.675697 108268 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dot(Tensor([1, 10],"float32"), Tensor([1, 4294967295],"float32"), )
[torch error] paddle.dot(Tensor([1, 10],"float32"), Tensor([1, 4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 47334 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:38:17.903775 109101 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:38:17.904899 109101 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dot(Tensor([1, 10],"float32"), Tensor([429496730, 10],"float32"), )
[torch error] paddle.dot(Tensor([1, 10],"float32"), Tensor([429496730, 10],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 77177 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:39:25.024406 109677 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:39:25.025482 109677 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dot(Tensor([1, 2],"float32"), Tensor([1, 4294967295],"float32"), )
[torch error] paddle.dot(Tensor([1, 2],"float32"), Tensor([1, 4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 107503 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:40:38.145835 110265 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:40:38.146971 110265 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dot(Tensor([1, 2],"float32"), Tensor([2147483648, 2],"float32"), )
[torch error] paddle.dot(Tensor([1, 2],"float32"), Tensor([2147483648, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 140779 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:41:57.917927 111096 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:41:57.918992 111096 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dot(Tensor([1, 4294967295],"float32"), Tensor([1, 1],"float32"), )
[torch error] paddle.dot(Tensor([1, 4294967295],"float32"), Tensor([1, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 19612 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:43:10.876693 111674 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:43:10.877766 111674 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dot(Tensor([1, 4294967295],"float32"), Tensor([1, 10],"float32"), )
[torch error] paddle.dot(Tensor([1, 4294967295],"float32"), Tensor([1, 10],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 49942 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:44:17.090193 112511 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:44:17.091166 112511 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dot(Tensor([1, 4294967295],"float32"), Tensor([1, 2],"float32"), )
[torch error] paddle.dot(Tensor([1, 4294967295],"float32"), Tensor([1, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 79936 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:45:28.798942 113084 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:45:28.799983 113084 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dot(Tensor([1, 4294967295],"float32"), Tensor([1, 4294967295],"float32"), )
[torch error] paddle.dot(Tensor([1, 4294967295],"float32"), Tensor([1, 4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 113065 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:46:36.159686 113660 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:46:36.160660 113660 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dot(Tensor([1],"float32"), Tensor([4294967295],"float32"), )
[torch error] paddle.dot(Tensor([1],"float32"), Tensor([4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 149802 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:47:49.771843 114484 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:47:49.772789 114484 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dot(Tensor([10],"float32"), Tensor([4294967295],"float32"), )
[torch error] paddle.dot(Tensor([10],"float32"), Tensor([4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 25823 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:49:02.477643 115037 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:49:02.478838 115037 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dot(Tensor([2, 2],"float32"), Tensor([2, 2147483648],"float32"), )
[torch error] paddle.dot(Tensor([2, 2],"float32"), Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 56262 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:50:10.182211 115623 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:50:10.183188 115623 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dot(Tensor([2, 2],"float32"), Tensor([2147483648, 2],"float32"), )
[torch error] paddle.dot(Tensor([2, 2],"float32"), Tensor([2147483648, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 86718 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:51:22.059093 116449 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:51:22.060123 116449 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dot(Tensor([2, 2147483648],"float32"), Tensor([2, 2],"float32"), )
[torch error] paddle.dot(Tensor([2, 2147483648],"float32"), Tensor([2, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 119779 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:52:29.538606 117032 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:52:29.539734 117032 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dot(Tensor([2, 2147483648],"float32"), Tensor([2, 2147483648],"float32"), )
[torch error] paddle.dot(Tensor([2, 2147483648],"float32"), Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 151697 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:53:40.851945 117593 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:53:40.852977 117593 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dot(Tensor([2],"float32"), Tensor([4294967295],"float32"), )
[torch error] paddle.dot(Tensor([2],"float32"), Tensor([4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 20307 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:54:47.009578 118418 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:54:47.010566 118418 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dot(Tensor([2147483648, 2],"float32"), Tensor([1, 2],"float32"), )
[torch error] paddle.dot(Tensor([2147483648, 2],"float32"), Tensor([1, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 57810 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:55:57.946633 119001 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:55:57.947777 119001 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dot(Tensor([2147483648, 2],"float32"), Tensor([2, 2],"float32"), )
[torch error] paddle.dot(Tensor([2147483648, 2],"float32"), Tensor([2, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 94579 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:57:04.850641 119576 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:57:04.851717 119576 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dot(Tensor([2147483648, 2],"float32"), Tensor([2147483648, 2],"float32"), )
[torch error] paddle.dot(Tensor([2147483648, 2],"float32"), Tensor([2147483648, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 127511 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:58:16.724412 120576 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:58:16.725380 120576 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dot(Tensor([4294967295, 1],"float32"), Tensor([1, 1],"float32"), )
[torch error] paddle.dot(Tensor([4294967295, 1],"float32"), Tensor([1, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 156361 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 22:59:28.900681 121150 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 22:59:28.901676 121150 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dot(Tensor([4294967295, 1],"float32"), Tensor([4294967295, 1],"float32"), )
[torch error] paddle.dot(Tensor([4294967295, 1],"float32"), Tensor([4294967295, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 24484 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:00:37.390882 121877 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:00:37.391860 121877 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dot(Tensor([4294967295],"float32"), Tensor([1],"float32"), )
[torch error] paddle.dot(Tensor([4294967295],"float32"), Tensor([1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 54598 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:01:42.541193 122701 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:01:42.542145 122701 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dot(Tensor([4294967295],"float32"), Tensor([10],"float32"), )
[torch error] paddle.dot(Tensor([4294967295],"float32"), Tensor([10],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 84481 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:02:53.177250 123275 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:02:53.178350 123275 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dot(Tensor([4294967295],"float32"), Tensor([2],"float32"), )
[torch error] paddle.dot(Tensor([4294967295],"float32"), Tensor([2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 123384 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:04:09.170961 123850 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:04:09.172096 123850 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dot(Tensor([4294967295],"float32"), Tensor([4294967295],"float32"), )
[torch error] paddle.dot(Tensor([4294967295],"float32"), Tensor([4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 158380 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:05:18.141862 124676 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:05:18.152436 124676 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dot(Tensor([429496730, 10],"float32"), Tensor([1, 10],"float32"), )
[torch error] paddle.dot(Tensor([429496730, 10],"float32"), Tensor([1, 10],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 23912 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:06:27.256613 125250 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:06:27.257579 125250 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dot(Tensor([429496730, 10],"float32"), Tensor([429496730, 10],"float32"), )
[torch error] paddle.dot(Tensor([429496730, 10],"float32"), Tensor([429496730, 10],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 59775 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:07:34.586580 125811 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:07:34.587747 125811 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([119304648, 3, 6],"int64"), 2, )
[torch error] paddle.dsplit(Tensor([119304648, 3, 6],"int64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 91822 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:08:18.670542 126635 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:08:18.671635 126635 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([119304648, 3, 6],"int64"), 3, )
[torch error] paddle.dsplit(Tensor([119304648, 3, 6],"int64"), 3, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 118662 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:09:02.272548 126930 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:09:02.273489 126930 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([119304648, 3, 6],"int64"), list[-1,], )
[torch error] paddle.dsplit(Tensor([119304648, 3, 6],"int64"), list[-1,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 141166 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:09:45.313160 127226 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:09:45.314254 127226 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([119304648, 3, 6],"int64"), list[-1,1,3,], )
[torch error] paddle.dsplit(Tensor([119304648, 3, 6],"int64"), list[-1,1,3,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 157668 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:10:30.635123 127771 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:10:30.636062 127771 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([119304648, 3, 6],"int64"), list[2,4,], )
[torch error] paddle.dsplit(Tensor([119304648, 3, 6],"int64"), list[2,4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 13635 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:11:16.194904 128066 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:11:16.195936 128066 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([119304648, 3, 6],"int64"), tuple(2,1,3,), )
[torch error] paddle.dsplit(Tensor([119304648, 3, 6],"int64"), tuple(2,1,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 35852 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:11:59.025372 128637 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:11:59.026433 128637 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([178956971, 2, 6],"float64"), 3, )
[torch error] paddle.dsplit(Tensor([178956971, 2, 6],"float64"), 3, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 57967 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:12:45.333273 128935 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:12:45.334218 128935 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([178956971, 2, 6],"int64"), 3, )
[torch error] paddle.dsplit(Tensor([178956971, 2, 6],"int64"), 3, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 76223 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:13:28.700764 129469 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:13:28.701805 129469 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([357913942, 2, 6],"bool"), 3, )
[torch error] paddle.dsplit(Tensor([357913942, 2, 6],"bool"), 3, ) 
 dsplit() received an invalid combination of arguments - got (indices=int, input=Tensor, ), but expected one of:
 * (Tensor input, int sections)
      didn't match because some of the keywords were incorrect: indices
 * (Tensor input, tuple of ints indices)
      didn't match because some of the arguments have invalid types: (input=Tensor, !indices=int!, )


W0212 23:14:34.430336 129740 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:14:34.431378 129740 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([357913942, 2, 6],"float16"), 3, )
[torch error] paddle.dsplit(Tensor([357913942, 2, 6],"float16"), 3, ) 
 dsplit() received an invalid combination of arguments - got (indices=int, input=Tensor, ), but expected one of:
 * (Tensor input, int sections)
      didn't match because some of the keywords were incorrect: indices
 * (Tensor input, tuple of ints indices)
      didn't match because some of the arguments have invalid types: (input=Tensor, !indices=int!, )


W0212 23:15:58.979135 130539 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:15:58.980278 130539 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([357913942, 2, 6],"float32"), 3, )
[torch error] paddle.dsplit(Tensor([357913942, 2, 6],"float32"), 3, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 10387 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:17:10.765411 131080 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:17:10.766418 131080 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([357913942, 2, 6],"int32"), 3, )
[torch error] paddle.dsplit(Tensor([357913942, 2, 6],"int32"), 3, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 43889 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:18:17.571559 131881 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:18:17.572503 131881 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([357913942, 2, 6],"uint8"), 3, )
[torch error] paddle.dsplit(Tensor([357913942, 2, 6],"uint8"), 3, ) 
 dsplit() received an invalid combination of arguments - got (indices=int, input=Tensor, ), but expected one of:
 * (Tensor input, int sections)
      didn't match because some of the keywords were incorrect: indices
 * (Tensor input, tuple of ints indices)
      didn't match because some of the arguments have invalid types: (input=Tensor, !indices=int!, )


W0212 23:19:25.866979 132417 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:19:25.868695 132417 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([4, 178956971, 6],"bool"), 3, )
[torch error] paddle.dsplit(Tensor([4, 178956971, 6],"bool"), 3, ) 
 dsplit() received an invalid combination of arguments - got (indices=int, input=Tensor, ), but expected one of:
 * (Tensor input, int sections)
      didn't match because some of the keywords were incorrect: indices
 * (Tensor input, tuple of ints indices)
      didn't match because some of the arguments have invalid types: (input=Tensor, !indices=int!, )


W0212 23:20:31.363603 133282 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:20:31.364713 133282 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([4, 178956971, 6],"float16"), 3, )
[torch error] paddle.dsplit(Tensor([4, 178956971, 6],"float16"), 3, ) 
 dsplit() received an invalid combination of arguments - got (indices=int, input=Tensor, ), but expected one of:
 * (Tensor input, int sections)
      didn't match because some of the keywords were incorrect: indices
 * (Tensor input, tuple of ints indices)
      didn't match because some of the arguments have invalid types: (input=Tensor, !indices=int!, )


W0212 23:21:57.008673 133829 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:21:57.010021 133829 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([4, 178956971, 6],"float32"), 3, )
[torch error] paddle.dsplit(Tensor([4, 178956971, 6],"float32"), 3, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 14577 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:23:03.522334 134604 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:23:03.523375 134604 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([4, 178956971, 6],"int32"), 3, )
[torch error] paddle.dsplit(Tensor([4, 178956971, 6],"int32"), 3, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 43689 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:24:13.775570 135116 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:24:13.776886 135116 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([4, 178956971, 6],"uint8"), 3, )
[torch error] paddle.dsplit(Tensor([4, 178956971, 6],"uint8"), 3, ) 
 dsplit() received an invalid combination of arguments - got (indices=int, input=Tensor, ), but expected one of:
 * (Tensor input, int sections)
      didn't match because some of the keywords were incorrect: indices
 * (Tensor input, tuple of ints indices)
      didn't match because some of the arguments have invalid types: (input=Tensor, !indices=int!, )


W0212 23:25:17.233369 135855 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:25:17.234771 135855 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([4, 2, 268435457],"float64"), 3, )
[torch error] paddle.dsplit(Tensor([4, 2, 268435457],"float64"), 3, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 109487 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:26:02.037286 136354 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:26:02.038381 136354 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([4, 2, 268435457],"int64"), 3, )
[torch error] paddle.dsplit(Tensor([4, 2, 268435457],"int64"), 3, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 138738 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:26:48.268546 136612 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:26:48.269624 136612 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([4, 2, 536870912],"bool"), 3, )
[torch error] paddle.dsplit(Tensor([4, 2, 536870912],"bool"), 3, ) 
 dsplit() received an invalid combination of arguments - got (indices=int, input=Tensor, ), but expected one of:
 * (Tensor input, int sections)
      didn't match because some of the keywords were incorrect: indices
 * (Tensor input, tuple of ints indices)
      didn't match because some of the arguments have invalid types: (input=Tensor, !indices=int!, )


W0212 23:27:52.900687 137122 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:27:52.901759 137122 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([4, 2, 536870912],"float16"), 3, )
[torch error] paddle.dsplit(Tensor([4, 2, 536870912],"float16"), 3, ) 
 dsplit() received an invalid combination of arguments - got (indices=int, input=Tensor, ), but expected one of:
 * (Tensor input, int sections)
      didn't match because some of the keywords were incorrect: indices
 * (Tensor input, tuple of ints indices)
      didn't match because some of the arguments have invalid types: (input=Tensor, !indices=int!, )


W0212 23:29:18.160789 137621 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:29:18.161994 137621 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([4, 2, 536870912],"float32"), 3, )
[torch error] paddle.dsplit(Tensor([4, 2, 536870912],"float32"), 3, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 61313 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:30:24.975703 138361 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:30:24.976723 138361 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([4, 2, 536870912],"int32"), 3, )
[torch error] paddle.dsplit(Tensor([4, 2, 536870912],"int32"), 3, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 94391 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:31:34.471792 138872 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:31:34.473263 138872 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([4, 2, 536870912],"uint8"), 3, )
[torch error] paddle.dsplit(Tensor([4, 2, 536870912],"uint8"), 3, ) 
 dsplit() received an invalid combination of arguments - got (indices=int, input=Tensor, ), but expected one of:
 * (Tensor input, int sections)
      didn't match because some of the keywords were incorrect: indices
 * (Tensor input, tuple of ints indices)
      didn't match because some of the arguments have invalid types: (input=Tensor, !indices=int!, )


W0212 23:32:36.956312 139611 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:32:36.957508 139611 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([4, 3, 178956971],"int64"), 2, )
[torch error] paddle.dsplit(Tensor([4, 3, 178956971],"int64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 153734 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:33:20.206302 140109 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:33:20.207371 140109 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([4, 3, 178956971],"int64"), 3, )
[torch error] paddle.dsplit(Tensor([4, 3, 178956971],"int64"), 3, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 12067 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:34:04.127485 140369 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:34:04.128377 140369 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([4, 3, 178956971],"int64"), list[-1,], )
[torch error] paddle.dsplit(Tensor([4, 3, 178956971],"int64"), list[-1,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 37848 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:34:52.356117 140878 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:34:52.357097 140878 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([4, 3, 178956971],"int64"), list[-1,1,3,], )
[torch error] paddle.dsplit(Tensor([4, 3, 178956971],"int64"), list[-1,1,3,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 59088 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:35:38.633157 141136 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:35:38.634152 141136 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([4, 3, 178956971],"int64"), list[2,4,], )
[torch error] paddle.dsplit(Tensor([4, 3, 178956971],"int64"), list[2,4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 75366 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:36:22.490274 141643 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:36:22.491283 141643 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([4, 3, 178956971],"int64"), tuple(2,1,3,), )
[torch error] paddle.dsplit(Tensor([4, 3, 178956971],"int64"), tuple(2,1,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 104924 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:37:05.383562 141900 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:37:05.384544 141900 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([4, 89478486, 6],"float64"), 3, )
[torch error] paddle.dsplit(Tensor([4, 89478486, 6],"float64"), 3, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 133524 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:37:54.757208 142396 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:37:54.758241 142396 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([4, 89478486, 6],"int64"), 2, )
[torch error] paddle.dsplit(Tensor([4, 89478486, 6],"int64"), 2, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 160187 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:38:37.982118 142676 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:38:37.983224 142676 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([4, 89478486, 6],"int64"), 3, )
[torch error] paddle.dsplit(Tensor([4, 89478486, 6],"int64"), 3, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 10987 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:39:22.273965 143182 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:39:22.274946 143182 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([4, 89478486, 6],"int64"), list[-1,], )
[torch error] paddle.dsplit(Tensor([4, 89478486, 6],"int64"), list[-1,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 32933 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:40:09.580966 143440 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:40:09.581966 143440 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([4, 89478486, 6],"int64"), list[-1,1,3,], )
[torch error] paddle.dsplit(Tensor([4, 89478486, 6],"int64"), list[-1,1,3,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 60558 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:40:57.675067 143938 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:40:57.676083 143938 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([4, 89478486, 6],"int64"), list[2,4,], )
[torch error] paddle.dsplit(Tensor([4, 89478486, 6],"int64"), list[2,4,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 84405 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:41:42.057017 144196 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:41:42.057981 144196 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dsplit(Tensor([4, 89478486, 6],"int64"), tuple(2,1,3,), )
[torch error] paddle.dsplit(Tensor([4, 89478486, 6],"int64"), tuple(2,1,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 100392 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:42:29.112905 144715 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:42:29.114086 144715 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 124689 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:43:17.349959 144973 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:43:17.351012 144973 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 147394 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:44:05.254546 145471 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:44:05.255664 145471 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 12649 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:44:55.276966 145967 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:44:55.278038 145967 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 34241 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:45:39.875236 146231 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:45:39.876324 146231 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 50234 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:46:23.967360 146744 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:46:23.968319 146744 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 76390 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:47:16.693826 147004 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:47:16.694968 147004 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 102803 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:48:02.543428 147504 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:48:02.544442 147504 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 128136 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:48:51.413782 147761 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:48:51.414770 147761 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 1, 1, 2147483649],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 1, 1, 2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 150888 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:49:41.363222 148260 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:49:41.364240 148260 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 3271 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:50:30.342757 148778 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:50:30.343822 148778 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),Tensor([1, 1, 1, 2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 26800 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:51:15.690285 149037 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:51:15.691371 149037 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 2147483649],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 48664 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:51:58.528051 149533 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:51:58.529114 149533 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 71399 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:52:48.490147 149791 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:52:48.491129 149791 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 93496 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:53:32.514413 150289 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:53:32.515502 150289 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 110788 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:54:17.124249 150560 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:54:17.125243 150560 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 1, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 1, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 135807 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:55:01.811329 151059 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:55:01.812310 151059 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 159158 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:55:51.042618 151316 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:55:51.043552 151316 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 1, 2147483649, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 1, 2147483649, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 25776 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:56:40.520076 151813 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:56:40.521041 151813 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 46460 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:57:25.290256 152311 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:57:25.297318 152311 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),Tensor([1, 1, 2147483649, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 68608 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:58:14.390674 152581 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:58:14.391667 152581 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 1, 2147483649],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 1, 2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 93239 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:58:58.033299 153079 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:58:58.034451 153079 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 117037 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0212 23:59:47.467109 153337 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0212 23:59:47.468092 153337 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 2147483649],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 2147483649],"float64"),Tensor([1, 1, 2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 135474 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:00:32.816443 153833 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:00:32.817690 153833 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),Tensor([1, 2147483649],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),Tensor([1, 2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 155521 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:01:20.403211 154104 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:01:20.404245 154104 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),Tensor([2147483649, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),Tensor([2147483649, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 15298 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:02:12.781950 154602 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:02:12.783103 154602 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 1],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 1],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 39480 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:03:02.814435 155099 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:03:02.815508 155099 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 1],"float64"),Tensor([2147483649, 1],"float64"),Tensor([1, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 1],"float64"),Tensor([2147483649, 1],"float64"),Tensor([1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 63654 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:03:48.972647 155357 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:03:48.974884 155357 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 2147483649, 1, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 2147483649, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 87396 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:04:41.196450 155867 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:04:41.197638 155867 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 106585 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:05:30.988019 156365 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:05:30.989126 156365 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),Tensor([1, 2147483649, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 133075 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:06:20.645114 156624 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:06:20.646241 156624 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 2147483649, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 2147483649, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 159555 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:07:06.326798 157121 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:07:06.327878 157121 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 22343 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:07:50.649649 157617 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:07:50.650741 157617 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),Tensor([1, 2147483649, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 42749 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:08:38.792804 157888 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:08:38.793890 157888 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 2147483649],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 58506 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:09:23.256014 158386 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:09:23.257087 158386 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 2147483649],"float64"),Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 2147483649],"float64"),Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 81157 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:10:11.178623 158643 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:10:11.179849 158643 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),Tensor([1, 2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 105708 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:10:58.970896 159149 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:10:58.971864 159149 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1],"float64"),Tensor([1],"float64"),Tensor([2147483649],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1],"float64"),Tensor([1],"float64"),Tensor([2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 129852 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:11:42.748695 159420 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:11:42.749764 159420 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1],"float64"),Tensor([2147483649],"float64"),Tensor([1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1],"float64"),Tensor([2147483649],"float64"),Tensor([1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 149777 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:12:31.478382 159916 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:12:31.479473 159916 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1073741825, 2],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1073741825, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 10978 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:13:17.539515 160175 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:13:17.540781 160175 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1073741825, 2],"float64"),Tensor([1073741825, 2],"float64"),Tensor([1073741825, 2],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1073741825, 2],"float64"),Tensor([1073741825, 2],"float64"),Tensor([1073741825, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 31134 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:14:03.229923 160671 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:14:03.231254 160671 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([1073741825, 2],"float64"),Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),], )
[torch error] paddle.dstack(list[Tensor([1073741825, 2],"float64"),Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 58198 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:14:52.302510 161168 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:14:52.303838 161168 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([2],"float64"),Tensor([1, 2, 1073741825],"float64"),], )
[torch error] paddle.dstack(list[Tensor([2],"float64"),Tensor([1, 2, 1073741825],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 81047 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:15:42.318199 161442 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:15:42.319214 161442 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([2],"float64"),Tensor([1, 2147483649, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([2],"float64"),Tensor([1, 2147483649, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 102634 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:16:32.849254 161940 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:16:32.851624 161940 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([2],"float64"),Tensor([1, 2147483649],"float64"),], )
[torch error] paddle.dstack(list[Tensor([2],"float64"),Tensor([1, 2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 131423 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:17:20.325287 162198 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:17:20.326300 162198 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([2],"float64"),Tensor([1073741825, 2, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([2],"float64"),Tensor([1073741825, 2, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 153916 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:18:09.343138 162695 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:18:09.344069 162695 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([2],"float64"),Tensor([1073741825, 2],"float64"),], )
[torch error] paddle.dstack(list[Tensor([2],"float64"),Tensor([1073741825, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 15092 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:18:56.203917 163204 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:18:56.204885 163204 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([2147483649, 1, 1, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([2147483649, 1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 37226 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:19:45.006174 163474 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:19:45.007227 163474 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([2147483649, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([2147483649, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 51227 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:20:30.613144   439 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:20:30.614221   439 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([2147483649, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([2147483649, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 75126 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:21:15.432271   713 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:21:15.433202   713 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([2147483649, 1, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([2147483649, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 98155 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:22:01.807981  1214 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:22:01.809139  1214 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([2147483649, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([2147483649, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 123500 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:22:47.631629  1488 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:22:47.632671  1488 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 138479 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:23:35.414686  1984 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:23:35.415658  1984 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([2147483649, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([2147483649, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 159956 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:24:23.358708  2483 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:24:23.359736  2483 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([2147483649, 1],"float64"),Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([2147483649, 1],"float64"),Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 21530 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:25:13.333603  2741 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:25:13.334740  2741 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([2147483649, 1],"float64"),Tensor([2147483649, 1],"float64"),Tensor([2147483649, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([2147483649, 1],"float64"),Tensor([2147483649, 1],"float64"),Tensor([2147483649, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 46270 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:26:02.537190  3239 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:26:02.538249  3239 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([2147483649],"float64"),], )
[torch error] paddle.dstack(list[Tensor([2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 75409 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:26:46.978159  3511 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:26:46.979243  3511 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([2147483649],"float64"),Tensor([1, 2, 1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([2147483649],"float64"),Tensor([1, 2, 1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 93288 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:27:36.643985  4008 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:27:36.645031  4008 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([2147483649],"float64"),Tensor([1, 2],"float64"),], )
[torch error] paddle.dstack(list[Tensor([2147483649],"float64"),Tensor([1, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 122035 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:28:20.710781  4508 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:28:20.711860  4508 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([2147483649],"float64"),Tensor([1],"float64"),Tensor([1],"float64"),], )
[torch error] paddle.dstack(list[Tensor([2147483649],"float64"),Tensor([1],"float64"),Tensor([1],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 144126 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:29:06.314146  4766 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:29:06.315112  4766 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),], )
[torch error] paddle.dstack(list[Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 4346 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:29:56.117761  5271 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:29:56.118711  5271 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([2147483649],"float64"),Tensor([5],"float64"),Tensor([5],"float64"),], )
[torch error] paddle.dstack(list[Tensor([2147483649],"float64"),Tensor([5],"float64"),Tensor([5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 27047 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:30:45.259020  5542 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:30:45.260098  5542 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([268435457, 4, 2],"float64"),], )
[torch error] paddle.dstack(list[Tensor([268435457, 4, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 42063 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:31:30.116626  6041 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:31:30.117578  6041 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([268435457, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),], )
[torch error] paddle.dstack(list[Tensor([268435457, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 64727 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:32:14.507776  6299 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:32:14.509081  6299 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([268435457, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[torch error] paddle.dstack(list[Tensor([268435457, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 87566 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:33:02.730530  6795 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:33:02.731614  6795 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 2],"float64"),Tensor([1073741825, 2],"float64"),Tensor([3, 2],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 2],"float64"),Tensor([1073741825, 2],"float64"),Tensor([3, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 112875 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:33:46.643565  7053 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:33:46.644622  7053 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),Tensor([1073741825, 2],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),Tensor([1073741825, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 127803 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:34:34.889179  7564 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:34:34.891609  7564 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),Tensor([3, 715827883],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),Tensor([3, 715827883],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 152552 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:35:22.854027  8073 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:35:22.855006  8073 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 2],"float64"),Tensor([3, 715827883],"float64"),Tensor([3, 2],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 2],"float64"),Tensor([3, 715827883],"float64"),Tensor([3, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 12254 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:36:10.388526  8331 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:36:10.389617  8331 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 357913942, 2],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 357913942, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 40026 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:36:59.260851  8828 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:36:59.261790  8828 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 66000 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:37:48.559564  9099 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:37:48.560552  9099 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 85521 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:38:36.185343  9598 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:38:36.186393  9598 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 4, 178956971],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 4, 178956971],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 106278 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:39:19.969722 10094 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:39:19.970777 10094 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 129670 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:40:05.349879 10352 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:40:05.351367 10352 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Including non-PyTorch memory, this process has 32.99 GiB memory in use. Process 152291 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:40:53.404183 10848 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:40:53.405232 10848 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 12413 has 1016.00 MiB memory in use. Of the allocated memory 2.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:41:39.693333 11120 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:41:39.694342 11120 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 28780 has 1016.00 MiB memory in use. Of the allocated memory 2.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:42:31.499258 11626 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:42:31.500299 11626 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 53070 has 1016.00 MiB memory in use. Of the allocated memory 2.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:43:19.951282 11884 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:43:19.952401 11884 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 76997 has 1016.00 MiB memory in use. Of the allocated memory 2.00 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:44:08.735849 12381 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:44:08.736954 12381 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 108683 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:44:58.354151 12891 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:44:58.355350 12891 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 133817 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:45:46.223927 13149 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:45:46.224912 13149 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 152088 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:46:34.254899 13646 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:46:34.255844 13646 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 15616 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:47:18.925205 14143 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:47:18.926239 14143 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 4, 2, 89478486],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 4, 2, 89478486],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 37686 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:48:04.132395 14403 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:48:04.133538 14403 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 59972 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:48:50.329597 14912 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:48:50.330667 14912 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 79286 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:49:41.474107 15180 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:49:41.475117 15180 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 99503 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:50:28.863152 15686 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:50:28.864260 15686 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 124684 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:51:18.069703 15944 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:51:18.072144 15944 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 147296 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:52:04.888110 16441 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:52:04.889169 16441 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 8334 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:52:52.912819 16962 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:52:52.913895 16962 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 27117 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:53:40.588261 17221 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:53:40.589354 17221 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 46448 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:54:25.144079 17718 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:54:25.144997 17718 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 4, 35791395, 5],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 4, 35791395, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 70884 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:55:12.043473 17975 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:55:12.044540 17975 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 95770 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:55:58.818368 18488 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:55:58.819464 18488 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 123868 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:56:46.202172 18746 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:56:46.203311 18746 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 715827883],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 715827883],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 140205 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:57:34.739266 19252 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:57:34.740443 19252 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 715827883],"float64"),Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 715827883],"float64"),Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 1319 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:58:24.433804 19510 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:58:24.435006 19510 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 715827883],"float64"),Tensor([3, 715827883],"float64"),Tensor([3, 715827883],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 715827883],"float64"),Tensor([3, 715827883],"float64"),Tensor([3, 715827883],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 24572 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 00:59:10.407099 19524 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 00:59:10.408411 19524 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 71582789, 2, 5],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 71582789, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 47614 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:00:01.130265 19551 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:00:01.131470 19551 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 76049 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:00:54.214825 19565 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:00:54.215863 19565 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], )
[torch error] paddle.dstack(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 100039 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:01:46.499848 19580 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:01:46.501008 19580 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([5],"float64"),Tensor([2147483649],"float64"),Tensor([5],"float64"),], )
[torch error] paddle.dstack(list[Tensor([5],"float64"),Tensor([2147483649],"float64"),Tensor([5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 118317 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:02:34.038877 19594 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:02:34.041556 19594 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([5],"float64"),Tensor([5],"float64"),Tensor([2147483649],"float64"),], )
[torch error] paddle.dstack(list[Tensor([5],"float64"),Tensor([5],"float64"),Tensor([2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 141626 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:03:24.738340 19621 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:03:24.739553 19621 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([53687092, 4, 2, 5],"float64"),], )
[torch error] paddle.dstack(list[Tensor([53687092, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 2264 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:04:12.833881 19635 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:04:12.835039 19635 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], )
[torch error] paddle.dstack(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 26652 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:04:57.201107 19663 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:04:57.202312 19663 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.dstack(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], )
[torch error] paddle.dstack(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 48693 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:05:44.678292 19677 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:05:44.679250 19677 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([1, 10, 429496730],"float32"), )
[torch error] paddle.empty_like(Tensor([1, 10, 429496730],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 64829 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:07:04.365471 19692 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:07:04.366446 19692 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([1, 858993459, 5],"float32"), )
[torch error] paddle.empty_like(Tensor([1, 858993459, 5],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 111931 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:08:15.401973 19706 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:08:15.402993 19706 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([10, 214748365],"float64"), )
[torch error] paddle.empty_like(Tensor([10, 214748365],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 140321 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:09:01.651780 19720 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:09:01.658977 19720 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([10, 214748365],"int64"), )
[torch error] paddle.empty_like(Tensor([10, 214748365],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 163540 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:09:44.366899 19747 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:09:44.367861 19747 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([10, 429496730],"bfloat16"), )
[torch error] paddle.empty_like(Tensor([10, 429496730],"bfloat16"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 11270 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:10:50.627534 19761 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:10:50.628576 19761 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([10, 429496730],"bool"), )
[paddle error] paddle.empty_like(Tensor([10, 429496730],"bool"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 75.569275GB memory has been allocated and available memory is only 3.615601GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0213 01:12:07.340778 19789 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:12:07.342064 19789 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([10, 429496730],"float16"), )
[torch error] paddle.empty_like(Tensor([10, 429496730],"float16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 78951 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:13:34.249048 19817 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:13:34.250164 19817 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([10, 429496730],"float32"), )
[torch error] paddle.empty_like(Tensor([10, 429496730],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 114193 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:14:41.746981 19832 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:14:41.748068 19832 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([10, 429496730],"int32"), )
[torch error] paddle.empty_like(Tensor([10, 429496730],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 144111 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:15:47.402858 19859 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:15:47.403968 19859 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([10, 429496730],"int8"), )
[paddle error] paddle.empty_like(Tensor([10, 429496730],"int8"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 75.569275GB memory has been allocated and available memory is only 3.615601GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0213 01:17:04.377444 19888 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:17:04.378273 19888 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([10, 429496730],"uint8"), )
[paddle error] paddle.empty_like(Tensor([10, 429496730],"uint8"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 75.569275GB memory has been allocated and available memory is only 3.615601GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0213 01:18:25.945363 19916 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:18:25.946292 19916 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([100, 42949673],"float32"), )
[torch error] paddle.empty_like(Tensor([100, 42949673],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 90144 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:19:30.297400 19944 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:19:30.298488 19944 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([1048577, 16, 128],"float64"), )
[torch error] paddle.empty_like(Tensor([1048577, 16, 128],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 119951 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:20:18.962816 19972 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:20:18.963959 19972 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([10737419, 20, 20],"float16"), )
[torch error] paddle.empty_like(Tensor([10737419, 20, 20],"float16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 142275 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:21:47.457260 19999 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:21:47.458446 19999 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([11, 390451573],"float32"), )
[torch error] paddle.empty_like(Tensor([11, 390451573],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 11437 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:22:54.450700 20014 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:22:54.451668 20014 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([134217728, 16, 2],"float32"), )
[torch error] paddle.empty_like(Tensor([134217728, 16, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 47282 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:24:00.144153 20041 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:24:00.145303 20041 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([16, 1048577, 128],"float64"), )
[torch error] paddle.empty_like(Tensor([16, 1048577, 128],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 78099 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:24:47.447400 20070 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:24:47.448499 20070 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([16, 134217729],"float64"), )
[torch error] paddle.empty_like(Tensor([16, 134217729],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 91073 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:25:38.514387 20098 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:25:38.515527 20098 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([16, 16, 8388609],"float64"), )
[torch error] paddle.empty_like(Tensor([16, 16, 8388609],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 117535 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:26:28.118484 20112 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:26:28.119438 20112 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([16777217, 128],"float64"), )
[torch error] paddle.empty_like(Tensor([16777217, 128],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 145290 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:27:13.678287 20140 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:27:13.679322 20140 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([2, 10, 214748365],"float32"), )
[torch error] paddle.empty_like(Tensor([2, 10, 214748365],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 3747 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:28:20.461828 20168 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:28:20.463004 20168 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([2, 107374183, 20],"float16"), )
[torch error] paddle.empty_like(Tensor([2, 107374183, 20],"float16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 30648 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:29:52.251984 20196 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:29:52.252936 20196 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([2, 20, 107374183],"float16"), )
[torch error] paddle.empty_like(Tensor([2, 20, 107374183],"float16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 67097 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:31:15.900918 20223 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:31:15.901913 20223 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([2, 2147483648],"float32"), )
[torch error] paddle.empty_like(Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 109042 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:32:26.388106 20251 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:32:26.389214 20251 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([2, 429496730, 5],"float32"), )
[torch error] paddle.empty_like(Tensor([2, 429496730, 5],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 140819 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:33:32.466154 20279 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:33:32.467254 20279 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([200, 21474837],"float32"), )
[torch error] paddle.empty_like(Tensor([200, 21474837],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 3523 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:34:39.575934 20307 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:34:39.576908 20307 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([2147483648, 2],"float32"), )
[torch error] paddle.empty_like(Tensor([2147483648, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 28900 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:35:46.622080 20322 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:35:46.623173 20322 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([2147483649],"int64"), )
[torch error] paddle.empty_like(Tensor([2147483649],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 56018 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:36:28.502916 20336 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:36:28.519523 20336 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([214748365, 20],"float32"), )
[torch error] paddle.empty_like(Tensor([214748365, 20],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 81899 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:37:34.713364 20350 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:37:34.714344 20350 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([21474837, 200],"float32"), )
[torch error] paddle.empty_like(Tensor([21474837, 200],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 116742 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:38:40.880643 20364 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:38:40.881621 20364 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([2147484, 1000],"float64"), )
[torch error] paddle.empty_like(Tensor([2147484, 1000],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 141161 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:39:24.686707 20378 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:39:24.687801 20378 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([2147484, 1000],"int64"), )
[torch error] paddle.empty_like(Tensor([2147484, 1000],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 160844 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:40:07.989625 20392 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:40:07.990693 20392 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([256, 8388609],"float64"), )
[torch error] paddle.empty_like(Tensor([256, 8388609],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 16530 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:40:56.652073 20406 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:40:56.653090 20406 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([330382100, 13],"float32"), )
[torch error] paddle.empty_like(Tensor([330382100, 13],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 37433 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:42:06.680018 20420 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:42:06.681094 20420 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([34, 126322568],"float32"), )
[torch error] paddle.empty_like(Tensor([34, 126322568],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 63675 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:43:12.140149 20434 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:43:12.141223 20434 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([4, 20, 53687092],"float16"), )
[torch error] paddle.empty_like(Tensor([4, 20, 53687092],"float16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 89126 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:44:43.114324 20448 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:44:43.115746 20448 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([4, 5, 214748365],"float32"), )
[torch error] paddle.empty_like(Tensor([4, 5, 214748365],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 123607 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:45:54.553033 20462 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:45:54.554113 20462 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([4, 53687092, 20],"float16"), )
[torch error] paddle.empty_like(Tensor([4, 53687092, 20],"float16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 157508 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:47:18.348289 20476 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:47:18.349360 20476 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([4, 53687092, 20],"float32"), )
[torch error] paddle.empty_like(Tensor([4, 53687092, 20],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 34306 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:48:24.659855 20490 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:48:24.660888 20490 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([4294967295],"bool"), )
[paddle error] paddle.empty_like(Tensor([4294967295],"bool"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 75.565369GB memory has been allocated and available memory is only 3.619507GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0213 01:49:38.768069 20504 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:49:38.769025 20504 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([4294967295],"uint8"), )
[paddle error] paddle.empty_like(Tensor([4294967295],"uint8"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 75.565369GB memory has been allocated and available memory is only 3.619507GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0213 01:50:56.939920 20518 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:50:56.940862 20518 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([42949673, 5, 20],"float32"), )
[torch error] paddle.empty_like(Tensor([42949673, 5, 20],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 121088 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:52:06.078729 20532 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:52:06.079712 20532 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([4294968, 1000],"bfloat16"), )
[torch error] paddle.empty_like(Tensor([4294968, 1000],"bfloat16"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 151352 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:53:11.961326 20546 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:53:11.962294 20546 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([4294968, 1000],"bool"), )
[paddle error] paddle.empty_like(Tensor([4294968, 1000],"bool"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000001GB memory on GPU 0, 75.569275GB memory has been allocated and available memory is only 3.615601GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0213 01:54:33.909138 20560 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:54:33.910069 20560 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([4294968, 1000],"float16"), )
[torch error] paddle.empty_like(Tensor([4294968, 1000],"float16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 43737 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:56:01.718796 20574 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:56:01.719771 20574 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([4294968, 1000],"float32"), )
[torch error] paddle.empty_like(Tensor([4294968, 1000],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 88704 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:57:12.867363 20588 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:57:12.868319 20588 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([4294968, 1000],"int32"), )
[torch error] paddle.empty_like(Tensor([4294968, 1000],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 117402 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 01:58:24.427325 20602 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:58:24.428442 20602 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([4294968, 1000],"int8"), )
[paddle error] paddle.empty_like(Tensor([4294968, 1000],"int8"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000001GB memory on GPU 0, 75.569275GB memory has been allocated and available memory is only 3.615601GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0213 01:59:38.770176 20616 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 01:59:38.771063 20616 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([4294968, 1000],"uint8"), )
[paddle error] paddle.empty_like(Tensor([4294968, 1000],"uint8"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000001GB memory on GPU 0, 75.569275GB memory has been allocated and available memory is only 3.615601GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0213 02:00:51.434010 20630 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:00:51.435019 20630 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([50, 85899346],"float32"), )
[torch error] paddle.empty_like(Tensor([50, 85899346],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 32856 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:02:00.666929 20644 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:02:00.667905 20644 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([8, 16, 33554432],"float32"), )
[torch error] paddle.empty_like(Tensor([8, 16, 33554432],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 68283 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:03:11.492964 20658 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:03:11.494064 20658 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([8, 268435456, 2],"float32"), )
[torch error] paddle.empty_like(Tensor([8, 268435456, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 98170 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:04:23.418576 20672 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:04:23.423343 20672 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.empty_like(Tensor([85899346, 10, 5],"float32"), )
[torch error] paddle.empty_like(Tensor([85899346, 10, 5],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 129071 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:05:31.009047 20686 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:05:31.020081 20686 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([1, 153391690, 28],"int32"), Tensor([6, 1, 1],"int32"), )
[torch error] paddle.equal(Tensor([1, 153391690, 28],"int32"), Tensor([6, 1, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 156189 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:06:35.673368 20701 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:06:35.674465 20701 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([1, 153391690, 28],"int32"), Tensor([6, 153391690, 1],"int32"), )
[torch error] paddle.equal(Tensor([1, 153391690, 28],"int32"), Tensor([6, 153391690, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 22552 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:07:41.217592 20715 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:07:41.218684 20715 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([1, 28, 153391690],"int32"), Tensor([6, 1, 1],"int32"), )
[torch error] paddle.equal(Tensor([1, 28, 153391690],"int32"), Tensor([6, 1, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 45809 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:08:47.074191 20729 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:08:47.075193 20729 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([1, 28, 153391690],"int32"), Tensor([6, 1, 153391690],"int32"), )
[torch error] paddle.equal(Tensor([1, 28, 153391690],"int32"), Tensor([6, 1, 153391690],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 69794 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:09:58.034031 20743 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:09:58.035097 20743 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([1, 28, 28],"int32"), Tensor([4294967295, 1, 1],"int32"), )
[torch error] paddle.equal(Tensor([1, 28, 28],"int32"), Tensor([4294967295, 1, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 105389 has 1016.00 MiB memory in use. Of the allocated memory 3.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:11:03.101955 20757 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:11:03.103008 20757 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([1, 28, 28],"int32"), Tensor([6, 1, 715827883],"int32"), )
[torch error] paddle.equal(Tensor([1, 28, 28],"int32"), Tensor([6, 1, 715827883],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 134630 has 1016.00 MiB memory in use. Of the allocated memory 3.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:12:13.488095 20771 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:12:13.489208 20771 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([1, 28, 28],"int32"), Tensor([6, 715827883, 1],"int32"), )
[torch error] paddle.equal(Tensor([1, 28, 28],"int32"), Tensor([6, 715827883, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 160032 has 1016.00 MiB memory in use. Of the allocated memory 3.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:13:19.100057 20785 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:13:19.101130 20785 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([1, 536870912, 8],"int32"), Tensor([6, 1, 1],"int32"), )
[torch error] paddle.equal(Tensor([1, 536870912, 8],"int32"), Tensor([6, 1, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 21610 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:14:28.163910 20799 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:14:28.165028 20799 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([1, 536870912, 8],"int32"), Tensor([6, 536870912, 1],"int32"), )
[torch error] paddle.equal(Tensor([1, 536870912, 8],"int32"), Tensor([6, 536870912, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 49333 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:15:40.124881 20813 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:15:40.125962 20813 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([1, 8, 536870912],"int32"), Tensor([6, 1, 1],"int32"), )
[torch error] paddle.equal(Tensor([1, 8, 536870912],"int32"), Tensor([6, 1, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 75410 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:16:52.270064 20827 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:16:52.271136 20827 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([1, 8, 536870912],"int32"), Tensor([6, 1, 536870912],"int32"), )
[torch error] paddle.equal(Tensor([1, 8, 536870912],"int32"), Tensor([6, 1, 536870912],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 111914 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:18:04.371381 20841 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:18:04.372393 20841 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([1, 8, 8],"int32"), Tensor([4294967295, 1, 1],"int32"), )
[torch error] paddle.equal(Tensor([1, 8, 8],"int32"), Tensor([4294967295, 1, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 146272 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:19:09.184296 20855 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:19:09.185340 20855 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([1, 8, 8],"int32"), Tensor([6, 1, 715827883],"int32"), )
[torch error] paddle.equal(Tensor([1, 8, 8],"int32"), Tensor([6, 1, 715827883],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 11408 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:20:20.302057 20869 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:20:20.303130 20869 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([1, 8, 8],"int32"), Tensor([6, 715827883, 1],"int32"), )
[torch error] paddle.equal(Tensor([1, 8, 8],"int32"), Tensor([6, 715827883, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 37747 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:21:31.060681 20883 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:21:31.061642 20883 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([1],"float32"), Tensor([4294967295],"float32"), )
[torch error] paddle.equal(Tensor([1],"float32"), Tensor([4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 64199 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:22:37.213482 20897 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:22:37.214457 20897 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([1],"int32"), Tensor([4294967295],"int32"), )
[torch error] paddle.equal(Tensor([1],"int32"), Tensor([4294967295],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 88891 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:23:45.772487 20911 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:23:45.773566 20911 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([1],"int64"), Tensor([2147483649],"int64"), )
[torch error] paddle.equal(Tensor([1],"int64"), Tensor([2147483649],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 114450 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:24:31.549744 20925 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:24:31.550710 20925 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 21474837],"float32"), )
[torch error] paddle.equal(Tensor([10, 20, 1],"float32"), Tensor([10, 20, 21474837],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 139291 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:25:41.300014 20939 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:25:41.301155 20939 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([10, 20, 1],"float32"), Tensor([10, 429496730, 1],"float32"), )
[torch error] paddle.equal(Tensor([10, 20, 1],"float32"), Tensor([10, 429496730, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 2250 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:26:48.636607 20953 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:26:48.637564 20953 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([10, 20, 1],"float32"), Tensor([214748365, 20, 1],"float32"), )
[torch error] paddle.equal(Tensor([10, 20, 1],"float32"), Tensor([214748365, 20, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 31697 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:27:53.269474 20967 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:27:53.270567 20967 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([10, 20, 21474837],"float32"), Tensor([10, 20, 1],"float32"), )
[torch error] paddle.equal(Tensor([10, 20, 21474837],"float32"), Tensor([10, 20, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 58731 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:28:59.097822 20981 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:28:59.098913 20981 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([10, 20, 21474837],"float32"), Tensor([10, 20, 21474837],"float32"), )
[torch error] paddle.equal(Tensor([10, 20, 21474837],"float32"), Tensor([10, 20, 21474837],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 86725 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:30:02.953485 20995 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:30:02.954670 20995 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([10, 429496730, 1],"float32"), Tensor([10, 20, 1],"float32"), )
[torch error] paddle.equal(Tensor([10, 429496730, 1],"float32"), Tensor([10, 20, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 116802 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:31:13.106482 21009 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:31:13.107553 21009 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([10, 429496730, 1],"float32"), Tensor([10, 429496730, 1],"float32"), )
[torch error] paddle.equal(Tensor([10, 429496730, 1],"float32"), Tensor([10, 429496730, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 141580 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:32:22.511298 21023 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:32:22.512403 21023 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([10, 429496730],"int32"), 0, )
[torch error] paddle.equal(Tensor([10, 429496730],"int32"), 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 3494 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:33:28.250495 21037 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:33:28.251525 21037 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([1073741824, 4],"float32"), Tensor([1073741824, 4],"float32"), )
[torch error] paddle.equal(Tensor([1073741824, 4],"float32"), Tensor([1073741824, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 28284 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:34:40.012359 21051 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:34:40.013336 21051 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([1073741824, 4],"float32"), Tensor([2, 4],"float32"), )
[torch error] paddle.equal(Tensor([1073741824, 4],"float32"), Tensor([2, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 57513 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:35:52.075606 21065 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:35:52.076526 21065 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([114, 1],"float64"), Tensor([114, 18837576],"float64"), )
[torch error] paddle.equal(Tensor([114, 1],"float64"), Tensor([114, 18837576],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 93591 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:36:35.423725 21079 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:36:35.424800 21079 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([114, 1],"float64"), Tensor([2147483649, 1],"float64"), )
[torch error] paddle.equal(Tensor([114, 1],"float64"), Tensor([2147483649, 1],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 116553 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:37:24.779994 21093 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:37:24.781088 21093 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([114, 18837576],"float64"), Tensor([114, 1],"float64"), )
[torch error] paddle.equal(Tensor([114, 18837576],"float64"), Tensor([114, 1],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 136892 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:38:14.249284 21107 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:38:14.250267 21107 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([114, 18837576],"float64"), Tensor([114, 18837576],"float64"), )
[torch error] paddle.equal(Tensor([114, 18837576],"float64"), Tensor([114, 18837576],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 156009 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:39:03.022284 21121 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:39:03.023260 21121 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([114],"float64"), Tensor([2147483649],"float64"), )
[torch error] paddle.equal(Tensor([114],"float64"), Tensor([2147483649],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 14772 has 1016.00 MiB memory in use. Of the allocated memory 1024 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:39:49.990962 21135 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:39:49.992017 21135 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([1431655765, 3],"float32"), 0, )
[torch error] paddle.equal(Tensor([1431655765, 3],"float32"), 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 26208 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:41:01.482127 21149 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:41:01.483211 21149 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([1431655765, 3],"float32"), Tensor([1431655765, 3],"float32"), )
[torch error] paddle.equal(Tensor([1431655765, 3],"float32"), Tensor([1431655765, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 61653 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:42:13.006935 21163 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:42:13.008005 21163 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([1431655765, 3],"float32"), Tensor([2, 3],"float32"), )
[torch error] paddle.equal(Tensor([1431655765, 3],"float32"), Tensor([2, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 89084 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:43:23.675408 21177 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:43:23.676501 21177 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([148, 5, 3],"float32"), Tensor([148, 5, 5804010],"float32"), )
[torch error] paddle.equal(Tensor([148, 5, 3],"float32"), Tensor([148, 5, 5804010],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 115833 has 1016.00 MiB memory in use. Of the allocated memory 9.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:44:33.407567 21191 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:44:33.408560 21191 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([148, 5, 3],"float32"), Tensor([148, 9673350, 3],"float32"), )
[torch error] paddle.equal(Tensor([148, 5, 3],"float32"), Tensor([148, 9673350, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 145145 has 1016.00 MiB memory in use. Of the allocated memory 9.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:45:38.679978 21205 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:45:38.680968 21205 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([148, 5, 3],"float32"), Tensor([286331153, 5, 3],"float32"), )
[torch error] paddle.equal(Tensor([148, 5, 3],"float32"), Tensor([286331153, 5, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 5875 has 1016.00 MiB memory in use. Of the allocated memory 9.00 KiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:46:48.994413 21219 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:46:48.995496 21219 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([148, 5, 5804010],"float32"), Tensor([148, 5, 3],"float32"), )
[torch error] paddle.equal(Tensor([148, 5, 5804010],"float32"), Tensor([148, 5, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 38094 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:47:56.475328 21233 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:47:56.476464 21233 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([148, 5, 5804010],"float32"), Tensor([148, 5, 5804010],"float32"), )
[torch error] paddle.equal(Tensor([148, 5, 5804010],"float32"), Tensor([148, 5, 5804010],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 66865 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:49:01.890337 21247 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:49:01.891456 21247 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([148, 9673350, 3],"float32"), Tensor([148, 5, 3],"float32"), )
[torch error] paddle.equal(Tensor([148, 9673350, 3],"float32"), Tensor([148, 5, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 97975 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:50:14.509943 21261 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:50:14.510922 21261 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([148, 9673350, 3],"float32"), Tensor([148, 9673350, 3],"float32"), )
[torch error] paddle.equal(Tensor([148, 9673350, 3],"float32"), Tensor([148, 9673350, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 124204 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:51:21.749756 21275 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:51:21.750867 21275 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([153391690, 28],"float32"), Tensor([153391690, 28],"float32"), )
[torch error] paddle.equal(Tensor([153391690, 28],"float32"), Tensor([153391690, 28],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 154386 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:52:37.730602 21289 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:52:37.731714 21289 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([153391690, 28],"float32"), Tensor([28, 28],"float32"), )
[torch error] paddle.equal(Tensor([153391690, 28],"float32"), Tensor([28, 28],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 18333 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:53:50.044946 21303 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:53:50.046041 21303 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([1948, 2],"float32"), Tensor([1948, 2204809],"float32"), )
[torch error] paddle.equal(Tensor([1948, 2],"float32"), Tensor([1948, 2204809],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 45898 has 1016.00 MiB memory in use. Of the allocated memory 15.50 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:55:00.502455 21317 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:55:00.503541 21317 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([1948, 2],"float32"), Tensor([2147483648, 2],"float32"), )
[torch error] paddle.equal(Tensor([1948, 2],"float32"), Tensor([2147483648, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 82672 has 1016.00 MiB memory in use. Of the allocated memory 15.50 KiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:56:05.835662 21331 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:56:05.836723 21331 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([1948, 2204809],"float32"), Tensor([1948, 2],"float32"), )
[torch error] paddle.equal(Tensor([1948, 2204809],"float32"), Tensor([1948, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 112055 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:57:18.852509 21345 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:57:18.853610 21345 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([1948, 2204809],"float32"), Tensor([1948, 2204809],"float32"), )
[torch error] paddle.equal(Tensor([1948, 2204809],"float32"), Tensor([1948, 2204809],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 140376 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:58:29.279124 21359 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:58:29.280258 21359 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2, 1, 268435456, 8],"int32"), Tensor([6, 1, 1],"int32"), )
[torch error] paddle.equal(Tensor([2, 1, 268435456, 8],"int32"), Tensor([6, 1, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 3916 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 02:59:41.407284 21373 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 02:59:41.408390 21373 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2, 1, 8, 268435456],"int32"), Tensor([6, 1, 1],"int32"), )
[torch error] paddle.equal(Tensor([2, 1, 8, 268435456],"int32"), Tensor([6, 1, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 29671 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:00:53.797631 21387 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:00:53.798609 21387 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2, 1, 8, 8],"int32"), Tensor([4294967295, 1, 1],"int32"), )
[torch error] paddle.equal(Tensor([2, 1, 8, 8],"int32"), Tensor([4294967295, 1, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 56705 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:01:57.509176 21401 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:01:57.512303 21401 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2, 1, 8, 8],"int32"), Tensor([6, 1, 715827883],"int32"), )
[torch error] paddle.equal(Tensor([2, 1, 8, 8],"int32"), Tensor([6, 1, 715827883],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 88328 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:03:01.863004 21415 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:03:01.866480 21415 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2, 1, 8, 8],"int32"), Tensor([6, 715827883, 1],"int32"), )
[torch error] paddle.equal(Tensor([2, 1, 8, 8],"int32"), Tensor([6, 715827883, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 116082 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:04:17.331073 21429 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:04:17.332048 21429 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2, 1073741825],"float64"), 0, )
[torch error] paddle.equal(Tensor([2, 1073741825],"float64"), 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 143127 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:05:05.446522 21443 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:05:05.447523 21443 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2, 2],"float32"), Tensor([2, 2147483648],"float32"), )
[torch error] paddle.equal(Tensor([2, 2],"float32"), Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 1585 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:06:14.941817 21457 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:06:14.942862 21457 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2, 2],"float32"), Tensor([2147483648, 2],"float32"), )
[torch error] paddle.equal(Tensor([2, 2],"float32"), Tensor([2147483648, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 30392 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:07:25.824025 21471 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:07:25.825214 21471 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2, 2147483648],"float32"), 0, )
[torch error] paddle.equal(Tensor([2, 2147483648],"float32"), 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 63425 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:08:34.044212 21485 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:08:34.045192 21485 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2, 2147483648],"float32"), Tensor([2, 2],"float32"), )
[torch error] paddle.equal(Tensor([2, 2147483648],"float32"), Tensor([2, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 90620 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:09:45.666914 21499 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:09:45.667917 21499 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2, 2147483648],"float32"), Tensor([2, 2147483648],"float32"), )
[torch error] paddle.equal(Tensor([2, 2147483648],"float32"), Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 116278 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:10:50.518862 21513 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:10:50.520023 21513 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2, 2147483648],"float32"), Tensor([2, 3],"float32"), )
[torch error] paddle.equal(Tensor([2, 2147483648],"float32"), Tensor([2, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 141728 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:11:57.871115 21527 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:11:57.872205 21527 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2, 2147483648],"float32"), Tensor([2, 4],"float32"), )
[torch error] paddle.equal(Tensor([2, 2147483648],"float32"), Tensor([2, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 9791 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:13:08.704921 21541 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:13:08.706050 21541 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2, 268435456, 8],"float32"), Tensor([2, 268435456, 8],"float32"), )
[torch error] paddle.equal(Tensor([2, 268435456, 8],"float32"), Tensor([2, 268435456, 8],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 38837 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:14:16.992659 21555 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:14:16.993631 21555 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2, 268435456, 8],"float32"), Tensor([2, 8, 8],"float32"), )
[torch error] paddle.equal(Tensor([2, 268435456, 8],"float32"), Tensor([2, 8, 8],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 65114 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:15:22.664074 21569 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:15:22.665094 21569 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2, 3],"float32"), Tensor([1431655765, 3],"float32"), )
[torch error] paddle.equal(Tensor([2, 3],"float32"), Tensor([1431655765, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 91401 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:16:32.373829 21583 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:16:32.374898 21583 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2, 3],"float32"), Tensor([2, 2147483648],"float32"), )
[torch error] paddle.equal(Tensor([2, 3],"float32"), Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 126454 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:17:37.431588 21597 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:17:37.432622 21597 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2, 33554432, 8, 8],"int32"), Tensor([6, 1, 1],"int32"), )
[torch error] paddle.equal(Tensor([2, 33554432, 8, 8],"int32"), Tensor([6, 1, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 148997 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:18:45.465430 21611 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:18:45.466388 21611 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2, 4],"float32"), Tensor([1073741824, 4],"float32"), )
[torch error] paddle.equal(Tensor([2, 4],"float32"), Tensor([1073741824, 4],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 10777 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:19:49.117302 21625 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:19:49.118268 21625 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2, 4],"float32"), Tensor([2, 2147483648],"float32"), )
[torch error] paddle.equal(Tensor([2, 4],"float32"), Tensor([2, 2147483648],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 34803 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:20:53.795377 21639 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:20:53.796442 21639 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2, 8, 268435456],"float32"), Tensor([2, 8, 268435456],"float32"), )
[torch error] paddle.equal(Tensor([2, 8, 268435456],"float32"), Tensor([2, 8, 268435456],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 61375 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:22:05.132943 21653 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:22:05.134004 21653 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2, 8, 268435456],"float32"), Tensor([2, 8, 8],"float32"), )
[torch error] paddle.equal(Tensor([2, 8, 268435456],"float32"), Tensor([2, 8, 8],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 95284 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:23:16.303824 21667 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:23:16.304947 21667 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2, 8, 8],"float32"), Tensor([2, 268435456, 8],"float32"), )
[torch error] paddle.equal(Tensor([2, 8, 8],"float32"), Tensor([2, 268435456, 8],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 121818 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:24:21.159171 21681 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:24:21.160216 21681 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2, 8, 8],"float32"), Tensor([2, 8, 268435456],"float32"), )
[torch error] paddle.equal(Tensor([2, 8, 8],"float32"), Tensor([2, 8, 268435456],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 142966 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:25:27.166975 21695 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:25:27.167953 21695 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2, 8, 8],"float32"), Tensor([67108864, 8, 8],"float32"), )
[torch error] paddle.equal(Tensor([2, 8, 8],"float32"), Tensor([67108864, 8, 8],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 161949 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:26:32.785423 21709 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:26:32.786422 21709 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2147483648, 2],"float32"), Tensor([1948, 2],"float32"), )
[torch error] paddle.equal(Tensor([2147483648, 2],"float32"), Tensor([1948, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 23890 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:27:39.177378 21723 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:27:39.178501 21723 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2147483648, 2],"float32"), Tensor([2, 2],"float32"), )
[torch error] paddle.equal(Tensor([2147483648, 2],"float32"), Tensor([2, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 42733 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:28:50.572201 21737 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:28:50.573202 21737 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2147483648, 2],"float32"), Tensor([2147483648, 2],"float32"), )
[torch error] paddle.equal(Tensor([2147483648, 2],"float32"), Tensor([2147483648, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 61443 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:30:01.156755 21751 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:30:01.157778 21751 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2147483649, 1],"float64"), Tensor([114, 1],"float64"), )
[torch error] paddle.equal(Tensor([2147483649, 1],"float64"), Tensor([114, 1],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 91984 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:30:50.099367 21765 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:30:50.100339 21765 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2147483649, 1],"float64"), Tensor([2147483649, 1],"float64"), )
[torch error] paddle.equal(Tensor([2147483649, 1],"float64"), Tensor([2147483649, 1],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 99610 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:31:38.705163 21779 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:31:38.706169 21779 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2147483649, 1],"float64"), Tensor([400, 1],"float64"), )
[torch error] paddle.equal(Tensor([2147483649, 1],"float64"), Tensor([400, 1],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 116231 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:32:28.044191 21805 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:32:28.045266 21805 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2147483649],"float64"), Tensor([114],"float64"), )
[torch error] paddle.equal(Tensor([2147483649],"float64"), Tensor([114],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 132536 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:33:16.884445 21819 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:33:16.894518 21819 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2147483649],"float64"), Tensor([2147483649],"float64"), )
[torch error] paddle.equal(Tensor([2147483649],"float64"), Tensor([2147483649],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 148531 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:34:08.159782 21833 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:34:08.160770 21833 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2147483649],"float64"), Tensor([400],"float64"), )
[torch error] paddle.equal(Tensor([2147483649],"float64"), Tensor([400],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 4778 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:34:57.360965 21847 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:34:57.361956 21847 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2147483649],"float64"), Tensor([5],"float64"), )
[torch error] paddle.equal(Tensor([2147483649],"float64"), Tensor([5],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 16147 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:35:46.082909 21861 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:35:46.083895 21861 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2147483649],"int64"), 0, )
[torch error] paddle.equal(Tensor([2147483649],"int64"), 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 30434 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:36:31.635141 21875 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:36:31.636207 21875 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2147483649],"int64"), 1, )
[torch error] paddle.equal(Tensor([2147483649],"int64"), 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 55018 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:37:16.947331 21889 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:37:16.948432 21889 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2147483649],"int64"), 1.0, )
[torch error] paddle.equal(Tensor([2147483649],"int64"), 1.0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 71776 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:38:02.561920 21903 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:38:02.562966 21903 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2147483649],"int64"), 10, )
[torch error] paddle.equal(Tensor([2147483649],"int64"), 10, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 92637 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:38:46.915812 21917 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:38:46.916786 21917 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2147483649],"int64"), Tensor([1],"int64"), )
[torch error] paddle.equal(Tensor([2147483649],"int64"), Tensor([1],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 103325 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:39:29.502828 21931 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:39:29.503806 21931 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2147483649],"int64"), Tensor([2147483649],"int64"), )
[torch error] paddle.equal(Tensor([2147483649],"int64"), Tensor([2147483649],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 120155 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:40:12.443755 21945 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:40:12.444792 21945 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2147483649],"int64"), Tensor([3],"int64"), )
[torch error] paddle.equal(Tensor([2147483649],"int64"), Tensor([3],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 135219 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:40:54.042941 21959 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:40:54.044035 21959 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2147483649],"int64"), Tensor([4],"int64"), )
[torch error] paddle.equal(Tensor([2147483649],"int64"), Tensor([4],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 141883 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:41:37.195118 21973 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:41:37.196230 21973 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([2147483649],"int64"), True, )
[torch error] paddle.equal(Tensor([2147483649],"int64"), True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 158715 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:42:21.787890 21987 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:42:21.788987 21987 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([214748365, 20, 1],"float32"), Tensor([10, 20, 1],"float32"), )
[torch error] paddle.equal(Tensor([214748365, 20, 1],"float32"), Tensor([10, 20, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 11411 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:43:28.816964 22001 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:43:28.817956 22001 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([214748365, 20, 1],"float32"), Tensor([214748365, 20, 1],"float32"), )
[torch error] paddle.equal(Tensor([214748365, 20, 1],"float32"), Tensor([214748365, 20, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 29995 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:44:34.258858 22015 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:44:34.259900 22015 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([214748365, 20],"int32"), 0, )
[torch error] paddle.equal(Tensor([214748365, 20],"int32"), 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 51128 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:45:39.595868 22029 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:45:39.596948 22029 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([28, 153391690],"float32"), Tensor([28, 153391690],"float32"), )
[torch error] paddle.equal(Tensor([28, 153391690],"float32"), Tensor([28, 153391690],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 70751 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:46:49.914709 22043 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:46:49.915659 22043 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([28, 153391690],"float32"), Tensor([28, 28],"float32"), )
[torch error] paddle.equal(Tensor([28, 153391690],"float32"), Tensor([28, 28],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 97190 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:47:58.442955 22057 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:47:58.444065 22057 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([28, 28],"float32"), Tensor([153391690, 28],"float32"), )
[torch error] paddle.equal(Tensor([28, 28],"float32"), Tensor([153391690, 28],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 122018 has 1016.00 MiB memory in use. Of the allocated memory 3.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:49:06.521520 22071 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:49:06.522636 22071 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([28, 28],"float32"), Tensor([28, 153391690],"float32"), )
[torch error] paddle.equal(Tensor([28, 28],"float32"), Tensor([28, 153391690],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 144272 has 1016.00 MiB memory in use. Of the allocated memory 3.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:50:17.277226 22085 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:50:17.278304 22085 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([286331153, 5, 3],"float32"), Tensor([148, 5, 3],"float32"), )
[torch error] paddle.equal(Tensor([286331153, 5, 3],"float32"), Tensor([148, 5, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 163700 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:51:27.726537 22099 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:51:27.727622 22099 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([286331153, 5, 3],"float32"), Tensor([286331153, 5, 3],"float32"), )
[torch error] paddle.equal(Tensor([286331153, 5, 3],"float32"), Tensor([286331153, 5, 3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 20297 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:52:37.474972 22113 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:52:37.476091 22113 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([3],"float32"), Tensor([4294967295],"float32"), )
[torch error] paddle.equal(Tensor([3],"float32"), Tensor([4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 39930 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:53:47.285748 22127 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:53:47.286768 22127 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([3],"int64"), Tensor([2147483649],"int64"), )
[torch error] paddle.equal(Tensor([3],"int64"), Tensor([2147483649],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 59085 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:54:31.707619 22141 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:54:31.708627 22141 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([357913942, 3, 2],"float64"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.equal(Tensor([357913942, 3, 2],"float64"), Tensor([4, 3, 2],"float16"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 79608 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:55:18.646783 22155 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:55:18.647819 22155 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([357913942, 3, 2],"float64"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.equal(Tensor([357913942, 3, 2],"float64"), Tensor([4, 3, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 98742 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:56:04.469391 22169 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:56:04.470367 22169 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([357913942, 3, 2],"float64"), Tensor([715827883, 3, 2],"float16"), )
[torch error] paddle.equal(Tensor([357913942, 3, 2],"float64"), Tensor([715827883, 3, 2],"float16"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 120200 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:56:51.427919 22183 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:56:51.428901 22183 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([357913942, 3, 2],"float64"), Tensor([715827883, 3, 2],"float32"), )
[torch error] paddle.equal(Tensor([357913942, 3, 2],"float64"), Tensor([715827883, 3, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 129542 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:57:38.332075 22197 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:57:38.333043 22197 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 268435457, 2],"float64"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.equal(Tensor([4, 268435457, 2],"float64"), Tensor([4, 3, 2],"float16"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 145804 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:58:25.675673 22211 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:58:25.676692 22211 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 268435457, 2],"float64"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.equal(Tensor([4, 268435457, 2],"float64"), Tensor([4, 3, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 161326 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 03:59:13.036815 22225 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 03:59:13.037926 22225 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 268435457, 2],"float64"), Tensor([4, 536870912, 2],"float16"), )
[torch error] paddle.equal(Tensor([4, 268435457, 2],"float64"), Tensor([4, 536870912, 2],"float16"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 14096 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:00:03.351704 22239 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:00:03.352722 22239 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 268435457, 2],"float64"), Tensor([4, 536870912, 2],"float32"), )
[torch error] paddle.equal(Tensor([4, 268435457, 2],"float64"), Tensor([4, 536870912, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 30571 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:00:55.101595 22253 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:00:55.102685 22253 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.equal(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 2],"float16"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 38635 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:01:42.339430 22267 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:01:42.340612 22267 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.equal(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 54591 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:02:28.196313 22281 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:02:28.197352 22281 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 357913942],"float16"), )
[torch error] paddle.equal(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 357913942],"float16"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 69547 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:03:16.142867 22295 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:03:16.143899 22295 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 357913942],"float32"), )
[torch error] paddle.equal(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 357913942],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 87243 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:04:08.841706 22309 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:04:08.850956 22309 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 2],"float16"), Tensor([357913942, 3, 2],"float64"), )
[torch error] paddle.equal(Tensor([4, 3, 2],"float16"), Tensor([357913942, 3, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 107039 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:04:52.313496 22323 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:04:52.314579 22323 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 2],"float16"), Tensor([4, 268435457, 2],"float64"), )
[torch error] paddle.equal(Tensor([4, 3, 2],"float16"), Tensor([4, 268435457, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 113970 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:05:39.905501 22337 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:05:39.906574 22337 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 2],"float16"), Tensor([4, 3, 178956971],"float64"), )
[torch error] paddle.equal(Tensor([4, 3, 2],"float16"), Tensor([4, 3, 178956971],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 131492 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:06:27.566659 22351 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:06:27.567747 22351 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 2],"float16"), Tensor([4, 3, 357913942],"float32"), )
[torch error] paddle.equal(Tensor([4, 3, 2],"float16"), Tensor([4, 3, 357913942],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 152869 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:07:33.719246 22365 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:07:33.720381 22365 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 2],"float16"), Tensor([4, 536870912, 2],"float32"), )
[torch error] paddle.equal(Tensor([4, 3, 2],"float16"), Tensor([4, 536870912, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 8384 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:08:43.750442 22379 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:08:43.751436 22379 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 2],"float16"), Tensor([715827883, 3, 2],"float32"), )
[torch error] paddle.equal(Tensor([4, 3, 2],"float16"), Tensor([715827883, 3, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 27645 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:09:53.527217 22393 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:09:53.528283 22393 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 2],"float32"), Tensor([357913942, 3, 2],"float64"), )
[torch error] paddle.equal(Tensor([4, 3, 2],"float32"), Tensor([357913942, 3, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 47431 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:10:40.672022 22407 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:10:40.673097 22407 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 2],"float32"), Tensor([4, 268435457, 2],"float64"), )
[torch error] paddle.equal(Tensor([4, 3, 2],"float32"), Tensor([4, 268435457, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 68581 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:11:28.674453 22421 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:11:28.675434 22421 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 2],"float32"), Tensor([4, 3, 178956971],"float64"), )
[torch error] paddle.equal(Tensor([4, 3, 2],"float32"), Tensor([4, 3, 178956971],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 87408 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:12:13.677570 22435 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:12:13.678632 22435 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 2],"float32"), Tensor([4, 3, 357913942],"float16"), )
[torch error] paddle.equal(Tensor([4, 3, 2],"float32"), Tensor([4, 3, 357913942],"float16"), ) 
 The size of tensor a (2) must match the size of tensor b (357913942) at non-singleton dimension 2

W0213 04:13:45.402304 22449 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:13:45.403385 22449 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 2],"float32"), Tensor([4, 536870912, 2],"float16"), )
[torch error] paddle.equal(Tensor([4, 3, 2],"float32"), Tensor([4, 536870912, 2],"float16"), ) 
 The size of tensor a (3) must match the size of tensor b (536870912) at non-singleton dimension 1

W0213 04:15:09.243044 22463 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:15:09.244110 22463 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 2],"float32"), Tensor([715827883, 3, 2],"float16"), )
[torch error] paddle.equal(Tensor([4, 3, 2],"float32"), Tensor([715827883, 3, 2],"float16"), ) 
 The size of tensor a (4) must match the size of tensor b (715827883) at non-singleton dimension 0

W0213 04:16:37.764475 22477 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:16:37.765575 22477 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 2],"float64"), Tensor([4, 3, 357913942],"float16"), )
[torch error] paddle.equal(Tensor([4, 3, 2],"float64"), Tensor([4, 3, 357913942],"float16"), ) 
 The size of tensor a (2) must match the size of tensor b (357913942) at non-singleton dimension 2

W0213 04:18:03.253978 22491 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:18:03.255023 22491 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 2],"float64"), Tensor([4, 3, 357913942],"float32"), )
[torch error] paddle.equal(Tensor([4, 3, 2],"float64"), Tensor([4, 3, 357913942],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 52900 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:19:12.317579 22505 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:19:12.318670 22505 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 2],"float64"), Tensor([4, 536870912, 2],"float16"), )
[torch error] paddle.equal(Tensor([4, 3, 2],"float64"), Tensor([4, 536870912, 2],"float16"), ) 
 The size of tensor a (3) must match the size of tensor b (536870912) at non-singleton dimension 1

W0213 04:20:42.584391 22519 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:20:42.585489 22519 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 2],"float64"), Tensor([4, 536870912, 2],"float32"), )
[torch error] paddle.equal(Tensor([4, 3, 2],"float64"), Tensor([4, 536870912, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 97447 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:21:47.389339 22533 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:21:47.390370 22533 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 2],"float64"), Tensor([715827883, 3, 2],"float16"), )
[torch error] paddle.equal(Tensor([4, 3, 2],"float64"), Tensor([715827883, 3, 2],"float16"), ) 
 The size of tensor a (4) must match the size of tensor b (715827883) at non-singleton dimension 0

W0213 04:23:12.347720 22547 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:23:12.348784 22547 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 2],"float64"), Tensor([715827883, 3, 2],"float32"), )
[torch error] paddle.equal(Tensor([4, 3, 2],"float64"), Tensor([715827883, 3, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 147341 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:24:21.591593 22561 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:24:21.592679 22561 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 178956971],"float64"), )
[torch error] paddle.equal(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 178956971],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 5851 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:26:17.286450 22575 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:26:17.287591 22575 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.equal(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 2],"float32"), ) 
 The size of tensor a (357913942) must match the size of tensor b (2) at non-singleton dimension 2

W0213 04:27:42.305948 22589 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:27:42.307113 22589 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.equal(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 2],"float64"), ) 
 The size of tensor a (357913942) must match the size of tensor b (2) at non-singleton dimension 2

W0213 04:29:07.067101 22603 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:29:07.068480 22603 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 357913942],"float32"), )
[torch error] paddle.equal(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 357913942],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 105307 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:31:38.348251 22617 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:31:38.349339 22617 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 178956971],"float64"), )
[torch error] paddle.equal(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 178956971],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 146535 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:32:50.224568 22631 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:32:50.225561 22631 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.equal(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 2],"float16"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 4141 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:33:55.596860 22645 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:33:55.598001 22645 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.equal(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 23505 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:35:06.900738 22659 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:35:06.901805 22659 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 357913942],"float16"), )
[torch error] paddle.equal(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 357913942],"float16"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 52416 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:36:20.114195 22673 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:36:20.127661 22673 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 536870912, 2],"float16"), Tensor([4, 268435457, 2],"float64"), )
[torch error] paddle.equal(Tensor([4, 536870912, 2],"float16"), Tensor([4, 268435457, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 77606 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:38:25.735863 22687 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:38:25.736845 22687 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 536870912, 2],"float16"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.equal(Tensor([4, 536870912, 2],"float16"), Tensor([4, 3, 2],"float32"), ) 
 The size of tensor a (536870912) must match the size of tensor b (3) at non-singleton dimension 1

W0213 04:39:56.486449 22701 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:39:56.487474 22701 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 536870912, 2],"float16"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.equal(Tensor([4, 536870912, 2],"float16"), Tensor([4, 3, 2],"float64"), ) 
 The size of tensor a (536870912) must match the size of tensor b (3) at non-singleton dimension 1

W0213 04:41:26.230379 22715 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:41:26.231371 22715 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 536870912, 2],"float16"), Tensor([4, 536870912, 2],"float32"), )
[torch error] paddle.equal(Tensor([4, 536870912, 2],"float16"), Tensor([4, 536870912, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 9621 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:43:52.410845 22729 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:43:52.411849 22729 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 536870912, 2],"float32"), Tensor([4, 268435457, 2],"float64"), )
[torch error] paddle.equal(Tensor([4, 536870912, 2],"float32"), Tensor([4, 268435457, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 56685 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:44:58.754616 22743 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:44:58.755787 22743 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 536870912, 2],"float32"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.equal(Tensor([4, 536870912, 2],"float32"), Tensor([4, 3, 2],"float16"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 77590 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:46:28.969647 22757 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:46:28.970696 22757 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 536870912, 2],"float32"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.equal(Tensor([4, 536870912, 2],"float32"), Tensor([4, 3, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 114331 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:47:35.290491 22771 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:47:35.291610 22771 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4, 536870912, 2],"float32"), Tensor([4, 536870912, 2],"float16"), )
[torch error] paddle.equal(Tensor([4, 536870912, 2],"float32"), Tensor([4, 536870912, 2],"float16"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 134519 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:48:40.762137 22785 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:48:40.763229 22785 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4],"float16"), Tensor([4294967295],"float16"), )
[torch error] paddle.equal(Tensor([4],"float16"), Tensor([4294967295],"float16"), ) 
 The size of tensor a (4) must match the size of tensor b (4294967295) at non-singleton dimension 0

W0213 04:50:08.226039 22799 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:50:08.227311 22799 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4],"int64"), Tensor([2147483649],"int64"), )
[torch error] paddle.equal(Tensor([4],"int64"), Tensor([2147483649],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 20062 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:50:52.705570 22813 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:50:52.706578 22813 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([400, 1],"float64"), Tensor([2147483649, 1],"float64"), )
[torch error] paddle.equal(Tensor([400, 1],"float64"), Tensor([2147483649, 1],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 27262 has 1016.00 MiB memory in use. Of the allocated memory 3.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:51:36.679066 22827 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:51:36.681723 22827 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([400, 1],"float64"), Tensor([400, 5368710],"float64"), )
[torch error] paddle.equal(Tensor([400, 1],"float64"), Tensor([400, 5368710],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 42716 has 1016.00 MiB memory in use. Of the allocated memory 3.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:52:23.893189 22841 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:52:23.894248 22841 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([400, 5368710],"float64"), Tensor([400, 1],"float64"), )
[torch error] paddle.equal(Tensor([400, 5368710],"float64"), Tensor([400, 1],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 58336 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:53:13.861474 22855 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:53:13.862471 22855 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([400, 5368710],"float64"), Tensor([400, 5368710],"float64"), )
[torch error] paddle.equal(Tensor([400, 5368710],"float64"), Tensor([400, 5368710],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 74072 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:53:58.676800 22869 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:53:58.677783 22869 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([400],"float64"), Tensor([2147483649],"float64"), )
[torch error] paddle.equal(Tensor([400],"float64"), Tensor([2147483649],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 85848 has 1016.00 MiB memory in use. Of the allocated memory 3.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:54:45.884939 22883 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:54:45.886011 22883 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4294967295],"float16"), Tensor([4],"float16"), )
[torch error] paddle.equal(Tensor([4294967295],"float16"), Tensor([4],"float16"), ) 
 The size of tensor a (4294967295) must match the size of tensor b (4) at non-singleton dimension 0

W0213 04:56:18.410228 22897 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:56:18.411567 22897 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4294967295],"float16"), Tensor([4294967295],"float16"), )
[torch error] paddle.equal(Tensor([4294967295],"float16"), Tensor([4294967295],"float16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 137986 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 04:58:59.932744 22911 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 04:58:59.933879 22911 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4294967295],"float32"), Tensor([1],"float32"), )
[torch error] paddle.equal(Tensor([4294967295],"float32"), Tensor([1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 28049 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 05:00:10.979187 22925 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 05:00:10.980181 22925 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4294967295],"float32"), Tensor([3],"float32"), )
[torch error] paddle.equal(Tensor([4294967295],"float32"), Tensor([3],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 52828 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 05:01:22.691725 22939 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 05:01:22.698210 22939 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4294967295],"float32"), Tensor([4294967295],"float32"), )
[torch error] paddle.equal(Tensor([4294967295],"float32"), Tensor([4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 73230 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 05:02:30.130705 22953 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 05:02:30.132176 22953 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4294967295],"int32"), 0, )
[torch error] paddle.equal(Tensor([4294967295],"int32"), 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 93121 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 05:03:59.836336 22967 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 05:03:59.837440 22967 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4294967295],"int32"), Tensor([1],"int32"), )
[torch error] paddle.equal(Tensor([4294967295],"int32"), Tensor([1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 121725 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 05:05:09.741132 22981 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 05:05:09.742347 22981 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([4294967295],"int32"), Tensor([4294967295],"int32"), )
[torch error] paddle.equal(Tensor([4294967295],"int32"), Tensor([4294967295],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 146699 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 05:06:14.822532 22995 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 05:06:14.823625 22995 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([5],"float64"), Tensor([2147483649],"float64"), )
[torch error] paddle.equal(Tensor([5],"float64"), Tensor([2147483649],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 5719 has 1016.00 MiB memory in use. Of the allocated memory 512 bytes is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 05:06:57.855650 23009 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 05:06:57.856623 23009 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([536870912, 8],"float32"), Tensor([536870912, 8],"float32"), )
[torch error] paddle.equal(Tensor([536870912, 8],"float32"), Tensor([536870912, 8],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 15909 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 05:08:07.166085 23023 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 05:08:07.167208 23023 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([536870912, 8],"float32"), Tensor([8, 8],"float32"), )
[torch error] paddle.equal(Tensor([536870912, 8],"float32"), Tensor([8, 8],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 43429 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 05:09:17.199550 23037 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 05:09:17.200524 23037 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([536870913, 4],"int64"), Tensor([1],"int64"), )
[torch error] paddle.equal(Tensor([536870913, 4],"int64"), Tensor([1],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 61311 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 05:10:01.526443 23051 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 05:10:01.527601 23051 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([536870913, 4],"int64"), Tensor([536870913, 4],"int64"), )
[torch error] paddle.equal(Tensor([536870913, 4],"int64"), Tensor([536870913, 4],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 73698 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 05:10:47.410832 23065 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 05:10:47.411815 23065 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([536870913, 4],"int64"), Tensor([8, 4],"int64"), )
[torch error] paddle.equal(Tensor([536870913, 4],"int64"), Tensor([8, 4],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 85818 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 05:11:31.377701 23079 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 05:11:31.378787 23079 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([5478275, 28, 28],"int32"), Tensor([5478275, 1, 1],"int32"), )
[torch error] paddle.equal(Tensor([5478275, 28, 28],"int32"), Tensor([5478275, 1, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 104393 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 05:12:43.016616 23093 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 05:12:43.017727 23093 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([5478275, 28, 28],"int32"), Tensor([6, 1, 1],"int32"), )
[torch error] paddle.equal(Tensor([5478275, 28, 28],"int32"), Tensor([6, 1, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 123821 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 05:13:54.600775 23107 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 05:13:54.601876 23107 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([67108864, 1, 8, 8],"int32"), Tensor([6, 1, 1],"int32"), )
[torch error] paddle.equal(Tensor([67108864, 1, 8, 8],"int32"), Tensor([6, 1, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 146506 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 05:15:03.083338 23121 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 05:15:03.084753 23121 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([67108864, 8, 8],"float32"), Tensor([2, 8, 8],"float32"), )
[torch error] paddle.equal(Tensor([67108864, 8, 8],"float32"), Tensor([2, 8, 8],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 13321 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 05:16:08.538283 23135 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 05:16:08.539404 23135 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([67108864, 8, 8],"float32"), Tensor([67108864, 8, 8],"float32"), )
[torch error] paddle.equal(Tensor([67108864, 8, 8],"float32"), Tensor([67108864, 8, 8],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 38354 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 05:17:13.301576 23149 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 05:17:13.302659 23149 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([67108864, 8, 8],"int32"), Tensor([6, 1, 1],"int32"), )
[torch error] paddle.equal(Tensor([67108864, 8, 8],"int32"), Tensor([6, 1, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 58556 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 05:18:17.791965 23163 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 05:18:17.793040 23163 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([67108864, 8, 8],"int32"), Tensor([67108864, 1, 1],"int32"), )
[torch error] paddle.equal(Tensor([67108864, 8, 8],"int32"), Tensor([67108864, 1, 1],"int32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 77783 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 05:19:22.882946 23177 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 05:19:22.884004 23177 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([715827883, 3, 2],"float16"), Tensor([357913942, 3, 2],"float64"), )
[torch error] paddle.equal(Tensor([715827883, 3, 2],"float16"), Tensor([357913942, 3, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 97610 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 05:21:27.712448 23191 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 05:21:27.713579 23191 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([715827883, 3, 2],"float16"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.equal(Tensor([715827883, 3, 2],"float16"), Tensor([4, 3, 2],"float32"), ) 
 The size of tensor a (715827883) must match the size of tensor b (4) at non-singleton dimension 0

W0213 05:22:55.046840 23205 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 05:22:55.047971 23205 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([715827883, 3, 2],"float16"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.equal(Tensor([715827883, 3, 2],"float16"), Tensor([4, 3, 2],"float64"), ) 
 The size of tensor a (715827883) must match the size of tensor b (4) at non-singleton dimension 0

W0213 05:24:24.438731 23219 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 05:24:24.439853 23219 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([715827883, 3, 2],"float16"), Tensor([715827883, 3, 2],"float32"), )
[torch error] paddle.equal(Tensor([715827883, 3, 2],"float16"), Tensor([715827883, 3, 2],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 27283 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 05:26:41.296242 23233 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 05:26:41.297262 23233 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([715827883, 3, 2],"float32"), Tensor([357913942, 3, 2],"float64"), )
[torch error] paddle.equal(Tensor([715827883, 3, 2],"float32"), Tensor([357913942, 3, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 72207 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 05:27:53.932233 23247 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 05:27:53.933310 23247 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([715827883, 3, 2],"float32"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.equal(Tensor([715827883, 3, 2],"float32"), Tensor([4, 3, 2],"float16"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 93398 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 05:28:59.346899 23261 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 05:28:59.348009 23261 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.equal(Tensor([715827883, 3, 2],"float32"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.equal(Tensor([715827883, 3, 2],"float32"), Tensor([4, 3, 2],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.21 GiB is free. Process 100328 has 32.99 GiB memory in use. Process 10848 has 32.99 GiB memory in use. Process 113872 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 05:30:11.080545 23275 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 05:30:11.081518 23275 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

