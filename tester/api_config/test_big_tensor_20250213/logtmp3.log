test begin: paddle.fmin(Tensor([10, 429496730],"float32"), Tensor([10, 15],"float32"), )
[torch error] paddle.fmin(Tensor([10, 429496730],"float32"), Tensor([10, 15],"float32"), ) 
 The size of tensor a (429496730) must match the size of tensor b (15) at non-singleton dimension 1

W0205 10:02:24.165351 88932 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:02:24.166479 88932 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([10, 429496730],"float32"), Tensor([10, 429496730],"float32"), )
[paddle error] paddle.fmin(Tensor([10, 429496730],"float32"), Tensor([10, 429496730],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:04:55.193506 89328 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:04:55.194509 89328 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([10, 429496730],"float32"), Tensor([15],"float32"), )
[torch error] paddle.fmin(Tensor([10, 429496730],"float32"), Tensor([15],"float32"), ) 
 The size of tensor a (429496730) must match the size of tensor b (15) at non-singleton dimension 1

W0205 10:06:04.925340 90073 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:06:04.926743 90073 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([2147483649],"int64"), Tensor([1],"int64"), )
[paddle error] paddle.fmin(Tensor([2147483649],"int64"), Tensor([1],"int64"), ) 
 (PreconditionNotMet) The meta data must be valid when call the mutable data function.
  [Hint: Expected valid() == true, but received valid():0 != true:1.] (at ../paddle/phi/core/dense_tensor.cc:117)


W0205 10:07:01.611425 90366 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:07:01.612520 90366 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([2147483649],"int64"), Tensor([2147483649],"int64"), )
[paddle error] paddle.fmin(Tensor([2147483649],"int64"), Tensor([2147483649],"int64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:08:51.085402 90479 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:08:51.086405 90479 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([2147483649],"int64"), Tensor([3],"int64"), )
[torch error] paddle.fmin(Tensor([2147483649],"int64"), Tensor([3],"int64"), ) 
 The size of tensor a (2147483649) must match the size of tensor b (3) at non-singleton dimension 0

W0205 10:09:37.403968 90857 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:09:37.405027 90857 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([286331153, 15],"float32"), Tensor([10, 15],"float32"), )
[torch error] paddle.fmin(Tensor([286331153, 15],"float32"), Tensor([10, 15],"float32"), ) 
 The size of tensor a (286331153) must match the size of tensor b (10) at non-singleton dimension 0

W0205 10:10:49.710461 91059 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:10:49.711886 91059 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([286331153, 15],"float32"), Tensor([15],"float32"), )
[Pass] paddle.fmin(Tensor([286331153, 15],"float32"), Tensor([15],"float32"), )

W0205 10:12:10.352679 91267 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:12:10.353623 91267 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([286331153, 15],"float32"), Tensor([286331153, 15],"float32"), )
[paddle error] paddle.fmin(Tensor([286331153, 15],"float32"), Tensor([286331153, 15],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:17:01.087069 91962 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:17:01.087952 91962 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([3],"int64"), Tensor([2147483649],"int64"), )
[torch error] paddle.fmin(Tensor([3],"int64"), Tensor([2147483649],"int64"), ) 
 The size of tensor a (3) must match the size of tensor b (2147483649) at non-singleton dimension 0

W0205 10:17:46.602598 92481 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:17:46.603869 92481 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([30, 200, 40],"float32"), Tensor([30, 200, 715828],"float32"), )
[torch error] paddle.fmin(Tensor([30, 200, 40],"float32"), Tensor([30, 200, 715828],"float32"), ) 
 The size of tensor a (40) must match the size of tensor b (715828) at non-singleton dimension 2

W0205 10:18:57.684118 92694 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:18:57.685130 92694 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([30, 200, 40],"float32"), Tensor([30, 3579140, 40],"float32"), )
[torch error] paddle.fmin(Tensor([30, 200, 40],"float32"), Tensor([30, 3579140, 40],"float32"), ) 
 The size of tensor a (200) must match the size of tensor b (3579140) at non-singleton dimension 1

W0205 10:20:15.625885 92923 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:20:15.627254 92923 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([30, 200, 40],"float32"), Tensor([536871, 200, 40],"float32"), )
[torch error] paddle.fmin(Tensor([30, 200, 40],"float32"), Tensor([536871, 200, 40],"float32"), ) 
 The size of tensor a (30) must match the size of tensor b (536871) at non-singleton dimension 0

W0205 10:21:28.682670 93226 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:21:28.684028 93226 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([30, 200, 715828],"float32"), Tensor([30, 200, 40],"float32"), )
[torch error] paddle.fmin(Tensor([30, 200, 715828],"float32"), Tensor([30, 200, 40],"float32"), ) 
 The size of tensor a (715828) must match the size of tensor b (40) at non-singleton dimension 2

W0205 10:22:41.434655 93440 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:22:41.435671 93440 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([30, 200, 715828],"float32"), Tensor([30, 200, 715828],"float32"), )
[paddle error] paddle.fmin(Tensor([30, 200, 715828],"float32"), Tensor([30, 200, 715828],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000003GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:25:18.223838 93729 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:25:18.224825 93729 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([30, 3579140, 40],"float32"), Tensor([30, 200, 40],"float32"), )
[torch error] paddle.fmin(Tensor([30, 3579140, 40],"float32"), Tensor([30, 200, 40],"float32"), ) 
 The size of tensor a (3579140) must match the size of tensor b (200) at non-singleton dimension 1

W0205 10:26:27.149408 94217 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:26:27.150411 94217 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([30, 3579140, 40],"float32"), Tensor([30, 3579140, 40],"float32"), )
[paddle error] paddle.fmin(Tensor([30, 3579140, 40],"float32"), Tensor([30, 3579140, 40],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000003GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:28:55.704787 94441 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:28:55.705739 94441 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([357913942, 3, 2],"float64"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.fmin(Tensor([357913942, 3, 2],"float64"), Tensor([4, 3, 2],"float16"), ) 
 The size of tensor a (357913942) must match the size of tensor b (4) at non-singleton dimension 0

W0205 10:29:46.492045 94957 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:29:46.493218 94957 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([357913942, 3, 2],"float64"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.fmin(Tensor([357913942, 3, 2],"float64"), Tensor([4, 3, 2],"float32"), ) 
 The size of tensor a (357913942) must match the size of tensor b (4) at non-singleton dimension 0

W0205 10:30:36.796715 95168 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:30:36.797865 95168 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([357913942, 3, 2],"float64"), Tensor([715827883, 3, 2],"float16"), )
[torch error] paddle.fmin(Tensor([357913942, 3, 2],"float64"), Tensor([715827883, 3, 2],"float16"), ) 
 The size of tensor a (357913942) must match the size of tensor b (715827883) at non-singleton dimension 0

W0205 10:32:40.214272 95396 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:32:40.215381 95396 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([357913942, 3, 2],"float64"), Tensor([715827883, 3, 2],"float32"), )
[torch error] paddle.fmin(Tensor([357913942, 3, 2],"float64"), Tensor([715827883, 3, 2],"float32"), ) 
 The size of tensor a (357913942) must match the size of tensor b (715827883) at non-singleton dimension 0

W0205 10:34:28.443228 95817 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:34:28.444523 95817 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 268435457, 2],"float64"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.fmin(Tensor([4, 268435457, 2],"float64"), Tensor([4, 3, 2],"float16"), ) 
 The size of tensor a (268435457) must match the size of tensor b (3) at non-singleton dimension 1

W0205 10:35:19.855152 96142 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:35:19.856372 96142 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 268435457, 2],"float64"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.fmin(Tensor([4, 268435457, 2],"float64"), Tensor([4, 3, 2],"float32"), ) 
 The size of tensor a (268435457) must match the size of tensor b (3) at non-singleton dimension 1

W0205 10:36:10.117020 96360 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:36:10.118206 96360 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 268435457, 2],"float64"), Tensor([4, 536870912, 2],"float16"), )
[torch error] paddle.fmin(Tensor([4, 268435457, 2],"float64"), Tensor([4, 536870912, 2],"float16"), ) 
 The size of tensor a (268435457) must match the size of tensor b (536870912) at non-singleton dimension 1

W0205 10:38:18.492308 96572 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:38:18.493497 96572 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 268435457, 2],"float64"), Tensor([4, 536870912, 2],"float32"), )
[torch error] paddle.fmin(Tensor([4, 268435457, 2],"float64"), Tensor([4, 536870912, 2],"float32"), ) 
 The size of tensor a (268435457) must match the size of tensor b (536870912) at non-singleton dimension 1

W0205 10:40:06.152160 96975 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:40:06.153323 96975 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.fmin(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 2],"float16"), ) 
 The size of tensor a (178956971) must match the size of tensor b (2) at non-singleton dimension 2

W0205 10:40:55.434036 97361 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:40:55.435206 97361 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.fmin(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 2],"float32"), ) 
 The size of tensor a (178956971) must match the size of tensor b (2) at non-singleton dimension 2

W0205 10:41:48.263114 97487 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:41:48.264109 97487 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 357913942],"float16"), )
[torch error] paddle.fmin(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 357913942],"float16"), ) 
 The size of tensor a (178956971) must match the size of tensor b (357913942) at non-singleton dimension 2

W0205 10:43:52.762426 97696 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:43:52.763876 97696 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 357913942],"float32"), )
[torch error] paddle.fmin(Tensor([4, 3, 178956971],"float64"), Tensor([4, 3, 357913942],"float32"), ) 
 The size of tensor a (178956971) must match the size of tensor b (357913942) at non-singleton dimension 2

W0205 10:45:41.069984 98084 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:45:41.071182 98084 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float16"), Tensor([357913942, 3, 2],"float64"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float16"), Tensor([357913942, 3, 2],"float64"), ) 
 The size of tensor a (4) must match the size of tensor b (357913942) at non-singleton dimension 0

W0205 10:46:48.239509 98485 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:46:48.240881 98485 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float16"), Tensor([4, 268435457, 2],"float64"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float16"), Tensor([4, 268435457, 2],"float64"), ) 
 The size of tensor a (3) must match the size of tensor b (268435457) at non-singleton dimension 1

W0205 10:47:42.572057 98680 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:47:42.573494 98680 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float16"), Tensor([4, 3, 178956971],"float64"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float16"), Tensor([4, 3, 178956971],"float64"), ) 
 The size of tensor a (2) must match the size of tensor b (178956971) at non-singleton dimension 2

W0205 10:48:31.970731 98901 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:48:31.971731 98901 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float16"), Tensor([4, 3, 357913942],"float32"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float16"), Tensor([4, 3, 357913942],"float32"), ) 
 The size of tensor a (2) must match the size of tensor b (357913942) at non-singleton dimension 2

W0205 10:49:48.195189 99017 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:49:48.196468 99017 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float16"), Tensor([4, 536870912, 2],"float32"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float16"), Tensor([4, 536870912, 2],"float32"), ) 
 The size of tensor a (3) must match the size of tensor b (536870912) at non-singleton dimension 1

W0205 10:51:00.281045 99320 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:51:00.282146 99320 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float16"), Tensor([715827883, 3, 2],"float32"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float16"), Tensor([715827883, 3, 2],"float32"), ) 
 The size of tensor a (4) must match the size of tensor b (715827883) at non-singleton dimension 0

W0205 10:52:14.810489 99542 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:52:14.811856 99542 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float32"), Tensor([357913942, 3, 2],"float64"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float32"), Tensor([357913942, 3, 2],"float64"), ) 
 The size of tensor a (4) must match the size of tensor b (357913942) at non-singleton dimension 0

W0205 10:53:04.263938 99819 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:53:04.265079 99819 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float32"), Tensor([4, 268435457, 2],"float64"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float32"), Tensor([4, 268435457, 2],"float64"), ) 
 The size of tensor a (3) must match the size of tensor b (268435457) at non-singleton dimension 1

W0205 10:53:55.089057 100026 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:53:55.090179 100026 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float32"), Tensor([4, 3, 178956971],"float64"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float32"), Tensor([4, 3, 178956971],"float64"), ) 
 The size of tensor a (2) must match the size of tensor b (178956971) at non-singleton dimension 2

W0205 10:54:44.358143 100154 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:54:44.359124 100154 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float32"), Tensor([4, 3, 357913942],"float16"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float32"), Tensor([4, 3, 357913942],"float16"), ) 
 The size of tensor a (2) must match the size of tensor b (357913942) at non-singleton dimension 2

W0205 10:56:13.879626 100349 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:56:13.880856 100349 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float32"), Tensor([4, 536870912, 2],"float16"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float32"), Tensor([4, 536870912, 2],"float16"), ) 
 The size of tensor a (3) must match the size of tensor b (536870912) at non-singleton dimension 1

W0205 10:57:43.618192 100640 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:57:43.619434 100640 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float32"), Tensor([715827883, 3, 2],"float16"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float32"), Tensor([715827883, 3, 2],"float16"), ) 
 The size of tensor a (4) must match the size of tensor b (715827883) at non-singleton dimension 0

W0205 10:59:09.961261 100959 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:59:09.962445 100959 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float64"), Tensor([4, 3, 357913942],"float16"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float64"), Tensor([4, 3, 357913942],"float16"), ) 
 The size of tensor a (2) must match the size of tensor b (357913942) at non-singleton dimension 2

W0205 11:00:41.346865 101282 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:00:41.348040 101282 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float64"), Tensor([4, 3, 357913942],"float32"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float64"), Tensor([4, 3, 357913942],"float32"), ) 
 The size of tensor a (2) must match the size of tensor b (357913942) at non-singleton dimension 2

W0205 11:01:52.629601 101580 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:01:52.630618 101580 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float64"), Tensor([4, 536870912, 2],"float16"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float64"), Tensor([4, 536870912, 2],"float16"), ) 
 The size of tensor a (3) must match the size of tensor b (536870912) at non-singleton dimension 1

W0205 11:03:22.120915 101811 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:03:22.122237 101811 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float64"), Tensor([4, 536870912, 2],"float32"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float64"), Tensor([4, 536870912, 2],"float32"), ) 
 The size of tensor a (3) must match the size of tensor b (536870912) at non-singleton dimension 1

W0205 11:04:37.668730 102236 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:04:37.669976 102236 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float64"), Tensor([715827883, 3, 2],"float16"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float64"), Tensor([715827883, 3, 2],"float16"), ) 
 The size of tensor a (4) must match the size of tensor b (715827883) at non-singleton dimension 0

W0205 11:06:12.464900 102647 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:06:12.466176 102647 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 2],"float64"), Tensor([715827883, 3, 2],"float32"), )
[torch error] paddle.fmin(Tensor([4, 3, 2],"float64"), Tensor([715827883, 3, 2],"float32"), ) 
 The size of tensor a (4) must match the size of tensor b (715827883) at non-singleton dimension 0

W0205 11:07:24.582971 103062 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:07:24.584190 103062 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 178956971],"float64"), )
[torch error] paddle.fmin(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 178956971],"float64"), ) 
 The size of tensor a (357913942) must match the size of tensor b (178956971) at non-singleton dimension 2

W0205 11:09:30.038039 103401 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:09:30.039237 103401 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.fmin(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 2],"float32"), ) 
 The size of tensor a (357913942) must match the size of tensor b (2) at non-singleton dimension 2

W0205 11:11:00.879148 104024 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:11:00.880326 104024 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.fmin(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 2],"float64"), ) 
 The size of tensor a (357913942) must match the size of tensor b (2) at non-singleton dimension 2

W0205 11:12:35.378756 104388 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:12:35.379935 104388 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 357913942],"float32"), )
[paddle error] paddle.fmin(Tensor([4, 3, 357913942],"float16"), Tensor([4, 3, 357913942],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_fmin(_object*, _object*, _object*)
1   fmin_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   cast_ad_func(paddle::Tensor const&, phi::DataType)
3   paddle::experimental::cast(paddle::Tensor const&, phi::DataType)
4   void phi::CastKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<phi::dtype::float16, float>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
7   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
8   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.594666GB memory has been allocated and available memory is only 13.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:15:16.866163 104806 dygraph_functions.cc:32444] got different data type, run type promotion automatically, this may cause data type been changed.
W0205 11:15:16.867444 104806 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:15:16.868263 104806 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 178956971],"float64"), )
[torch error] paddle.fmin(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 178956971],"float64"), ) 
 The size of tensor a (357913942) must match the size of tensor b (178956971) at non-singleton dimension 2

W0205 11:17:13.517815 105377 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:17:13.518966 105377 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.fmin(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 2],"float16"), ) 
 The size of tensor a (357913942) must match the size of tensor b (2) at non-singleton dimension 2

W0205 11:18:24.852620 105828 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:18:24.854074 105828 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.fmin(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 2],"float64"), ) 
 The size of tensor a (357913942) must match the size of tensor b (2) at non-singleton dimension 2

W0205 11:19:41.716327 106070 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:19:41.717471 106070 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 357913942],"float16"), )
[paddle error] paddle.fmin(Tensor([4, 3, 357913942],"float32"), Tensor([4, 3, 357913942],"float16"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_fmin(_object*, _object*, _object*)
1   fmin_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   cast_ad_func(paddle::Tensor const&, phi::DataType)
3   paddle::experimental::cast(paddle::Tensor const&, phi::DataType)
4   void phi::CastKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<phi::dtype::float16, float>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
7   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
8   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.594666GB memory has been allocated and available memory is only 13.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:22:14.684662 106443 dygraph_functions.cc:32444] got different data type, run type promotion automatically, this may cause data type been changed.
W0205 11:22:14.686038 106443 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:22:14.686919 106443 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 536870912, 2],"float16"), Tensor([4, 268435457, 2],"float64"), )
[torch error] paddle.fmin(Tensor([4, 536870912, 2],"float16"), Tensor([4, 268435457, 2],"float64"), ) 
 The size of tensor a (536870912) must match the size of tensor b (268435457) at non-singleton dimension 1

W0205 11:24:25.845559 107013 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:24:25.846822 107013 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 536870912, 2],"float16"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.fmin(Tensor([4, 536870912, 2],"float16"), Tensor([4, 3, 2],"float32"), ) 
 The size of tensor a (536870912) must match the size of tensor b (3) at non-singleton dimension 1

W0205 11:25:51.642793 107493 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:25:51.644014 107493 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 536870912, 2],"float16"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.fmin(Tensor([4, 536870912, 2],"float16"), Tensor([4, 3, 2],"float64"), ) 
 The size of tensor a (536870912) must match the size of tensor b (3) at non-singleton dimension 1

W0205 11:27:16.879379 107821 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:27:16.880513 107821 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 536870912, 2],"float16"), Tensor([4, 536870912, 2],"float32"), )
[paddle error] paddle.fmin(Tensor([4, 536870912, 2],"float16"), Tensor([4, 536870912, 2],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_fmin(_object*, _object*, _object*)
1   fmin_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   cast_ad_func(paddle::Tensor const&, phi::DataType)
3   paddle::experimental::cast(paddle::Tensor const&, phi::DataType)
4   void phi::CastKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<phi::dtype::float16, float>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
7   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
8   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:29:49.862630 108147 dygraph_functions.cc:32444] got different data type, run type promotion automatically, this may cause data type been changed.
W0205 11:29:49.863878 108147 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:29:49.864845 108147 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 536870912, 2],"float32"), Tensor([4, 268435457, 2],"float64"), )
[torch error] paddle.fmin(Tensor([4, 536870912, 2],"float32"), Tensor([4, 268435457, 2],"float64"), ) 
 The size of tensor a (536870912) must match the size of tensor b (268435457) at non-singleton dimension 1

W0205 11:31:56.479344 108680 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:31:56.480511 108680 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 536870912, 2],"float32"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.fmin(Tensor([4, 536870912, 2],"float32"), Tensor([4, 3, 2],"float16"), ) 
 The size of tensor a (536870912) must match the size of tensor b (3) at non-singleton dimension 1

W0205 11:33:08.385210 109055 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:33:08.386663 109055 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 536870912, 2],"float32"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.fmin(Tensor([4, 536870912, 2],"float32"), Tensor([4, 3, 2],"float64"), ) 
 The size of tensor a (536870912) must match the size of tensor b (3) at non-singleton dimension 1

W0205 11:34:27.498075 109357 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:34:27.499198 109357 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([4, 536870912, 2],"float32"), Tensor([4, 536870912, 2],"float16"), )
[paddle error] paddle.fmin(Tensor([4, 536870912, 2],"float32"), Tensor([4, 536870912, 2],"float16"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_fmin(_object*, _object*, _object*)
1   fmin_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   cast_ad_func(paddle::Tensor const&, phi::DataType)
3   paddle::experimental::cast(paddle::Tensor const&, phi::DataType)
4   void phi::CastKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<phi::dtype::float16, float>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
7   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
8   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:37:07.797335 109609 dygraph_functions.cc:32444] got different data type, run type promotion automatically, this may cause data type been changed.
W0205 11:37:07.798628 109609 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:37:07.799643 109609 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([536871, 200, 40],"float32"), Tensor([30, 200, 40],"float32"), )
[torch error] paddle.fmin(Tensor([536871, 200, 40],"float32"), Tensor([30, 200, 40],"float32"), ) 
 The size of tensor a (536871) must match the size of tensor b (30) at non-singleton dimension 0

W0205 11:38:39.744009 110177 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:38:39.745674 110177 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([536871, 200, 40],"float32"), Tensor([536871, 200, 40],"float32"), )
[paddle error] paddle.fmin(Tensor([536871, 200, 40],"float32"), Tensor([536871, 200, 40],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000003GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:41:24.074851 110481 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:41:24.075956 110481 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([715827883, 3, 2],"float16"), Tensor([357913942, 3, 2],"float64"), )
[torch error] paddle.fmin(Tensor([715827883, 3, 2],"float16"), Tensor([357913942, 3, 2],"float64"), ) 
 The size of tensor a (715827883) must match the size of tensor b (357913942) at non-singleton dimension 0

W0205 11:43:24.906522 111014 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:43:24.907624 111014 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([715827883, 3, 2],"float16"), Tensor([4, 3, 2],"float32"), )
[torch error] paddle.fmin(Tensor([715827883, 3, 2],"float16"), Tensor([4, 3, 2],"float32"), ) 
 The size of tensor a (715827883) must match the size of tensor b (4) at non-singleton dimension 0

W0205 11:44:53.299618 111418 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:44:53.301030 111418 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([715827883, 3, 2],"float16"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.fmin(Tensor([715827883, 3, 2],"float16"), Tensor([4, 3, 2],"float64"), ) 
 The size of tensor a (715827883) must match the size of tensor b (4) at non-singleton dimension 0

W0205 11:46:17.187413 111709 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:46:17.188413 111709 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([715827883, 3, 2],"float16"), Tensor([715827883, 3, 2],"float32"), )
[paddle error] paddle.fmin(Tensor([715827883, 3, 2],"float16"), Tensor([715827883, 3, 2],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_fmin(_object*, _object*, _object*)
1   fmin_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   cast_ad_func(paddle::Tensor const&, phi::DataType)
3   paddle::experimental::cast(paddle::Tensor const&, phi::DataType)
4   void phi::CastKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<phi::dtype::float16, float>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
7   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
8   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.594666GB memory has been allocated and available memory is only 13.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:49:00.419901 112016 dygraph_functions.cc:32444] got different data type, run type promotion automatically, this may cause data type been changed.
W0205 11:49:00.421052 112016 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:49:00.421952 112016 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([715827883, 3, 2],"float32"), Tensor([357913942, 3, 2],"float64"), )
[torch error] paddle.fmin(Tensor([715827883, 3, 2],"float32"), Tensor([357913942, 3, 2],"float64"), ) 
 The size of tensor a (715827883) must match the size of tensor b (357913942) at non-singleton dimension 0

W0205 11:51:04.021212 112667 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:51:04.022512 112667 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([715827883, 3, 2],"float32"), Tensor([4, 3, 2],"float16"), )
[torch error] paddle.fmin(Tensor([715827883, 3, 2],"float32"), Tensor([4, 3, 2],"float16"), ) 
 The size of tensor a (715827883) must match the size of tensor b (4) at non-singleton dimension 0

W0205 11:52:26.308178 113100 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:52:26.309736 113100 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([715827883, 3, 2],"float32"), Tensor([4, 3, 2],"float64"), )
[torch error] paddle.fmin(Tensor([715827883, 3, 2],"float32"), Tensor([4, 3, 2],"float64"), ) 
 The size of tensor a (715827883) must match the size of tensor b (4) at non-singleton dimension 0

W0205 11:53:40.119053 113324 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:53:40.120306 113324 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.fmin(Tensor([715827883, 3, 2],"float32"), Tensor([715827883, 3, 2],"float16"), )
[paddle error] paddle.fmin(Tensor([715827883, 3, 2],"float32"), Tensor([715827883, 3, 2],"float16"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_fmin(_object*, _object*, _object*)
1   fmin_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   cast_ad_func(paddle::Tensor const&, phi::DataType)
3   paddle::experimental::cast(paddle::Tensor const&, phi::DataType)
4   void phi::CastKernel<phi::dtype::float16, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
5   void phi::CastCUDAKernelImpl<phi::dtype::float16, float>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
6   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
7   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
8   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::Allocator::Allocate(unsigned long)
15  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
16  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
17  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.594666GB memory has been allocated and available memory is only 13.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:56:16.947459 113642 dygraph_functions.cc:32444] got different data type, run type promotion automatically, this may cause data type been changed.
W0205 11:56:16.949023 113642 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:56:16.949954 113642 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.frac(Tensor([10, 20, 21474837],"float32"), )
[paddle error] paddle.frac(Tensor([10, 20, 21474837],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_subtract(_object*, _object*, _object*)
1   subtract_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::subtract(paddle::Tensor const&, paddle::Tensor const&)
3   void phi::SubtractRawKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, int, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:57:39.523970 114159 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:57:39.524945 114159 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
Traceback (most recent call last):
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 70, in <module>
    main()
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 50, in main
    case.clear_tensor()
  File "/host_home/wanghuan29/PaddleAPITest/tester/base.py", line 208, in clear_tensor
    arg_config.clear_tensor()
  File "/host_home/wanghuan29/PaddleAPITest/tester/api_config/config_analyzer.py", line 86, in clear_tensor
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.9/dist-packages/torch/cuda/memory.py", line 192, in empty_cache
    torch._C._cuda_emptyCache()
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


test begin: paddle.frac(Tensor([10, 429496730, 1],"float32"), )
[paddle error] paddle.frac(Tensor([10, 429496730, 1],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_subtract(_object*, _object*, _object*)
1   subtract_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::subtract(paddle::Tensor const&, paddle::Tensor const&)
3   void phi::SubtractRawKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, int, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:59:04.842625 114532 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:59:04.843608 114532 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
Traceback (most recent call last):
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 70, in <module>
    main()
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 50, in main
    case.clear_tensor()
  File "/host_home/wanghuan29/PaddleAPITest/tester/base.py", line 208, in clear_tensor
    arg_config.clear_tensor()
  File "/host_home/wanghuan29/PaddleAPITest/tester/api_config/config_analyzer.py", line 86, in clear_tensor
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.9/dist-packages/torch/cuda/memory.py", line 192, in empty_cache
    torch._C._cuda_emptyCache()
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


test begin: paddle.frac(Tensor([1431655765, 3],"float32"), )
[paddle error] paddle.frac(Tensor([1431655765, 3],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_subtract(_object*, _object*, _object*)
1   subtract_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::subtract(paddle::Tensor const&, paddle::Tensor const&)
3   void phi::SubtractRawKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, int, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 12:00:30.872087 114972 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:00:30.872936 114972 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
Traceback (most recent call last):
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 70, in <module>
    main()
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 50, in main
    case.clear_tensor()
  File "/host_home/wanghuan29/PaddleAPITest/tester/base.py", line 208, in clear_tensor
    arg_config.clear_tensor()
  File "/host_home/wanghuan29/PaddleAPITest/tester/api_config/config_analyzer.py", line 86, in clear_tensor
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.9/dist-packages/torch/cuda/memory.py", line 192, in empty_cache
    torch._C._cuda_emptyCache()
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


test begin: paddle.frac(Tensor([1431655765, 3],"int32"), )
[torch error] paddle.frac(Tensor([1431655765, 3],"int32"), ) 
 "frac_cuda" not implemented for 'Int'

W0205 12:01:59.088270 115333 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:01:59.091055 115333 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.frac(Tensor([2, 1073741825],"float64"), )
[paddle error] paddle.frac(Tensor([2, 1073741825],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_subtract(_object*, _object*, _object*)
1   subtract_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::subtract(paddle::Tensor const&, paddle::Tensor const&)
3   void phi::SubtractRawKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, int, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 12:02:54.994423 115565 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:02:54.995340 115565 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
Traceback (most recent call last):
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 70, in <module>
    main()
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 50, in main
    case.clear_tensor()
  File "/host_home/wanghuan29/PaddleAPITest/tester/base.py", line 208, in clear_tensor
    arg_config.clear_tensor()
  File "/host_home/wanghuan29/PaddleAPITest/tester/api_config/config_analyzer.py", line 86, in clear_tensor
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.9/dist-packages/torch/cuda/memory.py", line 192, in empty_cache
    torch._C._cuda_emptyCache()
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


test begin: paddle.frac(Tensor([2, 1073741825],"int64"), )
[torch error] paddle.frac(Tensor([2, 1073741825],"int64"), ) 
 "frac_cuda" not implemented for 'Long'

W0205 12:03:52.188220 115867 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:03:52.189406 115867 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.frac(Tensor([2, 2147483648],"float32"), )
[paddle error] paddle.frac(Tensor([2, 2147483648],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_subtract(_object*, _object*, _object*)
1   subtract_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::subtract(paddle::Tensor const&, paddle::Tensor const&)
3   void phi::SubtractRawKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, int, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 12:05:08.330421 116011 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:05:08.331319 116011 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
Traceback (most recent call last):
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 70, in <module>
    main()
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 50, in main
    case.clear_tensor()
  File "/host_home/wanghuan29/PaddleAPITest/tester/base.py", line 208, in clear_tensor
    arg_config.clear_tensor()
  File "/host_home/wanghuan29/PaddleAPITest/tester/api_config/config_analyzer.py", line 86, in clear_tensor
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.9/dist-packages/torch/cuda/memory.py", line 192, in empty_cache
    torch._C._cuda_emptyCache()
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


test begin: paddle.frac(Tensor([2, 2147483648],"int32"), )
[torch error] paddle.frac(Tensor([2, 2147483648],"int32"), ) 
 "frac_cuda" not implemented for 'Int'

W0205 12:06:28.767778 116316 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:06:28.768849 116316 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.frac(Tensor([214748365, 20, 1],"float32"), )
[paddle error] paddle.frac(Tensor([214748365, 20, 1],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_subtract(_object*, _object*, _object*)
1   subtract_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::subtract(paddle::Tensor const&, paddle::Tensor const&)
3   void phi::SubtractRawKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, int, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 12:07:47.022841 116539 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:07:47.023852 116539 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
Traceback (most recent call last):
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 70, in <module>
    main()
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 50, in main
    case.clear_tensor()
  File "/host_home/wanghuan29/PaddleAPITest/tester/base.py", line 208, in clear_tensor
    arg_config.clear_tensor()
  File "/host_home/wanghuan29/PaddleAPITest/tester/api_config/config_analyzer.py", line 86, in clear_tensor
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.9/dist-packages/torch/cuda/memory.py", line 192, in empty_cache
    torch._C._cuda_emptyCache()
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


test begin: paddle.frac(Tensor([715827883, 3],"float64"), )
[paddle error] paddle.frac(Tensor([715827883, 3],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_subtract(_object*, _object*, _object*)
1   subtract_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::subtract(paddle::Tensor const&, paddle::Tensor const&)
3   void phi::SubtractRawKernel<double, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, int, phi::DenseTensor*)
4   double* phi::DeviceContext::Alloc<double>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 12:08:55.316978 116844 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:08:55.318405 116844 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
Traceback (most recent call last):
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 70, in <module>
    main()
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 50, in main
    case.clear_tensor()
  File "/host_home/wanghuan29/PaddleAPITest/tester/base.py", line 208, in clear_tensor
    arg_config.clear_tensor()
  File "/host_home/wanghuan29/PaddleAPITest/tester/api_config/config_analyzer.py", line 86, in clear_tensor
    torch.cuda.empty_cache()
  File "/usr/local/lib/python3.9/dist-packages/torch/cuda/memory.py", line 192, in empty_cache
    torch._C._cuda_emptyCache()
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


test begin: paddle.frac(Tensor([715827883, 3],"int64"), )
[torch error] paddle.frac(Tensor([715827883, 3],"int64"), ) 
 "frac_cuda" not implemented for 'Long'

W0205 12:09:53.285336 117162 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:09:53.286549 117162 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[], fill_value=Tensor([2147483649],"int64"), dtype="int64", )
[torch error] paddle.full(shape=list[], fill_value=Tensor([2147483649],"int64"), dtype="int64", ) 
 full() received an invalid combination of arguments - got (size=list, dtype=str, fill_value=Tensor, ), but expected one of:
 * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (tuple of ints size, Number fill_value, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0205 12:10:42.311218 117302 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:10:42.312404 117302 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[1,2,], dtype=type(numpy.float32), fill_value=Tensor([4294967295],"float32"), )
[torch error] paddle.full(shape=list[1,2,], dtype=type(numpy.float32), fill_value=Tensor([4294967295],"float32"), ) 
 full() received an invalid combination of arguments - got (size=list, fill_value=Tensor, dtype=type, ), but expected one of:
 * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (tuple of ints size, Number fill_value, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0205 12:12:00.628000 117509 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:12:00.629137 117509 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([1],"int32"),Tensor([1],"int64"),Tensor([2147483649],"int64"),], dtype="float32", fill_value=1.1, )
[torch error] paddle.full(shape=list[Tensor([1],"int32"),Tensor([1],"int64"),Tensor([2147483649],"int64"),], dtype="float32", fill_value=1.1, ) 
 full() received an invalid combination of arguments - got (size=list, fill_value=float, dtype=str, ), but expected one of:
 * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (tuple of ints size, Number fill_value, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0205 12:12:48.818575 117746 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:12:48.819897 117746 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([1],"int32"),Tensor([2147483649],"int64"),Tensor([1],"int64"),], dtype="float32", fill_value=1.1, )
[torch error] paddle.full(shape=list[Tensor([1],"int32"),Tensor([2147483649],"int64"),Tensor([1],"int64"),], dtype="float32", fill_value=1.1, ) 
 full() received an invalid combination of arguments - got (size=list, fill_value=float, dtype=str, ), but expected one of:
 * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (tuple of ints size, Number fill_value, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0205 12:13:42.009397 117939 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:13:42.010499 117939 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([1],"int32"),Tensor([4294967295],"int32"),], fill_value=0.0, )
[torch error] paddle.full(shape=list[Tensor([1],"int32"),Tensor([4294967295],"int32"),], fill_value=0.0, ) 
 full(): argument 'size' failed to unpack the object at pos 2 with error "type must be tuple of ints,but got Tensor"

W0205 12:14:56.977483 118149 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:14:56.978766 118149 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([1],"int32"),Tensor([4294967295],"int32"),], fill_value=10000000000, )
[torch error] paddle.full(shape=list[Tensor([1],"int32"),Tensor([4294967295],"int32"),], fill_value=10000000000, ) 
 full(): argument 'size' failed to unpack the object at pos 2 with error "type must be tuple of ints,but got Tensor"

W0205 12:16:12.649624 118386 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:16:12.651204 118386 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([1],"int32"),Tensor([4294967295],"int32"),], fill_value=3, )
[torch error] paddle.full(shape=list[Tensor([1],"int32"),Tensor([4294967295],"int32"),], fill_value=3, ) 
 full(): argument 'size' failed to unpack the object at pos 2 with error "type must be tuple of ints,but got Tensor"

W0205 12:17:24.968112 118690 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:17:24.969276 118690 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([1],"int32"),Tensor([4294967295],"int32"),], fill_value=3.8, )
[torch error] paddle.full(shape=list[Tensor([1],"int32"),Tensor([4294967295],"int32"),], fill_value=3.8, ) 
 full(): argument 'size' failed to unpack the object at pos 2 with error "type must be tuple of ints,but got Tensor"

W0205 12:18:43.192466 118915 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:18:43.193677 118915 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([1],"int32"),], fill_value=0.0, )
[torch error] paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([1],"int32"),], fill_value=0.0, ) 
 full(): argument 'size' must be tuple of ints, not list

W0205 12:19:56.667356 119219 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:19:56.668926 119219 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([1],"int32"),], fill_value=10000000000, )
[torch error] paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([1],"int32"),], fill_value=10000000000, ) 
 full(): argument 'size' must be tuple of ints, not list

W0205 12:21:15.867952 119442 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:21:15.869071 119442 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([1],"int32"),], fill_value=3, )
[torch error] paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([1],"int32"),], fill_value=3, ) 
 full(): argument 'size' must be tuple of ints, not list

W0205 12:22:27.967139 119748 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:22:27.968420 119748 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([1],"int32"),], fill_value=3.8, )
[torch error] paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([1],"int32"),], fill_value=3.8, ) 
 full(): argument 'size' must be tuple of ints, not list

W0205 12:23:40.636722 119972 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:23:40.638064 119972 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([1],"int64"),Tensor([1],"int64"),], dtype="float32", fill_value=1.1, )
[torch error] paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([1],"int64"),Tensor([1],"int64"),], dtype="float32", fill_value=1.1, ) 
 full() received an invalid combination of arguments - got (size=list, fill_value=float, dtype=str, ), but expected one of:
 * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (tuple of ints size, Number fill_value, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0205 12:25:03.782053 120277 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:25:03.783108 120277 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([2147483649],"int64"),Tensor([2147483649],"int64"),], dtype="float32", fill_value=1.1, )
[torch error] paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([2147483649],"int64"),Tensor([2147483649],"int64"),], dtype="float32", fill_value=1.1, ) 
 full() received an invalid combination of arguments - got (size=list, fill_value=float, dtype=str, ), but expected one of:
 * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (tuple of ints size, Number fill_value, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0205 12:27:38.170979 120649 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:27:38.175508 120649 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([4294967295],"int32"),], fill_value=0.0, )
[torch error] paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([4294967295],"int32"),], fill_value=0.0, ) 
 full(): argument 'size' must be tuple of ints, not list

W0205 12:30:09.933748 121185 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:30:09.934813 121185 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([4294967295],"int32"),], fill_value=10000000000, )
[torch error] paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([4294967295],"int32"),], fill_value=10000000000, ) 
 full(): argument 'size' must be tuple of ints, not list

W0205 12:32:38.430732 121687 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:32:38.431929 121687 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([4294967295],"int32"),], fill_value=3, )
[torch error] paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([4294967295],"int32"),], fill_value=3, ) 
 full(): argument 'size' must be tuple of ints, not list

W0205 12:34:48.174964 122169 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:34:48.176666 122169 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([4294967295],"int32"),], fill_value=3.8, )
[torch error] paddle.full(shape=list[Tensor([4294967295],"int32"),Tensor([4294967295],"int32"),], fill_value=3.8, ) 
 full(): argument 'size' must be tuple of ints, not list

W0205 12:37:08.003952 122575 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:37:08.005003 122575 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=Tensor([2],"int32"), fill_value=Tensor([4294967295],"float32"), )
[torch error] paddle.full(shape=Tensor([2],"int32"), fill_value=Tensor([4294967295],"float32"), ) 
 full(): argument 'size' must be tuple of ints, not Tensor

W0205 12:38:24.766884 123049 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:38:24.768309 123049 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=Tensor([2],"int32"), fill_value=Tensor([4294967295],"int32"), )
[torch error] paddle.full(shape=Tensor([2],"int32"), fill_value=Tensor([4294967295],"int32"), ) 
 full(): argument 'size' must be tuple of ints, not Tensor

W0205 12:39:43.926926 123290 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:39:43.928146 123290 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=Tensor([4294967295],"int32"), dtype="float32", fill_value=1.1, )
[torch error] paddle.full(shape=Tensor([4294967295],"int32"), dtype="float32", fill_value=1.1, ) 
 full() received an invalid combination of arguments - got (size=Tensor, fill_value=float, dtype=str, ), but expected one of:
 * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
 * (tuple of ints size, Number fill_value, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)


W0205 12:41:05.304008 123569 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:41:05.304994 123569 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=Tensor([4294967295],"int32"), fill_value=3.8, )
[torch error] paddle.full(shape=Tensor([4294967295],"int32"), fill_value=3.8, ) 
 full(): argument 'size' must be tuple of ints, not Tensor

W0205 12:42:20.005136 123859 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:42:20.006134 123859 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=Tensor([4294967295],"int32"), fill_value=Tensor([1],"float32"), )
[torch error] paddle.full(shape=Tensor([4294967295],"int32"), fill_value=Tensor([1],"float32"), ) 
 full(): argument 'size' must be tuple of ints, not Tensor

W0205 12:43:38.111702 124082 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:43:38.112672 124082 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=Tensor([4294967295],"int32"), fill_value=Tensor([1],"int32"), )
[torch error] paddle.full(shape=Tensor([4294967295],"int32"), fill_value=Tensor([1],"int32"), ) 
 full(): argument 'size' must be tuple of ints, not Tensor

W0205 12:44:57.246291 124372 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:44:57.248374 124372 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=Tensor([4294967295],"int32"), fill_value=Tensor([4294967295],"float32"), )
[torch error] paddle.full(shape=Tensor([4294967295],"int32"), fill_value=Tensor([4294967295],"float32"), ) 
 full(): argument 'size' must be tuple of ints, not Tensor

W0205 12:47:11.432245 124597 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:47:11.433305 124597 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full(shape=Tensor([4294967295],"int32"), fill_value=Tensor([4294967295],"int32"), )
[torch error] paddle.full(shape=Tensor([4294967295],"int32"), fill_value=Tensor([4294967295],"int32"), ) 
 full(): argument 'size' must be tuple of ints, not Tensor

W0205 12:49:31.937192 125080 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:49:31.938398 125080 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1, 1048576, 4096],"float32"), 1, )
[accuracy error] paddle.full_like(Tensor([1, 1048576, 4096],"float32"), 1, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[1., 1., 1., ..., 1., 1., 1.],
        [1., 1., 1., ..., 1., 1., 1.],
        [1., 1., 1., ..., 1., 1., 1.],...

W0205 12:50:53.302937 125485 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:50:53.304128 125485 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1, 3, 715827883],"float64"), fill_value=1, )
[accuracy error] paddle.full_like(Tensor([1, 3, 715827883],"float64"), fill_value=1, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483649 / 2147483649 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]]])
 y: array([[[1., 1., 1., ..., 1., 1., 1.],
        [1., 1., 1., ..., 1., 1., 1.],
        [1., 1., 1., ..., 1., 1., 1.]]])

W0205 12:56:42.646741 126719 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:56:42.647991 126719 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1, 300, 14316558],"float32"), 1, )
[Pass] paddle.full_like(Tensor([1, 300, 14316558],"float32"), 1, )

W0205 13:01:36.988735 127629 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:01:36.989650 127629 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1, 4294967295],"float32"), dtype=type(numpy.float32), fill_value=1.1, )
[torch error] paddle.full_like(Tensor([1, 4294967295],"float32"), dtype=type(numpy.float32), fill_value=1.1, ) 
 full_like(): argument 'dtype' must be torch.dtype, not type

W0205 13:05:09.893764 128373 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:05:09.894944 128373 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1, 536870913, 4],"float64"), fill_value=1, )
[accuracy error] paddle.full_like(Tensor([1, 536870913, 4],"float64"), fill_value=1, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483652 / 2147483652 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],...
 y: array([[[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.],...

W0205 13:06:05.285360 128677 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:06:05.286260 128677 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([10, 214748365],"float64"), 0, )
[Pass] paddle.full_like(Tensor([10, 214748365],"float64"), 0, )

W0205 13:10:31.147292 129496 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:10:31.148159 129496 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([10, 429496730],"float32"), 0, )
[Pass] paddle.full_like(Tensor([10, 429496730],"float32"), 0, )

W0205 13:14:16.235983 130182 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:14:16.237262 130182 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1024, 4194304],"float32"), 0.3917133774091194, )
[accuracy error] paddle.full_like(Tensor([1024, 4194304],"float32"), 0.3917133774091194, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 0.39171338
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[0.391713, 0.391713, 0.391713, ..., 0.391713, 0.391713, 0.391713],
       [0.391713, 0.391713, 0.391713, ..., 0.391713, 0.391713, 0.391713],
       [0.391713, 0.391713, 0.391713, ..., 0.391713, 0.391713, 0.391713],...

W0205 13:18:18.103765 131027 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:18:18.104651 131027 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1073741824, 4],"float32"), 0.0, )
[Pass] paddle.full_like(Tensor([1073741824, 4],"float32"), 0.0, )

W0205 13:23:19.550228 132068 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:23:19.551374 132068 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1073741824, 4],"float32"), 3.4028234663852886e+38, )
[accuracy error] paddle.full_like(Tensor([1073741824, 4],"float32"), 3.4028234663852886e+38, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 3.4028235e+38
Max relative difference: 1.
 x: array([[0., 0., 0., 0.],
       [0., 0., 0., 0.],
       [0., 0., 0., 0.],...
 y: array([[3.402823e+38, 3.402823e+38, 3.402823e+38, 3.402823e+38],
       [3.402823e+38, 3.402823e+38, 3.402823e+38, 3.402823e+38],
       [3.402823e+38, 3.402823e+38, 3.402823e+38, 3.402823e+38],...

W0205 13:27:05.121788 132819 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:27:05.123024 132819 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1073741824, 4],"float32"), -3.4028234663852886e+38, )
[accuracy error] paddle.full_like(Tensor([1073741824, 4],"float32"), -3.4028234663852886e+38, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 3.4028235e+38
Max relative difference: 1.
 x: array([[0., 0., 0., 0.],
       [0., 0., 0., 0.],
       [0., 0., 0., 0.],...
 y: array([[-3.402823e+38, -3.402823e+38, -3.402823e+38, -3.402823e+38],
       [-3.402823e+38, -3.402823e+38, -3.402823e+38, -3.402823e+38],
       [-3.402823e+38, -3.402823e+38, -3.402823e+38, -3.402823e+38],...

W0205 13:32:44.421094 133883 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:32:44.422217 133883 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1073741824, 4],"float32"), math.inf, )
[accuracy error] paddle.full_like(Tensor([1073741824, 4],"float32"), math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y +inf location mismatch:
 x: array([[0., 0., 0., 0.],
       [0., 0., 0., 0.],
       [0., 0., 0., 0.],...
 y: array([[inf, inf, inf, inf],
       [inf, inf, inf, inf],
       [inf, inf, inf, inf],...

W0205 13:38:35.724076 135108 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:38:35.724948 135108 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1073741824, 4],"float32"), -math.inf, )
[accuracy error] paddle.full_like(Tensor([1073741824, 4],"float32"), -math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y -inf location mismatch:
 x: array([[0., 0., 0., 0.],
       [0., 0., 0., 0.],
       [0., 0., 0., 0.],...
 y: array([[-inf, -inf, -inf, -inf],
       [-inf, -inf, -inf, -inf],
       [-inf, -inf, -inf, -inf],...

W0205 13:40:38.763283 135554 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:40:38.764351 135554 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([107374183, 40],"float32"), 1.0, )
[Pass] paddle.full_like(Tensor([107374183, 40],"float32"), 1.0, )

W0205 13:43:03.336674 136055 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:43:03.337559 136055 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([107374183, 40],"float32"), -1.0, )
[Pass] paddle.full_like(Tensor([107374183, 40],"float32"), -1.0, )

W0205 13:47:01.637315 136918 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:47:01.638656 136918 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([114, 18837576],"float64"), 0.0, )
[Pass] paddle.full_like(Tensor([114, 18837576],"float64"), 0.0, )

W0205 13:50:21.286278 137657 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:50:21.287201 137657 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([114, 18837576],"float64"), 1.7976931348623157e+308, )
[accuracy error] paddle.full_like(Tensor([114, 18837576],"float64"), 1.7976931348623157e+308, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483664 / 2147483664 (100%)
Max absolute difference: 1.79769313e+308
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[1.797693e+308, 1.797693e+308, 1.797693e+308, ..., 1.797693e+308,
        1.797693e+308, 1.797693e+308],
       [1.797693e+308, 1.797693e+308, 1.797693e+308, ..., 1.797693e+308,...

W0205 13:53:22.944222 138298 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:53:22.945161 138298 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([114, 18837576],"float64"), -2.220446049250313e-16, )
[Pass] paddle.full_like(Tensor([114, 18837576],"float64"), -2.220446049250313e-16, )

W0205 13:57:23.625662 139103 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:57:23.626681 139103 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([114, 18837576],"float64"), math.inf, )
[accuracy error] paddle.full_like(Tensor([114, 18837576],"float64"), math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y +inf location mismatch:
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[inf, inf, inf, ..., inf, inf, inf],
       [inf, inf, inf, ..., inf, inf, inf],
       [inf, inf, inf, ..., inf, inf, inf],...

W0205 14:00:41.521309 139821 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:00:41.522344 139821 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([114, 18837576],"float64"), -math.inf, )
[accuracy error] paddle.full_like(Tensor([114, 18837576],"float64"), -math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y -inf location mismatch:
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[-inf, -inf, -inf, ..., -inf, -inf, -inf],
       [-inf, -inf, -inf, ..., -inf, -inf, -inf],
       [-inf, -inf, -inf, ..., -inf, -inf, -inf],...

W0205 14:02:19.574605 140135 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:02:19.575538 140135 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([128, 33554432],"float16"), 127, )
[accuracy error] paddle.full_like(Tensor([128, 33554432],"float16"), 127, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 127.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[127., 127., 127., ..., 127., 127., 127.],
       [127., 127., 127., ..., 127., 127., 127.],
       [127., 127., 127., ..., 127., 127., 127.],...

W0205 14:04:38.136649 140553 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:04:38.137547 140553 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([128, 33554432],"float16"), -127, )
[accuracy error] paddle.full_like(Tensor([128, 33554432],"float16"), -127, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 127.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[-127., -127., -127., ..., -127., -127., -127.],
       [-127., -127., -127., ..., -127., -127., -127.],
       [-127., -127., -127., ..., -127., -127., -127.],...

W0205 14:18:19.306234 143323 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:18:19.307149 143323 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([131072, 8, 64, 64],"float16"), 127, )
[accuracy error] paddle.full_like(Tensor([131072, 8, 64, 64],"float16"), 127, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 127.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[127., 127., 127., ..., 127., 127., 127.],
         [127., 127., 127., ..., 127., 127., 127.],
         [127., 127., 127., ..., 127., 127., 127.],...

W0205 14:31:46.162573 145962 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:31:46.163698 145962 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([131072, 8, 64, 64],"float16"), -127, )
[accuracy error] paddle.full_like(Tensor([131072, 8, 64, 64],"float16"), -127, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 127.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[-127., -127., -127., ..., -127., -127., -127.],
         [-127., -127., -127., ..., -127., -127., -127.],
         [-127., -127., -127., ..., -127., -127., -127.],...

W0205 14:45:23.247363 151105 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:45:23.248626 151105 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1431655765, 3],"float32"), 0.0, )
[Pass] paddle.full_like(Tensor([1431655765, 3],"float32"), 0.0, )

W0205 14:58:48.319082 153732 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:58:48.319933 153732 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1431655765, 3],"float32"), 0.5, )
[accuracy error] paddle.full_like(Tensor([1431655765, 3],"float32"), 0.5, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 0.5
Max relative difference: 1.
 x: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],...
 y: array([[0.5, 0.5, 0.5],
       [0.5, 0.5, 0.5],
       [0.5, 0.5, 0.5],...

W0205 15:02:29.704545 154514 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:02:29.705425 154514 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1431655765, 3],"float32"), 1.0, )
[accuracy error] paddle.full_like(Tensor([1431655765, 3],"float32"), 1.0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],...
 y: array([[1., 1., 1.],
       [1., 1., 1.],
       [1., 1., 1.],...

W0205 15:07:34.274921 155487 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:07:34.275818 155487 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1431655765, 3],"float32"), -10.0, )
[accuracy error] paddle.full_like(Tensor([1431655765, 3],"float32"), -10.0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 10.
Max relative difference: 1.
 x: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],...
 y: array([[-10., -10., -10.],
       [-10., -10., -10.],
       [-10., -10., -10.],...

W0205 15:13:23.985904 156680 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:13:23.986799 156680 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1431655765, 3],"float32"), 100.0, )
[accuracy error] paddle.full_like(Tensor([1431655765, 3],"float32"), 100.0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 100.
Max relative difference: 1.
 x: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],...
 y: array([[100., 100., 100.],
       [100., 100., 100.],
       [100., 100., 100.],...

W0205 15:19:09.322175 157751 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:19:09.323021 157751 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1431655765, 3],"float32"), 2.0, )
[accuracy error] paddle.full_like(Tensor([1431655765, 3],"float32"), 2.0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 2.
Max relative difference: 1.
 x: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],...
 y: array([[2., 2., 2.],
       [2., 2., 2.],
       [2., 2., 2.],...

W0205 15:25:01.538748 158966 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:25:01.539686 158966 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1431655765, 3],"float32"), 3.4028234663852886e+38, )
[accuracy error] paddle.full_like(Tensor([1431655765, 3],"float32"), 3.4028234663852886e+38, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 3.4028235e+38
Max relative difference: 1.
 x: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],...
 y: array([[3.402823e+38, 3.402823e+38, 3.402823e+38],
       [3.402823e+38, 3.402823e+38, 3.402823e+38],
       [3.402823e+38, 3.402823e+38, 3.402823e+38],...

W0205 15:29:52.958178 159951 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:29:52.959273 159951 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1431655765, 3],"float32"), -3.4028234663852886e+38, )
[accuracy error] paddle.full_like(Tensor([1431655765, 3],"float32"), -3.4028234663852886e+38, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 3.4028235e+38
Max relative difference: 1.
 x: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],...
 y: array([[-3.402823e+38, -3.402823e+38, -3.402823e+38],
       [-3.402823e+38, -3.402823e+38, -3.402823e+38],
       [-3.402823e+38, -3.402823e+38, -3.402823e+38],...

W0205 15:34:44.036902 160926 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:34:44.037786 160926 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1431655765, 3],"float32"), fill_value=math.inf, )
[accuracy error] paddle.full_like(Tensor([1431655765, 3],"float32"), fill_value=math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y +inf location mismatch:
 x: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],...
 y: array([[inf, inf, inf],
       [inf, inf, inf],
       [inf, inf, inf],...

W0205 15:39:34.208461 161917 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:39:34.209389 161917 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1431655765, 3],"float32"), fill_value=nan, )
[accuracy error] paddle.full_like(Tensor([1431655765, 3],"float32"), fill_value=nan, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y nan location mismatch:
 x: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],...
 y: array([[nan, nan, nan],
       [nan, nan, nan],
       [nan, nan, nan],...

W0205 15:41:36.736406 162334 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:41:36.737250 162334 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1431655765, 3],"float32"), math.inf, )
[accuracy error] paddle.full_like(Tensor([1431655765, 3],"float32"), math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y +inf location mismatch:
 x: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],...
 y: array([[inf, inf, inf],
       [inf, inf, inf],
       [inf, inf, inf],...

W0205 15:43:29.068573 162849 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:43:29.069607 162849 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1431655765, 3],"float32"), -math.inf, )
[accuracy error] paddle.full_like(Tensor([1431655765, 3],"float32"), -math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y -inf location mismatch:
 x: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],...
 y: array([[-inf, -inf, -inf],
       [-inf, -inf, -inf],
       [-inf, -inf, -inf],...

W0205 15:45:42.118121 163723 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:45:42.119537 163723 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([148, 5, 5804010],"float32"), 0.0, )
[Pass] paddle.full_like(Tensor([148, 5, 5804010],"float32"), 0.0, )

W0205 15:48:06.951970   972 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:48:06.952914   972 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([148, 5, 5804010],"float32"), -1.1920928955078125e-07, )
[Pass] paddle.full_like(Tensor([148, 5, 5804010],"float32"), -1.1920928955078125e-07, )

W0205 15:51:57.562817  2063 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:51:57.563980  2063 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([148, 5, 5804010],"float32"), 3.4028234663852886e+38, )
[Pass] paddle.full_like(Tensor([148, 5, 5804010],"float32"), 3.4028234663852886e+38, )

W0205 15:55:35.421103  3018 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:55:35.422358  3018 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([148, 5, 5804010],"float32"), math.inf, )
[Pass] paddle.full_like(Tensor([148, 5, 5804010],"float32"), math.inf, )

W0205 15:59:23.838184  4140 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:59:23.839053  4140 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([148, 5, 5804010],"float32"), -math.inf, )
[Pass] paddle.full_like(Tensor([148, 5, 5804010],"float32"), -math.inf, )

W0205 16:01:52.105823  4853 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:01:52.107071  4853 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([148, 9673350, 3],"float32"), 0.0, )
[Pass] paddle.full_like(Tensor([148, 9673350, 3],"float32"), 0.0, )

W0205 16:04:26.838492  5541 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:04:26.839462  5541 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([148, 9673350, 3],"float32"), -1.1920928955078125e-07, )
[Pass] paddle.full_like(Tensor([148, 9673350, 3],"float32"), -1.1920928955078125e-07, )

W0205 16:07:57.766391  6622 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:07:57.767305  6622 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([148, 9673350, 3],"float32"), 3.4028234663852886e+38, )
[Pass] paddle.full_like(Tensor([148, 9673350, 3],"float32"), 3.4028234663852886e+38, )

W0205 16:11:51.304536  7647 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:11:51.305852  7647 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([148, 9673350, 3],"float32"), math.inf, )
[Pass] paddle.full_like(Tensor([148, 9673350, 3],"float32"), math.inf, )

W0205 16:15:30.908772  8911 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:15:30.909633  8911 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([148, 9673350, 3],"float32"), -math.inf, )
[Pass] paddle.full_like(Tensor([148, 9673350, 3],"float32"), -math.inf, )

W0205 16:18:17.044785  9651 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:18:17.045994  9651 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([16, 134217729],"float64"), 1.0, )
[accuracy error] paddle.full_like(Tensor([16, 134217729],"float64"), 1.0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483664 / 2147483664 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],...

W0205 16:20:05.111203 10316 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:20:05.112205 10316 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([16, 134217729],"float64"), 1e-20, )
[Pass] paddle.full_like(Tensor([16, 134217729],"float64"), 1e-20, )

W0205 16:23:54.243057 11291 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:23:54.243945 11291 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([16, 268435456],"float32"), 1.0, )
[accuracy error] paddle.full_like(Tensor([16, 268435456],"float32"), 1.0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],...

W0205 16:27:15.887393 12108 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:27:15.888312 12108 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([16, 268435456],"float32"), 1e-20, )
[Pass] paddle.full_like(Tensor([16, 268435456],"float32"), 1e-20, )

W0205 16:31:52.069772 13368 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:31:52.070665 13368 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([178956971, 12],"float64"), 0, )
[Pass] paddle.full_like(Tensor([178956971, 12],"float64"), 0, )

W0205 16:35:00.969976 14331 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:35:00.970966 14331 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([178956971, 3, 4],"float64"), fill_value=1, )
[accuracy error] paddle.full_like(Tensor([178956971, 3, 4],"float64"), fill_value=1, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483652 / 2147483652 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.]],...
 y: array([[[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]],...

W0205 16:38:11.821329 15276 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:38:11.822186 15276 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([18512791, 232],"float16"), 0.0, None, None, )
[Pass] paddle.full_like(Tensor([18512791, 232],"float16"), 0.0, None, None, )

W0205 16:42:48.397490 16401 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:42:48.398450 16401 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([18512791, 232],"float32"), 0.0, None, None, )
[Pass] paddle.full_like(Tensor([18512791, 232],"float32"), 0.0, None, None, )

W0205 16:51:57.438918 18926 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:51:57.440254 18926 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([18512791, 232],"float32"), 0.0, VarType(bfloat16), None, )
[torch error] paddle.full_like(Tensor([18512791, 232],"float32"), 0.0, VarType(bfloat16), None, ) 
 full_like(): argument 'dtype' must be torch.dtype, not paddle.base.libpaddle.VarType

W0205 16:55:53.557799 20042 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:55:53.559057 20042 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([18512791, 232],"int32"), 0.0, Dtype(int16), None, )
[torch error] paddle.full_like(Tensor([18512791, 232],"int32"), 0.0, Dtype(int16), None, ) 
 full_like(): argument 'dtype' must be torch.dtype, not paddle.base.libpaddle.DataType

W0205 16:57:14.363988 20460 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:57:14.365316 20460 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([18512791, 232],"int32"), 0.0, None, None, )
[Pass] paddle.full_like(Tensor([18512791, 232],"int32"), 0.0, None, None, )

W0205 16:58:36.671198 20874 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:58:36.672107 20874 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([18512791, 232],"int32"), 0.0, VarType(float32), None, )
[torch error] paddle.full_like(Tensor([18512791, 232],"int32"), 0.0, VarType(float32), None, ) 
 full_like(): argument 'dtype' must be torch.dtype, not paddle.base.libpaddle.VarType

W0205 17:03:14.537645 22116 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:03:14.539013 22116 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([18512791, 232],"int32"), 1.0, None, None, )
[Pass] paddle.full_like(Tensor([18512791, 232],"int32"), 1.0, None, None, )

W0205 17:04:39.477973 22521 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:04:39.478798 22521 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([18512791, 232],"int32"), 1e-10, None, None, )
[Pass] paddle.full_like(Tensor([18512791, 232],"int32"), 1e-10, None, None, )

W0205 17:09:42.736984 23877 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:09:42.737793 23877 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([18512791, 232],"int32"), 1e-100, None, None, )
[Pass] paddle.full_like(Tensor([18512791, 232],"int32"), 1e-100, None, None, )

W0205 17:14:38.511970 25152 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:14:38.513110 25152 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1948, 2204809],"float32"), 0.0, )
[Pass] paddle.full_like(Tensor([1948, 2204809],"float32"), 0.0, )

W0205 17:19:45.466848 26751 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:19:45.467721 26751 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1948, 2204809],"float32"), -1.1920928955078125e-07, )
[Pass] paddle.full_like(Tensor([1948, 2204809],"float32"), -1.1920928955078125e-07, )

W0205 17:23:36.877115 27813 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:23:36.878201 27813 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1948, 2204809],"float32"), 3.4028234663852886e+38, )
[Pass] paddle.full_like(Tensor([1948, 2204809],"float32"), 3.4028234663852886e+38, )

W0205 17:27:23.832893 28955 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:27:23.833936 28955 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1948, 2204809],"float32"), math.inf, )
[Pass] paddle.full_like(Tensor([1948, 2204809],"float32"), math.inf, )

W0205 17:31:08.732606 30063 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:31:08.733490 30063 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([1948, 2204809],"float32"), -math.inf, )
[Pass] paddle.full_like(Tensor([1948, 2204809],"float32"), -math.inf, )

W0205 17:33:26.459900 30656 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:33:26.460834 30656 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2, 1073741825],"float64"), 0.5, )
[accuracy error] paddle.full_like(Tensor([2, 1073741825],"float64"), 0.5, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483650 / 2147483650 (100%)
Max absolute difference: 0.5
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]])
 y: array([[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],
       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]])

W0205 17:35:19.970674 31320 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:35:19.971546 31320 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2, 1073741825],"float64"), fill_value=math.inf, )
[accuracy error] paddle.full_like(Tensor([2, 1073741825],"float64"), fill_value=math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y +inf location mismatch:
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]])
 y: array([[inf, inf, inf, ..., inf, inf, inf],
       [inf, inf, inf, ..., inf, inf, inf]])

W0205 17:39:31.977545 32437 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:39:31.978451 32437 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2, 1073741825],"float64"), fill_value=nan, )
[accuracy error] paddle.full_like(Tensor([2, 1073741825],"float64"), fill_value=nan, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y nan location mismatch:
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]])
 y: array([[nan, nan, nan, ..., nan, nan, nan],
       [nan, nan, nan, ..., nan, nan, nan]])

W0205 17:41:20.936723 32950 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:41:20.937657 32950 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2, 2147483648],"float16"), 127, )
[accuracy error] paddle.full_like(Tensor([2, 2147483648],"float16"), 127, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 127.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float16)
 y: array([[127., 127., 127., ..., 127., 127., 127.],
       [127., 127., 127., ..., 127., 127., 127.]], dtype=float16)

W0205 17:43:22.480113 33376 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:43:22.481097 33376 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2, 2147483648],"float16"), -127, )
[accuracy error] paddle.full_like(Tensor([2, 2147483648],"float16"), -127, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 127.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float16)
 y: array([[-127., -127., -127., ..., -127., -127., -127.],
       [-127., -127., -127., ..., -127., -127., -127.]], dtype=float16)

W0205 17:57:05.866394 37099 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:57:05.867420 37099 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2, 2147483648],"float32"), 0.0, )
[Pass] paddle.full_like(Tensor([2, 2147483648],"float32"), 0.0, )

W0205 18:10:44.343595 40933 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:10:44.344746 40933 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2, 2147483648],"float32"), 0.5, )
[accuracy error] paddle.full_like(Tensor([2, 2147483648],"float32"), 0.5, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 0.5
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)
 y: array([[0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5],
       [0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5]], dtype=float32)

W0205 18:14:36.535444 43433 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:14:36.536314 43433 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2, 2147483648],"float32"), 1.0, )
[accuracy error] paddle.full_like(Tensor([2, 2147483648],"float32"), 1.0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)
 y: array([[1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.]], dtype=float32)

W0205 18:19:08.783330 45027 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:19:08.784381 45027 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2, 2147483648],"float32"), -10.0, )
[accuracy error] paddle.full_like(Tensor([2, 2147483648],"float32"), -10.0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 10.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)
 y: array([[-10., -10., -10., ..., -10., -10., -10.],
       [-10., -10., -10., ..., -10., -10., -10.]], dtype=float32)

W0205 18:24:09.274385 46496 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:24:09.275259 46496 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2, 2147483648],"float32"), 100.0, )
[accuracy error] paddle.full_like(Tensor([2, 2147483648],"float32"), 100.0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 100.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)
 y: array([[100., 100., 100., ..., 100., 100., 100.],
       [100., 100., 100., ..., 100., 100., 100.]], dtype=float32)

W0205 18:28:48.474709 47880 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:28:48.475772 47880 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2, 2147483648],"float32"), 2.0, )
[accuracy error] paddle.full_like(Tensor([2, 2147483648],"float32"), 2.0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 2.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)
 y: array([[2., 2., 2., ..., 2., 2., 2.],
       [2., 2., 2., ..., 2., 2., 2.]], dtype=float32)

W0205 18:33:55.039985 49188 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:33:55.041148 49188 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2, 2147483648],"float32"), 3.4028234663852886e+38, )
[accuracy error] paddle.full_like(Tensor([2, 2147483648],"float32"), 3.4028234663852886e+38, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 3.4028235e+38
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)
 y: array([[3.402823e+38, 3.402823e+38, 3.402823e+38, ..., 3.402823e+38,
        3.402823e+38, 3.402823e+38],
       [3.402823e+38, 3.402823e+38, 3.402823e+38, ..., 3.402823e+38,
        3.402823e+38, 3.402823e+38]], dtype=float32)

W0205 18:38:46.069213 50611 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:38:46.070084 50611 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2, 2147483648],"float32"), -3.4028234663852886e+38, )
[accuracy error] paddle.full_like(Tensor([2, 2147483648],"float32"), -3.4028234663852886e+38, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 3.4028235e+38
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)
 y: array([[-3.402823e+38, -3.402823e+38, -3.402823e+38, ..., -3.402823e+38,
        -3.402823e+38, -3.402823e+38],
       [-3.402823e+38, -3.402823e+38, -3.402823e+38, ..., -3.402823e+38,
        -3.402823e+38, -3.402823e+38]], dtype=float32)

W0205 18:43:48.738631 52017 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:43:48.739528 52017 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2, 2147483648],"float32"), fill_value=2, )
[accuracy error] paddle.full_like(Tensor([2, 2147483648],"float32"), fill_value=2, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 2.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)
 y: array([[2., 2., 2., ..., 2., 2., 2.],
       [2., 2., 2., ..., 2., 2., 2.]], dtype=float32)

W0205 18:49:01.287143 53506 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:49:01.288012 53506 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2, 2147483648],"float32"), fill_value=math.inf, )
[accuracy error] paddle.full_like(Tensor([2, 2147483648],"float32"), fill_value=math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y +inf location mismatch:
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)
 y: array([[inf, inf, inf, ..., inf, inf, inf],
       [inf, inf, inf, ..., inf, inf, inf]], dtype=float32)

W0205 18:54:00.390772 54912 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:54:00.391621 54912 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2, 2147483648],"float32"), fill_value=nan, )
[accuracy error] paddle.full_like(Tensor([2, 2147483648],"float32"), fill_value=nan, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y nan location mismatch:
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)
 y: array([[nan, nan, nan, ..., nan, nan, nan],
       [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)

W0205 18:56:05.944655 55471 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:56:05.945845 55471 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2, 2147483648],"float32"), math.inf, )
[accuracy error] paddle.full_like(Tensor([2, 2147483648],"float32"), math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y +inf location mismatch:
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)
 y: array([[inf, inf, inf, ..., inf, inf, inf],
       [inf, inf, inf, ..., inf, inf, inf]], dtype=float32)

W0205 18:58:01.009719 56067 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:58:01.010597 56067 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2, 2147483648],"float32"), -math.inf, )
[accuracy error] paddle.full_like(Tensor([2, 2147483648],"float32"), -math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y -inf location mismatch:
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)
 y: array([[-inf, -inf, -inf, ..., -inf, -inf, -inf],
       [-inf, -inf, -inf, ..., -inf, -inf, -inf]], dtype=float32)

W0205 19:00:05.351238 56621 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:00:05.352281 56621 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2, 524288, 64, 64],"float16"), 127, )
[accuracy error] paddle.full_like(Tensor([2, 524288, 64, 64],"float16"), 127, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 127.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[127., 127., 127., ..., 127., 127., 127.],
         [127., 127., 127., ..., 127., 127., 127.],
         [127., 127., 127., ..., 127., 127., 127.],...

W0205 19:02:37.688766 57314 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:02:37.689903 57314 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2, 524288, 64, 64],"float16"), -127, )
[accuracy error] paddle.full_like(Tensor([2, 524288, 64, 64],"float16"), -127, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 127.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[-127., -127., -127., ..., -127., -127., -127.],
         [-127., -127., -127., ..., -127., -127., -127.],
         [-127., -127., -127., ..., -127., -127., -127.],...

W0205 19:16:20.767202 61129 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:16:20.768090 61129 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2, 8, 4194304, 64],"float16"), 127, )
[accuracy error] paddle.full_like(Tensor([2, 8, 4194304, 64],"float16"), 127, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 127.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[127., 127., 127., ..., 127., 127., 127.],
         [127., 127., 127., ..., 127., 127., 127.],
         [127., 127., 127., ..., 127., 127., 127.],...

W0205 19:30:01.878731 64963 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:30:01.880113 64963 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2, 8, 4194304, 64],"float16"), -127, )
[accuracy error] paddle.full_like(Tensor([2, 8, 4194304, 64],"float16"), -127, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 127.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[-127., -127., -127., ..., -127., -127., -127.],
         [-127., -127., -127., ..., -127., -127., -127.],
         [-127., -127., -127., ..., -127., -127., -127.],...

W0205 19:43:40.920156 68940 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:43:40.921177 68940 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2, 8, 64, 4194304],"float16"), 127, )
[accuracy error] paddle.full_like(Tensor([2, 8, 64, 4194304],"float16"), 127, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 127.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[127., 127., 127., ..., 127., 127., 127.],
         [127., 127., 127., ..., 127., 127., 127.],
         [127., 127., 127., ..., 127., 127., 127.],...

W0205 19:57:00.418766 72725 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:57:00.419642 72725 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2, 8, 64, 4194304],"float16"), -127, )
[accuracy error] paddle.full_like(Tensor([2, 8, 64, 4194304],"float16"), -127, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 127.
Max relative difference: 1.
 x: array([[[[0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],
         [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[[-127., -127., -127., ..., -127., -127., -127.],
         [-127., -127., -127., ..., -127., -127., -127.],
         [-127., -127., -127., ..., -127., -127., -127.],...

W0205 20:10:20.407629 76538 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:10:20.408521 76538 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2147483648, 2],"float32"), 0.0, )
[Pass] paddle.full_like(Tensor([2147483648, 2],"float32"), 0.0, )

W0205 20:23:35.025774 80310 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:23:35.026788 80310 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2147483648, 2],"float32"), 0.5, )
[accuracy error] paddle.full_like(Tensor([2147483648, 2],"float32"), 0.5, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 0.5
Max relative difference: 1.
 x: array([[0., 0.],
       [0., 0.],
       [0., 0.],...
 y: array([[0.5, 0.5],
       [0.5, 0.5],
       [0.5, 0.5],...

W0205 20:27:48.896415 81423 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:27:48.897538 81423 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2147483648, 2],"float32"), -1.1920928955078125e-07, )
[Pass] paddle.full_like(Tensor([2147483648, 2],"float32"), -1.1920928955078125e-07, )

W0205 20:32:33.821350 82892 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:32:33.822518 82892 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2147483648, 2],"float32"), 3.4028234663852886e+38, )
[accuracy error] paddle.full_like(Tensor([2147483648, 2],"float32"), 3.4028234663852886e+38, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 3.4028235e+38
Max relative difference: 1.
 x: array([[0., 0.],
       [0., 0.],
       [0., 0.],...
 y: array([[3.402823e+38, 3.402823e+38],
       [3.402823e+38, 3.402823e+38],
       [3.402823e+38, 3.402823e+38],...

W0205 20:36:05.694618 83903 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:36:05.695578 83903 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2147483648, 2],"float32"), dtype=type(numpy.float32), fill_value=1.1, )
[torch error] paddle.full_like(Tensor([2147483648, 2],"float32"), dtype=type(numpy.float32), fill_value=1.1, ) 
 full_like(): argument 'dtype' must be torch.dtype, not type

W0205 20:40:46.292999 85321 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:40:46.294234 85321 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2147483648, 2],"float32"), math.inf, )
[accuracy error] paddle.full_like(Tensor([2147483648, 2],"float32"), math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y +inf location mismatch:
 x: array([[0., 0.],
       [0., 0.],
       [0., 0.],...
 y: array([[inf, inf],
       [inf, inf],
       [inf, inf],...

W0205 20:42:03.988814 85641 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:42:03.989657 85641 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2147483648, 2],"float32"), -math.inf, )
[accuracy error] paddle.full_like(Tensor([2147483648, 2],"float32"), -math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y -inf location mismatch:
 x: array([[0., 0.],
       [0., 0.],
       [0., 0.],...
 y: array([[-inf, -inf],
       [-inf, -inf],
       [-inf, -inf],...

W0205 20:44:04.002832 86208 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:44:04.003738 86208 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2147483649, 1],"float64"), 0.0, )
[Pass] paddle.full_like(Tensor([2147483649, 1],"float64"), 0.0, )

W0205 20:45:48.353386 86805 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:45:48.354300 86805 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2147483649, 1],"float64"), 0.5, )
[accuracy error] paddle.full_like(Tensor([2147483649, 1],"float64"), 0.5, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483649 / 2147483649 (100%)
Max absolute difference: 0.5
Max relative difference: 1.
 x: array([[0.],
       [0.],
       [0.],...
 y: array([[0.5],
       [0.5],
       [0.5],...

W0205 20:48:40.578141 87624 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:48:40.578935 87624 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2147483649, 1],"float64"), 1.7976931348623157e+308, )
[accuracy error] paddle.full_like(Tensor([2147483649, 1],"float64"), 1.7976931348623157e+308, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483649 / 2147483649 (100%)
Max absolute difference: 1.79769313e+308
Max relative difference: 1.
 x: array([[0.],
       [0.],
       [0.],...
 y: array([[1.797693e+308],
       [1.797693e+308],
       [1.797693e+308],...

W0205 20:52:35.687747 88761 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:52:35.688702 88761 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2147483649, 1],"float64"), -2.220446049250313e-16, )
[Pass] paddle.full_like(Tensor([2147483649, 1],"float64"), -2.220446049250313e-16, )

W0205 20:56:27.540488 89789 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:56:27.541388 89789 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2147483649, 1],"float64"), fill_value=11, )
[accuracy error] paddle.full_like(Tensor([2147483649, 1],"float64"), fill_value=11, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483649 / 2147483649 (100%)
Max absolute difference: 11.
Max relative difference: 1.
 x: array([[0.],
       [0.],
       [0.],...
 y: array([[11.],
       [11.],
       [11.],...

W0205 20:59:28.089005 90668 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:59:28.090186 90668 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2147483649, 1],"float64"), fill_value=23, )
[accuracy error] paddle.full_like(Tensor([2147483649, 1],"float64"), fill_value=23, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483649 / 2147483649 (100%)
Max absolute difference: 23.
Max relative difference: 1.
 x: array([[0.],
       [0.],
       [0.],...
 y: array([[23.],
       [23.],
       [23.],...

W0205 21:03:43.684813 91929 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:03:43.685806 91929 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2147483649, 1],"float64"), fill_value=41, )
[accuracy error] paddle.full_like(Tensor([2147483649, 1],"float64"), fill_value=41, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483649 / 2147483649 (100%)
Max absolute difference: 41.
Max relative difference: 1.
 x: array([[0.],
       [0.],
       [0.],...
 y: array([[41.],
       [41.],
       [41.],...

W0205 21:07:30.136556 93070 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:07:30.137562 93070 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2147483649, 1],"float64"), fill_value=6, )
[accuracy error] paddle.full_like(Tensor([2147483649, 1],"float64"), fill_value=6, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483649 / 2147483649 (100%)
Max absolute difference: 6.
Max relative difference: 1.
 x: array([[0.],
       [0.],
       [0.],...
 y: array([[6.],
       [6.],
       [6.],...

W0205 21:11:14.496475 94188 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:11:14.497421 94188 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2147483649, 1],"float64"), math.inf, )
[accuracy error] paddle.full_like(Tensor([2147483649, 1],"float64"), math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y +inf location mismatch:
 x: array([[0.],
       [0.],
       [0.],...
 y: array([[inf],
       [inf],
       [inf],...

W0205 21:15:06.730571 95330 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:15:06.732177 95330 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2147483649, 1],"float64"), -math.inf, )
[accuracy error] paddle.full_like(Tensor([2147483649, 1],"float64"), -math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y -inf location mismatch:
 x: array([[0.],
       [0.],
       [0.],...
 y: array([[-inf],
       [-inf],
       [-inf],...

W0205 21:16:40.198221 95800 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:16:40.199117 95800 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2147483649],"float64"), 0.0, )
[Pass] paddle.full_like(Tensor([2147483649],"float64"), 0.0, )

W0205 21:18:16.221077 96243 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:18:16.221943 96243 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2147483649],"float64"), 0.9999998807907104, )
[accuracy error] paddle.full_like(Tensor([2147483649],"float64"), 0.9999998807907104, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483649 / 2147483649 (100%)
Max absolute difference: 0.99999988
Max relative difference: 1.
 x: array([0., 0., 0., ..., 0., 0., 0.])
 y: array([1., 1., 1., ..., 1., 1., 1.])

W0205 21:21:13.352305 97103 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:21:13.353098 97103 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2147483649],"float64"), 1.0, )
[accuracy error] paddle.full_like(Tensor([2147483649],"float64"), 1.0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483649 / 2147483649 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([0., 0., 0., ..., 0., 0., 0.])
 y: array([1., 1., 1., ..., 1., 1., 1.])

W0205 21:25:34.623612 98409 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:25:34.624506 98409 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2147483649],"float64"), 1.1754943508222875e-38, )
[Pass] paddle.full_like(Tensor([2147483649],"float64"), 1.1754943508222875e-38, )

W0205 21:29:31.837910 99575 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:29:31.838805 99575 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2147483649],"float64"), 1.7976931348623157e+308, )
[accuracy error] paddle.full_like(Tensor([2147483649],"float64"), 1.7976931348623157e+308, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483649 / 2147483649 (100%)
Max absolute difference: 1.79769313e+308
Max relative difference: 1.
 x: array([0., 0., 0., ..., 0., 0., 0.])
 y: array([1.797693e+308, 1.797693e+308, 1.797693e+308, ..., 1.797693e+308,
       1.797693e+308, 1.797693e+308])

W0205 21:32:27.637472 100343 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:32:27.638435 100343 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2147483649],"float64"), 1e-20, )
[Pass] paddle.full_like(Tensor([2147483649],"float64"), 1e-20, )

W0205 21:36:19.446857 101456 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:36:19.447772 101456 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2147483649],"float64"), -2.220446049250313e-16, )
[Pass] paddle.full_like(Tensor([2147483649],"float64"), -2.220446049250313e-16, )

W0205 21:39:16.072867 102294 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:39:16.073812 102294 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2147483649],"float64"), fill_value=167, )
[accuracy error] paddle.full_like(Tensor([2147483649],"float64"), fill_value=167, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483649 / 2147483649 (100%)
Max absolute difference: 167.
Max relative difference: 1.
 x: array([0., 0., 0., ..., 0., 0., 0.])
 y: array([167., 167., 167., ..., 167., 167., 167.])

W0205 21:42:34.287824 103246 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:42:34.288693 103246 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2147483649],"float64"), math.inf, )
[accuracy error] paddle.full_like(Tensor([2147483649],"float64"), math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y +inf location mismatch:
 x: array([0., 0., 0., ..., 0., 0., 0.])
 y: array([inf, inf, inf, ..., inf, inf, inf])

W0205 21:47:48.331682 104670 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:47:48.332733 104670 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2147483649],"float64"), -math.inf, )
[accuracy error] paddle.full_like(Tensor([2147483649],"float64"), -math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y -inf location mismatch:
 x: array([0., 0., 0., ..., 0., 0., 0.])
 y: array([-inf, -inf, -inf, ..., -inf, -inf, -inf])

W0205 21:49:26.037705 105120 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:49:26.038578 105120 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([2147483649],"int64"), False, dtype="bool", )
[torch error] paddle.full_like(Tensor([2147483649],"int64"), False, dtype="bool", ) 
 full_like(): argument 'dtype' must be torch.dtype, not str

W0205 21:50:59.753871 105672 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:50:59.754838 105672 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([214748365, 5, 2],"float64"), 0, )
[Pass] paddle.full_like(Tensor([214748365, 5, 2],"float64"), 0, )

W0205 21:52:00.180621 105869 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:52:00.181576 105869 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([219, 19611723],"float16"), 0.0, None, None, )
[Pass] paddle.full_like(Tensor([219, 19611723],"float16"), 0.0, None, None, )

W0205 21:55:46.289456 106863 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:55:46.290459 106863 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([219, 19611723],"float32"), 0.0, None, None, )
[Pass] paddle.full_like(Tensor([219, 19611723],"float32"), 0.0, None, None, )

W0205 22:04:44.668542 109464 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:04:44.669369 109464 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([219, 19611723],"float32"), 0.0, VarType(bfloat16), None, )
[torch error] paddle.full_like(Tensor([219, 19611723],"float32"), 0.0, VarType(bfloat16), None, ) 
 full_like(): argument 'dtype' must be torch.dtype, not paddle.base.libpaddle.VarType

W0205 22:08:34.716967 110613 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:08:34.718051 110613 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([219, 19611723],"int32"), 0.0, Dtype(int16), None, )
[torch error] paddle.full_like(Tensor([219, 19611723],"int32"), 0.0, Dtype(int16), None, ) 
 full_like(): argument 'dtype' must be torch.dtype, not paddle.base.libpaddle.DataType

W0205 22:09:45.053709 111048 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:09:45.054766 111048 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([219, 19611723],"int32"), 0.0, None, None, )
[Pass] paddle.full_like(Tensor([219, 19611723],"int32"), 0.0, None, None, )

W0205 22:11:03.576112 111373 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:11:03.576999 111373 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([219, 19611723],"int32"), 0.0, VarType(float32), None, )
[torch error] paddle.full_like(Tensor([219, 19611723],"int32"), 0.0, VarType(float32), None, ) 
 full_like(): argument 'dtype' must be torch.dtype, not paddle.base.libpaddle.VarType

W0205 22:15:54.175753 112837 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:15:54.176764 112837 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([219, 19611723],"int32"), 1.0, None, None, )
[Pass] paddle.full_like(Tensor([219, 19611723],"int32"), 1.0, None, None, )

W0205 22:17:18.445343 113152 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:17:18.446791 113152 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([219, 19611723],"int32"), 1e-10, None, None, )
[Pass] paddle.full_like(Tensor([219, 19611723],"int32"), 1e-10, None, None, )

W0205 22:22:16.546300 114646 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:22:16.547161 114646 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([219, 19611723],"int32"), 1e-100, None, None, )
[Pass] paddle.full_like(Tensor([219, 19611723],"int32"), 1e-100, None, None, )

W0205 22:27:03.022383 116065 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:27:03.023412 116065 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([286331153, 5, 3],"float32"), 0.0, )
[Pass] paddle.full_like(Tensor([286331153, 5, 3],"float32"), 0.0, )

W0205 22:32:01.808974 117495 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:32:01.809873 117495 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([286331153, 5, 3],"float32"), -1.1920928955078125e-07, )
[Pass] paddle.full_like(Tensor([286331153, 5, 3],"float32"), -1.1920928955078125e-07, )

W0205 22:35:45.294521 118524 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:35:45.295491 118524 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([286331153, 5, 3],"float32"), 3.4028234663852886e+38, )
[accuracy error] paddle.full_like(Tensor([286331153, 5, 3],"float32"), 3.4028234663852886e+38, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 3.4028235e+38
Max relative difference: 1.
 x: array([[[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],...
 y: array([[[3.402823e+38, 3.402823e+38, 3.402823e+38],
        [3.402823e+38, 3.402823e+38, 3.402823e+38],
        [3.402823e+38, 3.402823e+38, 3.402823e+38],...

W0205 22:39:38.116603 119512 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:39:38.117569 119512 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([286331153, 5, 3],"float32"), math.inf, )
[accuracy error] paddle.full_like(Tensor([286331153, 5, 3],"float32"), math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y +inf location mismatch:
 x: array([[[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],...
 y: array([[[inf, inf, inf],
        [inf, inf, inf],
        [inf, inf, inf],...

W0205 22:44:25.893509 120535 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:44:25.894695 120535 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([286331153, 5, 3],"float32"), -math.inf, )
[accuracy error] paddle.full_like(Tensor([286331153, 5, 3],"float32"), -math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y -inf location mismatch:
 x: array([[[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],...
 y: array([[[-inf, -inf, -inf],
        [-inf, -inf, -inf],
        [-inf, -inf, -inf],...

W0205 22:46:24.164079 120967 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:46:24.165153 120967 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([3, 1431655765],"float32"), 0.0, )
[Pass] paddle.full_like(Tensor([3, 1431655765],"float32"), 0.0, )

W0205 22:48:35.146663 121386 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:48:35.147568 121386 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([3, 1431655765],"float32"), 1.0, )
[accuracy error] paddle.full_like(Tensor([3, 1431655765],"float32"), 1.0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)
 y: array([[1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.]], dtype=float32)

W0205 22:52:15.182613 122135 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:52:15.183516 122135 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([3, 1431655765],"float32"), -1.0, )
[accuracy error] paddle.full_like(Tensor([3, 1431655765],"float32"), -1.0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)
 y: array([[-1., -1., -1., ..., -1., -1., -1.],
       [-1., -1., -1., ..., -1., -1., -1.],
       [-1., -1., -1., ..., -1., -1., -1.]], dtype=float32)

W0205 22:57:07.763406 123161 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:57:07.764544 123161 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([306783379, 7, 1],"float64"), fill_value=5, )
[accuracy error] paddle.full_like(Tensor([306783379, 7, 1],"float64"), fill_value=5, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483653 / 2147483653 (100%)
Max absolute difference: 5.
Max relative difference: 1.
 x: array([[[0.],
        [0.],
        [0.],...
 y: array([[[5.],
        [5.],
        [5.],...

W0205 23:01:38.229200 124215 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:01:38.230573 124215 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([33554433, 64],"float64"), 1.0, )
[accuracy error] paddle.full_like(Tensor([33554433, 64],"float64"), 1.0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483712 / 2147483712 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],...

W0205 23:05:34.864750 125038 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:05:34.865636 125038 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([33554433, 64],"float64"), 1e-20, )
[Pass] paddle.full_like(Tensor([33554433, 64],"float64"), 1e-20, )

W0205 23:09:25.207475 125789 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:09:25.208384 125789 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([3496, 300, 4096],"float32"), 1, )
[Pass] paddle.full_like(Tensor([3496, 300, 4096],"float32"), 1, )

W0205 23:12:42.903688 126423 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:12:42.904785 126423 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([357913942, 1, 6],"float64"), fill_value=6, )
[accuracy error] paddle.full_like(Tensor([357913942, 1, 6],"float64"), fill_value=6, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483652 / 2147483652 (100%)
Max absolute difference: 6.
Max relative difference: 1.
 x: array([[[0., 0., 0., 0., 0., 0.]],

       [[0., 0., 0., 0., 0., 0.]],...
 y: array([[[6., 6., 6., 6., 6., 6.]],

       [[6., 6., 6., 6., 6., 6.]],...

W0205 23:15:59.944902 127246 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:15:59.945780 127246 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([357913942, 12],"float32"), 0, )
[Pass] paddle.full_like(Tensor([357913942, 12],"float32"), 0, )

W0205 23:20:28.390643 128088 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:20:28.391435 128088 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([4, 1, 536870913],"float64"), fill_value=6, )
[accuracy error] paddle.full_like(Tensor([4, 1, 536870913],"float64"), fill_value=6, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483652 / 2147483652 (100%)
Max absolute difference: 6.
Max relative difference: 1.
 x: array([[[0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.]],...
 y: array([[[6., 6., 6., ..., 6., 6., 6.]],

       [[6., 6., 6., ..., 6., 6., 6.]],...

W0205 23:23:47.845273 128842 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:23:47.846343 128842 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([4, 1073741824],"float32"), fill_value=6, )
[accuracy error] paddle.full_like(Tensor([4, 1073741824],"float32"), fill_value=6, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 6.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)
 y: array([[6., 6., 6., ..., 6., 6., 6.],
       [6., 6., 6., ..., 6., 6., 6.],
       [6., 6., 6., ..., 6., 6., 6.],
       [6., 6., 6., ..., 6., 6., 6.]], dtype=float32)

W0205 23:28:08.948470 129679 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:28:08.949477 129679 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([4, 268435457, 2],"float64"), 0, )
[Pass] paddle.full_like(Tensor([4, 268435457, 2],"float64"), 0, )

W0205 23:32:55.036883 130831 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:32:55.038338 130831 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([4, 5, 107374183],"float64"), 0, )
[Pass] paddle.full_like(Tensor([4, 5, 107374183],"float64"), 0, )

W0205 23:35:49.220613 131381 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:35:49.221460 131381 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([4, 5, 214748365],"float32"), 0, )
[Pass] paddle.full_like(Tensor([4, 5, 214748365],"float32"), 0, )

W0205 23:39:06.881245 132000 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:39:06.882157 132000 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([4, 536870912, 2],"float32"), 0, )
[Pass] paddle.full_like(Tensor([4, 536870912, 2],"float32"), 0, )

W0205 23:43:09.775856 132742 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:43:09.776813 132742 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([4, 536870913, 1],"float64"), fill_value=5, )
[accuracy error] paddle.full_like(Tensor([4, 536870913, 1],"float64"), fill_value=5, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483652 / 2147483652 (100%)
Max absolute difference: 5.
Max relative difference: 1.
 x: array([[[0.],
        [0.],
        [0.],...
 y: array([[[5.],
        [5.],
        [5.],...

W0205 23:46:33.588508 133682 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:46:33.589406 133682 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([4, 536870913],"float64"), fill_value=41, )
[accuracy error] paddle.full_like(Tensor([4, 536870913],"float64"), fill_value=41, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483652 / 2147483652 (100%)
Max absolute difference: 41.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]])
 y: array([[41., 41., 41., ..., 41., 41., 41.],
       [41., 41., 41., ..., 41., 41., 41.],
       [41., 41., 41., ..., 41., 41., 41.],
       [41., 41., 41., ..., 41., 41., 41.]])

W0205 23:50:21.858105 134434 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:50:21.858961 134434 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([4, 536870913],"float64"), fill_value=6, )
[accuracy error] paddle.full_like(Tensor([4, 536870913],"float64"), fill_value=6, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483652 / 2147483652 (100%)
Max absolute difference: 6.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.]])
 y: array([[6., 6., 6., ..., 6., 6., 6.],
       [6., 6., 6., ..., 6., 6., 6.],
       [6., 6., 6., ..., 6., 6., 6.],
       [6., 6., 6., ..., 6., 6., 6.]])

W0205 23:54:16.206475 135243 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:54:16.207398 135243 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([4, 7, 76695845],"float64"), fill_value=5, )
[accuracy error] paddle.full_like(Tensor([4, 7, 76695845],"float64"), fill_value=5, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483660 / 2147483660 (100%)
Max absolute difference: 5.
Max relative difference: 1.
 x: array([[[0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[[5., 5., 5., ..., 5., 5., 5.],
        [5., 5., 5., ..., 5., 5., 5.],
        [5., 5., 5., ..., 5., 5., 5.],...

W0205 23:58:11.003268 136066 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:58:11.004146 136066 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([4, 89478486, 6],"float64"), fill_value=6, )
[accuracy error] paddle.full_like(Tensor([4, 89478486, 6],"float64"), fill_value=6, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483664 / 2147483664 (100%)
Max absolute difference: 6.
Max relative difference: 1.
 x: array([[[0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0.],...
 y: array([[[6., 6., 6., 6., 6., 6.],
        [6., 6., 6., 6., 6., 6.],
        [6., 6., 6., 6., 6., 6.],...

W0206 00:01:59.805918 136804 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:01:59.807430 136804 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([400, 5368710],"float64"), 0.0, )
[Pass] paddle.full_like(Tensor([400, 5368710],"float64"), 0.0, )

W0206 00:06:02.794759 137689 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:06:02.795825 137689 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([400, 5368710],"float64"), 1.7976931348623157e+308, )
[accuracy error] paddle.full_like(Tensor([400, 5368710],"float64"), 1.7976931348623157e+308, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147484000 / 2147484000 (100%)
Max absolute difference: 1.79769313e+308
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[1.797693e+308, 1.797693e+308, 1.797693e+308, ..., 1.797693e+308,
        1.797693e+308, 1.797693e+308],
       [1.797693e+308, 1.797693e+308, 1.797693e+308, ..., 1.797693e+308,...

W0206 00:09:14.801034 138296 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:09:14.802152 138296 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([400, 5368710],"float64"), -2.220446049250313e-16, )
[Pass] paddle.full_like(Tensor([400, 5368710],"float64"), -2.220446049250313e-16, )

W0206 00:13:00.275475 139137 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:13:00.276329 139137 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([400, 5368710],"float64"), math.inf, )
[accuracy error] paddle.full_like(Tensor([400, 5368710],"float64"), math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y +inf location mismatch:
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[inf, inf, inf, ..., inf, inf, inf],
       [inf, inf, inf, ..., inf, inf, inf],
       [inf, inf, inf, ..., inf, inf, inf],...

W0206 00:15:58.091270 139702 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:15:58.092171 139702 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([400, 5368710],"float64"), -math.inf, )
[accuracy error] paddle.full_like(Tensor([400, 5368710],"float64"), -math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y -inf location mismatch:
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[-inf, -inf, -inf, ..., -inf, -inf, -inf],
       [-inf, -inf, -inf, ..., -inf, -inf, -inf],
       [-inf, -inf, -inf, ..., -inf, -inf, -inf],...

W0206 00:17:36.985143 140120 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:17:36.986140 140120 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([4194304, 1024],"float32"), 0.3917133774091194, )
[accuracy error] paddle.full_like(Tensor([4194304, 1024],"float32"), 0.3917133774091194, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 0.39171338
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[0.391713, 0.391713, 0.391713, ..., 0.391713, 0.391713, 0.391713],
       [0.391713, 0.391713, 0.391713, ..., 0.391713, 0.391713, 0.391713],
       [0.391713, 0.391713, 0.391713, ..., 0.391713, 0.391713, 0.391713],...

W0206 00:19:41.669586 140483 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:19:41.670495 140483 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([4294967295, 1],"float32"), 0.5, )
[accuracy error] paddle.full_like(Tensor([4294967295, 1],"float32"), 0.5, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 0.5
Max relative difference: 1.
 x: array([[0.],
       [0.],
       [0.],...
 y: array([[0.5],
       [0.5],
       [0.5],...

W0206 00:24:35.360268 141493 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:24:35.361178 141493 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([4294967295, 1],"float32"), fill_value=2, )
[accuracy error] paddle.full_like(Tensor([4294967295, 1],"float32"), fill_value=2, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 2.
Max relative difference: 1.
 x: array([[0.],
       [0.],
       [0.],...
 y: array([[2.],
       [2.],
       [2.],...

W0206 00:29:55.302693 142580 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:29:55.304191 142580 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([4294967295, 1],"float32"), fill_value=6, )
[accuracy error] paddle.full_like(Tensor([4294967295, 1],"float32"), fill_value=6, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 6.
Max relative difference: 1.
 x: array([[0.],
       [0.],
       [0.],...
 y: array([[6.],
       [6.],
       [6.],...

W0206 00:35:18.042899 143538 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:35:18.043777 143538 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([4294967295],"float32"), 0.5, )
[accuracy error] paddle.full_like(Tensor([4294967295],"float32"), 0.5, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 0.5
Max relative difference: 1.
 x: array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)
 y: array([0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5], dtype=float32)

W0206 00:40:30.801430 144595 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:40:30.802507 144595 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([4294967295],"float32"), 1.0, )
[accuracy error] paddle.full_like(Tensor([4294967295],"float32"), 1.0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)
 y: array([1., 1., 1., ..., 1., 1., 1.], dtype=float32)

W0206 00:45:20.802173 145494 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:45:20.803064 145494 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([4294967295],"float32"), 1e-20, )
[Pass] paddle.full_like(Tensor([4294967295],"float32"), 1e-20, )

W0206 00:50:58.255929 146165 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:50:58.256832 146165 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([4294967295],"float32"), fill_value=0, )
[Pass] paddle.full_like(Tensor([4294967295],"float32"), fill_value=0, )

W0206 00:54:31.779770 146292 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:54:31.780602 146292 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([4294967295],"float32"), fill_value=2, )
[accuracy error] paddle.full_like(Tensor([4294967295],"float32"), fill_value=2, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 2.
Max relative difference: 1.
 x: array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)
 y: array([2., 2., 2., ..., 2., 2., 2.], dtype=float32)

W0206 00:58:11.051936 146403 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:58:11.053220 146403 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([4294967295],"float32"), fill_value=5, )
[accuracy error] paddle.full_like(Tensor([4294967295],"float32"), fill_value=5, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 5.
Max relative difference: 1.
 x: array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)
 y: array([5., 5., 5., ..., 5., 5., 5.], dtype=float32)

W0206 01:02:55.612830 146578 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:02:55.613763 146578 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([4294967295],"float32"), fill_value=7, )
[accuracy error] paddle.full_like(Tensor([4294967295],"float32"), fill_value=7, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967295 / 4294967295 (100%)
Max absolute difference: 7.
Max relative difference: 1.
 x: array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)
 y: array([7., 7., 7., ..., 7., 7., 7.], dtype=float32)

W0206 01:07:41.723577 146745 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:07:41.724603 146745 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([429496730, 5, 2],"float32"), 0, )
[Pass] paddle.full_like(Tensor([429496730, 5, 2],"float32"), 0, )

W0206 01:12:35.597092 146929 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:12:35.598021 146929 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([429497, 10000],"float32"), 0.0, )
[Pass] paddle.full_like(Tensor([429497, 10000],"float32"), 0.0, )

W0206 01:16:13.817518 147068 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:16:13.818608 147068 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([5, 1, 429496730],"float64"), fill_value=2, )
[accuracy error] paddle.full_like(Tensor([5, 1, 429496730],"float64"), fill_value=2, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483650 / 2147483650 (100%)
Max absolute difference: 2.
Max relative difference: 1.
 x: array([[[0., 0., 0., ..., 0., 0., 0.]],

       [[0., 0., 0., ..., 0., 0., 0.]],...
 y: array([[[2., 2., 2., ..., 2., 2., 2.]],

       [[2., 2., 2., ..., 2., 2., 2.]],...

W0206 01:19:31.135511 147194 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:19:31.136431 147194 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([5, 107374183, 4],"float64"), fill_value=2, )
[accuracy error] paddle.full_like(Tensor([5, 107374183, 4],"float64"), fill_value=2, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483660 / 2147483660 (100%)
Max absolute difference: 2.
Max relative difference: 1.
 x: array([[[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.],...
 y: array([[[2., 2., 2., 2.],
        [2., 2., 2., 2.],
        [2., 2., 2., 2.],...

W0206 01:23:20.300320 147335 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:23:20.301275 147335 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([5, 429496730],"float64"), 0.9999998807907104, )
[accuracy error] paddle.full_like(Tensor([5, 429496730],"float64"), 0.9999998807907104, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483650 / 2147483650 (100%)
Max absolute difference: 0.99999988
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],...

W0206 01:27:14.174228 147490 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:27:14.175230 147490 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([5, 429496730],"float64"), 1.1754943508222875e-38, )
[Pass] paddle.full_like(Tensor([5, 429496730],"float64"), 1.1754943508222875e-38, )

W0206 01:31:22.982240 147617 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:31:22.983520 147617 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([5, 429496730],"float64"), fill_value=11, )
[accuracy error] paddle.full_like(Tensor([5, 429496730],"float64"), fill_value=11, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483650 / 2147483650 (100%)
Max absolute difference: 11.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[11., 11., 11., ..., 11., 11., 11.],
       [11., 11., 11., ..., 11., 11., 11.],
       [11., 11., 11., ..., 11., 11., 11.],...

W0206 01:34:24.515959 147728 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:34:24.516813 147728 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([536870913, 1, 4],"float64"), fill_value=2, )
[accuracy error] paddle.full_like(Tensor([536870913, 1, 4],"float64"), fill_value=2, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483652 / 2147483652 (100%)
Max absolute difference: 2.
Max relative difference: 1.
 x: array([[[0., 0., 0., 0.]],

       [[0., 0., 0., 0.]],...
 y: array([[[2., 2., 2., 2.]],

       [[2., 2., 2., 2.]],...

W0206 01:38:41.061264 147868 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:38:41.062355 147868 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([67108864, 64],"float32"), 1.0, )
[accuracy error] paddle.full_like(Tensor([67108864, 64],"float32"), 1.0, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 1.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.],...

W0206 01:43:11.929558 147995 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:43:11.930816 147995 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([67108864, 64],"float32"), 1e-20, )
[Pass] paddle.full_like(Tensor([67108864, 64],"float32"), 1e-20, )

W0206 01:48:15.198910 148149 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:48:15.199923 148149 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([7, 306783379],"float64"), fill_value=23, )
[accuracy error] paddle.full_like(Tensor([7, 306783379],"float64"), fill_value=23, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483653 / 2147483653 (100%)
Max absolute difference: 23.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[23., 23., 23., ..., 23., 23., 23.],
       [23., 23., 23., ..., 23., 23., 23.],
       [23., 23., 23., ..., 23., 23., 23.],...

W0206 01:51:42.295280 148304 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:51:42.296061 148304 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([715827883, 3],"float64"), 0.5, )
[accuracy error] paddle.full_like(Tensor([715827883, 3],"float64"), 0.5, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483649 / 2147483649 (100%)
Max absolute difference: 0.5
Max relative difference: 1.
 x: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],...
 y: array([[0.5, 0.5, 0.5],
       [0.5, 0.5, 0.5],
       [0.5, 0.5, 0.5],...

W0206 01:55:49.520897 148444 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:55:49.522136 148444 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([715827883, 3],"float64"), 0.9999998807907104, )
[accuracy error] paddle.full_like(Tensor([715827883, 3],"float64"), 0.9999998807907104, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 2147483649 / 2147483649 (100%)
Max absolute difference: 0.99999988
Max relative difference: 1.
 x: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],...
 y: array([[1., 1., 1.],
       [1., 1., 1.],
       [1., 1., 1.],...

W0206 01:59:44.049921 148570 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:59:44.050982 148570 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([715827883, 3],"float64"), 1.1754943508222875e-38, )
[Pass] paddle.full_like(Tensor([715827883, 3],"float64"), 1.1754943508222875e-38, )

W0206 02:03:26.570112 148669 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:03:26.571151 148669 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([715827883, 3],"float64"), fill_value=math.inf, )
[accuracy error] paddle.full_like(Tensor([715827883, 3],"float64"), fill_value=math.inf, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y +inf location mismatch:
 x: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],...
 y: array([[inf, inf, inf],
       [inf, inf, inf],
       [inf, inf, inf],...

W0206 02:06:26.217417 148753 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:06:26.218362 148753 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([715827883, 3],"float64"), fill_value=nan, )
[accuracy error] paddle.full_like(Tensor([715827883, 3],"float64"), fill_value=nan, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

x and y nan location mismatch:
 x: array([[0., 0., 0.],
       [0., 0., 0.],
       [0., 0., 0.],...
 y: array([[nan, nan, nan],
       [nan, nan, nan],
       [nan, nan, nan],...

W0206 02:07:53.620752 148795 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:07:53.621665 148795 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([8388608, 512],"float16"), 127, )
[accuracy error] paddle.full_like(Tensor([8388608, 512],"float16"), 127, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 127.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[127., 127., 127., ..., 127., 127., 127.],
       [127., 127., 127., ..., 127., 127., 127.],
       [127., 127., 127., ..., 127., 127., 127.],...

W0206 02:09:49.198622 148838 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:09:49.199532 148838 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.full_like(Tensor([8388608, 512],"float16"), -127, )
[accuracy error] paddle.full_like(Tensor([8388608, 512],"float16"), -127, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 4294967296 / 4294967296 (100%)
Max absolute difference: 127.
Max relative difference: 1.
 x: array([[0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],
       [0., 0., 0., ..., 0., 0., 0.],...
 y: array([[-127., -127., -127., ..., -127., -127., -127.],
       [-127., -127., -127., ..., -127., -127., -127.],
       [-127., -127., -127., ..., -127., -127., -127.],...

W0206 02:23:13.946476 149174 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:23:13.947428 149174 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([107374183, 40],"float32"), y=Tensor([107374183, 40],"float32"), )
[paddle error] paddle.gammainc(Tensor([107374183, 40],"float32"), y=Tensor([107374183, 40],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 02:38:02.526361 149594 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:38:02.527276 149594 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([107374183, 40],"float32"), y=Tensor([3, 40],"float32"), )
[torch error] paddle.gammainc(Tensor([107374183, 40],"float32"), y=Tensor([3, 40],"float32"), ) 
 The size of tensor a (107374183) must match the size of tensor b (3) at non-singleton dimension 0

W0206 02:39:11.415650 149692 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:39:11.416884 149692 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([2, 107374183, 4, 5],"float32"), Tensor([2, 107374183, 4, 5],"float32"), )
[paddle error] paddle.gammainc(Tensor([2, 107374183, 4, 5],"float32"), Tensor([2, 107374183, 4, 5],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 02:41:44.084246 149748 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:41:44.085239 149748 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([2, 107374183, 4, 5],"float32"), Tensor([2, 3, 4, 5],"float32"), )
[torch error] paddle.gammainc(Tensor([2, 107374183, 4, 5],"float32"), Tensor([2, 3, 4, 5],"float32"), ) 
 The size of tensor a (107374183) must match the size of tensor b (3) at non-singleton dimension 1

W0206 02:42:54.948978 149845 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:42:54.950225 149845 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([2, 3, 143165577, 5],"float32"), Tensor([2, 3, 143165577, 5],"float32"), )
[paddle error] paddle.gammainc(Tensor([2, 3, 143165577, 5],"float32"), Tensor([2, 3, 143165577, 5],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 02:45:38.971391 149889 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:45:38.972482 149889 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([2, 3, 143165577, 5],"float32"), Tensor([2, 3, 4, 5],"float32"), )
[torch error] paddle.gammainc(Tensor([2, 3, 143165577, 5],"float32"), Tensor([2, 3, 4, 5],"float32"), ) 
 The size of tensor a (143165577) must match the size of tensor b (4) at non-singleton dimension 2

W0206 02:46:49.203174 149986 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:46:49.204388 149986 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([2, 3, 4, 178956971],"float32"), Tensor([2, 3, 4, 178956971],"float32"), )
[paddle error] paddle.gammainc(Tensor([2, 3, 4, 178956971],"float32"), Tensor([2, 3, 4, 178956971],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 02:49:17.018417 150041 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:49:17.019279 150041 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([2, 3, 4, 178956971],"float32"), Tensor([2, 3, 4, 5],"float32"), )
[torch error] paddle.gammainc(Tensor([2, 3, 4, 178956971],"float32"), Tensor([2, 3, 4, 5],"float32"), ) 
 The size of tensor a (178956971) must match the size of tensor b (5) at non-singleton dimension 3

W0206 02:50:26.842242 150112 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:50:26.843276 150112 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([2, 3, 4, 5],"float32"), Tensor([2, 107374183, 4, 5],"float32"), )
[torch error] paddle.gammainc(Tensor([2, 3, 4, 5],"float32"), Tensor([2, 107374183, 4, 5],"float32"), ) 
 The size of tensor a (3) must match the size of tensor b (107374183) at non-singleton dimension 1

W0206 02:51:42.543067 150154 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:51:42.544333 150154 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([2, 3, 4, 5],"float32"), Tensor([2, 3, 143165577, 5],"float32"), )
[torch error] paddle.gammainc(Tensor([2, 3, 4, 5],"float32"), Tensor([2, 3, 143165577, 5],"float32"), ) 
 The size of tensor a (4) must match the size of tensor b (143165577) at non-singleton dimension 2

W0206 02:53:00.227595 150197 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:53:00.228749 150197 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([2, 3, 4, 5],"float32"), Tensor([2, 3, 4, 178956971],"float32"), )
[torch error] paddle.gammainc(Tensor([2, 3, 4, 5],"float32"), Tensor([2, 3, 4, 178956971],"float32"), ) 
 The size of tensor a (5) must match the size of tensor b (178956971) at non-singleton dimension 3

W0206 02:54:18.426982 150251 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:54:18.428303 150251 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([2, 3, 4, 5],"float32"), Tensor([71582789, 3, 4, 5],"float32"), )
[torch error] paddle.gammainc(Tensor([2, 3, 4, 5],"float32"), Tensor([71582789, 3, 4, 5],"float32"), ) 
 The size of tensor a (2) must match the size of tensor b (71582789) at non-singleton dimension 0

W0206 02:55:32.621855 150309 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:55:32.623001 150309 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([2, 3, 4, 5],"float64"), Tensor([2, 3, 4, 89478486],"float64"), )
[torch error] paddle.gammainc(Tensor([2, 3, 4, 5],"float64"), Tensor([2, 3, 4, 89478486],"float64"), ) 
 The size of tensor a (5) must match the size of tensor b (89478486) at non-singleton dimension 3

W0206 02:56:26.104357 150351 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:56:26.105495 150351 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([2, 3, 4, 5],"float64"), Tensor([2, 3, 71582789, 5],"float64"), )
[torch error] paddle.gammainc(Tensor([2, 3, 4, 5],"float64"), Tensor([2, 3, 71582789, 5],"float64"), ) 
 The size of tensor a (4) must match the size of tensor b (71582789) at non-singleton dimension 2

W0206 02:57:18.895856 150406 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:57:18.897102 150406 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([2, 3, 4, 5],"float64"), Tensor([2, 53687092, 4, 5],"float64"), )
[torch error] paddle.gammainc(Tensor([2, 3, 4, 5],"float64"), Tensor([2, 53687092, 4, 5],"float64"), ) 
 The size of tensor a (3) must match the size of tensor b (53687092) at non-singleton dimension 1

W0206 02:58:11.812283 150448 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:58:11.813431 150448 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([2, 3, 4, 5],"float64"), Tensor([35791395, 3, 4, 5],"float64"), )
[torch error] paddle.gammainc(Tensor([2, 3, 4, 5],"float64"), Tensor([35791395, 3, 4, 5],"float64"), ) 
 The size of tensor a (2) must match the size of tensor b (35791395) at non-singleton dimension 0

W0206 02:59:04.220283 150464 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:59:04.221719 150464 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([2, 3, 4, 89478486],"float64"), Tensor([2, 3, 4, 5],"float64"), )
[torch error] paddle.gammainc(Tensor([2, 3, 4, 89478486],"float64"), Tensor([2, 3, 4, 5],"float64"), ) 
 The size of tensor a (89478486) must match the size of tensor b (5) at non-singleton dimension 3

W0206 03:00:00.622292 150505 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:00:00.623273 150505 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([2, 3, 4, 89478486],"float64"), Tensor([2, 3, 4, 89478486],"float64"), )
[paddle error] paddle.gammainc(Tensor([2, 3, 4, 89478486],"float64"), Tensor([2, 3, 4, 89478486],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 03:02:01.142669 150548 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:02:01.145170 150548 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([2, 3, 71582789, 5],"float64"), Tensor([2, 3, 4, 5],"float64"), )
[torch error] paddle.gammainc(Tensor([2, 3, 71582789, 5],"float64"), Tensor([2, 3, 4, 5],"float64"), ) 
 The size of tensor a (71582789) must match the size of tensor b (4) at non-singleton dimension 2

W0206 03:02:51.334156 150604 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:02:51.335233 150604 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([2, 3, 71582789, 5],"float64"), Tensor([2, 3, 71582789, 5],"float64"), )
[paddle error] paddle.gammainc(Tensor([2, 3, 71582789, 5],"float64"), Tensor([2, 3, 71582789, 5],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 03:04:34.514196 150646 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:04:34.515259 150646 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([2, 53687092, 4, 5],"float64"), Tensor([2, 3, 4, 5],"float64"), )
[torch error] paddle.gammainc(Tensor([2, 53687092, 4, 5],"float64"), Tensor([2, 3, 4, 5],"float64"), ) 
 The size of tensor a (53687092) must match the size of tensor b (3) at non-singleton dimension 1

W0206 03:05:27.612418 150688 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:05:27.613554 150688 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([2, 53687092, 4, 5],"float64"), Tensor([2, 53687092, 4, 5],"float64"), )
[paddle error] paddle.gammainc(Tensor([2, 53687092, 4, 5],"float64"), Tensor([2, 53687092, 4, 5],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 03:07:23.133396 150729 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:07:23.135792 150729 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([3, 1431655765],"float32"), y=Tensor([3, 1431655765],"float32"), )
[paddle error] paddle.gammainc(Tensor([3, 1431655765],"float32"), y=Tensor([3, 1431655765],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 03:09:53.781446 150771 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:09:53.782521 150771 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([3, 1431655765],"float32"), y=Tensor([3, 40],"float32"), )
[torch error] paddle.gammainc(Tensor([3, 1431655765],"float32"), y=Tensor([3, 40],"float32"), ) 
 The size of tensor a (1431655765) must match the size of tensor b (40) at non-singleton dimension 1

W0206 03:11:12.362438 150842 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:11:12.363476 150842 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([3, 40],"float32"), y=Tensor([107374183, 40],"float32"), )
[torch error] paddle.gammainc(Tensor([3, 40],"float32"), y=Tensor([107374183, 40],"float32"), ) 
 The size of tensor a (3) must match the size of tensor b (107374183) at non-singleton dimension 0

W0206 03:12:25.392395 150897 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:12:25.393653 150897 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([3, 40],"float32"), y=Tensor([3, 1431655765],"float32"), )
[torch error] paddle.gammainc(Tensor([3, 40],"float32"), y=Tensor([3, 1431655765],"float32"), ) 
 The size of tensor a (40) must match the size of tensor b (1431655765) at non-singleton dimension 1

W0206 03:13:35.671423 150927 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:13:35.672524 150927 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([35791395, 3, 4, 5],"float64"), Tensor([2, 3, 4, 5],"float64"), )
[torch error] paddle.gammainc(Tensor([35791395, 3, 4, 5],"float64"), Tensor([2, 3, 4, 5],"float64"), ) 
 The size of tensor a (35791395) must match the size of tensor b (2) at non-singleton dimension 0

W0206 03:14:30.826916 150968 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:14:30.827916 150968 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([35791395, 3, 4, 5],"float64"), Tensor([35791395, 3, 4, 5],"float64"), )
[paddle error] paddle.gammainc(Tensor([35791395, 3, 4, 5],"float64"), Tensor([35791395, 3, 4, 5],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 03:16:29.236938 151010 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:16:29.239754 151010 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([71582789, 3, 4, 5],"float32"), Tensor([2, 3, 4, 5],"float32"), )
[torch error] paddle.gammainc(Tensor([71582789, 3, 4, 5],"float32"), Tensor([2, 3, 4, 5],"float32"), ) 
 The size of tensor a (71582789) must match the size of tensor b (2) at non-singleton dimension 0

W0206 03:17:38.569054 151080 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:17:38.570295 151080 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammainc(Tensor([71582789, 3, 4, 5],"float32"), Tensor([71582789, 3, 4, 5],"float32"), )
[paddle error] paddle.gammainc(Tensor([71582789, 3, 4, 5],"float32"), Tensor([71582789, 3, 4, 5],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 03:20:11.740478 151123 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:20:11.742861 151123 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([107374183, 40],"float32"), Tensor([107374183, 40],"float32"), )
[paddle error] paddle.gammaincc(Tensor([107374183, 40],"float32"), Tensor([107374183, 40],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 03:22:41.212245 151219 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:22:41.214751 151219 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([107374183, 40],"float32"), Tensor([3, 40],"float32"), )
[torch error] paddle.gammaincc(Tensor([107374183, 40],"float32"), Tensor([3, 40],"float32"), ) 
 The size of tensor a (107374183) must match the size of tensor b (3) at non-singleton dimension 0

W0206 03:23:58.949076 151277 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:23:58.950066 151277 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([107374183, 40],"float32"), y=Tensor([107374183, 40],"float32"), )
[paddle error] paddle.gammaincc(Tensor([107374183, 40],"float32"), y=Tensor([107374183, 40],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 03:26:26.976308 151333 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:26:26.978459 151333 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([107374183, 40],"float32"), y=Tensor([3, 40],"float32"), )
[torch error] paddle.gammaincc(Tensor([107374183, 40],"float32"), y=Tensor([3, 40],"float32"), ) 
 The size of tensor a (107374183) must match the size of tensor b (3) at non-singleton dimension 0

W0206 03:27:36.371903 151431 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:27:36.373190 151431 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([2, 107374183, 4, 5],"float32"), Tensor([2, 107374183, 4, 5],"float32"), )
[paddle error] paddle.gammaincc(Tensor([2, 107374183, 4, 5],"float32"), Tensor([2, 107374183, 4, 5],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 03:30:07.147387 151473 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:30:07.148370 151473 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([2, 107374183, 4, 5],"float32"), Tensor([2, 3, 4, 5],"float32"), )
[torch error] paddle.gammaincc(Tensor([2, 107374183, 4, 5],"float32"), Tensor([2, 3, 4, 5],"float32"), ) 
 The size of tensor a (107374183) must match the size of tensor b (3) at non-singleton dimension 1

W0206 03:31:15.438714 151557 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:31:15.439990 151557 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([2, 3, 143165577, 5],"float32"), Tensor([2, 3, 143165577, 5],"float32"), )
[paddle error] paddle.gammaincc(Tensor([2, 3, 143165577, 5],"float32"), Tensor([2, 3, 143165577, 5],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 03:33:51.539150 151598 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:33:51.541735 151598 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([2, 3, 143165577, 5],"float32"), Tensor([2, 3, 4, 5],"float32"), )
[torch error] paddle.gammaincc(Tensor([2, 3, 143165577, 5],"float32"), Tensor([2, 3, 4, 5],"float32"), ) 
 The size of tensor a (143165577) must match the size of tensor b (4) at non-singleton dimension 2

W0206 03:35:10.222102 151668 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:35:10.223744 151668 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([2, 3, 4, 178956971],"float32"), Tensor([2, 3, 4, 178956971],"float32"), )
[paddle error] paddle.gammaincc(Tensor([2, 3, 4, 178956971],"float32"), Tensor([2, 3, 4, 178956971],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 03:37:39.077221 151710 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:37:39.078284 151710 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([2, 3, 4, 178956971],"float32"), Tensor([2, 3, 4, 5],"float32"), )
[torch error] paddle.gammaincc(Tensor([2, 3, 4, 178956971],"float32"), Tensor([2, 3, 4, 5],"float32"), ) 
 The size of tensor a (178956971) must match the size of tensor b (5) at non-singleton dimension 3

W0206 03:38:47.256968 151767 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:38:47.258143 151767 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([2, 3, 4, 5],"float32"), Tensor([2, 107374183, 4, 5],"float32"), )
[torch error] paddle.gammaincc(Tensor([2, 3, 4, 5],"float32"), Tensor([2, 107374183, 4, 5],"float32"), ) 
 The size of tensor a (3) must match the size of tensor b (107374183) at non-singleton dimension 1

W0206 03:39:58.514614 151808 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:39:58.515723 151808 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([2, 3, 4, 5],"float32"), Tensor([2, 3, 143165577, 5],"float32"), )
[torch error] paddle.gammaincc(Tensor([2, 3, 4, 5],"float32"), Tensor([2, 3, 143165577, 5],"float32"), ) 
 The size of tensor a (4) must match the size of tensor b (143165577) at non-singleton dimension 2

W0206 03:41:31.438658 151838 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:41:31.439913 151838 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([2, 3, 4, 5],"float32"), Tensor([2, 3, 4, 178956971],"float32"), )
[torch error] paddle.gammaincc(Tensor([2, 3, 4, 5],"float32"), Tensor([2, 3, 4, 178956971],"float32"), ) 
 The size of tensor a (5) must match the size of tensor b (178956971) at non-singleton dimension 3

W0206 03:42:42.272171 151866 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:42:42.273407 151866 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([2, 3, 4, 5],"float32"), Tensor([71582789, 3, 4, 5],"float32"), )
[torch error] paddle.gammaincc(Tensor([2, 3, 4, 5],"float32"), Tensor([71582789, 3, 4, 5],"float32"), ) 
 The size of tensor a (2) must match the size of tensor b (71582789) at non-singleton dimension 0

W0206 03:44:01.384744 151907 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:44:01.386008 151907 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([2, 3, 4, 5],"float64"), Tensor([2, 3, 4, 89478486],"float64"), )
[torch error] paddle.gammaincc(Tensor([2, 3, 4, 5],"float64"), Tensor([2, 3, 4, 89478486],"float64"), ) 
 The size of tensor a (5) must match the size of tensor b (89478486) at non-singleton dimension 3

W0206 03:44:50.029987 151949 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:44:50.031213 151949 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([2, 3, 4, 5],"float64"), Tensor([2, 3, 71582789, 5],"float64"), )
[torch error] paddle.gammaincc(Tensor([2, 3, 4, 5],"float64"), Tensor([2, 3, 71582789, 5],"float64"), ) 
 The size of tensor a (4) must match the size of tensor b (71582789) at non-singleton dimension 2

W0206 03:45:42.137084 151978 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:45:42.138137 151978 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([2, 3, 4, 5],"float64"), Tensor([2, 53687092, 4, 5],"float64"), )
[torch error] paddle.gammaincc(Tensor([2, 3, 4, 5],"float64"), Tensor([2, 53687092, 4, 5],"float64"), ) 
 The size of tensor a (3) must match the size of tensor b (53687092) at non-singleton dimension 1

W0206 03:46:29.800768 152006 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:46:29.801868 152006 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([2, 3, 4, 5],"float64"), Tensor([35791395, 3, 4, 5],"float64"), )
[torch error] paddle.gammaincc(Tensor([2, 3, 4, 5],"float64"), Tensor([35791395, 3, 4, 5],"float64"), ) 
 The size of tensor a (2) must match the size of tensor b (35791395) at non-singleton dimension 0

W0206 03:47:19.361814 152048 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:47:19.362890 152048 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([2, 3, 4, 89478486],"float64"), Tensor([2, 3, 4, 5],"float64"), )
[torch error] paddle.gammaincc(Tensor([2, 3, 4, 89478486],"float64"), Tensor([2, 3, 4, 5],"float64"), ) 
 The size of tensor a (89478486) must match the size of tensor b (5) at non-singleton dimension 3

W0206 03:48:11.440755 152076 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:48:11.441933 152076 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([2, 3, 4, 89478486],"float64"), Tensor([2, 3, 4, 89478486],"float64"), )
[paddle error] paddle.gammaincc(Tensor([2, 3, 4, 89478486],"float64"), Tensor([2, 3, 4, 89478486],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 03:50:18.145277 152105 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:50:18.146116 152105 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([2, 3, 71582789, 5],"float64"), Tensor([2, 3, 4, 5],"float64"), )
[torch error] paddle.gammaincc(Tensor([2, 3, 71582789, 5],"float64"), Tensor([2, 3, 4, 5],"float64"), ) 
 The size of tensor a (71582789) must match the size of tensor b (4) at non-singleton dimension 2

W0206 03:51:04.196404 152187 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:51:04.197664 152187 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([2, 3, 71582789, 5],"float64"), Tensor([2, 3, 71582789, 5],"float64"), )
[paddle error] paddle.gammaincc(Tensor([2, 3, 71582789, 5],"float64"), Tensor([2, 3, 71582789, 5],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 03:52:49.386451 152215 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:52:49.387338 152215 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([2, 53687092, 4, 5],"float64"), Tensor([2, 3, 4, 5],"float64"), )
[torch error] paddle.gammaincc(Tensor([2, 53687092, 4, 5],"float64"), Tensor([2, 3, 4, 5],"float64"), ) 
 The size of tensor a (53687092) must match the size of tensor b (3) at non-singleton dimension 1

W0206 03:53:36.267700 152286 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:53:36.268887 152286 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([2, 53687092, 4, 5],"float64"), Tensor([2, 53687092, 4, 5],"float64"), )
[paddle error] paddle.gammaincc(Tensor([2, 53687092, 4, 5],"float64"), Tensor([2, 53687092, 4, 5],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 03:55:26.490768 152327 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:55:26.491768 152327 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([3, 1431655765],"float32"), Tensor([3, 1431655765],"float32"), )
[paddle error] paddle.gammaincc(Tensor([3, 1431655765],"float32"), Tensor([3, 1431655765],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 03:58:02.694429 152412 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:58:02.695319 152412 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([3, 1431655765],"float32"), Tensor([3, 40],"float32"), )
[torch error] paddle.gammaincc(Tensor([3, 1431655765],"float32"), Tensor([3, 40],"float32"), ) 
 The size of tensor a (1431655765) must match the size of tensor b (40) at non-singleton dimension 1

W0206 03:59:19.667686 152482 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:59:19.668784 152482 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([3, 1431655765],"float32"), y=Tensor([3, 1431655765],"float32"), )
[paddle error] paddle.gammaincc(Tensor([3, 1431655765],"float32"), y=Tensor([3, 1431655765],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 04:01:56.517812 152515 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:01:56.518723 152515 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([3, 1431655765],"float32"), y=Tensor([3, 40],"float32"), )
[torch error] paddle.gammaincc(Tensor([3, 1431655765],"float32"), y=Tensor([3, 40],"float32"), ) 
 The size of tensor a (1431655765) must match the size of tensor b (40) at non-singleton dimension 1

W0206 04:03:05.754011 152580 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:03:05.755124 152580 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([3, 40],"float32"), Tensor([107374183, 40],"float32"), )
[torch error] paddle.gammaincc(Tensor([3, 40],"float32"), Tensor([107374183, 40],"float32"), ) 
 The size of tensor a (3) must match the size of tensor b (107374183) at non-singleton dimension 0

W0206 04:04:18.973230 152636 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:04:18.974292 152636 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([3, 40],"float32"), Tensor([3, 1431655765],"float32"), )
[torch error] paddle.gammaincc(Tensor([3, 40],"float32"), Tensor([3, 1431655765],"float32"), ) 
 The size of tensor a (40) must match the size of tensor b (1431655765) at non-singleton dimension 1

W0206 04:05:29.895676 152678 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:05:29.896718 152678 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([3, 40],"float32"), y=Tensor([107374183, 40],"float32"), )
[torch error] paddle.gammaincc(Tensor([3, 40],"float32"), y=Tensor([107374183, 40],"float32"), ) 
 The size of tensor a (3) must match the size of tensor b (107374183) at non-singleton dimension 0

W0206 04:06:39.069975 152720 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:06:39.071098 152720 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([3, 40],"float32"), y=Tensor([3, 1431655765],"float32"), )
[torch error] paddle.gammaincc(Tensor([3, 40],"float32"), y=Tensor([3, 1431655765],"float32"), ) 
 The size of tensor a (40) must match the size of tensor b (1431655765) at non-singleton dimension 1

W0206 04:08:02.357861 152762 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:08:02.358970 152762 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([35791395, 3, 4, 5],"float64"), Tensor([2, 3, 4, 5],"float64"), )
[torch error] paddle.gammaincc(Tensor([35791395, 3, 4, 5],"float64"), Tensor([2, 3, 4, 5],"float64"), ) 
 The size of tensor a (35791395) must match the size of tensor b (2) at non-singleton dimension 0

W0206 04:08:55.916765 152804 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:08:55.917846 152804 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([35791395, 3, 4, 5],"float64"), Tensor([35791395, 3, 4, 5],"float64"), )
[paddle error] paddle.gammaincc(Tensor([35791395, 3, 4, 5],"float64"), Tensor([35791395, 3, 4, 5],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 04:11:06.315791 152846 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:11:06.316810 152846 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([71582789, 3, 4, 5],"float32"), Tensor([2, 3, 4, 5],"float32"), )
[torch error] paddle.gammaincc(Tensor([71582789, 3, 4, 5],"float32"), Tensor([2, 3, 4, 5],"float32"), ) 
 The size of tensor a (71582789) must match the size of tensor b (2) at non-singleton dimension 0

W0206 04:12:15.989109 152888 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:12:15.990227 152888 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.gammaincc(Tensor([71582789, 3, 4, 5],"float32"), Tensor([71582789, 3, 4, 5],"float32"), )
[paddle error] paddle.gammaincc(Tensor([71582789, 3, 4, 5],"float32"), Tensor([71582789, 3, 4, 5],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 04:15:00.255587 152930 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:15:00.256479 152930 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.isin(Tensor([268435457, 8],"float64"), Tensor([2, 3],"float64"), False, False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738786559 (unix time) try "date -d @1738786559" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x255d2) received by PID 153042 (TID 0x7f4875dc1740) from PID 153042 ***]


W0206 04:15:58.705044 153042 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:15:58.706002 153042 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.isin(Tensor([268435457, 8],"float64"), Tensor([2, 3],"float64"), False, True, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738786648 (unix time) try "date -d @1738786648" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2560f) received by PID 153103 (TID 0x7f8648d64740) from PID 153103 ***]


W0206 04:17:28.200455 153103 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:17:28.201437 153103 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.isin(Tensor([268435457, 8],"int64"), Tensor([2, 3],"int64"), False, False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738786737 (unix time) try "date -d @1738786737" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x25650) received by PID 153168 (TID 0x7fd8482e5740) from PID 153168 ***]


W0206 04:18:57.396339 153168 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:18:57.397377 153168 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.isin(Tensor([268435457, 8],"int64"), Tensor([2, 3],"int64"), False, True, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738786809 (unix time) try "date -d @1738786809" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2567a) received by PID 153210 (TID 0x7feaac1db740) from PID 153210 ***]


W0206 04:20:08.607446 153210 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:20:08.608318 153210 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.isin(Tensor([4, 1073741824],"float16"), Tensor([2, 3],"float16"), False, False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_any(_object*, _object*, _object*)
1   any_ad_func(paddle::Tensor const&, std::vector<long, std::allocator<long> >, bool)
2   paddle::experimental::any(paddle::Tensor const&, std::vector<long, std::allocator<long> > const&, bool)
3   void phi::AnyKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<long, std::allocator<long> > const&, bool, phi::DenseTensor*)
4   void phi::AnyRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<long, std::allocator<long> > const&, bool, bool, phi::DenseTensor*)
5   void phi::Reduce<bool, phi::kps::LogicalOrFunctor, phi::kps::IdentityFunctor, false>(phi::GPUContext const&, phi::DenseTensor const&, bool, std::vector<long, std::allocator<long> > const&, bool, phi::DataType, phi::DenseTensor*)
6   void phi::funcs::ReduceKernel<bool, bool, phi::kps::LogicalOrFunctor, phi::kps::IdentityFunctor<bool, bool>, false>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*, phi::kps::IdentityFunctor<bool, bool> const&, std::vector<int, std::allocator<int> > const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738786913 (unix time) try "date -d @1738786913" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fe96f81ba1c) received by PID 153264 (TID 0x7fea69722740) from PID 1870772764 ***]


W0206 04:21:53.476115 153264 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:21:53.477072 153264 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.isin(Tensor([4, 1073741824],"float16"), Tensor([2, 3],"float16"), False, True, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_any(_object*, _object*, _object*)
1   any_ad_func(paddle::Tensor const&, std::vector<long, std::allocator<long> >, bool)
2   paddle::experimental::any(paddle::Tensor const&, std::vector<long, std::allocator<long> > const&, bool)
3   void phi::AnyKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<long, std::allocator<long> > const&, bool, phi::DenseTensor*)
4   void phi::AnyRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<long, std::allocator<long> > const&, bool, bool, phi::DenseTensor*)
5   void phi::Reduce<bool, phi::kps::LogicalOrFunctor, phi::kps::IdentityFunctor, false>(phi::GPUContext const&, phi::DenseTensor const&, bool, std::vector<long, std::allocator<long> > const&, bool, phi::DataType, phi::DenseTensor*)
6   void phi::funcs::ReduceKernel<bool, bool, phi::kps::LogicalOrFunctor, phi::kps::IdentityFunctor<bool, bool>, false>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*, phi::kps::IdentityFunctor<bool, bool> const&, std::vector<int, std::allocator<int> > const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738787036 (unix time) try "date -d @1738787036" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f4b647aba1c) received by PID 153335 (TID 0x7f4c5e6b2740) from PID 1685764636 ***]


W0206 04:23:56.287403 153335 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:23:56.288224 153335 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.isin(Tensor([4, 1073741824],"float32"), Tensor([2, 3],"float32"), False, False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_any(_object*, _object*, _object*)
1   any_ad_func(paddle::Tensor const&, std::vector<long, std::allocator<long> >, bool)
2   paddle::experimental::any(paddle::Tensor const&, std::vector<long, std::allocator<long> > const&, bool)
3   void phi::AnyKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<long, std::allocator<long> > const&, bool, phi::DenseTensor*)
4   void phi::AnyRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<long, std::allocator<long> > const&, bool, bool, phi::DenseTensor*)
5   void phi::Reduce<bool, phi::kps::LogicalOrFunctor, phi::kps::IdentityFunctor, false>(phi::GPUContext const&, phi::DenseTensor const&, bool, std::vector<long, std::allocator<long> > const&, bool, phi::DataType, phi::DenseTensor*)
6   void phi::funcs::ReduceKernel<bool, bool, phi::kps::LogicalOrFunctor, phi::kps::IdentityFunctor<bool, bool>, false>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*, phi::kps::IdentityFunctor<bool, bool> const&, std::vector<int, std::allocator<int> > const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738787150 (unix time) try "date -d @1738787150" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f08164d1a1c) received by PID 153405 (TID 0x7f09103d8740) from PID 374151708 ***]


W0206 04:25:50.938763 153405 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:25:50.939618 153405 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.isin(Tensor([4, 1073741824],"float32"), Tensor([2, 3],"float32"), False, True, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_any(_object*, _object*, _object*)
1   any_ad_func(paddle::Tensor const&, std::vector<long, std::allocator<long> >, bool)
2   paddle::experimental::any(paddle::Tensor const&, std::vector<long, std::allocator<long> > const&, bool)
3   void phi::AnyKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<long, std::allocator<long> > const&, bool, phi::DenseTensor*)
4   void phi::AnyRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<long, std::allocator<long> > const&, bool, bool, phi::DenseTensor*)
5   void phi::Reduce<bool, phi::kps::LogicalOrFunctor, phi::kps::IdentityFunctor, false>(phi::GPUContext const&, phi::DenseTensor const&, bool, std::vector<long, std::allocator<long> > const&, bool, phi::DataType, phi::DenseTensor*)
6   void phi::funcs::ReduceKernel<bool, bool, phi::kps::LogicalOrFunctor, phi::kps::IdentityFunctor<bool, bool>, false>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*, phi::kps::IdentityFunctor<bool, bool> const&, std::vector<int, std::allocator<int> > const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738787276 (unix time) try "date -d @1738787276" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f4779da0a1c) received by PID 153476 (TID 0x7f4873ca7740) from PID 2044332572 ***]


W0206 04:27:56.360831 153476 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:27:56.361686 153476 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.isin(Tensor([4, 1073741824],"int32"), Tensor([2, 3],"int32"), False, False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_any(_object*, _object*, _object*)
1   any_ad_func(paddle::Tensor const&, std::vector<long, std::allocator<long> >, bool)
2   paddle::experimental::any(paddle::Tensor const&, std::vector<long, std::allocator<long> > const&, bool)
3   void phi::AnyKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<long, std::allocator<long> > const&, bool, phi::DenseTensor*)
4   void phi::AnyRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<long, std::allocator<long> > const&, bool, bool, phi::DenseTensor*)
5   void phi::Reduce<bool, phi::kps::LogicalOrFunctor, phi::kps::IdentityFunctor, false>(phi::GPUContext const&, phi::DenseTensor const&, bool, std::vector<long, std::allocator<long> > const&, bool, phi::DataType, phi::DenseTensor*)
6   void phi::funcs::ReduceKernel<bool, bool, phi::kps::LogicalOrFunctor, phi::kps::IdentityFunctor<bool, bool>, false>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*, phi::kps::IdentityFunctor<bool, bool> const&, std::vector<int, std::allocator<int> > const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738787386 (unix time) try "date -d @1738787386" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f2106bf1a1c) received by PID 153532 (TID 0x7f2200af8740) from PID 113187356 ***]


W0206 04:29:46.548135 153532 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:29:46.549072 153532 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.isin(Tensor([4, 1073741824],"int32"), Tensor([2, 3],"int32"), False, True, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_any(_object*, _object*, _object*)
1   any_ad_func(paddle::Tensor const&, std::vector<long, std::allocator<long> >, bool)
2   paddle::experimental::any(paddle::Tensor const&, std::vector<long, std::allocator<long> > const&, bool)
3   void phi::AnyKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<long, std::allocator<long> > const&, bool, phi::DenseTensor*)
4   void phi::AnyRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<long, std::allocator<long> > const&, bool, bool, phi::DenseTensor*)
5   void phi::Reduce<bool, phi::kps::LogicalOrFunctor, phi::kps::IdentityFunctor, false>(phi::GPUContext const&, phi::DenseTensor const&, bool, std::vector<long, std::allocator<long> > const&, bool, phi::DataType, phi::DenseTensor*)
6   void phi::funcs::ReduceKernel<bool, bool, phi::kps::LogicalOrFunctor, phi::kps::IdentityFunctor<bool, bool>, false>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*, phi::kps::IdentityFunctor<bool, bool> const&, std::vector<int, std::allocator<int> > const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738787484 (unix time) try "date -d @1738787484" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f57039d0a1c) received by PID 153574 (TID 0x7f57fd8d7740) from PID 60623388 ***]


W0206 04:31:24.604055 153574 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:31:24.605085 153574 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.isin(Tensor([4, 536870913],"float64"), Tensor([2, 3],"float64"), False, False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738787558 (unix time) try "date -d @1738787558" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2582c) received by PID 153644 (TID 0x7f7788fe3740) from PID 153644 ***]


W0206 04:32:37.456104 153644 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:32:37.457034 153644 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.isin(Tensor([4, 536870913],"float64"), Tensor([2, 3],"float64"), False, True, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738787658 (unix time) try "date -d @1738787658" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x25856) received by PID 153686 (TID 0x7f7029951740) from PID 153686 ***]


W0206 04:34:17.719821 153686 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:34:17.720815 153686 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.isin(Tensor([4, 536870913],"int64"), Tensor([2, 3],"int64"), False, False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738787750 (unix time) try "date -d @1738787750" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x25880) received by PID 153728 (TID 0x7f0f4ce51740) from PID 153728 ***]


W0206 04:35:50.193934 153728 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:35:50.194810 153728 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.isin(Tensor([4, 536870913],"int64"), Tensor([2, 3],"int64"), False, True, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738787826 (unix time) try "date -d @1738787826" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x258aa) received by PID 153770 (TID 0x7fe4328a7740) from PID 153770 ***]


W0206 04:37:06.157900 153770 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:37:06.158748 153770 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.isin(Tensor([536870912, 8],"float16"), Tensor([2, 3],"float16"), False, False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_any(_object*, _object*, _object*)
1   any_ad_func(paddle::Tensor const&, std::vector<long, std::allocator<long> >, bool)
2   paddle::experimental::any(paddle::Tensor const&, std::vector<long, std::allocator<long> > const&, bool)
3   void phi::AnyKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<long, std::allocator<long> > const&, bool, phi::DenseTensor*)
4   void phi::AnyRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<long, std::allocator<long> > const&, bool, bool, phi::DenseTensor*)
5   void phi::Reduce<bool, phi::kps::LogicalOrFunctor, phi::kps::IdentityFunctor, false>(phi::GPUContext const&, phi::DenseTensor const&, bool, std::vector<long, std::allocator<long> > const&, bool, phi::DataType, phi::DenseTensor*)
6   void phi::funcs::ReduceKernel<bool, bool, phi::kps::LogicalOrFunctor, phi::kps::IdentityFunctor<bool, bool>, false>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*, phi::kps::IdentityFunctor<bool, bool> const&, std::vector<int, std::allocator<int> > const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738787935 (unix time) try "date -d @1738787935" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f2f99d3ca1c) received by PID 153812 (TID 0x7f3093c43740) from PID 18446744071995378204 ***]


W0206 04:38:55.163777 153812 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:38:55.164599 153812 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.isin(Tensor([536870912, 8],"float16"), Tensor([2, 3],"float16"), False, True, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_any(_object*, _object*, _object*)
1   any_ad_func(paddle::Tensor const&, std::vector<long, std::allocator<long> >, bool)
2   paddle::experimental::any(paddle::Tensor const&, std::vector<long, std::allocator<long> > const&, bool)
3   void phi::AnyKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<long, std::allocator<long> > const&, bool, phi::DenseTensor*)
4   void phi::AnyRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<long, std::allocator<long> > const&, bool, bool, phi::DenseTensor*)
5   void phi::Reduce<bool, phi::kps::LogicalOrFunctor, phi::kps::IdentityFunctor, false>(phi::GPUContext const&, phi::DenseTensor const&, bool, std::vector<long, std::allocator<long> > const&, bool, phi::DataType, phi::DenseTensor*)
6   void phi::funcs::ReduceKernel<bool, bool, phi::kps::LogicalOrFunctor, phi::kps::IdentityFunctor<bool, bool>, false>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*, phi::kps::IdentityFunctor<bool, bool> const&, std::vector<int, std::allocator<int> > const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738788058 (unix time) try "date -d @1738788058" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7ff1afb42a1c) received by PID 153868 (TID 0x7ff2a9a49740) from PID 18446744072362404380 ***]


W0206 04:40:58.392164 153868 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:40:58.393046 153868 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.isin(Tensor([536870912, 8],"float32"), Tensor([2, 3],"float32"), False, False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_any(_object*, _object*, _object*)
1   any_ad_func(paddle::Tensor const&, std::vector<long, std::allocator<long> >, bool)
2   paddle::experimental::any(paddle::Tensor const&, std::vector<long, std::allocator<long> > const&, bool)
3   void phi::AnyKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<long, std::allocator<long> > const&, bool, phi::DenseTensor*)
4   void phi::AnyRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<long, std::allocator<long> > const&, bool, bool, phi::DenseTensor*)
5   void phi::Reduce<bool, phi::kps::LogicalOrFunctor, phi::kps::IdentityFunctor, false>(phi::GPUContext const&, phi::DenseTensor const&, bool, std::vector<long, std::allocator<long> > const&, bool, phi::DataType, phi::DenseTensor*)
6   void phi::funcs::ReduceKernel<bool, bool, phi::kps::LogicalOrFunctor, phi::kps::IdentityFunctor<bool, bool>, false>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*, phi::kps::IdentityFunctor<bool, bool> const&, std::vector<int, std::allocator<int> > const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738788194 (unix time) try "date -d @1738788194" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fdbba74ca1c) received by PID 153910 (TID 0x7fdcb4653740) from PID 18446744072542800412 ***]


W0206 04:43:14.476464 153910 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:43:14.477972 153910 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.isin(Tensor([536870912, 8],"float32"), Tensor([2, 3],"float32"), False, True, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_any(_object*, _object*, _object*)
1   any_ad_func(paddle::Tensor const&, std::vector<long, std::allocator<long> >, bool)
2   paddle::experimental::any(paddle::Tensor const&, std::vector<long, std::allocator<long> > const&, bool)
3   void phi::AnyKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<long, std::allocator<long> > const&, bool, phi::DenseTensor*)
4   void phi::AnyRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<long, std::allocator<long> > const&, bool, bool, phi::DenseTensor*)
5   void phi::Reduce<bool, phi::kps::LogicalOrFunctor, phi::kps::IdentityFunctor, false>(phi::GPUContext const&, phi::DenseTensor const&, bool, std::vector<long, std::allocator<long> > const&, bool, phi::DataType, phi::DenseTensor*)
6   void phi::funcs::ReduceKernel<bool, bool, phi::kps::LogicalOrFunctor, phi::kps::IdentityFunctor<bool, bool>, false>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*, phi::kps::IdentityFunctor<bool, bool> const&, std::vector<int, std::allocator<int> > const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738788305 (unix time) try "date -d @1738788305" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7fb292336a1c) received by PID 153993 (TID 0x7fb38c23d740) from PID 18446744071867427356 ***]


W0206 04:45:05.427244 153993 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:45:05.428081 153993 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.isin(Tensor([536870912, 8],"int32"), Tensor([2, 3],"int32"), False, False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_any(_object*, _object*, _object*)
1   any_ad_func(paddle::Tensor const&, std::vector<long, std::allocator<long> >, bool)
2   paddle::experimental::any(paddle::Tensor const&, std::vector<long, std::allocator<long> > const&, bool)
3   void phi::AnyKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<long, std::allocator<long> > const&, bool, phi::DenseTensor*)
4   void phi::AnyRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<long, std::allocator<long> > const&, bool, bool, phi::DenseTensor*)
5   void phi::Reduce<bool, phi::kps::LogicalOrFunctor, phi::kps::IdentityFunctor, false>(phi::GPUContext const&, phi::DenseTensor const&, bool, std::vector<long, std::allocator<long> > const&, bool, phi::DataType, phi::DenseTensor*)
6   void phi::funcs::ReduceKernel<bool, bool, phi::kps::LogicalOrFunctor, phi::kps::IdentityFunctor<bool, bool>, false>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*, phi::kps::IdentityFunctor<bool, bool> const&, std::vector<int, std::allocator<int> > const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738788426 (unix time) try "date -d @1738788426" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7feea703aa1c) received by PID 154063 (TID 0x7fefa0f41740) from PID 18446744072216619548 ***]


W0206 04:47:06.609473 154063 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:47:06.614609 154063 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.isin(Tensor([536870912, 8],"int32"), Tensor([2, 3],"int32"), False, True, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_any(_object*, _object*, _object*)
1   any_ad_func(paddle::Tensor const&, std::vector<long, std::allocator<long> >, bool)
2   paddle::experimental::any(paddle::Tensor const&, std::vector<long, std::allocator<long> > const&, bool)
3   void phi::AnyKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<long, std::allocator<long> > const&, bool, phi::DenseTensor*)
4   void phi::AnyRawKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, std::vector<long, std::allocator<long> > const&, bool, bool, phi::DenseTensor*)
5   void phi::Reduce<bool, phi::kps::LogicalOrFunctor, phi::kps::IdentityFunctor, false>(phi::GPUContext const&, phi::DenseTensor const&, bool, std::vector<long, std::allocator<long> > const&, bool, phi::DataType, phi::DenseTensor*)
6   void phi::funcs::ReduceKernel<bool, bool, phi::kps::LogicalOrFunctor, phi::kps::IdentityFunctor<bool, bool>, false>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor*, phi::kps::IdentityFunctor<bool, bool> const&, std::vector<int, std::allocator<int> > const&)

----------------------
Error Message Summary:
----------------------
FatalError: `Erroneous arithmetic operation` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738788526 (unix time) try "date -d @1738788526" if you are using GNU date ***]
  [SignalInfo: *** SIGFPE (@0x7f1a11dcba1c) received by PID 154107 (TID 0x7f1b0bcd2740) from PID 299678236 ***]


W0206 04:48:46.459776 154107 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:48:46.460618 154107 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.linalg.cholesky_solve(Tensor([1, 1073741825, 2],"float64"), Tensor([2, 1073741825, 30],"float64"), upper=True, )
[torch error] paddle.linalg.cholesky_solve(Tensor([1, 1073741825, 2],"float64"), Tensor([2, 1073741825, 30],"float64"), upper=True, ) 
 CUDA out of memory. Tried to allocate 480.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 62.19 GiB is free. Process 125717 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:13:42.088341 154175 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:13:42.089349 154175 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.linalg.eigvals(Tensor([119304648, 9, 2, 2],"float32"), name="small_x", )
[Pass] paddle.linalg.eigvals(Tensor([119304648, 9, 2, 2],"float32"), name="small_x", )

W0206 05:28:54.368450 154750 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:28:54.369537 154750 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.linalg.matrix_norm(x=Tensor([178956971, 3, 4],"float64"), p="fro", axis=list[0,1,], keepdim=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738796195 (unix time) try "date -d @1738796195" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x26a44) received by PID 158276 (TID 0x7faabee85740) from PID 158276 ***]


W0206 06:56:35.505506 158276 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:56:35.506546 158276 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.linalg.matrix_norm(x=Tensor([178956971, 3, 4],"float64"), p="fro", axis=list[0,1,], keepdim=True, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738796285 (unix time) try "date -d @1738796285" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x26a8b) received by PID 158347 (TID 0x7f839a3db740) from PID 158347 ***]


W0206 06:58:05.171367 158347 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:58:05.172230 158347 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.linalg.matrix_norm(x=Tensor([2, 268435457, 4],"float64"), p="fro", axis=list[0,1,], keepdim=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738796384 (unix time) try "date -d @1738796384" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x26ab5) received by PID 158389 (TID 0x7f5b27d27740) from PID 158389 ***]


W0206 06:59:44.382179 158389 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:59:44.383598 158389 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.linalg.matrix_norm(x=Tensor([2, 268435457, 4],"float64"), p="fro", axis=list[0,1,], keepdim=True, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738796478 (unix time) try "date -d @1738796478" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x26aef) received by PID 158447 (TID 0x7f7f7c4ab740) from PID 158447 ***]


W0206 07:01:17.838575 158447 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:01:17.839617 158447 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.linalg.norm(Tensor([171798692, 5, 5],"float32"), p="fro", axis=list[0,1,], keepdim=True, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738796591 (unix time) try "date -d @1738796591" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x26b26) received by PID 158502 (TID 0x7fc5eb4aa740) from PID 158502 ***]


W0206 07:03:11.173594 158502 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:03:11.174620 158502 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.linalg.norm(Tensor([5, 171798692, 5],"float32"), p="fro", axis=list[0,1,], keepdim=True, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738796703 (unix time) try "date -d @1738796703" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x26b6b) received by PID 158571 (TID 0x7f95b87a1740) from PID 158571 ***]


W0206 07:05:02.763415 158571 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:05:02.764287 158571 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.linalg.vector_norm(x=Tensor([178956971, 3, 4],"float64"), p=math.inf, axis=list[0,1,], keepdim=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738796795 (unix time) try "date -d @1738796795" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x26ba3) received by PID 158627 (TID 0x7fd92d5e9740) from PID 158627 ***]


W0206 07:06:35.074002 158627 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:06:35.074924 158627 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.linalg.vector_norm(x=Tensor([178956971, 3, 4],"float64"), p=math.inf, axis=list[0,1,], keepdim=True, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738796904 (unix time) try "date -d @1738796904" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x26bce) received by PID 158670 (TID 0x7fd5d1a39740) from PID 158670 ***]


W0206 07:08:23.681401 158670 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:08:23.685345 158670 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.linalg.vector_norm(x=Tensor([2, 268435457, 4],"float64"), p=math.inf, axis=list[0,1,], keepdim=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738796994 (unix time) try "date -d @1738796994" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x26c15) received by PID 158741 (TID 0x7fa611f56740) from PID 158741 ***]


W0206 07:09:54.580622 158741 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:09:54.581640 158741 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.linalg.vector_norm(x=Tensor([2, 268435457, 4],"float64"), p=math.inf, axis=list[0,1,], keepdim=True, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738797080 (unix time) try "date -d @1738797080" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x26c31) received by PID 158769 (TID 0x7f143ef50740) from PID 158769 ***]


W0206 07:11:19.766534 158769 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:11:19.767515 158769 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.logsumexp(Tensor([2, 107374183, 4, 5],"float32"), list[2,-3,], False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738797195 (unix time) try "date -d @1738797195" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x26c68) received by PID 158824 (TID 0x7fd763a39740) from PID 158824 ***]


W0206 07:13:14.611109 158824 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:13:14.612118 158824 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.logsumexp(Tensor([2, 107374183, 4, 5],"float32"), tuple(0,1,-1,), False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738797305 (unix time) try "date -d @1738797305" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x26c9f) received by PID 158879 (TID 0x7fd6ef55f740) from PID 158879 ***]


W0206 07:15:04.745904 158879 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:15:04.746909 158879 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.logsumexp(Tensor([2, 3, 143165577, 5],"float32"), 2, False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738797419 (unix time) try "date -d @1738797419" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x26cd8) received by PID 158936 (TID 0x7fab12e68740) from PID 158936 ***]


W0206 07:16:59.501237 158936 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:16:59.502132 158936 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.logsumexp(Tensor([2, 3, 143165577, 5],"float32"), list[2,-3,], False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738797534 (unix time) try "date -d @1738797534" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x26d39) received by PID 159033 (TID 0x7f40e66f7740) from PID 159033 ***]


W0206 07:18:53.914005 159033 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:18:53.914866 159033 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.logsumexp(Tensor([2, 3, 4, 178956971],"float16"), list[-1,], False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738797657 (unix time) try "date -d @1738797657" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x26d7f) received by PID 159103 (TID 0x7f9a6e050740) from PID 159103 ***]


W0206 07:20:57.529711 159103 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:20:57.530565 159103 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.logsumexp(Tensor([2, 3, 4, 178956971],"float32"), list[-1,], False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738797765 (unix time) try "date -d @1738797765" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x26db8) received by PID 159160 (TID 0x7f4752b45740) from PID 159160 ***]


W0206 07:22:45.444316 159160 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:22:45.445178 159160 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.logsumexp(Tensor([2, 3, 4, 178956971],"float32"), tuple(0,1,-1,), False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738797879 (unix time) try "date -d @1738797879" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x26e0c) received by PID 159244 (TID 0x7f021833c740) from PID 159244 ***]


W0206 07:24:39.546242 159244 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:24:39.547226 159244 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.logsumexp(Tensor([2, 3, 4, 89478486],"float64"), list[0,-1,], False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738797973 (unix time) try "date -d @1738797973" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x26e44) received by PID 159300 (TID 0x7f9a08a05740) from PID 159300 ***]


W0206 07:26:12.855722 159300 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:26:12.856746 159300 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.logsumexp(Tensor([2, 3, 4, 89478486],"float64"), list[0,1,2,3,], False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738798067 (unix time) try "date -d @1738798067" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x26e7c) received by PID 159356 (TID 0x7f2c2ece6740) from PID 159356 ***]


W0206 07:27:47.674605 159356 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:27:47.675474 159356 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.logsumexp(Tensor([2, 3, 4, 89478486],"float64"), list[-1,], False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738798159 (unix time) try "date -d @1738798159" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x26ea6) received by PID 159398 (TID 0x7fdcdf59c740) from PID 159398 ***]


W0206 07:29:19.098335 159398 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:29:19.099287 159398 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.logsumexp(Tensor([2, 3, 4, 89478486],"float64"), list[-1,], True, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738798256 (unix time) try "date -d @1738798256" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x26eeb) received by PID 159467 (TID 0x7fef70ef2740) from PID 159467 ***]


W0206 07:30:55.841642 159467 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:30:55.842530 159467 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.logsumexp(Tensor([2, 3, 71582789, 5],"float64"), list[0,1,2,3,], False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738798354 (unix time) try "date -d @1738798354" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x26f15) received by PID 159509 (TID 0x7f2759aeb740) from PID 159509 ***]


W0206 07:32:33.883400 159509 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:32:33.884574 159509 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.logsumexp(Tensor([2, 53687092, 4, 5],"float64"), list[0,1,2,3,], False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738798472 (unix time) try "date -d @1738798472" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x26f40) received by PID 159552 (TID 0x7f9edc11b740) from PID 159552 ***]


W0206 07:34:31.915769 159552 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:34:31.916745 159552 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.logsumexp(Tensor([30, 200, 715828],"float32"), axis=-1, keepdim=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738798595 (unix time) try "date -d @1738798595" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x26f86) received by PID 159622 (TID 0x7fa6d233f740) from PID 159622 ***]


W0206 07:36:35.233274 159622 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:36:35.234136 159622 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.logsumexp(Tensor([30, 200, 715828],"float32"), axis=list[0,2,], keepdim=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738798711 (unix time) try "date -d @1738798711" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x26fcd) received by PID 159693 (TID 0x7fa299abe740) from PID 159693 ***]


W0206 07:38:30.955447 159693 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:38:30.956411 159693 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.logsumexp(Tensor([30, 3579140, 40],"float32"), axis=list[0,2,], keepdim=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738798832 (unix time) try "date -d @1738798832" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27013) received by PID 159763 (TID 0x7f821ae3c740) from PID 159763 ***]


W0206 07:40:32.487540 159763 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:40:32.488399 159763 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.logsumexp(Tensor([35791395, 3, 4, 5],"float64"), list[0,-1,], False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738798924 (unix time) try "date -d @1738798924" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27071) received by PID 159857 (TID 0x7fa3c0732740) from PID 159857 ***]


W0206 07:42:04.033610 159857 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:42:04.034641 159857 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.logsumexp(Tensor([35791395, 3, 4, 5],"float64"), list[0,1,2,3,], False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738799021 (unix time) try "date -d @1738799021" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x270bb) received by PID 159931 (TID 0x7f86e6dd7740) from PID 159931 ***]


W0206 07:43:41.526007 159931 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:43:41.526894 159931 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.logsumexp(Tensor([4, 5, 107374183],"float64"), list[-1,], False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738799112 (unix time) try "date -d @1738799112" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27101) received by PID 160001 (TID 0x7f996ed78740) from PID 160001 ***]


W0206 07:45:11.786029 160001 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:45:11.786922 160001 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.logsumexp(Tensor([536871, 200, 40],"float32"), axis=list[0,2,], keepdim=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738799221 (unix time) try "date -d @1738799221" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27147) received by PID 160071 (TID 0x7f75ec8c5740) from PID 160071 ***]


W0206 07:47:01.096284 160071 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:47:01.097390 160071 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.logsumexp(Tensor([71582789, 3, 4, 5],"float32"), tuple(0,1,-1,), False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738799336 (unix time) try "date -d @1738799336" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x271a6) received by PID 160166 (TID 0x7f8891fcf740) from PID 160166 ***]


W0206 07:48:56.688843 160166 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:48:56.689836 160166 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.mean(Tensor([1431655765, 3],"float32"), axis=list[0,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738799452 (unix time) try "date -d @1738799452" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x271e0) received by PID 160224 (TID 0x7f6b16480740) from PID 160224 ***]


W0206 07:50:52.444303 160224 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:50:52.445331 160224 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.mean(Tensor([16, 268435456],"float32"), axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738799569 (unix time) try "date -d @1738799569" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27239) received by PID 160313 (TID 0x7ff1ed3f9740) from PID 160313 ***]


W0206 07:52:48.819209 160313 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:52:48.820192 160313 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.mean(Tensor([16, 268435456],"float32"), axis=-1, keepdim=True, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738799688 (unix time) try "date -d @1738799688" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2727a) received by PID 160378 (TID 0x7f77be87f740) from PID 160378 ***]


W0206 07:54:48.192284 160378 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:54:48.193208 160378 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.mean(Tensor([2, 1, 268435456, 8],"float32"), axis=tuple(-3,-2,-1,), keepdim=True, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738799799 (unix time) try "date -d @1738799799" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x272b2) received by PID 160434 (TID 0x7f95c4697740) from PID 160434 ***]


W0206 07:56:39.684178 160434 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:56:39.685374 160434 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.mean(Tensor([2, 1, 8, 268435456],"float32"), axis=tuple(-3,-2,-1,), keepdim=True, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738799922 (unix time) try "date -d @1738799922" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27314) received by PID 160532 (TID 0x7ff4fea53740) from PID 160532 ***]


W0206 07:58:42.361274 160532 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:58:42.362246 160532 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.mean(Tensor([2, 1048576, 2048],"float32"), axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738800051 (unix time) try "date -d @1738800051" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27368) received by PID 160616 (TID 0x7fcbe3eba740) from PID 160616 ***]


W0206 08:00:51.124656 160616 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:00:51.125646 160616 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.mean(Tensor([2, 1048576, 2048],"float32"), axis=list[1,2,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738800191 (unix time) try "date -d @1738800191" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x273ca) received by PID 160714 (TID 0x7fe02aefc740) from PID 160714 ***]


W0206 08:03:10.897205 160714 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:03:10.898175 160714 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.mean(Tensor([2, 300, 7158279],"float32"), axis=list[1,2,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738800309 (unix time) try "date -d @1738800309" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2742c) received by PID 160812 (TID 0x7fc24f959740) from PID 160812 ***]


W0206 08:05:09.017904 160812 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:05:09.018767 160812 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.mean(Tensor([2, 33554432, 8, 8],"float32"), axis=tuple(-3,-2,-1,), keepdim=True, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738800428 (unix time) try "date -d @1738800428" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27480) received by PID 160896 (TID 0x7f5f1e19f740) from PID 160896 ***]


W0206 08:07:08.528808 160896 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:07:08.529810 160896 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.mean(Tensor([30, 200, 715828],"float32"), axis=-1, keepdim=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738800547 (unix time) try "date -d @1738800547" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x274c7) received by PID 160967 (TID 0x7fa9a21eb740) from PID 160967 ***]


W0206 08:09:07.711804 160967 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:09:07.712671 160967 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.mean(Tensor([30, 3579140, 40],"float32"), axis=1, keepdim=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738800660 (unix time) try "date -d @1738800660" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2750d) received by PID 161037 (TID 0x7f548e367740) from PID 161037 ***]


W0206 08:11:00.618974 161037 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:11:00.619889 161037 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.mean(Tensor([357913942, 12],"float32"), axis=list[0,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738800769 (unix time) try "date -d @1738800769" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27553) received by PID 161107 (TID 0x7f60ebbf4740) from PID 161107 ***]


W0206 08:12:49.539785 161107 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:12:49.540735 161107 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.mean(Tensor([35791395, 120],"float32"), axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738800882 (unix time) try "date -d @1738800882" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27599) received by PID 161177 (TID 0x7efc9fbd2740) from PID 161177 ***]


W0206 08:14:41.893195 161177 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:14:41.894078 161177 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.mean(Tensor([390451573, 11],"float32"), axis=list[0,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738801000 (unix time) try "date -d @1738801000" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x275de) received by PID 161246 (TID 0x7fb4a74d2740) from PID 161246 ***]


W0206 08:16:40.061911 161246 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:16:40.062927 161246 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.mean(Tensor([4, 1073741824],"float32"), axis=-1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738801111 (unix time) try "date -d @1738801111" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27616) received by PID 161302 (TID 0x7fbb97d1a740) from PID 161302 ***]


W0206 08:18:31.733129 161302 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:18:31.733942 161302 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.mean(Tensor([429496730, 10],"float32"), axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738801221 (unix time) try "date -d @1738801221" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2764f) received by PID 161359 (TID 0x7f4695d41740) from PID 161359 ***]


W0206 08:20:21.213771 161359 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:20:21.214792 161359 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.mean(Tensor([51130564, 84],"float32"), axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738801333 (unix time) try "date -d @1738801333" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27679) received by PID 161401 (TID 0x7f5e602a0740) from PID 161401 ***]


W0206 08:22:12.901880 161401 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:22:12.902822 161401 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.mean(Tensor([6, 715827883],"float32"), axis=1, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738801448 (unix time) try "date -d @1738801448" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x276cb) received by PID 161483 (TID 0x7f7b54d0b740) from PID 161483 ***]


W0206 08:24:07.758520 161483 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:24:07.759423 161483 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.mean(Tensor([6991, 300, 2048],"float32"), axis=list[1,2,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738801569 (unix time) try "date -d @1738801569" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27711) received by PID 161553 (TID 0x7f56ed237740) from PID 161553 ***]


W0206 08:26:09.196616 161553 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:26:09.197631 161553 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.multinomial(Tensor([1024, 4194304],"float32"), 20000, replacement=True, )
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.
Error: ../paddle/phi/kernels/gpu/multinomial_kernel.cu:59 Assertion `sum_rows[row_id] > 0.0` failed. The sum of one multinomial distribution probability should be > 0, but got 0.000000.


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738801692 (unix time) try "date -d @1738801692" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27767) received by PID 161639 (TID 0x7f4fdbee8740) from PID 161639 ***]


W0206 08:28:10.631729 161639 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:28:10.632711 161639 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(719), unspecified launch failure. 
  [Hint: 'cudaErrorLaunchFailure'. An exception occurred on the device while executing a kernel. Common causes include dereferencing an invalid device pointerand accessing out of bounds shared memory. Less common cases can be system specific - more information about these cases canbe found in the system specific user guide. This leaves the process in an inconsistent state and any further CUDA work willreturn the same error. To continue using CUDA, the process must be terminated and relaunched.] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.multinomial(Tensor([1024, 4194304],"float32"), 5000, replacement=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738801822 (unix time) try "date -d @1738801822" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x277d5) received by PID 161749 (TID 0x7f91068db740) from PID 161749 ***]


W0206 08:30:05.280617 161749 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:30:05.281467 161749 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 3, 715827883],"float32"), 16, False, None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738801941 (unix time) try "date -d @1738801941" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2782a) received by PID 161834 (TID 0x7fd4788b1740) from PID 161834 ***]


W0206 08:32:20.847599 161834 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:32:20.848496 161834 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool1d(Tensor([2, 3, 715827883],"float32"), output_size=16, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738802066 (unix time) try "date -d @1738802066" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2788c) received by PID 161932 (TID 0x7f400e63a740) from PID 161932 ***]


W0206 08:34:26.221483 161932 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:34:26.222855 161932 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 102261127, 7],"float32"), output_size=5, return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738802195 (unix time) try "date -d @1738802195" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x278ee) received by PID 162030 (TID 0x7f4d205f6740) from PID 162030 ***]


W0206 08:36:34.787231 162030 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:36:34.788193 162030 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 102261127, 7],"float32"), output_size=list[2,5,], return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738802339 (unix time) try "date -d @1738802339" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2794e) received by PID 162126 (TID 0x7f5ff1aac740) from PID 162126 ***]


W0206 08:38:58.751827 162126 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:38:58.752928 162126 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 102261127, 7],"float32"), output_size=list[3,3,], return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738802467 (unix time) try "date -d @1738802467" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27992) received by PID 162194 (TID 0x7f03013ac740) from PID 162194 ***]


W0206 08:41:06.766573 162194 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:41:06.767555 162194 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 102261127, 7],"float32"), output_size=list[None,3,], return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738802597 (unix time) try "date -d @1738802597" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x279cf) received by PID 162255 (TID 0x7fdf76d9f740) from PID 162255 ***]


W0206 08:43:16.913731 162255 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:43:16.914885 162255 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 7, 102261127],"float32"), output_size=5, return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738802717 (unix time) try "date -d @1738802717" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27a23) received by PID 162339 (TID 0x7f12da8a3740) from PID 162339 ***]


W0206 08:45:17.077301 162339 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:45:17.078461 162339 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 7, 102261127],"float32"), output_size=list[2,5,], return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738802844 (unix time) try "date -d @1738802844" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27a5b) received by PID 162395 (TID 0x7fd2e988a740) from PID 162395 ***]


W0206 08:47:24.168262 162395 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:47:24.169225 162395 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 7, 102261127],"float32"), output_size=list[3,3,], return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738802972 (unix time) try "date -d @1738802972" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27acb) received by PID 162507 (TID 0x7f964f33c740) from PID 162507 ***]


W0206 08:49:31.733619 162507 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:49:31.734740 162507 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 3, 7, 102261127],"float32"), output_size=list[None,3,], return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738803092 (unix time) try "date -d @1738803092" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27b20) received by PID 162592 (TID 0x7f53d2adc740) from PID 162592 ***]


W0206 08:51:32.117273 162592 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:51:32.118214 162592 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 43826197, 7, 7],"float32"), output_size=list[2,5,], return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738803200 (unix time) try "date -d @1738803200" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27b67) received by PID 162663 (TID 0x7fa384b4d740) from PID 162663 ***]


W0206 08:53:20.103238 162663 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:53:20.104128 162663 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 43826197, 7, 7],"float32"), output_size=list[3,3,], return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738803311 (unix time) try "date -d @1738803311" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27ba0) received by PID 162720 (TID 0x7f1a5b4c9740) from PID 162720 ***]


W0206 08:55:10.758670 162720 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:55:10.759685 162720 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool2d(Tensor([2, 43826197, 7, 7],"float32"), output_size=list[None,3,], return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738803421 (unix time) try "date -d @1738803421" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27bbb) received by PID 162747 (TID 0x7fa5c7b1f740) from PID 162747 ***]


W0206 08:57:01.023881 162747 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:57:01.024809 162747 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool2d(x=Tensor([2, 3, 102261127, 7],"float32"), output_size=5, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738803543 (unix time) try "date -d @1738803543" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27be5) received by PID 162789 (TID 0x7fb939cfa740) from PID 162789 ***]


W0206 08:59:02.758081 162789 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:59:02.759405 162789 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool2d(x=Tensor([2, 3, 102261127, 7],"float32"), output_size=list[2,5,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738803679 (unix time) try "date -d @1738803679" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27c02) received by PID 162818 (TID 0x7f078a47a740) from PID 162818 ***]


W0206 09:01:19.299372 162818 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:01:19.300311 162818 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool2d(x=Tensor([2, 3, 102261127, 7],"float32"), output_size=list[None,3,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738803806 (unix time) try "date -d @1738803806" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27c47) received by PID 162887 (TID 0x7ff17f9bf740) from PID 162887 ***]


W0206 09:03:26.022107 162887 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:03:26.022964 162887 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool2d(x=Tensor([2, 3, 102261127, 7],"float32"), return_mask=False, output_size=list[3,3,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738803943 (unix time) try "date -d @1738803943" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27c7f) received by PID 162943 (TID 0x7f00153c0740) from PID 162943 ***]


W0206 09:05:42.823606 162943 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:05:42.824433 162943 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool2d(x=Tensor([2, 3, 7, 102261127],"float32"), output_size=5, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738804066 (unix time) try "date -d @1738804066" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27cc2) received by PID 163010 (TID 0x7f4081b94740) from PID 163010 ***]


W0206 09:07:45.951229 163010 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:07:45.952157 163010 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool2d(x=Tensor([2, 3, 7, 102261127],"float32"), output_size=list[2,5,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738804189 (unix time) try "date -d @1738804189" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27ced) received by PID 163053 (TID 0x7fe039bf7740) from PID 163053 ***]


W0206 09:09:48.776575 163053 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:09:48.777473 163053 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool2d(x=Tensor([2, 3, 7, 102261127],"float32"), output_size=list[None,3,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738804302 (unix time) try "date -d @1738804302" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27d0a) received by PID 163082 (TID 0x7f3bf77a3740) from PID 163082 ***]


W0206 09:11:41.936844 163082 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:11:41.937726 163082 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool2d(x=Tensor([2, 3, 7, 102261127],"float32"), return_mask=False, output_size=list[3,3,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738804423 (unix time) try "date -d @1738804423" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27d4f) received by PID 163151 (TID 0x7f6ef1c8a740) from PID 163151 ***]


W0206 09:13:43.582228 163151 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:13:43.583191 163151 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool2d(x=Tensor([2, 43826197, 7, 7],"float32"), output_size=list[2,5,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738804534 (unix time) try "date -d @1738804534" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27d87) received by PID 163207 (TID 0x7f834bb77740) from PID 163207 ***]


W0206 09:15:34.077517 163207 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:15:34.078392 163207 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool2d(x=Tensor([2, 43826197, 7, 7],"float32"), output_size=list[None,3,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738804649 (unix time) try "date -d @1738804649" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27dd3) received by PID 163283 (TID 0x7f0a9fc43740) from PID 163283 ***]


W0206 09:17:29.420385 163283 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:17:29.421275 163283 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool2d(x=Tensor([2, 43826197, 7, 7],"float32"), return_mask=False, output_size=list[3,3,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738804760 (unix time) try "date -d @1738804760" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27e12) received by PID 163346 (TID 0x7f49ac938740) from PID 163346 ***]


W0206 09:19:20.638319 163346 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:19:20.639379 163346 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 14608733, 7, 7],"float32"), output_size=5, return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738804885 (unix time) try "date -d @1738804885" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27e5a) received by PID 163418 (TID 0x7ffa93ea1740) from PID 163418 ***]


W0206 09:21:24.811084 163418 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:21:24.812058 163418 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 14608733, 7, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738805013 (unix time) try "date -d @1738805013" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27e85) received by PID 163461 (TID 0x7f5443dce740) from PID 163461 ***]


W0206 09:23:32.844096 163461 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:23:32.845065 163461 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 14608733, 7, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738805148 (unix time) try "date -d @1738805148" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27eb0) received by PID 163504 (TID 0x7f8e5534b740) from PID 163504 ***]


W0206 09:25:48.456121 163504 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:25:48.457060 163504 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 14608733, 7, 7],"float32"), output_size=list[None,3,None,], return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738805269 (unix time) try "date -d @1738805269" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27ed9) received by PID 163545 (TID 0x7f15f56c6740) from PID 163545 ***]


W0206 09:27:49.391319 163545 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:27:49.392252 163545 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 20452226, 7],"float32"), output_size=5, return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738805383 (unix time) try "date -d @1738805383" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27f11) received by PID 163601 (TID 0x7f9a6e0e2740) from PID 163601 ***]


W0206 09:29:43.376971 163601 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:29:43.377954 163601 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 20452226, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738805505 (unix time) try "date -d @1738805505" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27f3b) received by PID 163643 (TID 0x7fdfaca38740) from PID 163643 ***]


W0206 09:31:45.018477 163643 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:31:45.019505 163643 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 20452226, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738805627 (unix time) try "date -d @1738805627" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27f65) received by PID 163685 (TID 0x7f37775d7740) from PID 163685 ***]


W0206 09:33:47.158865 163685 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:33:47.159754 163685 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 20452226, 7],"float32"), output_size=list[None,3,None,], return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738805740 (unix time) try "date -d @1738805740" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x27f82) received by PID 163714 (TID 0x7f2a5832c740) from PID 163714 ***]


W0206 09:35:40.610595 163714 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:35:40.611436 163714 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 7, 20452226],"float32"), output_size=5, return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738805855 (unix time) try "date -d @1738805855" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x286) received by PID 646 (TID 0x7f25bcf4f740) from PID 646 ***]


W0206 09:37:34.717092   646 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:37:34.718056   646 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 7, 20452226],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738805988 (unix time) try "date -d @1738805988" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4fd) received by PID 1277 (TID 0x7f08861e8740) from PID 1277 ***]


W0206 09:39:48.687379  1277 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:39:48.688802  1277 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 7, 20452226],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738806109 (unix time) try "date -d @1738806109" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x77a) received by PID 1914 (TID 0x7fa479962740) from PID 1914 ***]


W0206 09:41:48.866083  1914 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:41:48.867115  1914 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 3, 5, 7, 20452226],"float32"), output_size=list[None,3,None,], return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738806234 (unix time) try "date -d @1738806234" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x99a) received by PID 2458 (TID 0x7f9a4d498740) from PID 2458 ***]


W0206 09:43:54.377552  2458 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:43:54.378471  2458 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 8765240, 5, 7, 7],"float32"), output_size=5, return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738806348 (unix time) try "date -d @1738806348" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xbe1) received by PID 3041 (TID 0x7f4331769740) from PID 3041 ***]


W0206 09:45:47.939041  3041 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:45:47.939949  3041 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 8765240, 5, 7, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738806458 (unix time) try "date -d @1738806458" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0xe0b) received by PID 3595 (TID 0x7f9700b69740) from PID 3595 ***]


W0206 09:47:38.272624  3595 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:47:38.273895  3595 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 8765240, 5, 7, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738806568 (unix time) try "date -d @1738806568" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1040) received by PID 4160 (TID 0x7fd37a2d2740) from PID 4160 ***]


W0206 09:49:28.419986  4160 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:49:28.420941  4160 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([2, 8765240, 5, 7, 7],"float32"), output_size=list[None,3,None,], return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738806684 (unix time) try "date -d @1738806684" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x126c) received by PID 4716 (TID 0x7f958c411740) from PID 4716 ***]


W0206 09:51:23.929991  4716 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:51:23.930975  4716 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([5843493, 3, 5, 7, 7],"float32"), output_size=5, return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738806796 (unix time) try "date -d @1738806796" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1434) received by PID 5172 (TID 0x7f133c892740) from PID 5172 ***]


W0206 09:53:16.063298  5172 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:53:16.064236  5172 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([5843493, 3, 5, 7, 7],"float32"), output_size=list[2,3,5,], return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738806909 (unix time) try "date -d @1738806909" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1674) received by PID 5748 (TID 0x7f23e830f740) from PID 5748 ***]


W0206 09:55:08.887388  5748 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:55:08.888289  5748 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([5843493, 3, 5, 7, 7],"float32"), output_size=list[3,3,3,], return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738807018 (unix time) try "date -d @1738807018" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x18a7) received by PID 6311 (TID 0x7f1fc3e18740) from PID 6311 ***]


W0206 09:56:58.425346  6311 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:56:58.426261  6311 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(Tensor([5843493, 3, 5, 7, 7],"float32"), output_size=list[None,3,None,], return_mask=False, name=None, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738807129 (unix time) try "date -d @1738807129" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1a81) received by PID 6785 (TID 0x7fe3b46da740) from PID 6785 ***]


W0206 09:58:49.122256  6785 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:58:49.123101  6785 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(x=Tensor([2, 3, 14608733, 7, 7],"float32"), output_size=5, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738807251 (unix time) try "date -d @1738807251" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1c87) received by PID 7303 (TID 0x7ff05662e740) from PID 7303 ***]


W0206 10:00:51.588078  7303 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:00:51.589136  7303 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(x=Tensor([2, 3, 14608733, 7, 7],"float32"), output_size=list[2,3,5,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738807376 (unix time) try "date -d @1738807376" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1ed1) received by PID 7889 (TID 0x7fb4d4506740) from PID 7889 ***]


W0206 10:02:56.543569  7889 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:02:56.544776  7889 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(x=Tensor([2, 3, 14608733, 7, 7],"float32"), output_size=list[3,3,3,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738807503 (unix time) try "date -d @1738807503" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2138) received by PID 8504 (TID 0x7fc588478740) from PID 8504 ***]


W0206 10:05:03.677908  8504 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:05:03.678894  8504 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(x=Tensor([2, 3, 14608733, 7, 7],"float32"), output_size=list[None,3,None,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738807614 (unix time) try "date -d @1738807614" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x23f0) received by PID 9200 (TID 0x7f241a1ba740) from PID 9200 ***]


W0206 10:06:54.248121  9200 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:06:54.249082  9200 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(x=Tensor([2, 3, 5, 20452226, 7],"float32"), output_size=5, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738807736 (unix time) try "date -d @1738807736" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2665) received by PID 9829 (TID 0x7f13aca61740) from PID 9829 ***]


W0206 10:08:55.734776  9829 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:08:55.735755  9829 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(x=Tensor([2, 3, 5, 20452226, 7],"float32"), output_size=list[2,3,5,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738807861 (unix time) try "date -d @1738807861" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2855) received by PID 10325 (TID 0x7f3778626740) from PID 10325 ***]


W0206 10:11:00.788141 10325 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:11:00.789314 10325 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(x=Tensor([2, 3, 5, 20452226, 7],"float32"), output_size=list[3,3,3,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738807986 (unix time) try "date -d @1738807986" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2b1a) received by PID 11034 (TID 0x7f5a726e7740) from PID 11034 ***]


W0206 10:13:06.583061 11034 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:13:06.583976 11034 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(x=Tensor([2, 3, 5, 20452226, 7],"float32"), output_size=list[None,3,None,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738808107 (unix time) try "date -d @1738808107" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2d92) received by PID 11666 (TID 0x7ff51b022740) from PID 11666 ***]


W0206 10:15:07.579267 11666 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:15:07.580324 11666 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(x=Tensor([2, 3, 5, 7, 20452226],"float32"), output_size=5, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738808223 (unix time) try "date -d @1738808223" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x2ff8) received by PID 12280 (TID 0x7fbe709ab740) from PID 12280 ***]


W0206 10:17:02.817996 12280 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:17:02.818888 12280 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(x=Tensor([2, 3, 5, 7, 20452226],"float32"), output_size=list[2,3,5,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738808339 (unix time) try "date -d @1738808339" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x3253) received by PID 12883 (TID 0x7f8aa9d3c740) from PID 12883 ***]


W0206 10:18:59.573841 12883 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:18:59.575006 12883 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(x=Tensor([2, 3, 5, 7, 20452226],"float32"), output_size=list[3,3,3,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738808451 (unix time) try "date -d @1738808451" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x34a8) received by PID 13480 (TID 0x7f13d541d740) from PID 13480 ***]


W0206 10:20:51.597718 13480 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:20:51.598799 13480 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(x=Tensor([2, 3, 5, 7, 20452226],"float32"), output_size=list[None,3,None,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738808565 (unix time) try "date -d @1738808565" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x3696) received by PID 13974 (TID 0x7f3b5f007740) from PID 13974 ***]


W0206 10:22:45.057883 13974 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:22:45.058769 13974 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(x=Tensor([2, 8765240, 5, 7, 7],"float32"), output_size=5, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738808682 (unix time) try "date -d @1738808682" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x38d5) received by PID 14549 (TID 0x7f5513e7a740) from PID 14549 ***]


W0206 10:24:42.328424 14549 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:24:42.329327 14549 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(x=Tensor([2, 8765240, 5, 7, 7],"float32"), output_size=list[2,3,5,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738808793 (unix time) try "date -d @1738808793" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x3b26) received by PID 15142 (TID 0x7f6b9ba0a740) from PID 15142 ***]


W0206 10:26:32.862628 15142 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:26:32.863523 15142 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(x=Tensor([2, 8765240, 5, 7, 7],"float32"), output_size=list[3,3,3,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738808911 (unix time) try "date -d @1738808911" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x3d61) received by PID 15713 (TID 0x7f2bcb93e740) from PID 15713 ***]


W0206 10:28:31.352905 15713 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:28:31.353842 15713 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(x=Tensor([2, 8765240, 5, 7, 7],"float32"), output_size=list[None,3,None,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738809026 (unix time) try "date -d @1738809026" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x3fb4) received by PID 16308 (TID 0x7f95859ab740) from PID 16308 ***]


W0206 10:30:25.852444 16308 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:30:25.853288 16308 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(x=Tensor([5843493, 3, 5, 7, 7],"float32"), output_size=5, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738809143 (unix time) try "date -d @1738809143" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x41a1) received by PID 16801 (TID 0x7f84cd637740) from PID 16801 ***]


W0206 10:32:23.575557 16801 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:32:23.576486 16801 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(x=Tensor([5843493, 3, 5, 7, 7],"float32"), output_size=list[2,3,5,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738809267 (unix time) try "date -d @1738809267" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4407) received by PID 17415 (TID 0x7ff41307f740) from PID 17415 ***]


W0206 10:34:27.485857 17415 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:34:27.486766 17415 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(x=Tensor([5843493, 3, 5, 7, 7],"float32"), output_size=list[3,3,3,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738809388 (unix time) try "date -d @1738809388" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x464a) received by PID 17994 (TID 0x7f79ee465740) from PID 17994 ***]


W0206 10:36:28.264240 17994 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:36:28.265918 17994 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.adaptive_max_pool3d(x=Tensor([5843493, 3, 5, 7, 7],"float32"), output_size=list[None,3,None,], )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738809505 (unix time) try "date -d @1738809505" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4916) received by PID 18710 (TID 0x7fb11f0b9740) from PID 18710 ***]


W0206 10:38:25.530438 18710 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:38:25.531359 18710 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 134217728, 8],"float32"), Tensor([1, 8, 8, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738809627 (unix time) try "date -d @1738809627" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4b3a) received by PID 19258 (TID 0x7f9ccebe5740) from PID 19258 ***]


W0206 10:40:26.821244 19258 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:40:26.821282 19258 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 16777216, 64],"float32"), Tensor([1, 64, 64, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738809722 (unix time) try "date -d @1738809722" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4d61) received by PID 19809 (TID 0x7f7bc1342740) from PID 19809 ***]


W0206 10:42:01.077997 19809 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:42:01.078032 19809 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 16777216, 64],"float32"), Tensor([1, 88, 88, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738809840 (unix time) try "date -d @1738809840" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x4f37) received by PID 20279 (TID 0x7f4c8c82a740) from PID 20279 ***]


W0206 10:43:58.885072 20279 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:43:58.885128 20279 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 28, 38347923],"float32"), Tensor([1, 28, 28, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738809930 (unix time) try "date -d @1738809930" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x518a) received by PID 20874 (TID 0x7f5ad4fae740) from PID 20874 ***]


W0206 10:45:29.015863 20874 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:45:29.015928 20874 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 28, 38347923],"float32"), Tensor([1, 34, 34, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738810045 (unix time) try "date -d @1738810045" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x5354) received by PID 21332 (TID 0x7f066b60a740) from PID 21332 ***]


W0206 10:47:24.380648 21332 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:47:24.380721 21332 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 280, 3834793],"float32"), Tensor([1, 280, 350, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738810189 (unix time) try "date -d @1738810189" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x557f) received by PID 21887 (TID 0x7f631678c740) from PID 21887 ***]


W0206 10:49:47.646683 21887 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:49:47.646757 21887 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 3067834, 350],"float32"), Tensor([1, 280, 350, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738810343 (unix time) try "date -d @1738810343" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x57e4) received by PID 22500 (TID 0x7f141b2af740) from PID 22500 ***]


W0206 10:52:21.451517 22500 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:52:21.451694 22500 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 32, 33554432],"float32"), Tensor([1, 32, 26, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738810470 (unix time) try "date -d @1738810470" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x5a8d) received by PID 23181 (TID 0x7f548fa88740) from PID 23181 ***]


W0206 10:54:28.722057 23181 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:54:28.722121 23181 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 3579140, 300],"float32"), Tensor([1, 400, 300, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738810597 (unix time) try "date -d @1738810597" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x5d22) received by PID 23842 (TID 0x7f1f91229740) from PID 23842 ***]


W0206 10:56:36.005561 23842 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:56:36.005717 23842 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 38347923, 28],"float32"), Tensor([1, 28, 28, 2],"float32"), mode="bilinear", padding_mode="zeros", align_corners=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738810695 (unix time) try "date -d @1738810695" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x5f5a) received by PID 24410 (TID 0x7fcf55894740) from PID 24410 ***]


W0206 10:58:13.887863 24410 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:58:13.887912 24410 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 38347923, 28],"float32"), Tensor([1, 34, 34, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738810795 (unix time) try "date -d @1738810795" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x611f) received by PID 24863 (TID 0x7f0d9403c740) from PID 24863 ***]


W0206 10:59:54.218812 24863 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:59:54.218887 24863 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 400, 2684355],"float32"), Tensor([1, 400, 300, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738810893 (unix time) try "date -d @1738810893" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x6338) received by PID 25400 (TID 0x7f247046f740) from PID 25400 ***]


W0206 11:01:32.645640 25400 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:01:32.645684 25400 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 41297763, 26],"float32"), Tensor([1, 32, 26, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738810985 (unix time) try "date -d @1738810985" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x64ed) received by PID 25837 (TID 0x7fab15f13740) from PID 25837 ***]


W0206 11:03:04.018821 25837 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:03:04.018879 25837 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 64, 16777216],"float32"), Tensor([1, 64, 64, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738811073 (unix time) try "date -d @1738811073" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x669b) received by PID 26267 (TID 0x7ff2ed048740) from PID 26267 ***]


W0206 11:04:32.440078 26267 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:04:32.440133 26267 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 64, 16777216],"float32"), Tensor([1, 88, 88, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738811162 (unix time) try "date -d @1738811162" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x6856) received by PID 26710 (TID 0x7efde9430740) from PID 26710 ***]


W0206 11:06:01.259776 26710 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:06:01.259814 26710 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.grid_sample(Tensor([1, 4, 8, 134217728],"float32"), Tensor([1, 8, 8, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738811259 (unix time) try "date -d @1738811259" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x6a0b) received by PID 27147 (TID 0x7f278d564740) from PID 27147 ***]


W0206 11:07:38.743469 27147 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:07:38.743506 27147 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.grid_sample(Tensor([2, 4, 134217728, 4],"float32"), Tensor([2, 4, 4, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738811357 (unix time) try "date -d @1738811357" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x6bde) received by PID 27614 (TID 0x7faa58277740) from PID 27614 ***]


W0206 11:09:16.283792 27614 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:09:16.283856 27614 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.grid_sample(Tensor([2, 4, 4, 134217728],"float32"), Tensor([2, 4, 4, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738811444 (unix time) try "date -d @1738811444" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x6d96) received by PID 28054 (TID 0x7f84a6f04740) from PID 28054 ***]


W0206 11:10:43.789485 28054 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:10:43.789525 28054 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.grid_sample(Tensor([2, 4, 67108864, 8],"float32"), Tensor([2, 8, 8, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738811532 (unix time) try "date -d @1738811532" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x6f47) received by PID 28487 (TID 0x7f213f4d0740) from PID 28487 ***]


W0206 11:12:11.278031 28487 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:12:11.278090 28487 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.grid_sample(Tensor([2, 4, 8, 67108864],"float32"), Tensor([2, 8, 8, 2],"float32"), mode="nearest", padding_mode="zeros", align_corners=False, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1738811617 (unix time) try "date -d @1738811617" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x70e1) received by PID 28897 (TID 0x7f22988cf740) from PID 28897 ***]


W0206 11:13:36.260075 28897 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:13:36.260119 28897 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.nn.functional.relu(Tensor([1048576, 4096],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([1048576, 4096],"float32"), )

W0206 11:15:01.589344 29308 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:15:01.590348 29308 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([1048576, 8, 16, 32],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([1048576, 8, 16, 32],"float32"), )

W0206 11:18:30.413136 30282 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:18:30.414132 30282 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([10700, 2048, 14, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([10700, 2048, 14, 14],"float32"), None, )

W0206 11:22:32.701664 31404 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:22:32.702804 31404 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([10700, 32, 112, 112],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([10700, 32, 112, 112],"float32"), None, )

W0206 11:26:25.231971 32553 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:26:25.232967 32553 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([10700, 512, 28, 28],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([10700, 512, 28, 28],"float16"), )

W0206 11:30:10.160068 33567 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:30:10.160962 33567 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([1073741824, 4],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([1073741824, 4],"float32"), )

W0206 11:38:57.028100 36137 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:38:57.029057 36137 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([107374183, 40],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([107374183, 40],"float32"), )

W0206 11:42:35.639106 37140 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:42:35.639983 37140 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([10737419, 400],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([10737419, 400],"float32"), )

W0206 11:46:09.510619 38169 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:46:09.511704 38169 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([107375, 64, 25, 25],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([107375, 64, 25, 25],"float32"), None, )

W0206 11:49:41.401398 39164 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:49:41.402359 39164 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([10894, 32, 111, 111],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([10894, 32, 111, 111],"float32"), None, )

W0206 11:53:23.876252 40185 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:53:23.877171 40185 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([11184811, 384, 1, 1],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([11184811, 384, 1, 1],"float16"), )

W0206 11:57:07.366397 41308 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:57:07.367383 41308 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([11184811, 384, 1, 1],"float16"), None, )
[Pass] paddle.nn.functional.relu(Tensor([11184811, 384, 1, 1],"float16"), None, )

W0206 12:06:18.394079 43849 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:06:18.395000 43849 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([11184811, 384, 1, 1],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([11184811, 384, 1, 1],"float32"), )

W0206 12:15:13.416183 46398 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:15:13.417129 46398 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([11184811, 384, 1, 1],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([11184811, 384, 1, 1],"float32"), None, )

W0206 12:18:54.608628 47376 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:18:54.609493 47376 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([11297, 32, 109, 109],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([11297, 32, 109, 109],"float32"), None, )

W0206 12:23:02.565946 48518 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:23:02.566910 48518 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([114131, 12, 56, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([114131, 12, 56, 56],"float32"), None, )

W0206 12:26:55.137935 49725 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:26:55.138870 49725 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([114131, 48, 28, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([114131, 48, 28, 28],"float32"), None, )

W0206 12:30:42.335299 50896 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:30:42.336207 50896 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([11508, 128, 54, 54],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([11508, 128, 54, 54],"float32"), )

W0206 12:34:19.493781 51947 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:34:19.494849 51947 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([116509, 1024, 6, 6],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([116509, 1024, 6, 6],"float32"), )

W0206 12:38:05.845261 53098 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:38:05.846201 53098 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([116509, 256, 12, 12],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([116509, 256, 12, 12],"float32"), )

W0206 12:41:36.244587 54123 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:41:36.245687 54123 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([12229, 112, 56, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([12229, 112, 56, 56],"float32"), None, )

W0206 12:45:18.563505 55144 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:45:18.564494 55144 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([12275, 480, 27, 27],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([12275, 480, 27, 27],"float32"), )

W0206 12:48:54.992151 56277 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:48:54.993176 56277 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([124507, 176, 14, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([124507, 176, 14, 14],"float32"), None, )

W0206 12:52:33.592617 57307 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:52:33.593837 57307 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([131072, 512, 8, 8],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([131072, 512, 8, 8],"float32"), None, )

W0206 12:56:06.173635 58340 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:56:06.174455 58340 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([132365, 192, 13, 13],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([132365, 192, 13, 13],"float32"), )

W0206 12:59:46.674037 59348 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:59:46.675046 59348 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([132365, 48, 26, 26],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([132365, 48, 26, 26],"float32"), )

W0206 13:03:38.110010 60482 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:03:38.110869 60482 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([1338, 64, 224, 224],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([1338, 64, 224, 224],"float32"), None, )

W0206 13:07:20.160594 61526 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:07:20.161494 61526 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([1369569, 64, 7, 7],"float16"), None, )
[Pass] paddle.nn.functional.relu(Tensor([1369569, 64, 7, 7],"float16"), None, )

W0206 13:11:07.126523 62649 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:11:07.127452 62649 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([1369569, 64, 7, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([1369569, 64, 7, 7],"float32"), None, )

W0206 13:19:55.278739 65178 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:19:55.279829 65178 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([1398102, 24, 16, 8],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([1398102, 24, 16, 8],"float32"), )

W0206 13:23:43.963912 66309 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:23:43.964972 66309 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([14267, 24, 112, 112],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([14267, 24, 112, 112],"float32"), None, )

W0206 13:27:35.021957 67480 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:27:35.022929 67480 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([1431655765, 3, 1],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([1431655765, 3, 1],"float32"), )

W0206 13:31:13.555666 68501 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:31:13.556510 68501 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([1431655765, 3],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([1431655765, 3],"float32"), )

W0206 13:35:01.270452 69649 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:35:01.271369 69649 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([1431655765, 3],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([1431655765, 3],"float32"), None, )

W0206 13:38:46.849247 70740 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:38:46.850138 70740 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([143166, 48, 25, 25],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([143166, 48, 25, 25],"float32"), None, )

W0206 13:42:30.991508 71884 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:42:30.992352 71884 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([143396, 832, 6, 6],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([143396, 832, 6, 6],"float32"), )

W0206 13:46:21.316103 72963 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:46:21.317226 72963 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([155345, 192, 12, 12],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([155345, 192, 12, 12],"float32"), None, )

W0206 13:50:00.211593 74121 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:50:00.212632 74121 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([15564, 88, 56, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([15564, 88, 56, 56],"float32"), None, )

W0206 13:53:31.955801 75168 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:53:31.956693 75168 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([16, 10737419, 5, 5],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([16, 10737419, 5, 5],"float32"), )

W0206 13:57:17.806177 76236 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:57:17.807112 76236 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([16, 24, 1398102, 8],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([16, 24, 1398102, 8],"float32"), )

W0206 14:02:07.542840 77491 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:02:07.544574 77491 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([16, 24, 16, 699051],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([16, 24, 16, 699051],"float32"), )

W0206 14:07:50.330729 78954 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:07:50.331741 78954 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([16, 256, 18725, 56],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([16, 256, 18725, 56],"float32"), )

W0206 14:11:52.566040 80304 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:11:52.569888 80304 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([16, 256, 56, 18725],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([16, 256, 56, 18725],"float32"), )

W0206 14:15:41.822010 81309 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:15:41.822886 81309 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([16, 268435456],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([16, 268435456],"float32"), None, )

W0206 14:19:37.985666 82437 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:19:37.987219 82437 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([16, 342393, 28, 28],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([16, 342393, 28, 28],"float32"), )

W0206 14:23:28.318933 83573 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:23:28.320079 83573 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([16, 342393, 28, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([16, 342393, 28, 28],"float32"), None, )

W0206 14:27:19.448436 84661 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:27:19.449440 84661 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([16, 512, 18725, 28],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([16, 512, 18725, 28],"float32"), )

W0206 14:31:10.682853 85778 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:31:10.684667 85778 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([16, 512, 28, 18725],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([16, 512, 28, 18725],"float32"), )

W0206 14:34:44.833129 86805 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:34:44.834124 86805 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([16, 6, 1597831, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([16, 6, 1597831, 28],"float32"), None, )

W0206 14:38:24.347750 87890 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:38:24.348810 87890 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([16, 6, 28, 1597831],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([16, 6, 28, 1597831],"float32"), None, )

W0206 14:41:56.433698 88866 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:41:56.434731 88866 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([16, 6, 5, 8947849],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([16, 6, 5, 8947849],"float32"), )

W0206 14:45:31.916404 89905 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:45:31.917387 89905 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([16, 6, 8947849, 5],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([16, 6, 8947849, 5],"float32"), )

W0206 14:49:15.299530 90921 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:49:15.300614 90921 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([16, 85599, 56, 56],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([16, 85599, 56, 56],"float32"), )

W0206 14:52:53.130412 92004 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:52:53.131378 92004 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([16384, 1024, 16, 16],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([16384, 1024, 16, 16],"float32"), None, )

W0206 14:56:23.453522 92883 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:56:23.454406 92883 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([16384, 256, 32, 32],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([16384, 256, 32, 32],"float32"), None, )

W0206 14:59:57.193531 93877 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:59:57.194482 93877 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([16384, 64, 64, 64],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([16384, 64, 64, 64],"float32"), None, )

W0206 15:03:48.451534 94930 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:03:48.452857 94930 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([16777216, 256, 1, 1],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([16777216, 256, 1, 1],"float16"), )

W0206 15:07:36.151188 96081 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:07:36.152204 96081 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([16777216, 256, 1, 1],"float16"), None, )
[Pass] paddle.nn.functional.relu(Tensor([16777216, 256, 1, 1],"float16"), None, )

W0206 15:16:33.194804 98589 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:16:33.195871 98589 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([16777216, 256, 1, 1],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([16777216, 256, 1, 1],"float32"), )

W0206 15:25:33.553615 101292 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:25:33.554672 101292 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([16777216, 256, 1, 1],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([16777216, 256, 1, 1],"float32"), None, )

W0206 15:29:08.572778 102344 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:29:08.573725 102344 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([16777216, 256],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([16777216, 256],"float32"), )

W0206 15:32:39.772398 103395 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:32:39.773298 103395 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([16777216, 4, 8, 8],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([16777216, 4, 8, 8],"float32"), )

W0206 15:36:13.315057 104412 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:36:13.316038 104412 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([16777216, 8, 32],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([16777216, 8, 32],"float32"), )

W0206 15:39:47.338353 105451 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:39:47.339403 105451 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([171197, 32, 28, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([171197, 32, 28, 28],"float32"), None, )

W0206 15:43:26.624181 106564 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:43:26.625164 106564 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([17895698, 240, 1, 1],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([17895698, 240, 1, 1],"float32"), None, )

W0206 15:47:04.755447 107612 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:47:04.756481 107612 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([179616, 488, 7, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([179616, 488, 7, 7],"float32"), None, )

W0206 15:50:41.186393 108620 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:50:41.187400 108620 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([1826092, 48, 7, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([1826092, 48, 7, 7],"float32"), None, )

W0206 15:54:21.874202 109613 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:54:21.875160 109613 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([184113, 32, 27, 27],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([184113, 32, 27, 27],"float32"), )

W0206 15:58:08.560313 110728 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:58:08.561272 110728 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([18412, 80, 54, 54],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([18412, 80, 54, 54],"float32"), None, )

W0206 16:01:53.834242 111868 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:01:53.835287 111868 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([186414, 160, 12, 12],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([186414, 160, 12, 12],"float32"), None, )

W0206 16:05:33.458014 112829 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:05:33.458878 112829 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([188907, 116, 14, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([188907, 116, 14, 14],"float32"), None, )

W0206 16:09:13.591850 113791 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:09:13.593034 113791 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([19022, 72, 56, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([19022, 72, 56, 56],"float32"), None, )

W0206 16:12:48.243906 114803 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:12:48.244944 114803 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([198547, 32, 26, 26],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([198547, 32, 26, 26],"float32"), )

W0206 16:16:24.362643 115779 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:16:24.363739 115779 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 1000, 12, 178957],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 1000, 12, 178957],"float32"), )

W0206 16:20:21.001394 116888 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:20:21.002424 116888 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 1000, 13, 165192],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 1000, 13, 165192],"float32"), )

W0206 16:24:01.498036 117972 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:24:01.498943 117972 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 1000, 165192, 13],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 1000, 165192, 13],"float32"), )

W0206 16:27:44.728031 118980 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:27:44.728963 118980 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 1000, 178957, 12],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 1000, 178957, 12],"float32"), )

W0206 16:31:28.090394 119996 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:31:28.091384 119996 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 1024, 14, 149797],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 1024, 14, 149797],"float16"), )

W0206 16:35:23.282560 121100 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:35:23.283738 121100 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 1024, 14, 149797],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 1024, 14, 149797],"float32"), )

W0206 16:44:07.802029 123567 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:44:07.802923 123567 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 1024, 14, 149797],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 1024, 14, 149797],"float32"), None, )

W0206 16:47:49.488096 124620 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:47:49.489054 124620 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 1024, 149797, 14],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 1024, 149797, 14],"float16"), )

W0206 16:51:53.511023 125751 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:51:53.511897 125751 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 1024, 149797, 14],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 1024, 149797, 14],"float32"), )

W0206 17:00:54.267899 128380 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:00:54.268858 128380 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 1024, 149797, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 1024, 149797, 14],"float32"), None, )

W0206 17:04:35.336004 129502 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:04:35.336905 129502 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 1024, 28, 74899],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 1024, 28, 74899],"float32"), None, )

W0206 17:08:17.176301 130567 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:08:17.177254 130567 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 1024, 299594, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 1024, 299594, 7],"float32"), None, )

W0206 17:12:06.578087 131680 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:12:06.578999 131680 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 1024, 349526, 6],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 1024, 349526, 6],"float32"), )

W0206 17:15:47.272838 132692 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:15:47.273741 132692 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 1024, 6, 349526],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 1024, 6, 349526],"float32"), )

W0206 17:19:22.062002 133758 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:19:22.063051 133758 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 1024, 7, 299594],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 1024, 7, 299594],"float32"), None, )

W0206 17:23:08.170984 134812 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:23:08.171872 134812 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 1024, 74899, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 1024, 74899, 28],"float32"), None, )

W0206 17:26:48.872202 135798 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:26:48.873167 135798 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 1048576, 2048],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 1048576, 2048],"float32"), )

W0206 17:30:31.266750 136904 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:30:31.267719 136904 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 1073741824, 2],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 1073741824, 2],"float32"), )

W0206 17:34:10.585889 137867 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:34:10.586813 137867 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 1073741825],"float64"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 1073741825],"float64"), )

W0206 17:37:36.432237 138980 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:37:36.433336 138980 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 10956550, 14, 14],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 10956550, 14, 14],"float16"), )

W0206 17:41:15.618095 139846 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:41:15.618990 139846 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 10956550, 14, 14],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 10956550, 14, 14],"float32"), )

W0206 17:50:02.225458 142326 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:50:02.226334 142326 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 10956550, 14, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 10956550, 14, 14],"float32"), None, )

W0206 17:53:49.139482 143321 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:53:49.140408 143321 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 112, 28, 684785],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 112, 28, 684785],"float32"), None, )

W0206 17:57:35.943028 144409 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:57:35.943955 144409 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 112, 342393, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 112, 342393, 56],"float32"), None, )

W0206 18:01:27.363704 145406 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:01:27.364588 145406 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 112, 56, 342393],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 112, 56, 342393],"float32"), None, )

W0206 18:05:17.538775 146523 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:05:17.539680 146523 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 112, 684785, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 112, 684785, 28],"float32"), None, )

W0206 18:08:57.642617 147636 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:08:57.643463 147636 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 116, 1322343, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 116, 1322343, 14],"float32"), None, )

W0206 18:12:37.892606 148634 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:12:37.893570 148634 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 116, 14, 1322343],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 116, 14, 1322343],"float32"), None, )

W0206 18:16:33.392865 149731 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:16:33.393764 149731 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 116, 28, 661172],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 116, 28, 661172],"float32"), None, )

W0206 18:20:06.885875 150747 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:20:06.886791 150747 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 116, 661172, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 116, 661172, 28],"float32"), None, )

W0206 18:23:41.185516 151791 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:23:41.186642 151791 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 12, 28, 6391321],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 12, 28, 6391321],"float32"), None, )

W0206 18:27:13.682085 152828 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:27:13.682955 152828 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 12, 3195661, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 12, 3195661, 56],"float32"), None, )

W0206 18:30:53.334414 153870 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:30:53.335744 153870 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 12, 56, 3195661],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 12, 56, 3195661],"float32"), None, )

W0206 18:34:45.687192 155020 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:34:45.688262 155020 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 12, 6391321, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 12, 6391321, 28],"float32"), None, )

W0206 18:38:42.035902 156186 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:38:42.037220 156186 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 120, 1, 17895698],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 120, 1, 17895698],"float32"), None, )

W0206 18:42:21.706827 157253 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:42:21.707768 157253 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 120, 17895698, 1],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 120, 17895698, 1],"float32"), None, )

W0206 18:46:02.159296 158358 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:46:02.161006 158358 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 120, 28, 639133],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 120, 28, 639133],"float32"), None, )

W0206 18:49:49.946830 159382 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:49:49.947903 159382 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 120, 639133, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 120, 639133, 28],"float32"), None, )

W0206 18:53:34.863595 160463 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:53:34.865065 160463 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 12707004, 13, 13],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 12707004, 13, 13],"float32"), )

W0206 18:57:15.174686 161498 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:57:15.175745 161498 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 12707004, 13, 13],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 12707004, 13, 13],"float32"), None, )

W0206 19:01:01.053994 162581 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:01:01.055047 162581 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 128, 112, 149797],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 128, 112, 149797],"float32"), None, )

W0206 19:04:41.936093 163612 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:04:41.937234 163612 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 128, 12, 1398102],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 128, 12, 1398102],"float32"), None, )

W0206 19:08:26.970937  1429 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:08:26.972074  1429 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 128, 1398102, 12],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 128, 1398102, 12],"float32"), None, )

W0206 19:12:14.707149  2473 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:12:14.708207  2473 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 128, 149797, 112],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 128, 149797, 112],"float32"), None, )

W0206 19:16:06.185252  3611 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:16:06.186543  3611 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 128, 26, 645278],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 128, 26, 645278],"float32"), )

W0206 19:20:02.478293  4665 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:20:02.479174  4665 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 128, 27, 621379],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 128, 27, 621379],"float32"), )

W0206 19:23:33.194267  5622 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:23:33.195238  5622 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 128, 28, 599187],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 128, 28, 599187],"float32"), None, )

W0206 19:27:05.083412  6633 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:27:05.084364  6633 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 128, 299594, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 128, 299594, 56],"float32"), None, )

W0206 19:30:49.232802  7656 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:30:49.233731  7656 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 128, 310690, 54],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 128, 310690, 54],"float32"), )

W0206 19:34:26.451241  8746 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:34:26.452145  8746 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 128, 54, 310690],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 128, 54, 310690],"float32"), )

W0206 19:37:53.753360  9739 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:37:53.754246  9739 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 128, 56, 299594],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 128, 56, 299594],"float32"), None, )

W0206 19:41:26.868072 10729 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:41:26.868991 10729 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 128, 599187, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 128, 599187, 28],"float32"), None, )

W0206 19:45:07.426981 11716 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:45:07.427906 11716 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 128, 621379, 27],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 128, 621379, 27],"float32"), )

W0206 19:48:41.920488 12710 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:48:41.921409 12710 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 128, 645278, 26],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 128, 645278, 26],"float32"), )

W0206 19:52:13.840598 13685 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:52:13.841516 13685 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 144, 1, 14913081],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 144, 1, 14913081],"float32"), None, )

W0206 19:55:46.266896 14670 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:55:46.268007 14670 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 144, 14913081, 1],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 144, 14913081, 1],"float32"), None, )

W0206 19:59:41.481269 15763 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:59:41.482257 15763 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 14913081, 12, 12],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 14913081, 12, 12],"float32"), )

W0206 20:03:17.110430 16760 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:03:17.111646 16760 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 14913081, 12, 12],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 14913081, 12, 12],"float32"), None, )

W0206 20:07:05.794914 17887 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:07:05.795883 17887 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 16, 10, 13421773],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 16, 10, 13421773],"float32"), None, )

W0206 20:10:53.418386 18904 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:10:53.419251 18904 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 16, 112, 1198373],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 16, 112, 1198373],"float32"), None, )

W0206 20:14:39.823964 20037 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:14:39.824992 20037 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 16, 1198373, 112],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 16, 1198373, 112],"float32"), None, )

W0206 20:18:18.803578 21065 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:18:18.804482 21065 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 16, 13421773, 10],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 16, 13421773, 10],"float32"), None, )

W0206 20:22:08.693674 22161 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:22:08.695163 22161 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 16, 2396746, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 16, 2396746, 56],"float32"), None, )

W0206 20:25:47.360828 23200 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:25:47.361946 23200 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 16, 2440323, 55],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 16, 2440323, 55],"float32"), )

W0206 20:29:27.197916 24289 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:29:27.198887 24289 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 16, 2485514, 54],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 16, 2485514, 54],"float32"), )

W0206 20:33:01.028669 25310 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:33:01.029702 25310 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 16, 28, 4793491],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 16, 28, 4793491],"float32"), None, )

W0206 20:36:35.983687 26339 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:36:35.985064 26339 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 16, 4793491, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 16, 4793491, 28],"float32"), None, )

W0206 20:40:24.799939 27375 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:40:24.800824 27375 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 16, 54, 2485514],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 16, 54, 2485514],"float32"), )

W0206 20:44:12.653390 28502 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:44:12.654345 28502 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 16, 55, 2440323],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 16, 55, 2440323],"float32"), )

W0206 20:47:52.800941 29471 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:47:52.801944 29471 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 16, 56, 2396746],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 16, 56, 2396746],"float32"), None, )

W0206 20:51:40.259922 30611 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:51:40.261193 30611 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 160, 1118482, 12],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 160, 1118482, 12],"float32"), None, )

W0206 20:55:26.544855 31674 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:55:26.546043 31674 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 160, 12, 1118482],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 160, 12, 1118482],"float32"), None, )

W0206 20:59:13.310750 32795 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:59:13.312093 32795 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 168, 1, 12782641],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 168, 1, 12782641],"float32"), None, )

W0206 21:03:00.348925 33939 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:03:00.349952 33939 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 168, 12782641, 1],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 168, 12782641, 1],"float32"), None, )

W0206 21:06:47.459587 34955 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:06:47.461015 34955 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 171197, 112, 112],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 171197, 112, 112],"float32"), )

W0206 21:10:50.201563 36103 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:10:50.202425 36103 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 171197, 112, 112],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 171197, 112, 112],"float32"), None, )

W0206 21:14:35.894774 37260 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:14:35.895853 37260 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 174295, 111, 111],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 174295, 111, 111],"float32"), None, )

W0206 21:18:14.490765 38287 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:18:14.492158 38287 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 176, 14, 871544],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 176, 14, 871544],"float32"), None, )

W0206 21:22:07.366384 39408 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:22:07.367291 39408 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 176, 28, 435772],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 176, 28, 435772],"float32"), None, )

W0206 21:25:46.724905 40414 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:25:46.726101 40414 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 176, 435772, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 176, 435772, 28],"float32"), None, )

W0206 21:29:24.631832 41533 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:29:24.632828 41533 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 176, 871544, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 176, 871544, 14],"float32"), None, )

W0206 21:32:59.079329 42542 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:32:59.080227 42542 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 180750, 109, 109],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 180750, 109, 109],"float32"), )

W0206 21:36:32.304600 43518 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:36:32.305510 43518 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 180750, 109, 109],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 180750, 109, 109],"float32"), None, )

W0206 21:40:16.724417 44549 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:40:16.725279 44549 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 192, 12, 932068],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 192, 12, 932068],"float32"), None, )

W0206 21:44:02.890558 45699 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:44:02.891721 45699 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 192, 13, 860371],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 192, 13, 860371],"float32"), )

W0206 21:47:50.481823 46800 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:47:50.482748 46800 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 192, 215093, 52],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 192, 215093, 52],"float32"), None, )

W0206 21:51:35.860532 47874 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:51:35.861589 47874 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 192, 2236963, 5],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 192, 2236963, 5],"float32"), None, )

W0206 21:55:09.659404 48882 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:55:09.660549 48882 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 192, 26, 430186],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 192, 26, 430186],"float32"), )

W0206 21:59:04.949963 50038 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:59:04.951202 50038 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 192, 27, 414253],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 192, 27, 414253],"float32"), None, )

W0206 22:02:45.341765 51096 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:02:45.342679 51096 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 192, 3, 3728271],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 192, 3, 3728271],"float16"), )

W0206 22:06:42.191854 52177 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:06:42.192844 52177 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 192, 3, 3728271],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 192, 3, 3728271],"float32"), )

W0206 22:15:26.842144 54717 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:15:26.843382 54717 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 192, 3728271, 3],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 192, 3728271, 3],"float16"), )

W0206 22:19:19.039148 55737 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:19:19.041149 55737 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 192, 3728271, 3],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 192, 3728271, 3],"float32"), )

W0206 22:28:20.165690 58327 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:28:20.166721 58327 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 192, 414253, 27],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 192, 414253, 27],"float32"), None, )

W0206 22:31:57.556015 59460 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:31:57.557000 59460 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 192, 430186, 26],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 192, 430186, 26],"float32"), )

W0206 22:35:39.129077 60541 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:35:39.130054 60541 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 192, 5, 2236963],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 192, 5, 2236963],"float32"), None, )

W0206 22:39:25.795727 61589 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:39:25.797394 61589 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 192, 52, 215093],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 192, 52, 215093],"float32"), None, )

W0206 22:43:18.609263 62732 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:43:18.610246 62732 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 192, 860371, 13],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 192, 860371, 13],"float32"), )

W0206 22:47:13.366289 63904 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:47:13.367504 63904 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 192, 932068, 12],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 192, 932068, 12],"float32"), None, )

W0206 22:50:52.944695 65037 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:50:52.945740 65037 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 2048, 14, 74899],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 2048, 14, 74899],"float32"), None, )

W0206 22:54:37.280828 66085 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:54:37.281720 66085 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 2048, 149797, 7],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 2048, 149797, 7],"float16"), )

W0206 22:58:27.760887 67149 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:58:27.761749 67149 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 2048, 149797, 7],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 2048, 149797, 7],"float32"), )

W0206 23:07:41.735980 69909 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:07:41.736886 69909 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 2048, 149797, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 2048, 149797, 7],"float32"), None, )

W0206 23:11:29.514470 70980 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:11:29.515383 70980 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 2048, 7, 149797],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 2048, 7, 149797],"float16"), )

W0206 23:15:28.848922 72145 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:15:28.849751 72145 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 2048, 7, 149797],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 2048, 7, 149797],"float32"), )

W0206 23:24:28.046646 74825 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:24:28.047503 74825 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 2048, 7, 149797],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 2048, 7, 149797],"float32"), None, )

W0206 23:28:15.312953 75878 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:28:15.313980 75878 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 2048, 74899, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 2048, 74899, 14],"float32"), None, )

W0206 23:31:50.246173 76916 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:31:50.247181 76916 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 2147483648, 1, 1],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 2147483648, 1, 1],"float16"), )

W0206 23:35:38.536928 78047 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:35:38.537818 78047 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 2147483648, 1, 1],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 2147483648, 1, 1],"float32"), )

W0206 23:44:31.434942 80584 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:44:31.436026 80584 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 2147483648, 1, 1],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 2147483648, 1, 1],"float32"), None, )

W0206 23:48:13.345008 81590 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:48:13.346004 81590 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 2147483648, 1],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 2147483648, 1],"float32"), )

W0206 23:51:57.315028 82706 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:51:57.316037 82706 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 2147483648],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 2147483648],"float32"), )

W0206 23:55:37.356236 83677 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:55:37.357228 83677 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 2147483648],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 2147483648],"float32"), None, )

W0206 23:59:18.095270 84685 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:59:18.096186 84685 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 21474837, 10, 10],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 21474837, 10, 10],"float32"), None, )

W0207 00:03:00.209201 85776 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:03:00.210124 85776 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 232, 1322343, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 232, 1322343, 7],"float32"), None, )

W0207 00:06:35.770577 86770 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:06:35.771449 86770 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 232, 14, 661172],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 232, 14, 661172],"float32"), None, )

W0207 00:10:12.449955 87742 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:10:12.450827 87742 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 232, 661172, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 232, 661172, 14],"float32"), None, )

W0207 00:13:56.533466 88765 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:13:56.534657 88765 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 232, 7, 1322343],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 232, 7, 1322343],"float32"), None, )

W0207 00:17:44.578190 89908 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:17:44.579303 89908 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 238609295, 3, 3],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 238609295, 3, 3],"float16"), )

W0207 00:21:42.028590 91058 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:21:42.029654 91058 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 238609295, 3, 3],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 238609295, 3, 3],"float32"), )

W0207 00:30:46.122902 93748 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:30:46.123802 93748 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 24, 1, 89478486],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 24, 1, 89478486],"float32"), None, )

W0207 00:34:34.059032 94875 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:34:34.060010 94875 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 24, 112, 798916],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 24, 112, 798916],"float32"), None, )

W0207 00:38:06.780249 95897 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:38:06.781194 95897 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 24, 14, 6391321],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 24, 14, 6391321],"float32"), None, )

W0207 00:41:43.842587 96921 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:41:43.843501 96921 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 24, 1597831, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 24, 1597831, 56],"float32"), None, )

W0207 00:45:29.583916 98044 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:45:29.584882 98044 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 24, 28, 3195661],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 24, 28, 3195661],"float32"), None, )

W0207 00:49:15.521230 99069 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:49:15.522140 99069 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 24, 3195661, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 24, 3195661, 28],"float32"), None, )

W0207 00:52:58.945108 100200 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:52:58.946228 100200 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 24, 56, 1597831],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 24, 56, 1597831],"float32"), None, )

W0207 00:56:41.837389 101216 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:56:41.838521 101216 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 24, 6391321, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 24, 6391321, 14],"float32"), None, )

W0207 01:00:28.541510 102264 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:00:28.542555 102264 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 24, 798916, 112],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 24, 798916, 112],"float32"), None, )

W0207 01:04:10.215797 103386 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:04:10.219812 103386 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 24, 89478486, 1],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 24, 89478486, 1],"float32"), None, )

W0207 01:07:56.735615 104520 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:07:56.736434 104520 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 240, 1, 8947849],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 240, 1, 8947849],"float32"), None, )

W0207 01:11:47.775290 105562 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:11:47.776371 105562 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 240, 8947849, 1],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 240, 8947849, 1],"float32"), None, )

W0207 01:15:43.035172 106687 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:15:43.036033 106687 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 244, 14, 628655],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 244, 14, 628655],"float32"), None, )

W0207 01:19:18.900197 107740 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:19:18.901098 107740 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 244, 28, 314328],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 244, 28, 314328],"float32"), None, )

W0207 01:22:48.298980 108739 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:22:48.299947 108739 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 244, 314328, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 244, 314328, 28],"float32"), None, )

W0207 01:26:23.676162 109854 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:26:23.677211 109854 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 244, 628655, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 244, 628655, 14],"float32"), None, )

W0207 01:29:51.656160 110843 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:29:51.657232 110843 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 256, 1, 8388608],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 256, 1, 8388608],"float16"), )

W0207 01:33:47.986728 111813 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:33:47.987623 111813 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 256, 1, 8388608],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 256, 1, 8388608],"float32"), )

W0207 01:42:43.970435 112901 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:42:43.971482 112901 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 256, 12, 699051],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 256, 12, 699051],"float32"), )

W0207 01:46:20.199852 113028 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:46:20.200917 113028 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 256, 13, 645278],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 256, 13, 645278],"float32"), )

W0207 01:49:58.923420 113139 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:49:58.924268 113139 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 256, 13, 645278],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 256, 13, 645278],"float32"), None, )

W0207 01:53:39.417301 113251 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:53:39.418277 113251 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 256, 14, 599187],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 256, 14, 599187],"float32"), None, )

W0207 01:57:16.533131 113377 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:57:16.534121 113377 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 256, 149797, 56],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 256, 149797, 56],"float16"), )

W0207 02:01:24.612901 113529 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:01:24.613757 113529 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 256, 149797, 56],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 256, 149797, 56],"float32"), )

W0207 02:10:34.118309 113756 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:10:34.119189 113756 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 256, 149797, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 256, 149797, 56],"float32"), None, )

W0207 02:14:12.033418 113880 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:14:12.034258 113880 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 256, 26, 322639],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 256, 26, 322639],"float32"), )

W0207 02:17:49.927382 113992 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:17:49.928220 113992 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 256, 27, 310690],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 256, 27, 310690],"float32"), )

W0207 02:21:29.961108 114134 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:21:29.962762 114134 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 256, 28, 299594],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 256, 28, 299594],"float32"), None, )

W0207 02:25:24.252041 114273 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:25:24.252988 114273 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 256, 299594, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 256, 299594, 28],"float32"), None, )

W0207 02:29:11.629612 114414 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:29:11.630482 114414 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 256, 310690, 27],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 256, 310690, 27],"float32"), )

W0207 02:32:53.935912 114496 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:32:53.936919 114496 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 256, 322639, 26],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 256, 322639, 26],"float32"), )

W0207 02:36:30.986423 114595 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:36:30.987742 114595 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 256, 56, 149797],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 256, 56, 149797],"float16"), )

W0207 02:40:38.294519 114707 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:40:38.295696 114707 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 256, 56, 149797],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 256, 56, 149797],"float32"), )

W0207 02:49:35.393301 114973 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:49:35.394407 114973 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 256, 56, 149797],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 256, 56, 149797],"float32"), None, )

W0207 02:53:32.284871 115126 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:53:32.285837 115126 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 256, 599187, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 256, 599187, 14],"float32"), None, )

W0207 02:57:08.675040 115225 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:57:08.676122 115225 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 256, 645278, 13],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 256, 645278, 13],"float32"), )

W0207 03:00:47.683336 115323 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:00:47.684185 115323 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 256, 645278, 13],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 256, 645278, 13],"float32"), None, )

W0207 03:04:36.141738 115449 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:04:36.142679 115449 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 256, 699051, 12],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 256, 699051, 12],"float32"), )

W0207 03:08:12.991359 115560 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:08:12.992260 115560 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 256, 8388608, 1],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 256, 8388608, 1],"float16"), )

W0207 03:12:10.758770 115687 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:12:10.759698 115687 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 256, 8388608, 1],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 256, 8388608, 1],"float32"), )

W0207 03:20:57.772387 115967 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:20:57.773456 115967 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 2739138, 28, 28],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 2739138, 28, 28],"float16"), )

W0207 03:24:43.660231 116106 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:24:43.661099 116106 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 2739138, 28, 28],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 2739138, 28, 28],"float32"), )

W0207 03:33:40.231321 116401 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:33:40.232232 116401 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 2739138, 28, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 2739138, 28, 28],"float32"), None, )

W0207 03:37:29.243731 116568 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:37:29.244525 116568 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 2945794, 27, 27],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 2945794, 27, 27],"float32"), )

W0207 03:41:09.639247 116694 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:41:09.640125 116694 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 2945794, 27, 27],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 2945794, 27, 27],"float32"), None, )

W0207 03:45:00.144590 116821 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:45:00.145534 116821 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 3, 715827883],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 3, 715827883],"float32"), )

W0207 03:48:44.269940 116947 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:48:44.270812 116947 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 300, 7158279],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 300, 7158279],"float32"), )

W0207 03:52:11.073657 117058 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:52:11.074558 117058 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 3176751, 26, 26],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 3176751, 26, 26],"float32"), )

W0207 03:55:45.847846 117185 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:55:45.848760 117185 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 32, 1, 67108864],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 32, 1, 67108864],"float32"), None, )

W0207 03:59:37.381749 117311 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:59:37.382649 117311 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 32, 109, 615678],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 32, 109, 615678],"float32"), None, )

W0207 04:03:30.921240 117470 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:03:30.922214 117470 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 32, 111, 604585],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 32, 111, 604585],"float32"), None, )

W0207 04:07:22.239504 117590 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:07:22.240378 117590 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 32, 112, 599187],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 32, 112, 599187],"float32"), None, )

W0207 04:11:15.634215 117708 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:11:15.635066 117708 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 32, 1242757, 54],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 32, 1242757, 54],"float32"), )

W0207 04:15:04.637923 117849 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:15:04.638927 117849 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 32, 14, 4793491],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 32, 14, 4793491],"float32"), None, )

W0207 04:18:46.316488 117997 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:18:46.317591 117997 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 32, 2396746, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 32, 2396746, 28],"float32"), None, )

W0207 04:22:34.654712 118136 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:22:34.655525 118136 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 32, 2485514, 27],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 32, 2485514, 27],"float32"), )

W0207 04:26:07.308506 118262 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:26:07.309536 118262 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 32, 25, 2684355],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 32, 25, 2684355],"float32"), None, )

W0207 04:29:57.283306 118402 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:29:57.284180 118402 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 32, 2581111, 26],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 32, 2581111, 26],"float32"), )

W0207 04:33:28.972621 118530 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:33:28.973728 118530 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 32, 26, 2581111],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 32, 26, 2581111],"float32"), )

W0207 04:37:00.156636 118655 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:37:00.157542 118655 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 32, 2684355, 25],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 32, 2684355, 25],"float32"), None, )

W0207 04:40:41.002380 118795 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:40:41.003607 118795 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 32, 27, 2485514],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 32, 27, 2485514],"float32"), )

W0207 04:44:20.062100 118934 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:44:20.062934 118934 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 32, 28, 2396746],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 32, 28, 2396746],"float32"), None, )

W0207 04:47:55.620808 119059 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:47:55.621709 119059 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 32, 4793491, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 32, 4793491, 14],"float32"), None, )

W0207 04:51:34.370756 119185 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:51:34.371711 119185 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 32, 54, 1242757],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 32, 54, 1242757],"float32"), )

W0207 04:55:18.321769 119297 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:55:18.322672 119297 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 32, 599187, 112],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 32, 599187, 112],"float32"), None, )

W0207 04:58:56.337908 119410 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:58:56.338805 119410 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 32, 604585, 111],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 32, 604585, 111],"float32"), None, )

W0207 05:02:33.622804 119536 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:02:33.623656 119536 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 32, 615678, 109],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 32, 615678, 109],"float32"), None, )

W0207 05:06:10.583451 119661 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:06:10.584337 119661 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 32, 67108864, 1],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 32, 67108864, 1],"float32"), None, )

W0207 05:10:01.689800 119787 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:10:01.690671 119787 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 320, 1342178, 5],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 320, 1342178, 5],"float32"), None, )

W0207 05:13:51.163184 119900 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:13:51.164122 119900 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 320, 5, 1342178],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 320, 5, 1342178],"float32"), None, )

W0207 05:17:39.782011 120039 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:17:39.782821 120039 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 33554432, 8, 8],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 33554432, 8, 8],"float16"), )

W0207 05:21:27.576900 120110 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:21:27.578722 120110 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 33554432, 8, 8],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 33554432, 8, 8],"float32"), )

W0207 05:30:24.633812 120321 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:30:24.634742 120321 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 3435974, 25, 25],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 3435974, 25, 25],"float32"), None, )

W0207 05:34:01.605882 120419 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:34:01.607008 120419 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 352, 14, 435772],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 352, 14, 435772],"float32"), None, )

W0207 05:37:40.304351 120518 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:37:40.305209 120518 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 352, 435772, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 352, 435772, 14],"float32"), None, )

W0207 05:41:25.915961 120642 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:41:25.916891 120642 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 352, 7, 871544],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 352, 7, 871544],"float32"), None, )

W0207 05:45:24.078820 120727 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:45:24.079665 120727 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 352, 871544, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 352, 871544, 7],"float32"), None, )

W0207 05:49:00.615458 120837 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:49:00.616331 120837 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 384, 1, 5592406],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 384, 1, 5592406],"float16"), )

W0207 05:52:49.718546 120949 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:52:49.719566 120949 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 384, 1, 5592406],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 384, 1, 5592406],"float32"), )

W0207 06:01:50.003836 121203 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:01:50.004750 121203 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 384, 1118482, 5],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 384, 1118482, 5],"float32"), None, )

W0207 06:05:21.626724 121287 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:05:21.627771 121287 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 384, 12, 466034],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 384, 12, 466034],"float32"), None, )

W0207 06:09:03.876592 121385 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:09:03.877817 121385 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 384, 13, 430186],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 384, 13, 430186],"float32"), )

W0207 06:12:44.401023 121469 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:12:44.401954 121469 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 384, 430186, 13],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 384, 430186, 13],"float32"), )

W0207 06:16:34.229195 121580 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:16:34.230505 121580 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 384, 466034, 12],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 384, 466034, 12],"float32"), None, )

W0207 06:20:22.110702 121666 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:20:22.111593 121666 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 384, 5, 1118482],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 384, 5, 1118482],"float32"), None, )

W0207 06:24:04.525388 121768 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:24:04.526342 121768 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 384, 5592406, 1],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 384, 5592406, 1],"float16"), )

W0207 06:27:48.718003 121874 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:27:48.718907 121874 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 384, 5592406, 1],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 384, 5592406, 1],"float32"), )

W0207 06:36:40.749329 122099 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:36:40.750273 122099 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 4, 67108864, 8],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 4, 67108864, 8],"float32"), )

W0207 06:40:23.977311 122197 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:40:23.978179 122197 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 4, 8, 67108864],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 4, 8, 67108864],"float32"), )

W0207 06:44:12.438048 122281 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:44:12.438975 122281 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 40, 1, 53687092],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 40, 1, 53687092],"float32"), None, )

W0207 06:47:55.805333 122365 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:47:55.806396 122365 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 40, 53687092, 1],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 40, 53687092, 1],"float32"), None, )

W0207 06:51:27.537259 122448 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:51:27.538264 122448 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 42800, 224, 224],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 42800, 224, 224],"float32"), None, )

W0207 06:54:58.590869 122560 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:54:58.591787 122560 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 43826197, 7, 7],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 43826197, 7, 7],"float16"), )

W0207 06:58:53.919222 122687 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:58:53.920068 122687 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 43826197, 7, 7],"float16"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 43826197, 7, 7],"float16"), None, )

W0207 07:08:03.764115 122980 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:08:03.765038 122980 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 43826197, 7, 7],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 43826197, 7, 7],"float32"), )

W0207 07:16:49.887867 123229 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:16:49.888861 123229 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 43826197, 7, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 43826197, 7, 7],"float32"), None, )

W0207 07:20:43.139261 123331 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:20:43.140107 123331 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 448, 5, 958699],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 448, 5, 958699],"float32"), None, )

W0207 07:24:40.550652 123442 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:24:40.551625 123442 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 448, 958699, 5],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 448, 958699, 5],"float32"), None, )

W0207 07:28:14.870779 123551 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:28:14.871645 123551 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 48, 13, 3441481],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 48, 13, 3441481],"float32"), )

W0207 07:31:49.142971 123649 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:31:49.143857 123649 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 48, 14, 3195661],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 48, 14, 3195661],"float32"), None, )

W0207 07:35:25.998930 123764 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:35:25.999958 123764 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 48, 1597831, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 48, 1597831, 28],"float32"), None, )

W0207 07:39:11.025861 123919 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:39:11.026816 123919 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 48, 1720741, 26],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 48, 1720741, 26],"float32"), )

W0207 07:42:48.136370 124058 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:42:48.137262 124058 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 48, 1789570, 25],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 48, 1789570, 25],"float32"), None, )

W0207 07:46:28.931653 124157 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:46:28.932575 124157 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 48, 25, 1789570],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 48, 25, 1789570],"float32"), None, )

W0207 07:50:06.309491 124281 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:50:06.310357 124281 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 48, 26, 1720741],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 48, 26, 1720741],"float32"), )

W0207 07:53:44.529556 124407 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:53:44.530475 124407 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 48, 28, 1597831],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 48, 28, 1597831],"float32"), None, )

W0207 07:57:20.916234 124540 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:57:20.917420 124540 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 48, 3195661, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 48, 3195661, 14],"float32"), None, )

W0207 08:01:06.548791 124674 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:01:06.549751 124674 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 48, 3441481, 13],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 48, 3441481, 13],"float32"), )

W0207 08:04:40.911171 124799 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:04:40.912205 124799 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 48, 6391321, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 48, 6391321, 7],"float32"), None, )

W0207 08:08:16.205534 124927 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:08:16.206864 124927 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 48, 7, 6391321],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 48, 7, 6391321],"float32"), None, )

W0207 08:12:06.145345 125025 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:12:06.146342 125025 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 480, 165701, 27],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 480, 165701, 27],"float32"), )

W0207 08:15:46.504047 125109 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:15:46.505275 125109 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 480, 27, 165701],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 480, 27, 165701],"float32"), )

W0207 08:19:31.100188 125262 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:19:31.101111 125262 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 488, 14, 314328],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 488, 14, 314328],"float32"), None, )

W0207 08:23:10.074848 125387 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:23:10.076453 125387 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 488, 314328, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 488, 314328, 14],"float32"), None, )

W0207 08:26:56.961046 125541 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:26:56.961969 125541 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 488, 628655, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 488, 628655, 7],"float32"), None, )

W0207 08:30:45.948303 125656 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:30:45.949234 125656 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 488, 7, 628655],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 488, 7, 628655],"float32"), None, )

W0207 08:34:30.257305 125809 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:34:30.258203 125809 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 512, 13, 322639],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 512, 13, 322639],"float32"), )

W0207 08:38:28.968168 125906 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:38:28.969213 125906 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 512, 14, 299594],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 512, 14, 299594],"float32"), None, )

W0207 08:42:10.572341 126045 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:42:10.573274 126045 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 512, 149797, 28],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 512, 149797, 28],"float16"), )

W0207 08:46:10.545593 126187 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:46:10.546617 126187 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 512, 149797, 28],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 512, 149797, 28],"float32"), )

W0207 08:55:04.328148 126479 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:55:04.329133 126479 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 512, 149797, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 512, 149797, 28],"float32"), None, )

W0207 08:58:47.951922 126620 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:58:47.952811 126620 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 512, 28, 149797],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 512, 28, 149797],"float16"), )

W0207 09:02:38.824837 126731 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:02:38.825767 126731 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 512, 28, 149797],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 512, 28, 149797],"float32"), )

W0207 09:11:32.792455 126997 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:11:32.793402 126997 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 512, 28, 149797],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 512, 28, 149797],"float32"), None, )

W0207 09:15:30.493933 127111 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:15:30.494818 127111 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 512, 299594, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 512, 299594, 14],"float32"), None, )

W0207 09:19:20.699532 127264 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:19:20.700485 127264 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 512, 322639, 13],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 512, 322639, 13],"float32"), )

W0207 09:23:17.028013 127377 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:23:17.028885 127377 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 512, 56, 74899],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 512, 56, 74899],"float32"), None, )

W0207 09:26:51.975258 127504 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:26:51.976225 127504 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 512, 599187, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 512, 599187, 7],"float32"), None, )

W0207 09:30:25.263557 127642 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:30:25.264539 127642 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 512, 7, 599187],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 512, 7, 599187],"float32"), None, )

W0207 09:34:15.287997 127769 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:34:15.289249 127769 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 512, 74899, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 512, 74899, 56],"float32"), None, )

W0207 09:37:56.971050 128765 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:37:56.971977 128765 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 528, 13, 312862],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 528, 13, 312862],"float32"), )

W0207 09:41:50.670722 129802 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:41:50.671715 129802 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 528, 312862, 13],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 528, 312862, 13],"float32"), )

W0207 09:45:37.505456 130882 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:45:37.506397 130882 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 536870912, 4],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 536870912, 4],"float32"), )

W0207 09:49:27.816797 131833 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:49:27.817860 131833 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 58, 1322343, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 58, 1322343, 28],"float32"), None, )

W0207 09:53:25.229251 132873 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:53:25.230162 132873 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 58, 28, 1322343],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 58, 28, 1322343],"float32"), None, )

W0207 09:57:06.307415 133893 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:57:06.311864 133893 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 58, 56, 661172],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 58, 56, 661172],"float32"), None, )

W0207 10:00:48.373519 134976 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:00:48.374395 134976 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 58, 661172, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 58, 661172, 56],"float32"), None, )

W0207 10:04:25.017107 135976 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:04:25.018096 135976 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 59652324, 6, 6],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 59652324, 6, 6],"float32"), )

W0207 10:08:12.476171 137076 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:08:12.477022 137076 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 6, 12782641, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 6, 12782641, 28],"float32"), None, )

W0207 10:11:43.357648 138071 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:11:43.358707 138071 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 6, 28, 12782641],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 6, 28, 12782641],"float32"), None, )

W0207 10:15:17.409945 139093 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:15:17.411013 139093 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 1, 33554432],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 1, 33554432],"float32"), None, )

W0207 10:18:58.601326 140109 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:18:58.602334 140109 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 109, 307839],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 109, 307839],"float32"), None, )

W0207 10:22:44.168200 141215 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:22:44.169108 141215 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 112, 299594],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 112, 299594],"float32"), )

W0207 10:26:33.927887 142223 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:26:33.928895 142223 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 112, 299594],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 112, 299594],"float32"), None, )

W0207 10:30:12.408051 143330 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:30:12.408995 143330 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 12, 2796203],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 12, 2796203],"float32"), )

W0207 10:33:54.445832 144337 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:33:54.446771 144337 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 1290556, 26],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 1290556, 26],"float32"), )

W0207 10:37:47.758827 145501 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:37:47.759768 145501 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 13, 2581111],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 13, 2581111],"float32"), )

W0207 10:41:26.218946 146533 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:41:26.219898 146533 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 1342178, 25],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 1342178, 25],"float32"), None, )

W0207 10:45:22.478489 147659 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:45:22.479434 147659 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 14, 2396746],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 14, 2396746],"float32"), None, )

W0207 10:49:17.663401 148790 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:49:17.664287 148790 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 149797, 224],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 149797, 224],"float32"), None, )

W0207 10:52:54.573998 149784 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:52:54.575083 149784 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 224, 149797],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 224, 149797],"float32"), None, )

W0207 10:56:38.084388 150811 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:56:38.085853 150811 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 2396746, 14],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 2396746, 14],"float32"), None, )

W0207 11:00:15.883486 151848 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:00:15.884689 151848 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 25, 1342178],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 25, 1342178],"float32"), None, )

W0207 11:04:16.772917 152851 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:04:16.774322 152851 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 2581111, 13],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 2581111, 13],"float32"), )

W0207 11:08:06.532663 154078 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:08:06.533656 154078 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 26, 1290556],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 26, 1290556],"float32"), )

W0207 11:11:53.857736 155121 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:11:53.858642 155121 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 2796203, 12],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 2796203, 12],"float32"), )

W0207 11:15:38.261966 156250 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:15:38.263024 156250 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 299594, 112],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 299594, 112],"float32"), )

W0207 11:19:12.407091 157257 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:19:12.407974 157257 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 299594, 112],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 299594, 112],"float32"), None, )

W0207 11:23:03.272352 158262 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:23:03.273272 158262 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 307839, 109],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 307839, 109],"float32"), None, )

W0207 11:27:05.859740 159357 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:27:05.861034 159357 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 33554432, 1],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 33554432, 1],"float32"), None, )

W0207 11:30:57.063068 160488 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:30:57.063931 160488 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 4793491, 7],"float16"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 4793491, 7],"float16"), None, )

W0207 11:34:51.003288 161530 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:34:51.004330 161530 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 4793491, 7],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 4793491, 7],"float32"), None, )

W0207 11:43:52.770455   432 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:43:52.771431   432 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 54, 621379],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 54, 621379],"float32"), )

W0207 11:47:36.703796  1527 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:47:36.704986  1527 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 55, 610081],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 55, 610081],"float32"), )

W0207 11:51:34.644236  2626 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:51:34.645179  2626 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 55, 610081],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 55, 610081],"float32"), None, )

W0207 11:55:16.989823  3582 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:55:16.990711  3582 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 56, 599187],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 56, 599187],"float32"), None, )

W0207 11:59:07.939857  4630 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:59:07.940928  4630 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 599187, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 599187, 56],"float32"), None, )

W0207 12:02:54.485850  5744 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:02:54.487516  5744 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 610081, 55],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 610081, 55],"float32"), )

W0207 12:06:56.659164  6870 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:06:56.660025  6870 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 610081, 55],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 610081, 55],"float32"), None, )

W0207 12:10:36.266006  7959 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:10:36.266917  7959 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 621379, 54],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 621379, 54],"float32"), )

W0207 12:14:15.045578  8985 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:14:15.046464  8985 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 7, 4793491],"float16"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 7, 4793491],"float16"), None, )

W0207 12:18:04.271061  9977 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:18:04.272092  9977 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 64, 7, 4793491],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 64, 7, 4793491],"float32"), None, )

W0207 12:26:59.891059 12474 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:26:59.892577 12474 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 684785, 56, 56],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 684785, 56, 56],"float16"), )

W0207 12:30:51.568253 13582 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:30:51.569263 13582 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 684785, 56, 56],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 684785, 56, 56],"float32"), )

W0207 12:39:39.252089 16103 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:39:39.252971 16103 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 684785, 56, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 684785, 56, 56],"float32"), None, )

W0207 12:43:12.381752 17101 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:43:12.382783 17101 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 709912, 55, 55],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 709912, 55, 55],"float32"), )

W0207 12:46:45.813906 18082 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:46:45.815016 18082 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 709912, 55, 55],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 709912, 55, 55],"float32"), None, )

W0207 12:50:24.499011 19073 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:50:24.499961 19073 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 72, 1, 29826162],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 72, 1, 29826162],"float32"), None, )

W0207 12:54:08.120110 20141 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:54:08.121076 20141 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 72, 1065221, 28],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 72, 1065221, 28],"float32"), None, )

W0207 12:57:40.101563 21132 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:57:40.102527 21132 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 72, 28, 1065221],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 72, 28, 1065221],"float32"), None, )

W0207 13:01:20.319577 22125 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:01:20.320744 22125 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 72, 29826162, 1],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 72, 29826162, 1],"float32"), None, )

W0207 13:05:08.608022 23242 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:05:08.608928 23242 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 72, 532611, 56],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 72, 532611, 56],"float32"), None, )

W0207 13:09:42.212253 24504 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:09:42.213650 24504 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 72, 56, 532611],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 72, 56, 532611],"float32"), None, )

W0207 13:13:19.122994 25527 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:13:19.123950 25527 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 736449, 54, 54],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 736449, 54, 54],"float32"), )

W0207 13:16:50.315698 26519 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:16:50.316645 26519 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 736449, 54, 54],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 736449, 54, 54],"float32"), None, )

W0207 13:20:38.588645 27628 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:20:38.589550 27628 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 794188, 52, 52],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 794188, 52, 52],"float32"), None, )

W0207 13:24:25.465037 28630 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:24:25.466012 28630 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 8, 1, 268435456],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 8, 1, 268435456],"float32"), None, )

W0207 13:28:09.395655 29651 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:28:09.396793 29651 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 8, 268435456, 1],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 8, 268435456, 1],"float32"), None, )

W0207 13:32:16.211398 30784 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:32:16.212575 30784 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 8, 33554432, 8],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 8, 33554432, 8],"float16"), )

W0207 13:36:26.608703 32000 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:36:26.609644 32000 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 8, 33554432, 8],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 8, 33554432, 8],"float32"), )

W0207 13:45:18.135777 34525 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:45:18.136720 34525 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 8, 8, 33554432],"float16"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 8, 8, 33554432],"float16"), )

W0207 13:49:11.596047 35530 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:49:11.596973 35530 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 8, 8, 33554432],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 8, 8, 33554432],"float32"), )

W0207 13:58:17.617389 38184 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:58:17.618351 38184 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 80, 497103, 54],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 80, 497103, 54],"float32"), None, )

W0207 14:02:18.665508 39301 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:02:18.666556 39301 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 80, 54, 497103],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 80, 54, 497103],"float32"), None, )

W0207 14:06:03.472115 40324 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:06:03.473255 40324 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 832, 13, 198547],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 832, 13, 198547],"float32"), )

W0207 14:10:01.420487 41438 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:10:01.422124 41438 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 832, 198547, 13],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 832, 198547, 13],"float32"), )

W0207 14:13:54.214025 42521 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:13:54.214946 42521 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 832, 430186, 6],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 832, 430186, 6],"float32"), )

W0207 14:17:44.058954 43746 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:17:44.060250 43746 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 832, 6, 430186],"float32"), )
[Pass] paddle.nn.functional.relu(Tensor([2, 832, 6, 430186],"float32"), )

W0207 14:21:40.424608 44813 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:21:40.425757 44813 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.nn.functional.relu(Tensor([2, 85899346, 5, 5],"float32"), None, )
[Pass] paddle.nn.functional.relu(Tensor([2, 85899346, 5, 5],"float32"), None, )

W0207 14:25:39.271518 46115 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:25:39.272428 46115 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

Traceback (most recent call last):
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 70, in <module>
    main()
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 65, in main
    print(str(res.stdout.read(), encoding="utf-8"), flush=True)
KeyboardInterrupt
