test begin: paddle.concat(list[Tensor([64, 67108864],"float16"),Tensor([64, 32],"float16"),], axis=-1, )
[Pass] paddle.concat(list[Tensor([64, 67108864],"float16"),Tensor([64, 32],"float16"),], axis=-1, )

W0208 14:36:49.932472 79043 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 14:36:49.933368 79043 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([64, 67108864],"float16"),Tensor([64, 67108864],"float16"),], axis=-1, )
[Pass] paddle.concat(list[Tensor([64, 67108864],"float16"),Tensor([64, 67108864],"float16"),], axis=-1, )

W0208 14:47:48.473538 83969 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 14:47:48.474519 83969 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([64, 67108864],"float32"),Tensor([64, 67108864],"float32"),], 0, )
[paddle error] paddle.concat(list[Tensor([64, 67108864],"float32"),Tensor([64, 67108864],"float32"),], 0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0208 15:05:59.923482 93221 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:05:59.924363 93221 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([64, 67108864],"float32"),Tensor([64, 96],"float32"),], 0, )
[torch error] paddle.concat(list[Tensor([64, 67108864],"float32"),Tensor([64, 96],"float32"),], 0, ) 
 Sizes of tensors must match except in dimension 0. Expected size 67108864 but got size 96 for tensor number 1 in the list.

W0208 15:07:17.956300 94426 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:07:17.957396 94426 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([64, 96],"float32"),Tensor([44739243, 96],"float32"),], 0, )
[Pass] paddle.concat(list[Tensor([64, 96],"float32"),Tensor([44739243, 96],"float32"),], 0, )

W0208 15:08:39.353406 94959 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:08:39.354423 94959 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([64, 96],"float32"),Tensor([64, 67108864],"float32"),], 0, )
[torch error] paddle.concat(list[Tensor([64, 96],"float32"),Tensor([64, 67108864],"float32"),], 0, ) 
 Sizes of tensors must match except in dimension 0. Expected size 96 but got size 67108864 for tensor number 1 in the list.

W0208 15:12:14.423810 96887 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:12:14.425047 96887 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([65, 32],"float16"),Tensor([134217728, 32],"float16"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([65, 32],"float16"),Tensor([134217728, 32],"float16"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 65 but got size 134217728 for tensor number 1 in the list.

W0208 15:13:46.350273 97419 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:13:46.351531 97419 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([65, 32],"float16"),Tensor([65, 66076420],"float16"),], axis=-1, )
[Pass] paddle.concat(list[Tensor([65, 32],"float16"),Tensor([65, 66076420],"float16"),], axis=-1, )

W0208 15:15:17.655519 98157 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:15:17.656920 98157 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([65, 66076420],"float16"),Tensor([65, 32],"float16"),], axis=-1, )
[Pass] paddle.concat(list[Tensor([65, 66076420],"float16"),Tensor([65, 32],"float16"),], axis=-1, )

W0208 15:24:41.800282 102676 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:24:41.801677 102676 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([65, 66076420],"float16"),Tensor([65, 66076420],"float16"),], axis=-1, )
[Pass] paddle.concat(list[Tensor([65, 66076420],"float16"),Tensor([65, 66076420],"float16"),], axis=-1, )

W0208 15:35:48.112948 107872 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:35:48.113945 107872 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([65075263, 66],"float32"),Tensor([2, 66],"float32"),Tensor([2, 66],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([65075263, 66],"float32"),Tensor([2, 66],"float32"),Tensor([2, 66],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 65075263 but got size 2 for tensor number 1 in the list.

W0208 15:54:18.613111 117927 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:54:18.614692 117927 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([65075263, 66],"float32"),Tensor([65075263, 66],"float32"),Tensor([65075263, 66],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([65075263, 66],"float32"),Tensor([65075263, 66],"float32"),Tensor([65075263, 66],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 57575 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0208 15:57:55.411689 118446 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:57:55.412791 118446 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([65218, 1344, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([65218, 1344, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 65218 but got size 2 for tensor number 1 in the list.

W0208 15:59:12.194645 120407 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 15:59:12.195624 120407 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([65218, 1344, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([65218, 1344, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 65218 but got size 2 for tensor number 1 in the list.

W0208 16:00:37.359032 120922 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:00:37.359993 120922 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([65218, 1344, 7, 7],"float32"),Tensor([65218, 32, 7, 7],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([65218, 1344, 7, 7],"float32"),Tensor([65218, 32, 7, 7],"float32"),], axis=1, )

W0208 16:01:57.809240 121668 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:01:57.810133 121668 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([65218, 1344, 7, 7],"float32"),Tensor([65218, 48, 7, 7],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([65218, 1344, 7, 7],"float32"),Tensor([65218, 48, 7, 7],"float32"),], axis=1, )

W0208 16:05:35.888142 123352 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:05:35.888984 123352 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([65536, 8, 128, 64],"float16"),Tensor([2, 8, 1, 64],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([65536, 8, 128, 64],"float16"),Tensor([2, 8, 1, 64],"float16"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 65536 but got size 2 for tensor number 1 in the list.

W0208 16:09:54.634224 125255 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:09:54.635248 125255 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([65536, 8, 128, 64],"float16"),Tensor([65536, 8, 1, 64],"float16"),], axis=2, )
[Pass] paddle.concat(list[Tensor([65536, 8, 128, 64],"float16"),Tensor([65536, 8, 1, 64],"float16"),], axis=2, )

W0208 16:11:36.149008 126016 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:11:36.149927 126016 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([66809, 1312, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([66809, 1312, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 66809 but got size 2 for tensor number 1 in the list.

W0208 16:21:20.816704 130747 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:21:20.817720 130747 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([66809, 1312, 7, 7],"float32"),Tensor([66809, 32, 7, 7],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([66809, 1312, 7, 7],"float32"),Tensor([66809, 32, 7, 7],"float32"),], axis=1, )

W0208 16:22:48.977357 131447 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:22:48.978494 131447 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([67108864, 2, 8, 4],"float32"),Tensor([1, 2, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([67108864, 2, 8, 4],"float32"),Tensor([1, 2, 8, 4],"float32"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 3. Expected size 67108864 but got size 1 for tensor number 1 in the list.

W0208 16:26:46.025913 133638 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:26:46.026914 133638 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([67108864, 2, 8, 4],"float32"),Tensor([67108864, 2, 8, 4],"float32"),], axis=-1, )
[paddle error] paddle.concat(list[Tensor([67108864, 2, 8, 4],"float32"),Tensor([67108864, 2, 8, 4],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0208 16:29:10.358371 134339 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:29:10.361452 134339 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([67108864, 64],"float32"),Tensor([128, 64],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([67108864, 64],"float32"),Tensor([128, 64],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 67108864 but got size 128 for tensor number 1 in the list.

W0208 16:30:33.385344 135526 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:30:33.386376 135526 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([67108864, 64],"float32"),Tensor([2048, 64],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([67108864, 64],"float32"),Tensor([2048, 64],"float32"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 67108864 but got size 2048 for tensor number 1 in the list.

W0208 16:31:51.142117 136218 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:31:51.143137 136218 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([67108864, 64],"float32"),Tensor([67108864, 64],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([67108864, 64],"float32"),Tensor([67108864, 64],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0208 16:34:44.574633 136724 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:34:44.575994 136724 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([67108864, 64],"float32"),Tensor([67108864, 64],"float32"),], axis=-1, )
[paddle error] paddle.concat(list[Tensor([67108864, 64],"float32"),Tensor([67108864, 64],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0208 16:37:11.752450 138105 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:37:11.755292 138105 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([67108864, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=2, )
[torch error] paddle.concat(list[Tensor([67108864, 8, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 67108864 but got size 2 for tensor number 1 in the list.

W0208 16:38:28.876673 139319 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:38:28.877795 139319 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([67108864, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),], axis=2, )
[paddle error] paddle.concat(list[Tensor([67108864, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),], axis=2, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0208 16:41:06.097642 140021 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:41:06.098510 140021 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([67108865, 4, 8],"float64"),Tensor([12, 4, 8],"float64"),], -1, )
[torch error] paddle.concat(list[Tensor([67108865, 4, 8],"float64"),Tensor([12, 4, 8],"float64"),], -1, ) 
 Sizes of tensors must match except in dimension 2. Expected size 67108865 but got size 12 for tensor number 1 in the list.

W0208 16:41:55.404187 141227 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:41:55.405386 141227 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([67108865, 4, 8],"float64"),Tensor([67108865, 4, 8],"float64"),], -1, )
[paddle error] paddle.concat(list[Tensor([67108865, 4, 8],"float64"),Tensor([67108865, 4, 8],"float64"),], -1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0208 16:43:46.660926 141703 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:43:46.661998 141703 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([671089, 256, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([671089, 256, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 671089 but got size 1 for tensor number 1 in the list.

W0208 16:44:55.279160 142447 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:44:55.280197 142447 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([671089, 256, 5, 5],"float32"),Tensor([671089, 32, 5, 5],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([671089, 256, 5, 5],"float32"),Tensor([671089, 32, 5, 5],"float32"),], axis=1, )

W0208 16:46:26.753523 143120 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:46:26.754724 143120 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([67109, 160, 20, 20],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([67109, 160, 20, 20],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 67109 but got size 1 for tensor number 1 in the list.

W0208 16:50:37.294569 145066 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:50:37.295717 145066 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([67109, 160, 20, 20],"float32"),Tensor([67109, 32, 20, 20],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([67109, 160, 20, 20],"float32"),Tensor([67109, 32, 20, 20],"float32"),], axis=1, )

W0208 16:52:16.342994 145752 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:52:16.343984 145752 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([67634, 1296, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([67634, 1296, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 67634 but got size 2 for tensor number 1 in the list.

W0208 16:56:18.470397 147857 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:56:18.471534 147857 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([67634, 1296, 7, 7],"float32"),Tensor([67634, 48, 7, 7],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([67634, 1296, 7, 7],"float32"),Tensor([67634, 48, 7, 7],"float32"),], axis=1, )

W0208 16:57:41.856225 148365 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 16:57:41.857872 148365 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([684785, 32, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([684785, 32, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 684785 but got size 2 for tensor number 1 in the list.

W0208 17:01:27.195894 150237 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:01:27.196967 150237 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([684785, 32, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([684785, 32, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000016GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0208 17:03:58.314234 150917 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:03:58.315233 150917 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([68479, 1280, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([68479, 1280, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 68479 but got size 2 for tensor number 1 in the list.

W0208 17:05:11.066565 152098 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:05:11.067664 152098 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([68479, 1280, 7, 7],"float32"),Tensor([68479, 32, 7, 7],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([68479, 1280, 7, 7],"float32"),Tensor([68479, 32, 7, 7],"float32"),], axis=1, )

W0208 17:06:32.844672 152593 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:06:32.845474 152593 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([68479, 320, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([68479, 320, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 68479 but got size 2 for tensor number 1 in the list.

W0208 17:10:15.032563 154451 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:10:15.033504 154451 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([68479, 320, 14, 14],"float32"),Tensor([68479, 32, 14, 14],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([68479, 320, 14, 14],"float32"),Tensor([68479, 32, 14, 14],"float32"),], axis=1, )

W0208 17:11:41.904403 154952 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:11:41.905313 154952 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([70235, 1248, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([70235, 1248, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 70235 but got size 2 for tensor number 1 in the list.

W0208 17:15:26.886440 156806 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:15:26.887432 156806 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([70235, 1248, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([70235, 1248, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 70235 but got size 2 for tensor number 1 in the list.

W0208 17:16:42.553427 157485 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:16:42.554488 157485 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([70235, 1248, 7, 7],"float32"),Tensor([70235, 32, 7, 7],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([70235, 1248, 7, 7],"float32"),Tensor([70235, 32, 7, 7],"float32"),], axis=1, )

W0208 17:18:03.948204 158013 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:18:03.949011 158013 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([70235, 1248, 7, 7],"float32"),Tensor([70235, 48, 7, 7],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([70235, 1248, 7, 7],"float32"),Tensor([70235, 48, 7, 7],"float32"),], axis=1, )

W0208 17:21:43.752451 159641 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:21:43.753829 159641 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([7134, 192, 56, 56],"float32"),Tensor([2, 32, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([7134, 192, 56, 56],"float32"),Tensor([2, 32, 56, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7134 but got size 2 for tensor number 1 in the list.

W0208 17:25:30.590883 161528 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:25:30.591732 161528 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([7134, 192, 56, 56],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([7134, 192, 56, 56],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7134 but got size 2 for tensor number 1 in the list.

W0208 17:26:42.125635 162221 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:26:42.126806 162221 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([7134, 192, 56, 56],"float32"),Tensor([7134, 32, 56, 56],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([7134, 192, 56, 56],"float32"),Tensor([7134, 32, 56, 56],"float32"),], axis=1, )

W0208 17:28:13.773200 162723 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:28:13.774195 162723 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([7134, 192, 56, 56],"float32"),Tensor([7134, 48, 56, 56],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([7134, 192, 56, 56],"float32"),Tensor([7134, 48, 56, 56],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 20.002327GB memory on GPU 0, 61.596619GB memory has been allocated and available memory is only 17.588257GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0208 17:33:04.352407  1580 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:33:04.353256  1580 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([715827883, 3],"float64"),Tensor([2, 3],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([715827883, 3],"float64"),Tensor([2, 3],"float64"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 715827883 but got size 2 for tensor number 1 in the list.

W0208 17:34:04.054966  2313 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:34:04.056185  2313 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([715827883, 3],"float64"),Tensor([2, 3],"float64"),Tensor([2, 3],"float64"),], )
[Pass] paddle.concat(list[Tensor([715827883, 3],"float64"),Tensor([2, 3],"float64"),Tensor([2, 3],"float64"),], )

W0208 17:35:04.378103  2739 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:35:04.378991  2739 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([715827883, 3],"float64"),Tensor([2, 3],"float64"),Tensor([2, 3],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([715827883, 3],"float64"),Tensor([2, 3],"float64"),Tensor([2, 3],"float64"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 715827883 but got size 2 for tensor number 1 in the list.

W0208 17:37:59.347178  4161 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:37:59.348177  4161 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([715827883, 3],"float64"),Tensor([715827883, 3],"float64"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([715827883, 3],"float64"),Tensor([715827883, 3],"float64"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0208 17:39:39.784499  4609 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:39:39.785410  4609 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([715827883, 3],"float64"),Tensor([715827883, 3],"float64"),Tensor([715827883, 3],"float64"),], )
[torch error] paddle.concat(list[Tensor([715827883, 3],"float64"),Tensor([715827883, 3],"float64"),Tensor([715827883, 3],"float64"),], ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 87314 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0208 17:41:51.652467  5367 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:41:51.653566  5367 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([715827883, 3],"float64"),Tensor([715827883, 3],"float64"),Tensor([715827883, 3],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([715827883, 3],"float64"),Tensor([715827883, 3],"float64"),Tensor([715827883, 3],"float64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 42788 has 49.00 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 6.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0208 17:43:57.022730  6326 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:43:57.023844  6326 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([7158279, 24, 5, 5],"float32"),Tensor([1, 24, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([7158279, 24, 5, 5],"float32"),Tensor([1, 24, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7158279 but got size 1 for tensor number 1 in the list.

W0208 17:45:16.187994  7476 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:45:16.189051  7476 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([7158279, 24, 5, 5],"float32"),Tensor([7158279, 24, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([7158279, 24, 5, 5],"float32"),Tensor([7158279, 24, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0208 17:47:38.232070  7992 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:47:38.233558  7992 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([72083, 1216, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([72083, 1216, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 72083 but got size 2 for tensor number 1 in the list.

W0208 17:48:52.683604  9165 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:48:52.684636  9165 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([72083, 1216, 7, 7],"float32"),Tensor([72083, 32, 7, 7],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([72083, 1216, 7, 7],"float32"),Tensor([72083, 32, 7, 7],"float32"),], axis=1, )

W0208 17:50:17.347306  9667 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:50:17.348170  9667 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([73044, 1200, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([73044, 1200, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 73044 but got size 2 for tensor number 1 in the list.

W0208 17:54:21.857432 11756 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:54:21.858618 11756 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([73044, 1200, 7, 7],"float32"),Tensor([73044, 48, 7, 7],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([73044, 1200, 7, 7],"float32"),Tensor([73044, 48, 7, 7],"float32"),], axis=1, )

W0208 17:55:43.242614 12288 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:55:43.243463 12288 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([74031, 1184, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([74031, 1184, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 74031 but got size 2 for tensor number 1 in the list.

W0208 17:59:17.160146 14199 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 17:59:17.161388 14199 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([74031, 1184, 7, 7],"float32"),Tensor([74031, 32, 7, 7],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([74031, 1184, 7, 7],"float32"),Tensor([74031, 32, 7, 7],"float32"),], axis=1, )

W0208 18:00:38.115310 14700 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:00:38.116521 14700 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([76088, 1152, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([76088, 1152, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 76088 but got size 2 for tensor number 1 in the list.

W0208 18:04:23.963755 16549 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:04:23.964843 16549 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([76088, 1152, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([76088, 1152, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 76088 but got size 2 for tensor number 1 in the list.

W0208 18:05:37.401511 16996 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:05:37.402539 16996 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([76088, 1152, 7, 7],"float32"),Tensor([76088, 32, 7, 7],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([76088, 1152, 7, 7],"float32"),Tensor([76088, 32, 7, 7],"float32"),], axis=1, )

W0208 18:07:04.606262 17684 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:07:04.607336 17684 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([76088, 1152, 7, 7],"float32"),Tensor([76088, 48, 7, 7],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([76088, 1152, 7, 7],"float32"),Tensor([76088, 48, 7, 7],"float32"),], axis=1, )

W0208 18:11:02.803972 19641 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:11:02.804798 19641 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([76088, 288, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([76088, 288, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 76088 but got size 2 for tensor number 1 in the list.

W0208 18:14:38.338501 21316 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:14:38.339588 21316 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([76088, 288, 14, 14],"float32"),Tensor([76088, 32, 14, 14],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([76088, 288, 14, 14],"float32"),Tensor([76088, 32, 14, 14],"float32"),], axis=1, )

W0208 18:16:07.410547 22017 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:16:07.411684 22017 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([7609, 720, 28, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([7609, 720, 28, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7609 but got size 2 for tensor number 1 in the list.

W0208 18:20:12.936852 23919 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:20:12.938390 23919 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([7609, 720, 28, 28],"float32"),Tensor([7609, 48, 28, 28],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([7609, 720, 28, 28],"float32"),Tensor([7609, 48, 28, 28],"float32"),], axis=1, )

W0208 18:21:41.894414 24625 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:21:41.895227 24625 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([77673, 384, 12, 12],"float32"),Tensor([2, 96, 12, 12],"float32"),Tensor([2, 288, 12, 12],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([77673, 384, 12, 12],"float32"),Tensor([2, 96, 12, 12],"float32"),Tensor([2, 288, 12, 12],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 77673 but got size 2 for tensor number 1 in the list.

W0208 18:25:30.147141 26559 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:25:30.148597 26559 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([77673, 384, 12, 12],"float32"),Tensor([77673, 96, 12, 12],"float32"),Tensor([77673, 288, 12, 12],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([77673, 384, 12, 12],"float32"),Tensor([77673, 96, 12, 12],"float32"),Tensor([77673, 288, 12, 12],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000145GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0208 18:27:55.814679 27239 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:27:55.815634 27239 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([78262, 1120, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([78262, 1120, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 78262 but got size 2 for tensor number 1 in the list.

W0208 18:29:10.525074 28251 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:29:10.526051 28251 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([78262, 1120, 7, 7],"float32"),Tensor([78262, 32, 7, 7],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([78262, 1120, 7, 7],"float32"),Tensor([78262, 32, 7, 7],"float32"),], axis=1, )

W0208 18:30:32.495627 28943 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:30:32.496810 28943 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([79396, 1104, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([79396, 1104, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 79396 but got size 2 for tensor number 1 in the list.

W0208 18:34:20.207897 30846 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:34:20.209098 30846 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([79396, 1104, 7, 7],"float32"),Tensor([79396, 48, 7, 7],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([79396, 1104, 7, 7],"float32"),Tensor([79396, 48, 7, 7],"float32"),], axis=1, )

W0208 18:35:41.961261 31361 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:35:41.962137 31361 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 100],"float16"),Tensor([42949673, 100],"float16"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([8, 100],"float16"),Tensor([42949673, 100],"float16"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 8 but got size 42949673 for tensor number 1 in the list.

W0208 18:39:28.151453 33227 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:39:28.152550 33227 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 100],"float16"),Tensor([8, 536870912],"float16"),], axis=-1, )
[Pass] paddle.concat(list[Tensor([8, 100],"float16"),Tensor([8, 536870912],"float16"),], axis=-1, )

W0208 18:41:00.260154 33933 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:41:00.261027 33933 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 100],"float32"),Tensor([42949673, 100],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([8, 100],"float32"),Tensor([42949673, 100],"float32"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 8 but got size 42949673 for tensor number 1 in the list.

W0208 18:49:40.273509 38162 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:49:40.274709 38162 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 100],"float32"),Tensor([8, 536870912],"float32"),], axis=-1, )
[Pass] paddle.concat(list[Tensor([8, 100],"float32"),Tensor([8, 536870912],"float32"),], axis=-1, )

W0208 18:51:00.473083 38650 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:51:00.474151 38650 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 100],"float64"),Tensor([21474837, 100],"float64"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([8, 100],"float64"),Tensor([21474837, 100],"float64"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 8 but got size 21474837 for tensor number 1 in the list.

W0208 18:54:04.925127 40295 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:54:04.926214 40295 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 100],"float64"),Tensor([8, 268435457],"float64"),], axis=-1, )
[Pass] paddle.concat(list[Tensor([8, 100],"float64"),Tensor([8, 268435457],"float64"),], axis=-1, )

W0208 18:55:00.944473 40765 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:55:00.945904 40765 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 16, 128, 262144],"float32"),Tensor([8, 16, 1, 262144],"float32"),], axis=-2, )
[Pass] paddle.concat(list[Tensor([8, 16, 128, 262144],"float32"),Tensor([8, 16, 1, 262144],"float32"),], axis=-2, )

W0208 18:58:11.743808 42183 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 18:58:11.744807 42183 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 16, 128, 262144],"float32"),Tensor([8, 16, 1, 64],"float32"),], axis=-2, )
[torch error] paddle.concat(list[Tensor([8, 16, 128, 262144],"float32"),Tensor([8, 16, 1, 64],"float32"),], axis=-2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 262144 but got size 64 for tensor number 1 in the list.

W0208 19:01:37.429795 43855 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:01:37.431186 43855 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 16, 128, 64],"float32"),Tensor([4194304, 16, 1, 64],"float32"),], axis=-2, )
[torch error] paddle.concat(list[Tensor([8, 16, 128, 64],"float32"),Tensor([4194304, 16, 1, 64],"float32"),], axis=-2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 8 but got size 4194304 for tensor number 1 in the list.

W0208 19:02:54.455816 44349 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:02:54.457446 44349 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 16, 128, 64],"float32"),Tensor([8, 16, 1, 33554432],"float32"),], axis=-2, )
[torch error] paddle.concat(list[Tensor([8, 16, 128, 64],"float32"),Tensor([8, 16, 1, 33554432],"float32"),], axis=-2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 64 but got size 33554432 for tensor number 1 in the list.

W0208 19:04:04.812839 45052 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:04:04.814321 45052 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 16, 128, 64],"float32"),Tensor([8, 16, 524288, 64],"float32"),], axis=-2, )
[Pass] paddle.concat(list[Tensor([8, 16, 128, 64],"float32"),Tensor([8, 16, 524288, 64],"float32"),], axis=-2, )

W0208 19:05:30.602790 45550 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:05:30.603699 45550 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 16, 128, 64],"float32"),Tensor([8, 8388608, 1, 64],"float32"),], axis=-2, )
[torch error] paddle.concat(list[Tensor([8, 16, 128, 64],"float32"),Tensor([8, 8388608, 1, 64],"float32"),], axis=-2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 16 but got size 8388608 for tensor number 1 in the list.

W0208 19:09:02.434016 47236 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:09:02.435112 47236 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 16, 2],"float32"),Tensor([134217728, 16, 2],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([8, 16, 2],"float32"),Tensor([134217728, 16, 2],"float32"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 2. Expected size 8 but got size 134217728 for tensor number 1 in the list.

W0208 19:10:24.194974 47926 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:10:24.196516 47926 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 16, 2],"float32"),Tensor([8, 16, 33554432],"float32"),], axis=-1, )
[Pass] paddle.concat(list[Tensor([8, 16, 2],"float32"),Tensor([8, 16, 33554432],"float32"),], axis=-1, )

W0208 19:11:43.942541 48620 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:11:43.943862 48620 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 16, 2],"float32"),Tensor([8, 268435456, 2],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([8, 16, 2],"float32"),Tensor([8, 268435456, 2],"float32"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 2. Expected size 16 but got size 268435456 for tensor number 1 in the list.

W0208 19:15:03.769062 50297 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:15:03.770277 50297 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 16, 33554432],"float32"),Tensor([8, 16, 2],"float32"),], axis=-1, )
[Pass] paddle.concat(list[Tensor([8, 16, 33554432],"float32"),Tensor([8, 16, 2],"float32"),], axis=-1, )

W0208 19:16:23.688551 50806 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:16:23.689441 50806 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 16, 33554432],"float32"),Tensor([8, 16, 33554432],"float32"),], axis=-1, )
[paddle error] paddle.concat(list[Tensor([8, 16, 33554432],"float32"),Tensor([8, 16, 33554432],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0208 19:21:11.121680 52456 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:21:11.122550 52456 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 16, 524288, 64],"float32"),Tensor([8, 16, 1, 64],"float32"),], axis=-2, )
[Pass] paddle.concat(list[Tensor([8, 16, 524288, 64],"float32"),Tensor([8, 16, 1, 64],"float32"),], axis=-2, )

W0208 19:22:28.642952 53631 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:22:28.643741 53631 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 16, 524288, 64],"float32"),Tensor([8, 16, 524288, 64],"float32"),], axis=-2, )
[paddle error] paddle.concat(list[Tensor([8, 16, 524288, 64],"float32"),Tensor([8, 16, 524288, 64],"float32"),], axis=-2, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0208 19:27:31.789693 55506 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:27:31.790711 55506 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 16],"float32"),Tensor([536870912, 8],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([8, 16],"float32"),Tensor([536870912, 8],"float32"),], 1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 8 but got size 536870912 for tensor number 1 in the list.

W0208 19:28:46.332901 56687 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:28:46.334192 56687 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 16],"float32"),Tensor([8, 536870912],"float32"),], 1, )
[Pass] paddle.concat(list[Tensor([8, 16],"float32"),Tensor([8, 536870912],"float32"),], 1, )

W0208 19:30:11.046326 57200 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:30:11.047224 57200 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 268435456, 2],"float32"),Tensor([8, 16, 2],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([8, 268435456, 2],"float32"),Tensor([8, 16, 2],"float32"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 2. Expected size 268435456 but got size 16 for tensor number 1 in the list.

W0208 19:33:49.910976 59078 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:33:49.912108 59078 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 268435456, 2],"float32"),Tensor([8, 268435456, 2],"float32"),], axis=-1, )
[paddle error] paddle.concat(list[Tensor([8, 268435456, 2],"float32"),Tensor([8, 268435456, 2],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0208 19:36:14.674979 59605 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:36:14.675817 59605 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 268435457],"float64"),Tensor([8, 100],"float64"),], axis=-1, )
[Pass] paddle.concat(list[Tensor([8, 268435457],"float64"),Tensor([8, 100],"float64"),], axis=-1, )

W0208 19:37:14.321642 60774 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:37:14.322613 60774 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),], axis=-1, )
[paddle error] paddle.concat(list[Tensor([8, 268435457],"float64"),Tensor([8, 268435457],"float64"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0208 19:41:10.273133 62205 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:41:10.274165 62205 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 536870912],"float16"),Tensor([8, 100],"float16"),], axis=-1, )
[Pass] paddle.concat(list[Tensor([8, 536870912],"float16"),Tensor([8, 100],"float16"),], axis=-1, )

W0208 19:42:41.275743 63141 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:42:41.276600 63141 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 536870912],"float16"),Tensor([8, 536870912],"float16"),], axis=-1, )
[Pass] paddle.concat(list[Tensor([8, 536870912],"float16"),Tensor([8, 536870912],"float16"),], axis=-1, )

W0208 19:53:06.575887 67363 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 19:53:06.576758 67363 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 536870912],"float32"),Tensor([8, 100],"float32"),], axis=-1, )
[Pass] paddle.concat(list[Tensor([8, 536870912],"float32"),Tensor([8, 100],"float32"),], axis=-1, )

W0208 20:10:26.194154 76673 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:10:26.195092 76673 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),], 1, )
[paddle error] paddle.concat(list[Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),], 1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0208 20:15:16.213551 78365 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:15:16.214404 78365 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),], axis=-1, )
[paddle error] paddle.concat(list[Tensor([8, 536870912],"float32"),Tensor([8, 536870912],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0208 20:17:44.091302 79556 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:17:44.092154 79556 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),], 1, )
[Pass] paddle.concat(list[Tensor([8, 536870912],"float32"),Tensor([8, 8],"float32"),], 1, )

W0208 20:19:00.778085 80719 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:19:00.778940 80719 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 65536, 128, 64],"float32"),Tensor([8, 16, 1, 64],"float32"),], axis=-2, )
[torch error] paddle.concat(list[Tensor([8, 65536, 128, 64],"float32"),Tensor([8, 16, 1, 64],"float32"),], axis=-2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 65536 but got size 16 for tensor number 1 in the list.

W0208 20:22:25.050571 82367 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:22:25.051640 82367 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 65536, 128, 64],"float32"),Tensor([8, 65536, 1, 64],"float32"),], axis=-2, )
[Pass] paddle.concat(list[Tensor([8, 65536, 128, 64],"float32"),Tensor([8, 65536, 1, 64],"float32"),], axis=-2, )

W0208 20:23:49.109263 83039 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:23:49.110308 83039 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([8, 8],"float32"),Tensor([536870912, 8],"float32"),], 1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 8 but got size 536870912 for tensor number 1 in the list.

W0208 20:27:24.777446 84754 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:27:24.778749 84754 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),], 1, )
[Pass] paddle.concat(list[Tensor([8, 8],"float32"),Tensor([8, 536870912],"float32"),], 1, )

W0208 20:28:39.799369 85435 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:28:39.800302 85435 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8],"float32"),Tensor([4294967295],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),], axis=0, )
[Pass] paddle.concat(list[Tensor([8],"float32"),Tensor([4294967295],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),], axis=0, )

W0208 20:32:09.040148 86888 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:32:09.041121 86888 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8],"float32"),Tensor([8],"float32"),Tensor([4294967295],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),], axis=0, )
[Pass] paddle.concat(list[Tensor([8],"float32"),Tensor([8],"float32"),Tensor([4294967295],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),], axis=0, )

W0208 20:35:35.920949 88558 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:35:35.921970 88558 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([4294967295],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),], axis=0, )
[Pass] paddle.concat(list[Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([4294967295],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),], axis=0, )

W0208 20:39:11.294139 90403 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:39:11.295228 90403 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([4294967295],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),], axis=0, )
[Pass] paddle.concat(list[Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([4294967295],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),], axis=0, )

W0208 20:42:40.659340 91852 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:42:40.660336 91852 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([4294967295],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),], axis=0, )
[Pass] paddle.concat(list[Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([4294967295],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),], axis=0, )

W0208 20:46:09.766391 93486 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:46:09.767237 93486 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([4294967295],"float32"),Tensor([8],"float32"),], axis=0, )
[Pass] paddle.concat(list[Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([4294967295],"float32"),Tensor([8],"float32"),], axis=0, )

W0208 20:49:43.477253 95124 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:49:43.478194 95124 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([4294967295],"float32"),], axis=0, )
[Pass] paddle.concat(list[Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([4294967295],"float32"),], axis=0, )

W0208 20:53:24.043359 96971 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:53:24.044310 96971 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8],"float64"),Tensor([2147483649],"float64"),], axis=0, )
[Pass] paddle.concat(list[Tensor([8],"float64"),Tensor([2147483649],"float64"),], axis=0, )

W0208 20:56:36.190404 98611 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:56:36.191330 98611 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8],"float64"),Tensor([2147483649],"float64"),Tensor([8],"float64"),Tensor([8],"float64"),], axis=0, )
[Pass] paddle.concat(list[Tensor([8],"float64"),Tensor([2147483649],"float64"),Tensor([8],"float64"),Tensor([8],"float64"),], axis=0, )

W0208 20:59:28.330603 100023 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 20:59:28.331490 100023 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8],"float64"),Tensor([8],"float64"),Tensor([2147483649],"float64"),Tensor([8],"float64"),], axis=0, )
[Pass] paddle.concat(list[Tensor([8],"float64"),Tensor([8],"float64"),Tensor([2147483649],"float64"),Tensor([8],"float64"),], axis=0, )

W0208 21:02:17.989744 101242 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:02:17.990717 101242 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8],"float64"),Tensor([8],"float64"),Tensor([8],"float64"),Tensor([2147483649],"float64"),], axis=0, )
[Pass] paddle.concat(list[Tensor([8],"float64"),Tensor([8],"float64"),Tensor([8],"float64"),Tensor([2147483649],"float64"),], axis=0, )

W0208 21:05:11.553071 102642 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:05:11.553999 102642 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([80],"float32"),Tensor([4294967295],"float32"),Tensor([80],"float32"),Tensor([10],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),Tensor([200],"float32"),], )
[Pass] paddle.concat(list[Tensor([80],"float32"),Tensor([4294967295],"float32"),Tensor([80],"float32"),Tensor([10],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),Tensor([200],"float32"),], )

W0208 21:08:34.756147 104094 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:08:34.757175 104094 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([80],"float32"),Tensor([8],"float32"),Tensor([4294967295],"float32"),Tensor([10],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),Tensor([200],"float32"),], )
[Pass] paddle.concat(list[Tensor([80],"float32"),Tensor([8],"float32"),Tensor([4294967295],"float32"),Tensor([10],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),Tensor([200],"float32"),], )

W0208 21:12:08.947887 105764 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:12:08.948856 105764 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([80],"float32"),Tensor([8],"float32"),Tensor([80],"float32"),Tensor([10],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),Tensor([4294967295],"float32"),], )
[Pass] paddle.concat(list[Tensor([80],"float32"),Tensor([8],"float32"),Tensor([80],"float32"),Tensor([10],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),Tensor([4294967295],"float32"),], )

W0208 21:15:48.630705 107585 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:15:48.631726 107585 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([80],"float32"),Tensor([8],"float32"),Tensor([80],"float32"),Tensor([10],"float32"),Tensor([100],"float32"),Tensor([4294967295],"float32"),Tensor([200],"float32"),], )
[Pass] paddle.concat(list[Tensor([80],"float32"),Tensor([8],"float32"),Tensor([80],"float32"),Tensor([10],"float32"),Tensor([100],"float32"),Tensor([4294967295],"float32"),Tensor([200],"float32"),], )

W0208 21:19:20.417306 109228 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:19:20.418263 109228 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([80],"float32"),Tensor([8],"float32"),Tensor([80],"float32"),Tensor([10],"float32"),Tensor([4294967295],"float32"),Tensor([10],"float32"),Tensor([200],"float32"),], )
[Pass] paddle.concat(list[Tensor([80],"float32"),Tensor([8],"float32"),Tensor([80],"float32"),Tensor([10],"float32"),Tensor([4294967295],"float32"),Tensor([10],"float32"),Tensor([200],"float32"),], )

W0208 21:22:47.127628 110867 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:22:47.128997 110867 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([80],"float32"),Tensor([8],"float32"),Tensor([80],"float32"),Tensor([4294967295],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),Tensor([200],"float32"),], )
[Pass] paddle.concat(list[Tensor([80],"float32"),Tensor([8],"float32"),Tensor([80],"float32"),Tensor([4294967295],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),Tensor([200],"float32"),], )

W0208 21:26:23.308156 112526 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:26:23.309002 112526 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([80563, 1088, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([80563, 1088, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 80563 but got size 2 for tensor number 1 in the list.

W0208 21:29:57.041348 114190 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:29:57.042970 114190 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([80563, 1088, 7, 7],"float32"),Tensor([80563, 32, 7, 7],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([80563, 1088, 7, 7],"float32"),Tensor([80563, 32, 7, 7],"float32"),], axis=1, )

W0208 21:31:18.773619 114857 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:31:18.774616 114857 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8153, 672, 28, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([8153, 672, 28, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 8153 but got size 2 for tensor number 1 in the list.

W0208 21:34:47.090730 116527 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:34:47.091564 116527 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8153, 672, 28, 28],"float32"),Tensor([8153, 48, 28, 28],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([8153, 672, 28, 28],"float32"),Tensor([8153, 48, 28, 28],"float32"),], axis=1, )

W0208 21:36:16.469233 117035 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:36:16.470088 117035 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([83005, 1056, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([83005, 1056, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 83005 but got size 2 for tensor number 1 in the list.

W0208 21:40:25.294848 118959 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:40:25.296219 118959 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([83005, 1056, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([83005, 1056, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 83005 but got size 2 for tensor number 1 in the list.

W0208 21:41:40.147504 119533 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:41:40.149201 119533 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([83005, 1056, 7, 7],"float32"),Tensor([83005, 32, 7, 7],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([83005, 1056, 7, 7],"float32"),Tensor([83005, 32, 7, 7],"float32"),], axis=1, )

W0208 21:43:08.431229 119926 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:43:08.432124 119926 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([83005, 1056, 7, 7],"float32"),Tensor([83005, 48, 7, 7],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([83005, 1056, 7, 7],"float32"),Tensor([83005, 48, 7, 7],"float32"),], axis=1, )

W0208 21:47:08.344995 121439 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:47:08.346464 121439 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8388608, 512],"float16"),Tensor([128, 128],"float16"),Tensor([128, 128],"float16"),], axis=1, )
[torch error] paddle.concat(list[Tensor([8388608, 512],"float16"),Tensor([128, 128],"float16"),Tensor([128, 128],"float16"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 8388608 but got size 128 for tensor number 1 in the list.

W0208 21:50:55.017143 122987 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:50:55.018818 122987 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8388608, 512],"float16"),Tensor([2, 128],"float16"),Tensor([2, 128],"float16"),], axis=1, )
[torch error] paddle.concat(list[Tensor([8388608, 512],"float16"),Tensor([2, 128],"float16"),Tensor([2, 128],"float16"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 8388608 but got size 2 for tensor number 1 in the list.

W0208 21:52:25.150595 123381 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:52:25.151733 123381 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8388608, 512],"float16"),Tensor([8388608, 128],"float16"),Tensor([8388608, 128],"float16"),], axis=1, )
[Pass] paddle.concat(list[Tensor([8388608, 512],"float16"),Tensor([8388608, 128],"float16"),Tensor([8388608, 128],"float16"),], axis=1, )

W0208 21:54:35.933051 124135 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 21:54:35.934104 124135 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8388608, 512],"int32"),Tensor([128, 128],"int32"),Tensor([128, 128],"int32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([8388608, 512],"int32"),Tensor([128, 128],"int32"),Tensor([128, 128],"int32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 8388608 but got size 128 for tensor number 1 in the list.

W0208 22:07:28.649284 129237 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:07:28.650250 129237 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8388608, 512],"int32"),Tensor([2, 128],"int32"),Tensor([2, 128],"int32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([8388608, 512],"int32"),Tensor([2, 128],"int32"),Tensor([2, 128],"int32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 8388608 but got size 2 for tensor number 1 in the list.

W0208 22:08:38.924932 129797 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:08:38.926090 129797 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8388608, 512],"int32"),Tensor([8388608, 128],"int32"),Tensor([8388608, 128],"int32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([8388608, 512],"int32"),Tensor([8388608, 128],"int32"),Tensor([8388608, 128],"int32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<int, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   int* phi::DeviceContext::Alloc<int>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 24.000000GB memory on GPU 0, 73.584900GB memory has been allocated and available memory is only 5.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0208 22:10:36.095501 130189 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:10:36.096853 130189 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([83887, 128, 20, 20],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([83887, 128, 20, 20],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 83887 but got size 1 for tensor number 1 in the list.

W0208 22:12:07.061419 130954 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:12:07.062460 130954 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([83887, 128, 20, 20],"float32"),Tensor([83887, 32, 20, 20],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([83887, 128, 20, 20],"float32"),Tensor([83887, 32, 20, 20],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 20.000219GB memory on GPU 0, 61.594666GB memory has been allocated and available memory is only 17.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0208 22:13:54.129138 131540 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:13:54.130193 131540 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([85599, 1024, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([85599, 1024, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 85599 but got size 2 for tensor number 1 in the list.

W0208 22:15:22.008708 132297 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:15:22.010109 132297 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([85599, 1024, 7, 7],"float32"),Tensor([85599, 32, 7, 7],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([85599, 1024, 7, 7],"float32"),Tensor([85599, 32, 7, 7],"float32"),], axis=1, )

W0208 22:16:51.470237 133032 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:16:51.471503 133032 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([85599, 256, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([85599, 256, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 85599 but got size 2 for tensor number 1 in the list.

W0208 22:20:38.429333 134768 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:20:38.430452 134768 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([85599, 256, 14, 14],"float32"),Tensor([85599, 32, 14, 14],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([85599, 256, 14, 14],"float32"),Tensor([85599, 32, 14, 14],"float32"),], axis=1, )

W0208 22:22:09.569550 135148 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:22:09.570447 135148 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8560, 160, 56, 56],"float32"),Tensor([2, 32, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([8560, 160, 56, 56],"float32"),Tensor([2, 32, 56, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 8560 but got size 2 for tensor number 1 in the list.

W0208 22:26:23.237960 136815 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:26:23.238844 136815 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8560, 160, 56, 56],"float32"),Tensor([8560, 32, 56, 56],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([8560, 160, 56, 56],"float32"),Tensor([8560, 32, 56, 56],"float32"),], axis=1, )

W0208 22:27:58.711853 137208 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:27:58.712857 137208 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([858993459, 5],"float32"),Tensor([2, 3],"float32"),Tensor([2, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([858993459, 5],"float32"),Tensor([2, 3],"float32"),Tensor([2, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 858993459 but got size 2 for tensor number 1 in the list.

W0208 22:32:14.665961 139146 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:32:14.667814 139146 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([858993459, 5],"float32"),Tensor([858993459, 3],"float32"),Tensor([858993459, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([858993459, 5],"float32"),Tensor([858993459, 3],"float32"),Tensor([858993459, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 41.60 GiB. GPU 0 has a total capacity of 79.18 GiB of which 36.59 GiB is free. Process 124194 has 42.59 GiB memory in use. Of the allocated memory 41.60 GiB is allocated by PyTorch, and 1.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0208 22:35:05.753711 139528 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:35:05.759169 139528 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([85899346, 10, 5],"float32"),Tensor([1, 10, 5],"float32"),], )
[Pass] paddle.concat(list[Tensor([85899346, 10, 5],"float32"),Tensor([1, 10, 5],"float32"),], )

W0208 22:36:21.050009 140649 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:36:21.051033 140649 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([85899346, 10, 5],"float32"),Tensor([2, 10, 5],"float32"),], )
[Pass] paddle.concat(list[Tensor([85899346, 10, 5],"float32"),Tensor([2, 10, 5],"float32"),], )

W0208 22:39:59.571020 141951 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:39:59.571844 141951 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([85899346, 10, 5],"float32"),Tensor([85899346, 10, 5],"float32"),], )
[paddle error] paddle.concat(list[Tensor([85899346, 10, 5],"float32"),Tensor([85899346, 10, 5],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0208 22:44:29.223297 143254 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:44:29.224166 143254 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8780, 624, 28, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([8780, 624, 28, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 8780 but got size 2 for tensor number 1 in the list.

W0208 22:45:40.416566 144185 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:45:40.417623 144185 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([8780, 624, 28, 28],"float32"),Tensor([8780, 48, 28, 28],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([8780, 624, 28, 28],"float32"),Tensor([8780, 48, 28, 28],"float32"),], axis=1, )

W0208 22:47:14.617794 144564 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:47:14.618728 144564 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([88360, 992, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([88360, 992, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 88360 but got size 2 for tensor number 1 in the list.

W0208 22:51:01.847052 146069 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:51:01.848151 146069 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([88360, 992, 7, 7],"float32"),Tensor([88360, 32, 7, 7],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([88360, 992, 7, 7],"float32"),Tensor([88360, 32, 7, 7],"float32"),], axis=1, )

W0208 22:52:23.843230 146645 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:52:23.844457 146645 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([89479, 480, 10, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([89479, 480, 10, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 89479 but got size 1 for tensor number 1 in the list.

W0208 22:56:01.989265 147953 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:56:01.990427 147953 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([89479, 480, 10, 10],"float32"),Tensor([89479, 32, 10, 10],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([89479, 480, 10, 10],"float32"),Tensor([89479, 32, 10, 10],"float32"),], axis=1, )

W0208 22:57:27.581512 148539 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 22:57:27.582314 148539 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([89808, 244, 14, 14],"float32"),Tensor([2, 244, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([89808, 244, 14, 14],"float32"),Tensor([2, 244, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 89808 but got size 2 for tensor number 1 in the list.

W0208 23:01:11.077991 150053 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:01:11.078892 150053 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([89808, 244, 14, 14],"float32"),Tensor([89808, 244, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([89808, 244, 14, 14],"float32"),Tensor([89808, 244, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000039GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0208 23:03:32.883147 150433 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:03:32.883981 150433 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([913046, 24, 14, 14],"float32"),Tensor([2, 24, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([913046, 24, 14, 14],"float32"),Tensor([2, 24, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 913046 but got size 2 for tensor number 1 in the list.

W0208 23:04:43.242528 151386 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:04:43.243577 151386 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([913046, 24, 14, 14],"float32"),Tensor([913046, 24, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([913046, 24, 14, 14],"float32"),Tensor([913046, 24, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0208 23:07:12.407843 151779 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:07:12.408983 151779 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([913046, 96, 7, 7],"float32"),Tensor([2, 96, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([913046, 96, 7, 7],"float32"),Tensor([2, 96, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 913046 but got size 2 for tensor number 1 in the list.

W0208 23:08:30.495795 152718 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:08:30.496752 152718 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([913046, 96, 7, 7],"float32"),Tensor([913046, 96, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([913046, 96, 7, 7],"float32"),Tensor([913046, 96, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0208 23:10:54.693941 153299 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:10:54.694888 153299 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([91305, 960, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([91305, 960, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 91305 but got size 2 for tensor number 1 in the list.

W0208 23:12:07.147816 154066 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:12:07.148737 154066 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([91305, 960, 7, 7],"float32"),Tensor([91305, 32, 7, 7],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([91305, 960, 7, 7],"float32"),Tensor([91305, 32, 7, 7],"float32"),], axis=1, )

W0208 23:13:31.499681 154647 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:13:31.500814 154647 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([92057, 64, 27, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([92057, 64, 27, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 92057 but got size 2 for tensor number 1 in the list.

W0208 23:17:23.192698 156146 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:17:23.193565 156146 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([92057, 64, 27, 27],"float32"),Tensor([92057, 128, 27, 27],"float32"),Tensor([92057, 32, 27, 27],"float32"),Tensor([92057, 32, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([92057, 64, 27, 27],"float32"),Tensor([92057, 128, 27, 27],"float32"),Tensor([92057, 32, 27, 27],"float32"),Tensor([92057, 32, 27, 27],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 64.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 14.18 GiB is free. Process 86048 has 65.00 GiB memory in use. Of the allocated memory 64.00 GiB is allocated by PyTorch, and 7.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0208 23:21:37.871270 156540 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:21:37.872303 156540 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([94454, 58, 28, 28],"float32"),Tensor([2, 58, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([94454, 58, 28, 28],"float32"),Tensor([2, 58, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 94454 but got size 2 for tensor number 1 in the list.

W0208 23:22:54.304654 158286 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:22:54.305737 158286 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([94454, 58, 28, 28],"float32"),Tensor([94454, 58, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([94454, 58, 28, 28],"float32"),Tensor([94454, 58, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000168GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0208 23:25:15.232561 158681 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:25:15.233363 158681 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([94454, 928, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([94454, 928, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 94454 but got size 2 for tensor number 1 in the list.

W0208 23:26:28.254462 159645 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:26:28.255481 159645 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([94454, 928, 7, 7],"float32"),Tensor([94454, 32, 7, 7],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([94454, 928, 7, 7],"float32"),Tensor([94454, 32, 7, 7],"float32"),], axis=1, )

W0208 23:27:50.820901 160218 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:27:50.822049 160218 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([9511, 144, 56, 56],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([9511, 144, 56, 56],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 9511 but got size 2 for tensor number 1 in the list.

W0208 23:31:24.968628 161537 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:31:24.969676 161537 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([9511, 144, 56, 56],"float32"),Tensor([9511, 48, 56, 56],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([9511, 144, 56, 56],"float32"),Tensor([9511, 48, 56, 56],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333572GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0208 23:33:07.028775 161929 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:33:07.029572 161929 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([9511, 576, 28, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([9511, 576, 28, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 9511 but got size 2 for tensor number 1 in the list.

W0208 23:34:27.501631 162671 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:34:27.502506 162671 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([9511, 576, 28, 28],"float32"),Tensor([9511, 48, 28, 28],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([9511, 576, 28, 28],"float32"),Tensor([9511, 48, 28, 28],"float32"),], axis=1, )

W0208 23:35:57.007479 163254 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:35:57.008402 163254 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([95870, 448, 10, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([95870, 448, 10, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 95870 but got size 1 for tensor number 1 in the list.

W0208 23:39:46.456209  1245 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:39:46.457324  1245 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([95870, 448, 10, 10],"float32"),Tensor([95870, 32, 10, 10],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([95870, 448, 10, 10],"float32"),Tensor([95870, 32, 10, 10],"float32"),], axis=1, )

W0208 23:41:11.342963  1650 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:41:11.343809  1650 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([9645, 2272, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([9645, 2272, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 9645 but got size 2 for tensor number 1 in the list.

W0208 23:44:54.103376  3176 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:44:54.104332  3176 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([9645, 2272, 14, 14],"float32"),Tensor([9645, 32, 14, 14],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([9645, 2272, 14, 14],"float32"),Tensor([9645, 32, 14, 14],"float32"),], axis=1, )

W0208 23:46:14.511509  3558 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:46:14.512820  3558 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([97827, 896, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([97827, 896, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 97827 but got size 2 for tensor number 1 in the list.

W0208 23:49:57.460470  5080 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:49:57.461776  5080 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([97827, 896, 7, 7],"float32"),Tensor([97827, 32, 7, 7],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([97827, 896, 7, 7],"float32"),Tensor([97827, 32, 7, 7],"float32"),], axis=1, )

W0208 23:51:21.426069  5638 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:51:21.427196  5638 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([9783, 2240, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([9783, 2240, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 9783 but got size 2 for tensor number 1 in the list.

W0208 23:55:08.957619  7159 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:55:08.958832  7159 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([9783, 2240, 14, 14],"float32"),Tensor([9783, 32, 14, 14],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([9783, 2240, 14, 14],"float32"),Tensor([9783, 32, 14, 14],"float32"),], axis=1, )

W0208 23:56:25.021871  7553 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:56:25.022859  7553 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([9925, 2208, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([9925, 2208, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 9925 but got size 2 for tensor number 1 in the list.

W0208 23:59:49.101662  8885 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0208 23:59:49.102764  8885 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([9925, 2208, 14, 14],"float32"),Tensor([9925, 32, 14, 14],"float32"),], axis=1, )
[Pass] paddle.concat(list[Tensor([9925, 2208, 14, 14],"float32"),Tensor([9925, 32, 14, 14],"float32"),], axis=1, )

W0209 00:01:12.046931  9278 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:01:12.047793  9278 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([99274, 256, 13, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([99274, 256, 13, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 99274 but got size 2 for tensor number 1 in the list.

W0209 00:04:45.067817 10805 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:04:45.068763 10805 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([99274, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([99274, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 99274 but got size 2 for tensor number 1 in the list.

W0209 00:05:58.979079 11212 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:05:58.979890 11212 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([99274, 256, 13, 13],"float32"),Tensor([99274, 256, 13, 13],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([99274, 256, 13, 13],"float32"),Tensor([99274, 256, 13, 13],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000086GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 00:08:21.395502 11794 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:08:21.396421 11794 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([99274, 256, 13, 13],"float32"),Tensor([99274, 320, 13, 13],"float32"),Tensor([99274, 128, 13, 13],"float32"),Tensor([99274, 128, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([99274, 256, 13, 13],"float32"),Tensor([99274, 320, 13, 13],"float32"),Tensor([99274, 128, 13, 13],"float32"),Tensor([99274, 128, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 52.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 26.18 GiB is free. Process 41760 has 53.00 GiB memory in use. Of the allocated memory 52.00 GiB is allocated by PyTorch, and 7.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0209 00:12:04.035269 12553 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:12:04.036295 12553 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([9942054, 48, 3, 3],"float32"),Tensor([1, 48, 3, 3],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([9942054, 48, 3, 3],"float32"),Tensor([1, 48, 3, 3],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 9942054 but got size 1 for tensor number 1 in the list.

W0209 00:13:21.933931 14072 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:13:21.938746 14072 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([9942054, 48, 3, 3],"float32"),Tensor([9942054, 48, 3, 3],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([9942054, 48, 3, 3],"float32"),Tensor([9942054, 48, 3, 3],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 00:15:54.162468 14481 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:15:54.163535 14481 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 1048576, 64, 64],"float32"),Tensor([1, 1, 64, 64],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([1, 1048576, 64, 64],"float32"),Tensor([1, 1, 64, 64],"float32"),), axis=1, )

W0209 00:17:13.452363 15454 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:17:13.453282 15454 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 1048576, 64, 64],"float32"),Tensor([1, 1048576, 64, 64],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 1048576, 64, 64],"float32"),Tensor([1, 1048576, 64, 64],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 00:22:01.701402 15497 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:22:01.702296 15497 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 17459, 498, 494],"float32"),Tensor([1, 1, 498, 494],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([1, 17459, 498, 494],"float32"),Tensor([1, 1, 498, 494],"float32"),), axis=1, )

W0209 00:23:15.785593 15525 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:23:15.786484 15525 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 17459, 498, 494],"float32"),Tensor([1, 17459, 498, 494],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 17459, 498, 494],"float32"),Tensor([1, 17459, 498, 494],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000582GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 00:27:56.664634 15594 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:27:56.665623 15594 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 22193, 432, 448],"float32"),Tensor([1, 1, 432, 448],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([1, 22193, 432, 448],"float32"),Tensor([1, 1, 432, 448],"float32"),), axis=1, )

W0209 00:29:12.837010 15625 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:29:12.837858 15625 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 22193, 432, 448],"float32"),Tensor([1, 22193, 432, 448],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 22193, 432, 448],"float32"),Tensor([1, 22193, 432, 448],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000660GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 00:33:56.690793 15692 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:33:56.691726 15692 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 23809, 410, 440],"float32"),Tensor([1, 1, 410, 440],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([1, 23809, 410, 440],"float32"),Tensor([1, 1, 410, 440],"float32"),), axis=1, )

W0209 00:35:12.205510 15720 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:35:12.206454 15720 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 23809, 410, 440],"float32"),Tensor([1, 23809, 410, 440],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 23809, 410, 440],"float32"),Tensor([1, 23809, 410, 440],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000657GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 00:39:48.230335 15776 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:39:48.232992 15776 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 24421, 458, 384],"float32"),Tensor([1, 1, 458, 384],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([1, 24421, 458, 384],"float32"),Tensor([1, 1, 458, 384],"float32"),), axis=1, )

W0209 00:41:02.007026 15819 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:41:02.007979 15819 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 24421, 458, 384],"float32"),Tensor([1, 24421, 458, 384],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 24421, 458, 384],"float32"),Tensor([1, 24421, 458, 384],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000010GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 00:45:43.837289 15889 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:45:43.839943 15889 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 178956971, 8],"float32"),Tensor([1, 1, 178956971, 8],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 3, 178956971, 8],"float32"),Tensor([1, 1, 178956971, 8],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333333GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 00:47:20.013613 15931 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:47:20.014484 15931 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 178956971, 8],"float32"),Tensor([1, 1, 8, 8],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 178956971, 8],"float32"),Tensor([1, 1, 8, 8],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 178956971 but got size 8 for tensor number 1 in the list.

W0209 00:48:37.005571 15972 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:48:37.006911 15972 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 22369622, 64],"float32"),Tensor([1, 1, 22369622, 64],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 3, 22369622, 64],"float32"),Tensor([1, 1, 22369622, 64],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333334GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 00:50:14.622664 16014 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:50:14.623651 16014 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 22369622, 64],"float32"),Tensor([1, 1, 64, 64],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 22369622, 64],"float32"),Tensor([1, 1, 64, 64],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 22369622 but got size 64 for tensor number 1 in the list.

W0209 00:51:33.585891 16056 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:51:33.586942 16056 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 28, 28],"float32"),Tensor([1, 1, 153391690, 28],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 28, 28],"float32"),Tensor([1, 1, 153391690, 28],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 153391690 for tensor number 1 in the list.

W0209 00:52:53.109664 16071 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:52:53.110864 16071 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 28, 28],"float32"),Tensor([1, 1, 28, 153391690],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 28, 28],"float32"),Tensor([1, 1, 28, 153391690],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 153391690 for tensor number 1 in the list.

W0209 00:54:10.731606 16085 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:54:10.732856 16085 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 28, 28],"float32"),Tensor([1, 5478275, 28, 28],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([1, 3, 28, 28],"float32"),Tensor([1, 5478275, 28, 28],"float32"),), axis=1, )

W0209 00:55:26.354874 16112 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:55:26.356036 16112 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 28, 28],"float32"),Tensor([5478275, 1, 28, 28],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 28, 28],"float32"),Tensor([5478275, 1, 28, 28],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1 but got size 5478275 for tensor number 1 in the list.

W0209 00:59:05.994618 16141 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 00:59:05.995711 16141 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 28, 51130564],"float32"),Tensor([1, 1, 28, 28],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 28, 51130564],"float32"),Tensor([1, 1, 28, 28],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 51130564 but got size 28 for tensor number 1 in the list.

W0209 01:00:18.482522 16155 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:00:18.483552 16155 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 28, 51130564],"float32"),Tensor([1, 1, 28, 51130564],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 3, 28, 51130564],"float32"),Tensor([1, 1, 28, 51130564],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333334GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 01:02:00.346151 16169 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:02:00.347187 16169 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 280, 350],"float32"),Tensor([1, 1, 12271336, 350],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 280, 350],"float32"),Tensor([1, 1, 12271336, 350],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 280 but got size 12271336 for tensor number 1 in the list.

W0209 01:03:19.989255 16183 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:03:19.990305 16183 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 280, 350],"float32"),Tensor([1, 1, 280, 15339169],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 280, 350],"float32"),Tensor([1, 1, 280, 15339169],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 350 but got size 15339169 for tensor number 1 in the list.

W0209 01:04:35.412422 16225 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:04:35.413573 16225 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 280, 350],"float32"),Tensor([1, 43827, 280, 350],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([1, 3, 280, 350],"float32"),Tensor([1, 43827, 280, 350],"float32"),), axis=1, )

W0209 01:05:59.020390 16239 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:05:59.021564 16239 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 280, 350],"float32"),Tensor([43827, 1, 280, 350],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 280, 350],"float32"),Tensor([43827, 1, 280, 350],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1 but got size 43827 for tensor number 1 in the list.

W0209 01:09:21.580557 16267 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:09:21.582036 16267 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 280, 5113057],"float32"),Tensor([1, 1, 280, 350],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 280, 5113057],"float32"),Tensor([1, 1, 280, 350],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5113057 but got size 350 for tensor number 1 in the list.

W0209 01:10:40.529632 16307 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:10:40.530453 16307 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 280, 5113057],"float32"),Tensor([1, 1, 280, 5113057],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 3, 280, 5113057],"float32"),Tensor([1, 1, 280, 5113057],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333336GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 01:12:17.938330 16323 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:12:17.939141 16323 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 2898089, 494],"float32"),Tensor([1, 1, 2898089, 494],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 3, 2898089, 494],"float32"),Tensor([1, 1, 2898089, 494],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333336GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 01:14:10.133899 16337 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:14:10.134793 16337 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 2898089, 494],"float32"),Tensor([1, 1, 498, 494],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 2898089, 494],"float32"),Tensor([1, 1, 498, 494],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2898089 but got size 498 for tensor number 1 in the list.

W0209 01:15:30.386902 16365 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:15:30.387877 16365 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 3195661, 448],"float32"),Tensor([1, 1, 3195661, 448],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 3, 3195661, 448],"float32"),Tensor([1, 1, 3195661, 448],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333339GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 01:17:16.457628 16392 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:17:16.458879 16392 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 3195661, 448],"float32"),Tensor([1, 1, 432, 448],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 3195661, 448],"float32"),Tensor([1, 1, 432, 448],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 3195661 but got size 432 for tensor number 1 in the list.

W0209 01:18:36.648715 16434 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:18:36.649727 16434 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 32, 26],"float32"),Tensor([1, 1, 165191050, 26],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 32, 26],"float32"),Tensor([1, 1, 165191050, 26],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 32 but got size 165191050 for tensor number 1 in the list.

W0209 01:19:47.446707 16463 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:19:47.448014 16463 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 32, 26],"float32"),Tensor([1, 1, 32, 134217728],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 32, 26],"float32"),Tensor([1, 1, 32, 134217728],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 26 but got size 134217728 for tensor number 1 in the list.

W0209 01:21:03.872354 16490 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:21:03.873597 16490 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 32, 26],"float32"),Tensor([1, 5162221, 32, 26],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([1, 3, 32, 26],"float32"),Tensor([1, 5162221, 32, 26],"float32"),), axis=1, )

W0209 01:22:21.335331 16518 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:22:21.336174 16518 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 32, 26],"float32"),Tensor([5162221, 1, 32, 26],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 32, 26],"float32"),Tensor([5162221, 1, 32, 26],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1 but got size 5162221 for tensor number 1 in the list.

W0209 01:25:41.709784 16574 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:25:41.711006 16574 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 32, 44739243],"float32"),Tensor([1, 1, 32, 26],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 32, 44739243],"float32"),Tensor([1, 1, 32, 26],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 44739243 but got size 26 for tensor number 1 in the list.

W0209 01:26:56.099960 16602 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:26:56.100934 16602 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 32, 44739243],"float32"),Tensor([1, 1, 32, 44739243],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 3, 32, 44739243],"float32"),Tensor([1, 1, 32, 44739243],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333333GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 01:28:33.987306 16645 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:28:33.988183 16645 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 3253764, 440],"float32"),Tensor([1, 1, 3253764, 440],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 3, 3253764, 440],"float32"),Tensor([1, 1, 3253764, 440],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333339GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 01:30:19.727303 16686 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:30:19.728147 16686 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 3253764, 440],"float32"),Tensor([1, 1, 410, 440],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 3253764, 440],"float32"),Tensor([1, 1, 410, 440],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 3253764 but got size 410 for tensor number 1 in the list.

W0209 01:31:47.530027 16727 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:31:47.531179 16727 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 3728271, 384],"float32"),Tensor([1, 1, 3728271, 384],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 3, 3728271, 384],"float32"),Tensor([1, 1, 3728271, 384],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333338GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 01:33:32.714988 16756 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:33:32.716184 16756 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 3728271, 384],"float32"),Tensor([1, 1, 458, 384],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 3728271, 384],"float32"),Tensor([1, 1, 458, 384],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 3728271 but got size 458 for tensor number 1 in the list.

W0209 01:34:57.485522 16785 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:34:57.487555 16785 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 400, 300],"float32"),Tensor([1, 1, 14316558, 300],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 400, 300],"float32"),Tensor([1, 1, 14316558, 300],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 400 but got size 14316558 for tensor number 1 in the list.

W0209 01:36:11.827893 16813 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:36:11.829159 16813 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 400, 300],"float32"),Tensor([1, 1, 400, 10737419],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 400, 300],"float32"),Tensor([1, 1, 400, 10737419],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 300 but got size 10737419 for tensor number 1 in the list.

W0209 01:37:26.872613 16854 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:37:26.873889 16854 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 400, 300],"float32"),Tensor([1, 35792, 400, 300],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([1, 3, 400, 300],"float32"),Tensor([1, 35792, 400, 300],"float32"),), axis=1, )

W0209 01:38:47.515226 16882 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:38:47.516059 16882 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 400, 300],"float32"),Tensor([35792, 1, 400, 300],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 400, 300],"float32"),Tensor([35792, 1, 400, 300],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1 but got size 35792 for tensor number 1 in the list.

W0209 01:42:20.734150 16952 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:42:20.735266 16952 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 400, 3579140],"float32"),Tensor([1, 1, 400, 300],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 400, 3579140],"float32"),Tensor([1, 1, 400, 300],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 3579140 but got size 300 for tensor number 1 in the list.

W0209 01:43:40.840822 16980 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:43:40.841883 16980 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 400, 3579140],"float32"),Tensor([1, 1, 400, 3579140],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 3, 400, 3579140],"float32"),Tensor([1, 1, 400, 3579140],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333337GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 01:45:32.221858 17009 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:45:32.223181 17009 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 4090446, 350],"float32"),Tensor([1, 1, 280, 350],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 4090446, 350],"float32"),Tensor([1, 1, 280, 350],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 4090446 but got size 280 for tensor number 1 in the list.

W0209 01:47:03.888342 17063 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:47:03.890008 17063 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 4090446, 350],"float32"),Tensor([1, 1, 4090446, 350],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 3, 4090446, 350],"float32"),Tensor([1, 1, 4090446, 350],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333338GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 01:48:51.020074 17092 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:48:51.021302 17092 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 410, 3491844],"float32"),Tensor([1, 1, 410, 3491844],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 3, 410, 3491844],"float32"),Tensor([1, 1, 410, 3491844],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333338GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 01:50:40.589874 17133 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:50:40.590754 17133 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 410, 3491844],"float32"),Tensor([1, 1, 410, 440],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 410, 3491844],"float32"),Tensor([1, 1, 410, 440],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 3491844 but got size 440 for tensor number 1 in the list.

W0209 01:52:08.066280 17176 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:52:08.067179 17176 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 410, 440],"float32"),Tensor([1, 1, 410, 10475530],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 410, 440],"float32"),Tensor([1, 1, 410, 10475530],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 440 but got size 10475530 for tensor number 1 in the list.

W0209 01:53:21.999840 17204 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:53:22.000996 17204 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 410, 440],"float32"),Tensor([1, 1, 9761290, 440],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 410, 440],"float32"),Tensor([1, 1, 9761290, 440],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 410 but got size 9761290 for tensor number 1 in the list.

W0209 01:54:39.833755 17245 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:54:39.835052 17245 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 410, 440],"float32"),Tensor([1, 23809, 410, 440],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([1, 3, 410, 440],"float32"),Tensor([1, 23809, 410, 440],"float32"),), axis=1, )

W0209 01:55:56.974476 17261 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:55:56.975394 17261 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 410, 440],"float32"),Tensor([23809, 1, 410, 440],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 410, 440],"float32"),Tensor([23809, 1, 410, 440],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1 but got size 23809 for tensor number 1 in the list.

W0209 01:59:28.065053 17303 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 01:59:28.066232 17303 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 432, 3314018],"float32"),Tensor([1, 1, 432, 3314018],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 3, 432, 3314018],"float32"),Tensor([1, 1, 432, 3314018],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333333GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 02:01:18.278228 17330 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:01:18.279289 17330 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 432, 3314018],"float32"),Tensor([1, 1, 432, 448],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 432, 3314018],"float32"),Tensor([1, 1, 432, 448],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 3314018 but got size 448 for tensor number 1 in the list.

W0209 02:02:36.425995 17345 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:02:36.426995 17345 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 432, 448],"float32"),Tensor([1, 1, 432, 9942054],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 432, 448],"float32"),Tensor([1, 1, 432, 9942054],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 448 but got size 9942054 for tensor number 1 in the list.

W0209 02:03:51.584976 17385 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:03:51.586613 17385 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 432, 448],"float32"),Tensor([1, 1, 9586981, 448],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 432, 448],"float32"),Tensor([1, 1, 9586981, 448],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 432 but got size 9586981 for tensor number 1 in the list.

W0209 02:05:09.441079 17414 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:05:09.442212 17414 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 432, 448],"float32"),Tensor([1, 22193, 432, 448],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([1, 3, 432, 448],"float32"),Tensor([1, 22193, 432, 448],"float32"),), axis=1, )

W0209 02:06:32.172681 17442 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:06:32.174273 17442 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 432, 448],"float32"),Tensor([22193, 1, 432, 448],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 432, 448],"float32"),Tensor([22193, 1, 432, 448],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1 but got size 22193 for tensor number 1 in the list.

W0209 02:10:07.412564 17512 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:10:07.413995 17512 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 458, 3125886],"float32"),Tensor([1, 1, 458, 3125886],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 3, 458, 3125886],"float32"),Tensor([1, 1, 458, 3125886],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333334GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 02:11:49.845793 17527 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:11:49.846808 17527 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 458, 3125886],"float32"),Tensor([1, 1, 458, 384],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 458, 3125886],"float32"),Tensor([1, 1, 458, 384],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 3125886 but got size 384 for tensor number 1 in the list.

W0209 02:13:11.097124 17568 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:13:11.098090 17568 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 458, 384],"float32"),Tensor([1, 1, 11184811, 384],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 458, 384],"float32"),Tensor([1, 1, 11184811, 384],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 458 but got size 11184811 for tensor number 1 in the list.

W0209 02:14:20.124837 17583 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:14:20.126070 17583 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 458, 384],"float32"),Tensor([1, 1, 458, 9377658],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 458, 384],"float32"),Tensor([1, 1, 458, 9377658],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 384 but got size 9377658 for tensor number 1 in the list.

W0209 02:15:35.762559 17611 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:15:35.763783 17611 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 458, 384],"float32"),Tensor([1, 24421, 458, 384],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([1, 3, 458, 384],"float32"),Tensor([1, 24421, 458, 384],"float32"),), axis=1, )

W0209 02:16:54.857856 17651 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:16:54.858814 17651 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 458, 384],"float32"),Tensor([24421, 1, 458, 384],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 458, 384],"float32"),Tensor([24421, 1, 458, 384],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1 but got size 24421 for tensor number 1 in the list.

W0209 02:20:20.649959 17708 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:20:20.651067 17708 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 4772186, 300],"float32"),Tensor([1, 1, 400, 300],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 4772186, 300],"float32"),Tensor([1, 1, 400, 300],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 4772186 but got size 400 for tensor number 1 in the list.

W0209 02:21:36.609666 17737 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:21:36.611106 17737 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 4772186, 300],"float32"),Tensor([1, 1, 4772186, 300],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 3, 4772186, 300],"float32"),Tensor([1, 1, 4772186, 300],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333334GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 02:23:16.539634 17764 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:23:16.540490 17764 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 498, 2874811],"float32"),Tensor([1, 1, 498, 2874811],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 3, 498, 2874811],"float32"),Tensor([1, 1, 498, 2874811],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333335GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 02:25:11.401757 17807 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:25:11.403288 17807 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 498, 2874811],"float32"),Tensor([1, 1, 498, 494],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 498, 2874811],"float32"),Tensor([1, 1, 498, 494],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2874811 but got size 494 for tensor number 1 in the list.

W0209 02:26:29.928174 17834 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:26:29.929224 17834 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 498, 494],"float32"),Tensor([1, 1, 498, 8624433],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 498, 494],"float32"),Tensor([1, 1, 498, 8624433],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 494 but got size 8624433 for tensor number 1 in the list.

W0209 02:27:45.269040 17862 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:27:45.270304 17862 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 498, 494],"float32"),Tensor([1, 1, 8694266, 494],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 498, 494],"float32"),Tensor([1, 1, 8694266, 494],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 498 but got size 8694266 for tensor number 1 in the list.

W0209 02:29:02.251858 17890 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:29:02.253114 17890 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 498, 494],"float32"),Tensor([1, 17459, 498, 494],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([1, 3, 498, 494],"float32"),Tensor([1, 17459, 498, 494],"float32"),), axis=1, )

W0209 02:30:18.543843 17918 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:30:18.544739 17918 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 498, 494],"float32"),Tensor([17459, 1, 498, 494],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 498, 494],"float32"),Tensor([17459, 1, 498, 494],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1 but got size 17459 for tensor number 1 in the list.

W0209 02:33:46.378436 17961 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:33:46.379916 17961 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 51130564, 28],"float32"),Tensor([1, 1, 28, 28],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 51130564, 28],"float32"),Tensor([1, 1, 28, 28],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 51130564 but got size 28 for tensor number 1 in the list.

W0209 02:35:06.956182 18001 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:35:06.957561 18001 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 51130564, 28],"float32"),Tensor([1, 1, 51130564, 28],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 3, 51130564, 28],"float32"),Tensor([1, 1, 51130564, 28],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333334GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 02:36:52.480037 18017 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:36:52.481384 18017 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 55063684, 26],"float32"),Tensor([1, 1, 32, 26],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 55063684, 26],"float32"),Tensor([1, 1, 32, 26],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 55063684 but got size 32 for tensor number 1 in the list.

W0209 02:38:16.938061 18045 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:38:16.939246 18045 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 55063684, 26],"float32"),Tensor([1, 1, 55063684, 26],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 3, 55063684, 26],"float32"),Tensor([1, 1, 55063684, 26],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333334GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 02:40:10.443928 18086 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:40:10.445070 18086 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 64, 22369622],"float32"),Tensor([1, 1, 64, 22369622],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 3, 64, 22369622],"float32"),Tensor([1, 1, 64, 22369622],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333334GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 02:42:04.783197 18114 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:42:04.784435 18114 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 64, 22369622],"float32"),Tensor([1, 1, 64, 64],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 64, 22369622],"float32"),Tensor([1, 1, 64, 64],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 22369622 but got size 64 for tensor number 1 in the list.

W0209 02:43:24.031834 18156 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:43:24.033147 18156 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 64, 64],"float32"),Tensor([1, 1, 64, 67108864],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 64, 64],"float32"),Tensor([1, 1, 64, 67108864],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 64 but got size 67108864 for tensor number 1 in the list.

W0209 02:44:37.733628 18171 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:44:37.734985 18171 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 64, 64],"float32"),Tensor([1, 1, 67108864, 64],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 64, 64],"float32"),Tensor([1, 1, 67108864, 64],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 64 but got size 67108864 for tensor number 1 in the list.

W0209 02:45:49.021401 18211 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:45:49.022487 18211 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 64, 64],"float32"),Tensor([1, 1048576, 64, 64],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([1, 3, 64, 64],"float32"),Tensor([1, 1048576, 64, 64],"float32"),), axis=1, )

W0209 02:47:05.077831 18239 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:47:05.079285 18239 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 64, 64],"float32"),Tensor([1048576, 1, 64, 64],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 64, 64],"float32"),Tensor([1048576, 1, 64, 64],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1 but got size 1048576 for tensor number 1 in the list.

W0209 02:50:27.100610 18296 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:50:27.101708 18296 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 8, 178956971],"float32"),Tensor([1, 1, 8, 178956971],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 3, 8, 178956971],"float32"),Tensor([1, 1, 8, 178956971],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333333GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 02:52:04.450248 18311 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:52:04.451138 18311 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 8, 178956971],"float32"),Tensor([1, 1, 8, 8],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 8, 178956971],"float32"),Tensor([1, 1, 8, 8],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 178956971 but got size 8 for tensor number 1 in the list.

W0209 02:53:23.445688 18352 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:53:23.447274 18352 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 8, 8],"float32"),Tensor([1, 1, 536870912, 8],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 8, 8],"float32"),Tensor([1, 1, 536870912, 8],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 8 but got size 536870912 for tensor number 1 in the list.

W0209 02:54:37.449092 18380 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:54:37.450357 18380 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 8, 8],"float32"),Tensor([1, 1, 8, 536870912],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 8, 8],"float32"),Tensor([1, 1, 8, 536870912],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 8 but got size 536870912 for tensor number 1 in the list.

W0209 02:55:47.339433 18421 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:55:47.340528 18421 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 8, 8],"float32"),Tensor([1, 67108864, 8, 8],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([1, 3, 8, 8],"float32"),Tensor([1, 67108864, 8, 8],"float32"),), axis=1, )

W0209 02:57:01.937197 18450 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 02:57:01.938230 18450 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 3, 8, 8],"float32"),Tensor([67108864, 1, 8, 8],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1, 3, 8, 8],"float32"),Tensor([67108864, 1, 8, 8],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1 but got size 67108864 for tensor number 1 in the list.

W0209 03:00:27.185250 18465 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:00:27.186590 18465 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 35792, 400, 300],"float32"),Tensor([1, 1, 400, 300],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([1, 35792, 400, 300],"float32"),Tensor([1, 1, 400, 300],"float32"),), axis=1, )

W0209 03:01:52.497820 18479 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:01:52.498699 18479 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 35792, 400, 300],"float32"),Tensor([1, 35792, 400, 300],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 35792, 400, 300],"float32"),Tensor([1, 35792, 400, 300],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000271GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 03:06:48.217862 18534 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:06:48.218767 18534 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 43827, 280, 350],"float32"),Tensor([1, 1, 280, 350],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([1, 43827, 280, 350],"float32"),Tensor([1, 1, 280, 350],"float32"),), axis=1, )

W0209 03:08:10.430122 18576 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:08:10.431061 18576 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 43827, 280, 350],"float32"),Tensor([1, 43827, 280, 350],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 43827, 280, 350],"float32"),Tensor([1, 43827, 280, 350],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000293GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 03:13:21.923298 18645 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:13:21.924177 18645 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 5162221, 32, 26],"float32"),Tensor([1, 1, 32, 26],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([1, 5162221, 32, 26],"float32"),Tensor([1, 1, 32, 26],"float32"),), axis=1, )

W0209 03:14:48.425817 18674 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:14:48.426784 18674 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 5162221, 32, 26],"float32"),Tensor([1, 5162221, 32, 26],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 5162221, 32, 26],"float32"),Tensor([1, 5162221, 32, 26],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000002GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 03:19:54.653702 18758 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:19:54.654547 18758 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 5478275, 28, 28],"float32"),Tensor([1, 1, 28, 28],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([1, 5478275, 28, 28],"float32"),Tensor([1, 1, 28, 28],"float32"),), axis=1, )

W0209 03:21:15.743758 18787 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:21:15.744649 18787 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 5478275, 28, 28],"float32"),Tensor([1, 5478275, 28, 28],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 5478275, 28, 28],"float32"),Tensor([1, 5478275, 28, 28],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 03:26:02.531041 18828 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:26:02.531904 18828 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 67108864, 8, 8],"float32"),Tensor([1, 1, 8, 8],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([1, 67108864, 8, 8],"float32"),Tensor([1, 1, 8, 8],"float32"),), axis=1, )

W0209 03:27:28.374902 18884 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:27:28.375798 18884 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1, 67108864, 8, 8],"float32"),Tensor([1, 67108864, 8, 8],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1, 67108864, 8, 8],"float32"),Tensor([1, 67108864, 8, 8],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 03:32:19.727180 18927 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:32:19.729486 18927 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1],"float64"),Tensor([2147483649],"float64"),), )
[Pass] paddle.concat(tuple(Tensor([1],"float64"),Tensor([2147483649],"float64"),), )

W0209 03:33:12.278031 18968 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:33:12.279048 18968 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1073741824, 4],"float32"),), 1, )
[Pass] paddle.concat(tuple(Tensor([1073741824, 4],"float32"),), 1, )

W0209 03:36:25.558916 19010 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:36:25.560420 19010 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([11931, 3, 400, 300],"float32"),Tensor([1, 1, 400, 300],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([11931, 3, 400, 300],"float32"),Tensor([1, 1, 400, 300],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 11931 but got size 1 for tensor number 1 in the list.

W0209 03:40:01.248055 19066 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:40:01.249050 19066 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([11931, 3, 400, 300],"float32"),Tensor([11931, 1, 400, 300],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([11931, 3, 400, 300],"float32"),Tensor([11931, 1, 400, 300],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.334291GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 03:41:44.249773 19107 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:41:44.250658 19107 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([12],"float64"),Tensor([2147483649],"float64"),), )
[Pass] paddle.concat(tuple(Tensor([12],"float64"),Tensor([2147483649],"float64"),), )

W0209 03:42:46.484278 19136 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:42:46.485352 19136 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1398102, 3, 32, 32],"float32"),Tensor([1398102, 3, 32, 32],"float32"),), 1, )
[paddle error] paddle.concat(tuple(Tensor([1398102, 3, 32, 32],"float32"),Tensor([1398102, 3, 32, 32],"float32"),), 1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000008GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 03:46:58.832700 19192 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:46:58.833542 19192 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1398102, 3, 32, 32],"float32"),Tensor([2, 3, 32, 32],"float32"),), 1, )
[torch error] paddle.concat(tuple(Tensor([1398102, 3, 32, 32],"float32"),Tensor([2, 3, 32, 32],"float32"),), 1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1398102 but got size 2 for tensor number 1 in the list.

W0209 03:48:06.784699 19234 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:48:06.785844 19234 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1431655765, 3],"float32"),), 1, )
[Pass] paddle.concat(tuple(Tensor([1431655765, 3],"float32"),), 1, )

W0209 03:49:24.371280 19262 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:49:24.372546 19262 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([14609, 3, 280, 350],"float32"),Tensor([1, 1, 280, 350],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([14609, 3, 280, 350],"float32"),Tensor([1, 1, 280, 350],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14609 but got size 1 for tensor number 1 in the list.

W0209 03:53:00.425786 19332 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:53:00.426966 19332 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([14609, 3, 280, 350],"float32"),Tensor([14609, 1, 280, 350],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([14609, 3, 280, 350],"float32"),Tensor([14609, 1, 280, 350],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333724GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 03:54:47.686632 19360 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:54:47.687737 19360 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1720741, 3, 32, 26],"float32"),Tensor([1, 1, 32, 26],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1720741, 3, 32, 26],"float32"),Tensor([1, 1, 32, 26],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1720741 but got size 1 for tensor number 1 in the list.

W0209 03:56:07.136209 19408 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:56:07.137461 19408 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1720741, 3, 32, 26],"float32"),Tensor([1720741, 1, 32, 26],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1720741, 3, 32, 26],"float32"),Tensor([1720741, 1, 32, 26],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333344GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 03:57:44.776528 19430 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:57:44.777459 19430 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([178956971, 12],"float64"),), 1, )
[Pass] paddle.concat(tuple(Tensor([178956971, 12],"float64"),), 1, )

W0209 03:58:46.638190 19485 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 03:58:46.639055 19485 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1826092, 3, 28, 28],"float32"),Tensor([1, 1, 28, 28],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([1826092, 3, 28, 28],"float32"),Tensor([1, 1, 28, 28],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1826092 but got size 1 for tensor number 1 in the list.

W0209 04:02:18.426306 19515 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:02:18.427867 19515 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([1826092, 3, 28, 28],"float32"),Tensor([1826092, 1, 28, 28],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([1826092, 3, 28, 28],"float32"),Tensor([1826092, 1, 28, 28],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333339GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 04:03:55.975705 19556 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:03:55.976686 19556 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 1073741825],"float64"),), 1, )
[Pass] paddle.concat(tuple(Tensor([2, 1073741825],"float64"),), 1, )

W0209 04:05:03.928287 19584 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:05:03.929494 19584 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 134217728, 4, 4],"float32"),Tensor([2, 1, 4, 4],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([2, 134217728, 4, 4],"float32"),Tensor([2, 1, 4, 4],"float32"),), axis=1, )

W0209 04:08:21.543236 19626 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:08:21.544054 19626 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 134217728, 4, 4],"float32"),Tensor([2, 134217728, 4, 4],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([2, 134217728, 4, 4],"float32"),Tensor([2, 134217728, 4, 4],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 04:13:09.100500 19669 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:13:09.101505 19669 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 2],"float32"),Tensor([2, 2147483648],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([2, 2],"float32"),Tensor([2, 2147483648],"float32"),), axis=1, )

W0209 04:14:23.600054 19723 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:14:23.601212 19723 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 2],"float32"),Tensor([4294967295, 1],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([2, 2],"float32"),Tensor([4294967295, 1],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 4294967295 for tensor number 1 in the list.

W0209 04:17:46.914430 19780 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:17:46.915663 19780 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 2097152, 32, 32],"float32"),Tensor([2, 2097152, 32, 32],"float32"),), 1, )
[paddle error] paddle.concat(tuple(Tensor([2, 2097152, 32, 32],"float32"),Tensor([2, 2097152, 32, 32],"float32"),), 1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 04:20:16.725932 19808 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:20:16.728251 19808 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 2097152, 32, 32],"float32"),Tensor([2, 3, 32, 32],"float32"),), 1, )
[Pass] paddle.concat(tuple(Tensor([2, 2097152, 32, 32],"float32"),Tensor([2, 3, 32, 32],"float32"),), 1, )

W0209 04:21:44.326100 19863 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:21:44.326968 19863 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 2147483648],"float32"),Tensor([2, 1],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([2, 2147483648],"float32"),Tensor([2, 1],"float32"),), axis=1, )

W0209 04:25:28.877238 19933 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:25:28.878198 19933 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 2147483648],"float32"),Tensor([2, 2147483648],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([2, 2147483648],"float32"),Tensor([2, 2147483648],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 04:30:18.202858 19976 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:30:18.203837 19976 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 3, 178956971, 4],"float32"),Tensor([2, 1, 178956971, 4],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([2, 3, 178956971, 4],"float32"),Tensor([2, 1, 178956971, 4],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333333GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 04:31:56.501013 20017 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:31:56.501971 20017 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 3, 178956971, 4],"float32"),Tensor([2, 1, 4, 4],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([2, 3, 178956971, 4],"float32"),Tensor([2, 1, 4, 4],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 178956971 but got size 4 for tensor number 1 in the list.

W0209 04:33:15.160385 20047 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:33:15.161536 20047 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 3, 22369622, 32],"float32"),Tensor([2, 3, 22369622, 32],"float32"),), 1, )
[paddle error] paddle.concat(tuple(Tensor([2, 3, 22369622, 32],"float32"),Tensor([2, 3, 22369622, 32],"float32"),), 1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 04:35:48.604395 20074 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:35:48.605460 20074 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 3, 22369622, 32],"float32"),Tensor([2, 3, 32, 32],"float32"),), 1, )
[torch error] paddle.concat(tuple(Tensor([2, 3, 22369622, 32],"float32"),Tensor([2, 3, 32, 32],"float32"),), 1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 22369622 but got size 32 for tensor number 1 in the list.

W0209 04:37:06.295137 20116 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:37:06.296411 20116 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 3, 32, 22369622],"float32"),Tensor([2, 3, 32, 22369622],"float32"),), 1, )
[paddle error] paddle.concat(tuple(Tensor([2, 3, 32, 22369622],"float32"),Tensor([2, 3, 32, 22369622],"float32"),), 1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 04:39:29.951328 20131 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:39:29.952175 20131 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 3, 32, 22369622],"float32"),Tensor([2, 3, 32, 32],"float32"),), 1, )
[torch error] paddle.concat(tuple(Tensor([2, 3, 32, 22369622],"float32"),Tensor([2, 3, 32, 32],"float32"),), 1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 22369622 but got size 32 for tensor number 1 in the list.

W0209 04:40:37.959059 20186 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:40:37.960145 20186 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 3, 32, 32],"float32"),Tensor([1398102, 3, 32, 32],"float32"),), 1, )
[torch error] paddle.concat(tuple(Tensor([2, 3, 32, 32],"float32"),Tensor([1398102, 3, 32, 32],"float32"),), 1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 1398102 for tensor number 1 in the list.

W0209 04:41:47.403558 20214 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:41:47.404779 20214 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 3, 32, 32],"float32"),Tensor([2, 2097152, 32, 32],"float32"),), 1, )
[Pass] paddle.concat(tuple(Tensor([2, 3, 32, 32],"float32"),Tensor([2, 2097152, 32, 32],"float32"),), 1, )

W0209 04:43:02.565452 20229 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:43:02.566819 20229 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 3, 32, 32],"float32"),Tensor([2, 3, 22369622, 32],"float32"),), 1, )
[torch error] paddle.concat(tuple(Tensor([2, 3, 32, 32],"float32"),Tensor([2, 3, 22369622, 32],"float32"),), 1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 32 but got size 22369622 for tensor number 1 in the list.

W0209 04:46:36.328538 20284 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:46:36.329847 20284 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 3, 32, 32],"float32"),Tensor([2, 3, 32, 22369622],"float32"),), 1, )
[torch error] paddle.concat(tuple(Tensor([2, 3, 32, 32],"float32"),Tensor([2, 3, 32, 22369622],"float32"),), 1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 32 but got size 22369622 for tensor number 1 in the list.

W0209 04:47:46.762156 20326 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:47:46.763262 20326 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 3, 4, 178956971],"float32"),Tensor([2, 1, 4, 178956971],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([2, 3, 4, 178956971],"float32"),Tensor([2, 1, 4, 178956971],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333333GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 04:49:33.628412 20368 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:49:33.629613 20368 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 3, 4, 178956971],"float32"),Tensor([2, 1, 4, 4],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([2, 3, 4, 178956971],"float32"),Tensor([2, 1, 4, 4],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 178956971 but got size 4 for tensor number 1 in the list.

W0209 04:50:59.839018 20396 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:50:59.840121 20396 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 3, 4, 4],"float32"),Tensor([2, 1, 4, 536870912],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([2, 3, 4, 4],"float32"),Tensor([2, 1, 4, 536870912],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 4 but got size 536870912 for tensor number 1 in the list.

W0209 04:52:08.159709 20424 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:52:08.160822 20424 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 3, 4, 4],"float32"),Tensor([2, 1, 536870912, 4],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([2, 3, 4, 4],"float32"),Tensor([2, 1, 536870912, 4],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 4 but got size 536870912 for tensor number 1 in the list.

W0209 04:53:22.979688 20452 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:53:22.980783 20452 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 3, 4, 4],"float32"),Tensor([2, 134217728, 4, 4],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([2, 3, 4, 4],"float32"),Tensor([2, 134217728, 4, 4],"float32"),), axis=1, )

W0209 04:54:41.759950 20481 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:54:41.760845 20481 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 3, 4, 4],"float32"),Tensor([268435456, 1, 4, 4],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([2, 3, 4, 4],"float32"),Tensor([268435456, 1, 4, 4],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 268435456 for tensor number 1 in the list.

W0209 04:58:10.178747 20564 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:58:10.179863 20564 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 3, 8, 8],"float32"),Tensor([2, 1, 268435456, 8],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([2, 3, 8, 8],"float32"),Tensor([2, 1, 268435456, 8],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 8 but got size 268435456 for tensor number 1 in the list.

W0209 04:59:27.975893 20592 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 04:59:27.977011 20592 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 3, 8, 8],"float32"),Tensor([2, 1, 8, 268435456],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([2, 3, 8, 8],"float32"),Tensor([2, 1, 8, 268435456],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 8 but got size 268435456 for tensor number 1 in the list.

W0209 05:00:43.872859 20621 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:00:43.873943 20621 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 3, 8, 8],"float32"),Tensor([2, 33554432, 8, 8],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([2, 3, 8, 8],"float32"),Tensor([2, 33554432, 8, 8],"float32"),), axis=1, )

W0209 05:02:02.152828 20662 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:02:02.153767 20662 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 3, 8, 8],"float32"),Tensor([67108864, 1, 8, 8],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([2, 3, 8, 8],"float32"),Tensor([67108864, 1, 8, 8],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 67108864 for tensor number 1 in the list.

W0209 05:05:22.322571 20706 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:05:22.323871 20706 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 3, 8, 89478486],"float32"),Tensor([2, 1, 8, 8],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([2, 3, 8, 89478486],"float32"),Tensor([2, 1, 8, 8],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 89478486 but got size 8 for tensor number 1 in the list.

W0209 05:06:34.876173 20733 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:06:34.877189 20733 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 3, 8, 89478486],"float32"),Tensor([2, 1, 8, 89478486],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([2, 3, 8, 89478486],"float32"),Tensor([2, 1, 8, 89478486],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333333GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 05:08:16.981441 20761 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:08:16.982282 20761 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 3, 89478486, 8],"float32"),Tensor([2, 1, 8, 8],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([2, 3, 89478486, 8],"float32"),Tensor([2, 1, 8, 8],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 89478486 but got size 8 for tensor number 1 in the list.

W0209 05:09:37.959213 20803 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:09:37.960276 20803 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 3, 89478486, 8],"float32"),Tensor([2, 1, 89478486, 8],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([2, 3, 89478486, 8],"float32"),Tensor([2, 1, 89478486, 8],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333333GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 05:11:26.809962 20818 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:11:26.810863 20818 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 33554432, 8, 8],"float32"),Tensor([2, 1, 8, 8],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([2, 33554432, 8, 8],"float32"),Tensor([2, 1, 8, 8],"float32"),), axis=1, )

W0209 05:12:56.490686 20859 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:12:56.491729 20859 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2, 33554432, 8, 8],"float32"),Tensor([2, 33554432, 8, 8],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([2, 33554432, 8, 8],"float32"),Tensor([2, 33554432, 8, 8],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 05:17:44.020833 20928 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:17:44.021948 20928 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2],"float32"),Tensor([4294967295],"float32"),), )
[Pass] paddle.concat(tuple(Tensor([2],"float32"),Tensor([4294967295],"float32"),), )

W0209 05:19:03.931063 20971 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:19:03.932099 20971 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2147483648, 2],"float32"),), 1, )
[Pass] paddle.concat(tuple(Tensor([2147483648, 2],"float32"),), 1, )

W0209 05:22:36.993667 21000 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:22:36.994544 21000 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2147483648, 2],"float32"),Tensor([2, 1],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([2147483648, 2],"float32"),Tensor([2, 1],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2147483648 but got size 2 for tensor number 1 in the list.

W0209 05:26:11.583763 21056 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:26:11.584805 21056 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2147483648, 2],"float32"),Tensor([2147483648, 1],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([2147483648, 2],"float32"),Tensor([2147483648, 1],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 24.000000GB memory on GPU 0, 73.584900GB memory has been allocated and available memory is only 5.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 05:28:13.858059 21083 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:28:13.858994 21083 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2147483648, 2],"float32"),Tensor([2147483648, 2],"float32"),), 1, )
[paddle error] paddle.concat(tuple(Tensor([2147483648, 2],"float32"),Tensor([2147483648, 2],"float32"),), 1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 05:30:45.976208 21098 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:30:45.977083 21098 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2147483648, 2],"float32"),Tensor([5, 2],"float32"),), 1, )
[torch error] paddle.concat(tuple(Tensor([2147483648, 2],"float32"),Tensor([5, 2],"float32"),), 1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2147483648 but got size 5 for tensor number 1 in the list.

W0209 05:31:57.787765 21126 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:31:57.788898 21126 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2147483649],"float64"),), )
[Pass] paddle.concat(tuple(Tensor([2147483649],"float64"),), )

W0209 05:32:53.773325 21140 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:32:53.774250 21140 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2147483649],"float64"),Tensor([1],"float64"),), )
[Pass] paddle.concat(tuple(Tensor([2147483649],"float64"),Tensor([1],"float64"),), )

W0209 05:35:44.572261 21182 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:35:44.573338 21182 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2147483649],"float64"),Tensor([12],"float64"),), )
[Pass] paddle.concat(tuple(Tensor([2147483649],"float64"),Tensor([12],"float64"),), )

W0209 05:38:47.885226 21238 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:38:47.886128 21238 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),), )
[paddle error] paddle.concat(tuple(Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 05:42:24.133284 21292 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:42:24.134199 21292 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2147483649],"float64"),Tensor([3],"float64"),), )
[Pass] paddle.concat(tuple(Tensor([2147483649],"float64"),Tensor([3],"float64"),), )

W0209 05:43:18.333820 21332 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:43:18.334796 21332 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([2147483649],"float64"),Tensor([4],"float64"),), )
[Pass] paddle.concat(tuple(Tensor([2147483649],"float64"),Tensor([4],"float64"),), )

W0209 05:46:08.167388 21377 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:46:08.168254 21377 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([22369622, 3, 8, 8],"float32"),Tensor([1, 1, 8, 8],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([22369622, 3, 8, 8],"float32"),Tensor([1, 1, 8, 8],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 22369622 but got size 1 for tensor number 1 in the list.

W0209 05:49:15.103327 21419 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:49:15.104751 21419 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([22369622, 3, 8, 8],"float32"),Tensor([2, 1, 8, 8],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([22369622, 3, 8, 8],"float32"),Tensor([2, 1, 8, 8],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 22369622 but got size 2 for tensor number 1 in the list.

W0209 05:50:29.999212 21447 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:50:30.000341 21447 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([22369622, 3, 8, 8],"float32"),Tensor([22369622, 1, 8, 8],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([22369622, 3, 8, 8],"float32"),Tensor([22369622, 1, 8, 8],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333334GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 05:52:10.954859 21462 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:52:10.955844 21462 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([3, 1431655765],"float32"),), 1, )
[Pass] paddle.concat(tuple(Tensor([3, 1431655765],"float32"),), 1, )

W0209 05:53:40.534654 21504 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:53:40.535548 21504 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([3],"float64"),Tensor([2147483649],"float64"),), )
[Pass] paddle.concat(tuple(Tensor([3],"float64"),Tensor([2147483649],"float64"),), )

W0209 05:56:59.318279 21560 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 05:56:59.319312 21560 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([349526, 3, 64, 64],"float32"),Tensor([1, 1, 64, 64],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([349526, 3, 64, 64],"float32"),Tensor([1, 1, 64, 64],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 349526 but got size 1 for tensor number 1 in the list.

W0209 06:00:07.031805 21601 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 06:00:07.032933 21601 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([349526, 3, 64, 64],"float32"),Tensor([349526, 1, 64, 64],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([349526, 3, 64, 64],"float32"),Tensor([349526, 1, 64, 64],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333374GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 06:01:55.986141 21630 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 06:01:55.987051 21630 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([4, 1],"float32"),Tensor([4, 1],"float32"),Tensor([4, 1073741824],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([4, 1],"float32"),Tensor([4, 1],"float32"),Tensor([4, 1073741824],"float32"),), axis=1, )

W0209 06:03:26.204174 21684 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 06:03:26.205207 21684 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([4, 1],"float32"),Tensor([4, 1],"float32"),Tensor([4294967295, 1],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([4, 1],"float32"),Tensor([4, 1],"float32"),Tensor([4294967295, 1],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 4 but got size 4294967295 for tensor number 2 in the list.

W0209 06:06:53.638684 21727 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 06:06:53.639886 21727 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([4, 1],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([4, 1],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1],"float32"),), axis=1, )

W0209 06:08:16.365270 21769 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 06:08:16.366330 21769 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([4, 1],"float32"),Tensor([4294967295, 1],"float32"),Tensor([4, 1],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([4, 1],"float32"),Tensor([4294967295, 1],"float32"),Tensor([4, 1],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 4 but got size 4294967295 for tensor number 1 in the list.

W0209 06:11:56.659317 21838 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 06:11:56.660902 21838 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([4, 1073741824],"float32"),Tensor([4, 1],"float32"),Tensor([4, 1],"float32"),), axis=1, )
[Pass] paddle.concat(tuple(Tensor([4, 1073741824],"float32"),Tensor([4, 1],"float32"),Tensor([4, 1],"float32"),), axis=1, )

W0209 06:13:13.855991 21865 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 06:13:13.856915 21865 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),), axis=1, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 55178 has 48.99 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0209 06:18:47.857048 21922 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 06:18:47.858006 21922 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([4],"float32"),Tensor([4294967295],"float32"),), )
[Pass] paddle.concat(tuple(Tensor([4],"float32"),Tensor([4294967295],"float32"),), )

W0209 06:20:08.767103 21963 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 06:20:08.768360 21963 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([4],"float64"),Tensor([2147483649],"float64"),), )
[Pass] paddle.concat(tuple(Tensor([4],"float64"),Tensor([2147483649],"float64"),), )

W0209 06:23:21.929010 22032 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 06:23:21.930140 22032 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([4294967295, 1],"float32"),), 1, )
[Pass] paddle.concat(tuple(Tensor([4294967295, 1],"float32"),), 1, )

W0209 06:27:07.971951 22062 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 06:27:07.972895 22062 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([4294967295, 1],"float32"),Tensor([4, 1],"float32"),Tensor([4, 1],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([4294967295, 1],"float32"),Tensor([4, 1],"float32"),Tensor([4, 1],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 4294967295 but got size 4 for tensor number 1 in the list.

W0209 06:30:31.713631 22117 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 06:30:31.714955 22117 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([4294967295, 1],"float32"),Tensor([4294967295, 1],"float32"),Tensor([4294967295, 1],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([4294967295, 1],"float32"),Tensor([4294967295, 1],"float32"),Tensor([4294967295, 1],"float32"),), axis=1, ) 
 CUDA out of memory. Tried to allocate 48.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 30.19 GiB is free. Process 89955 has 48.99 GiB memory in use. Of the allocated memory 48.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0209 06:33:39.840238 22145 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 06:33:39.841321 22145 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),), )
[Pass] paddle.concat(tuple(Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),), )

W0209 06:36:36.384157 22187 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 06:36:36.385185 22187 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([4294967295],"float16"),Tensor([60],"float16"),), )
[Pass] paddle.concat(tuple(Tensor([4294967295],"float16"),Tensor([60],"float16"),), )

W0209 06:53:36.390537 22412 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 06:53:36.391440 22412 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([4294967295],"float32"),), )
[Pass] paddle.concat(tuple(Tensor([4294967295],"float32"),), )

W0209 07:02:36.611510 22566 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:02:36.612550 22566 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([4294967295],"float32"),Tensor([2],"float32"),), )
[Pass] paddle.concat(tuple(Tensor([4294967295],"float32"),Tensor([2],"float32"),), )

W0209 07:06:17.770546 22635 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:06:17.771387 22635 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([4294967295],"float32"),Tensor([4],"float32"),), )
[Pass] paddle.concat(tuple(Tensor([4294967295],"float32"),Tensor([4],"float32"),), )

W0209 07:09:55.430625 22683 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:09:55.431716 22683 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),), )
[paddle error] paddle.concat(tuple(Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 07:14:50.707435 22720 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:14:50.708292 22720 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([4294967295],"float32"),Tensor([60],"float32"),), )
[Pass] paddle.concat(tuple(Tensor([4294967295],"float32"),Tensor([60],"float32"),), )

W0209 07:16:13.876997 22762 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:16:13.877918 22762 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([5, 2],"float32"),Tensor([2147483648, 2],"float32"),), 1, )
[torch error] paddle.concat(tuple(Tensor([5, 2],"float32"),Tensor([2147483648, 2],"float32"),), 1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5 but got size 2147483648 for tensor number 1 in the list.

W0209 07:19:39.457353 22817 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:19:39.458439 22817 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([5, 2],"float32"),Tensor([5, 858993459],"float32"),), 1, )
[Pass] paddle.concat(tuple(Tensor([5, 2],"float32"),Tensor([5, 858993459],"float32"),), 1, )

W0209 07:21:24.568817 22845 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:21:24.569757 22845 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([5, 858993459],"float32"),), 1, )
[Pass] paddle.concat(tuple(Tensor([5, 858993459],"float32"),), 1, )

W0209 07:25:07.651168 22888 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:25:07.652017 22888 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([5, 858993459],"float32"),Tensor([5, 2],"float32"),), 1, )
[Pass] paddle.concat(tuple(Tensor([5, 858993459],"float32"),Tensor([5, 2],"float32"),), 1, )

W0209 07:28:36.969221 22944 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:28:36.970085 22944 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([5, 858993459],"float32"),Tensor([5, 858993459],"float32"),), 1, )
[paddle error] paddle.concat(tuple(Tensor([5, 858993459],"float32"),Tensor([5, 858993459],"float32"),), 1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 07:33:22.425678 22999 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:33:22.426560 22999 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([5820, 3, 498, 494],"float32"),Tensor([1, 1, 498, 494],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([5820, 3, 498, 494],"float32"),Tensor([1, 1, 498, 494],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5820 but got size 1 for tensor number 1 in the list.

W0209 07:34:32.018936 23041 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:34:32.031451 23041 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([5820, 3, 498, 494],"float32"),Tensor([5820, 1, 498, 494],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([5820, 3, 498, 494],"float32"),Tensor([5820, 1, 498, 494],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.335331GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 07:36:20.092494 23070 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:36:20.093539 23070 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([60],"float16"),Tensor([4294967295],"float16"),), )
[Pass] paddle.concat(tuple(Tensor([60],"float16"),Tensor([4294967295],"float16"),), )

W0209 07:38:00.441370 23111 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:38:00.442286 23111 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([60],"float32"),Tensor([4294967295],"float32"),), )
[Pass] paddle.concat(tuple(Tensor([60],"float32"),Tensor([4294967295],"float32"),), )

W0209 07:47:05.494468 23251 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:47:05.495321 23251 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([715827883, 3],"float64"),), 1, )
[Pass] paddle.concat(tuple(Tensor([715827883, 3],"float64"),), 1, )

W0209 07:50:23.358476 23293 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:50:23.359537 23293 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([7398, 3, 432, 448],"float32"),Tensor([1, 1, 432, 448],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([7398, 3, 432, 448],"float32"),Tensor([1, 1, 432, 448],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7398 but got size 1 for tensor number 1 in the list.

W0209 07:53:30.981491 23335 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:53:30.982303 23335 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([7398, 3, 432, 448],"float32"),Tensor([7398, 1, 432, 448],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([7398, 3, 432, 448],"float32"),Tensor([7398, 1, 432, 448],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.335175GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 07:55:09.278369 23376 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:55:09.279500 23376 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([7937, 3, 410, 440],"float32"),Tensor([1, 1, 410, 440],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([7937, 3, 410, 440],"float32"),Tensor([1, 1, 410, 440],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7937 but got size 1 for tensor number 1 in the list.

W0209 07:56:37.486598 23405 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:56:37.487401 23405 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([7937, 3, 410, 440],"float32"),Tensor([7937, 1, 410, 440],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([7937, 3, 410, 440],"float32"),Tensor([7937, 1, 410, 440],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.336001GB memory on GPU 0, 65.602478GB memory has been allocated and available memory is only 13.582397GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 07:58:16.167676 23433 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:58:16.168566 23433 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([8141, 3, 458, 384],"float32"),Tensor([1, 1, 458, 384],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([8141, 3, 458, 384],"float32"),Tensor([1, 1, 458, 384],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 8141 but got size 1 for tensor number 1 in the list.

W0209 07:59:33.404206 23461 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 07:59:33.405186 23461 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([8141, 3, 458, 384],"float32"),Tensor([8141, 1, 458, 384],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([8141, 3, 458, 384],"float32"),Tensor([8141, 1, 458, 384],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.335094GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 08:01:10.094163 23476 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:01:10.095023 23476 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([89478486, 3, 4, 4],"float32"),Tensor([2, 1, 4, 4],"float32"),), axis=1, )
[torch error] paddle.concat(tuple(Tensor([89478486, 3, 4, 4],"float32"),Tensor([2, 1, 4, 4],"float32"),), axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 89478486 but got size 2 for tensor number 1 in the list.

W0209 08:02:27.624475 23504 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:02:27.625532 23504 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(tuple(Tensor([89478486, 3, 4, 4],"float32"),Tensor([89478486, 1, 4, 4],"float32"),), axis=1, )
[paddle error] paddle.concat(tuple(Tensor([89478486, 3, 4, 4],"float32"),Tensor([89478486, 1, 4, 4],"float32"),), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_concat(_object*, _object*, _object*)
1   concat_ad_func(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor>)
2   paddle::experimental::concat(std::vector<paddle::Tensor, std::allocator<paddle::Tensor> > const&, paddle::experimental::ScalarBase<paddle::Tensor> const&)
3   void phi::ConcatKernel<float, phi::GPUContext>(phi::GPUContext const&, std::vector<phi::DenseTensor const*, std::allocator<phi::DenseTensor const*> > const&, paddle::experimental::ScalarBase<phi::DenseTensor> const&, phi::DenseTensor*)
4   float* phi::DeviceContext::Alloc<float>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 21.333333GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 08:04:09.909734 23531 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:04:09.910569 23531 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(x=list[Tensor([1, 25565282, 14, 12],"float32"),Tensor([1, 25565282, 14, 12],"float32"),], axis=0, )
[paddle error] paddle.concat(x=list[Tensor([1, 25565282, 14, 12],"float32"),Tensor([1, 25565282, 14, 12],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 08:06:51.984426 23559 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:06:51.986716 23559 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(x=list[Tensor([1, 25565282, 14, 12],"float32"),Tensor([1, 8, 14, 12],"float32"),], axis=0, )
[torch error] paddle.concat(x=list[Tensor([1, 25565282, 14, 12],"float32"),Tensor([1, 8, 14, 12],"float32"),], axis=0, ) 
 Sizes of tensors must match except in dimension 0. Expected size 25565282 but got size 8 for tensor number 1 in the list.

W0209 08:08:09.463222 23601 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:08:09.464264 23601 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(x=list[Tensor([1, 3],"float32"),Tensor([1, 4294967295],"float32"),], axis=0, )
[torch error] paddle.concat(x=list[Tensor([1, 3],"float32"),Tensor([1, 4294967295],"float32"),], axis=0, ) 
 Sizes of tensors must match except in dimension 0. Expected size 3 but got size 4294967295 for tensor number 1 in the list.

W0209 08:09:23.327216 23616 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:09:23.328334 23616 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(x=list[Tensor([1, 3],"float32"),Tensor([1431655765, 3],"float32"),], axis=0, )
[Pass] paddle.concat(x=list[Tensor([1, 3],"float32"),Tensor([1431655765, 3],"float32"),], axis=0, )

W0209 08:10:45.026695 23657 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:10:45.027909 23657 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(x=list[Tensor([1, 4294967295],"float32"),Tensor([1, 3],"float32"),], axis=0, )
[torch error] paddle.concat(x=list[Tensor([1, 4294967295],"float32"),Tensor([1, 3],"float32"),], axis=0, ) 
 Sizes of tensors must match except in dimension 0. Expected size 4294967295 but got size 3 for tensor number 1 in the list.

W0209 08:14:42.904579 23726 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:14:42.905551 23726 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(x=list[Tensor([1, 4294967295],"float32"),Tensor([1, 4294967295],"float32"),], axis=0, )
[paddle error] paddle.concat(x=list[Tensor([1, 4294967295],"float32"),Tensor([1, 4294967295],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 08:17:13.079267 23742 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:17:13.080225 23742 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(x=list[Tensor([1, 8, 14, 12],"float32"),Tensor([1, 25565282, 14, 12],"float32"),], axis=0, )
[torch error] paddle.concat(x=list[Tensor([1, 8, 14, 12],"float32"),Tensor([1, 25565282, 14, 12],"float32"),], axis=0, ) 
 Sizes of tensors must match except in dimension 0. Expected size 8 but got size 25565282 for tensor number 1 in the list.

W0209 08:18:19.957974 23796 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:18:19.959103 23796 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(x=list[Tensor([1, 8, 14, 12],"float32"),Tensor([1, 8, 14, 38347923],"float32"),], axis=0, )
[torch error] paddle.concat(x=list[Tensor([1, 8, 14, 12],"float32"),Tensor([1, 8, 14, 38347923],"float32"),], axis=0, ) 
 Sizes of tensors must match except in dimension 0. Expected size 12 but got size 38347923 for tensor number 1 in the list.

W0209 08:19:37.252681 23825 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:19:37.254179 23825 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(x=list[Tensor([1, 8, 14, 12],"float32"),Tensor([1, 8, 44739243, 12],"float32"),], axis=0, )
[torch error] paddle.concat(x=list[Tensor([1, 8, 14, 12],"float32"),Tensor([1, 8, 44739243, 12],"float32"),], axis=0, ) 
 Sizes of tensors must match except in dimension 0. Expected size 14 but got size 44739243 for tensor number 1 in the list.

W0209 08:20:48.301710 23840 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:20:48.302917 23840 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(x=list[Tensor([1, 8, 14, 12],"float32"),Tensor([3195661, 8, 14, 12],"float32"),], axis=0, )
[Pass] paddle.concat(x=list[Tensor([1, 8, 14, 12],"float32"),Tensor([3195661, 8, 14, 12],"float32"),], axis=0, )

W0209 08:22:07.983024 23881 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:22:07.983834 23881 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(x=list[Tensor([1, 8, 14, 38347923],"float32"),Tensor([1, 8, 14, 12],"float32"),], axis=0, )
[torch error] paddle.concat(x=list[Tensor([1, 8, 14, 38347923],"float32"),Tensor([1, 8, 14, 12],"float32"),], axis=0, ) 
 Sizes of tensors must match except in dimension 0. Expected size 38347923 but got size 12 for tensor number 1 in the list.

W0209 08:25:56.656411 23937 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:25:56.657498 23937 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(x=list[Tensor([1, 8, 14, 38347923],"float32"),Tensor([1, 8, 14, 38347923],"float32"),], axis=0, )
[paddle error] paddle.concat(x=list[Tensor([1, 8, 14, 38347923],"float32"),Tensor([1, 8, 14, 38347923],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 08:28:36.427681 23966 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:28:36.428573 23966 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(x=list[Tensor([1, 8, 44739243, 12],"float32"),Tensor([1, 8, 14, 12],"float32"),], axis=0, )
[torch error] paddle.concat(x=list[Tensor([1, 8, 44739243, 12],"float32"),Tensor([1, 8, 14, 12],"float32"),], axis=0, ) 
 Sizes of tensors must match except in dimension 0. Expected size 44739243 but got size 14 for tensor number 1 in the list.

W0209 08:29:44.902546 24020 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:29:44.903836 24020 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(x=list[Tensor([1, 8, 44739243, 12],"float32"),Tensor([1, 8, 44739243, 12],"float32"),], axis=0, )
[paddle error] paddle.concat(x=list[Tensor([1, 8, 44739243, 12],"float32"),Tensor([1, 8, 44739243, 12],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 08:32:24.836063 24036 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:32:24.837327 24036 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(x=list[Tensor([1431655765, 3],"float32"),Tensor([1, 3],"float32"),], axis=0, )
[Pass] paddle.concat(x=list[Tensor([1431655765, 3],"float32"),Tensor([1, 3],"float32"),], axis=0, )

W0209 08:33:45.315932 24104 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:33:45.316738 24104 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(x=list[Tensor([1431655765, 3],"float32"),Tensor([1431655765, 3],"float32"),], axis=0, )
[paddle error] paddle.concat(x=list[Tensor([1431655765, 3],"float32"),Tensor([1431655765, 3],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 08:38:35.988494 24175 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:38:35.989452 24175 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(x=list[Tensor([3195661, 8, 14, 12],"float32"),Tensor([1, 8, 14, 12],"float32"),], axis=0, )
[Pass] paddle.concat(x=list[Tensor([3195661, 8, 14, 12],"float32"),Tensor([1, 8, 14, 12],"float32"),], axis=0, )

W0209 08:39:51.584453 24217 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:39:51.585395 24217 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(x=list[Tensor([3195661, 8, 14, 12],"float32"),Tensor([3195661, 8, 14, 12],"float32"),], axis=0, )
[paddle error] paddle.concat(x=list[Tensor([3195661, 8, 14, 12],"float32"),Tensor([3195661, 8, 14, 12],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 65.590759GB memory has been allocated and available memory is only 13.594116GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 08:44:35.235397 24272 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:44:35.236452 24272 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.conj(Tensor([17895698, 20, 2, 3],"float64"), )
[Pass] paddle.conj(Tensor([17895698, 20, 2, 3],"float64"), )

W0209 08:45:28.799975 24301 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:45:28.800951 24301 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.conj(Tensor([2, 178956971, 2, 3],"float64"), )
[Pass] paddle.conj(Tensor([2, 178956971, 2, 3],"float64"), )

W0209 08:48:18.739493 24344 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:48:18.740290 24344 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.conj(Tensor([2, 20, 17895698, 3],"float64"), )
[Pass] paddle.conj(Tensor([2, 20, 17895698, 3],"float64"), )

W0209 08:51:05.396796 24399 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:51:05.397862 24399 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.conj(Tensor([2, 20, 2, 26843546],"float64"), )
[Pass] paddle.conj(Tensor([2, 20, 2, 26843546],"float64"), )

W0209 08:54:01.453938 24440 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:54:01.454910 24440 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.conj(Tensor([2, 20, 2, 53687092],"float32"), )
[accuracy error] paddle.conj(Tensor([2, 20, 2, 53687092],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 63 / 4294967360 (1.47e-06%)
Max absolute difference: 0.99775034
Max relative difference: 1.
 x: array([[[[0.906229, 0.721947, 0.463664, ..., 0.012646, 0.268901,
          0.552786],
         [0.815116, 0.598403, 0.104964, ..., 0.88018 , 0.098767,...
 y: array([[[[0.906229, 0.721947, 0.463664, ..., 0.012646, 0.268901,
          0.552786],
         [0.815116, 0.598403, 0.104964, ..., 0.88018 , 0.098767,...

W0209 08:57:37.058670 24475 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 08:57:37.059551 24475 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.conj(Tensor([2, 20, 35791395, 3],"float32"), )
[accuracy error] paddle.conj(Tensor([2, 20, 35791395, 3],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 102 / 4294967400 (2.37e-06%)
Max absolute difference: 0.9997191
Max relative difference: 1.
 x: array([[[[7.896239e-01, 2.747567e-03, 7.095596e-01],
         [7.293234e-01, 9.535462e-01, 4.162248e-02],
         [9.785516e-01, 7.966234e-01, 1.847360e-01],...
 y: array([[[[7.896239e-01, 2.747567e-03, 7.095596e-01],
         [7.293234e-01, 9.535462e-01, 4.162248e-02],
         [9.785516e-01, 7.966234e-01, 1.847360e-01],...

W0209 09:02:26.820211 24566 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:02:26.821173 24566 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.conj(Tensor([2, 357913942, 2, 3],"float32"), )
[accuracy error] paddle.conj(Tensor([2, 357913942, 2, 3],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 8 / 4294967304 (1.86e-07%)
Max absolute difference: 0.7125682
Max relative difference: 1.
 x: array([[[[0.526836, 0.797022, 0.718158],
         [0.119862, 0.010929, 0.031088]],
...
 y: array([[[[0.526836, 0.797022, 0.718158],
         [0.119862, 0.010929, 0.031088]],
...

W0209 09:07:04.075062 24638 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:07:04.076148 24638 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.conj(Tensor([35791395, 20, 2, 3],"float32"), )
[accuracy error] paddle.conj(Tensor([35791395, 20, 2, 3],"float32"), ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 104 / 4294967400 (2.42e-06%)
Max absolute difference: 0.9828911
Max relative difference: 1.
 x: array([[[[8.775246e-01, 8.022555e-01, 5.773287e-01],
         [8.806893e-01, 1.035829e-01, 8.500971e-01]],
...
 y: array([[[[8.775246e-01, 8.022555e-01, 5.773287e-01],
         [8.806893e-01, 1.035829e-01, 8.500971e-01]],
...

W0209 09:11:52.727088 24666 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:11:52.728041 24666 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 20],"bool"), Tensor([10, 429496730],"bool"), )
[torch error] paddle.copysign(Tensor([10, 20],"bool"), Tensor([10, 429496730],"bool"), ) 
 The size of tensor a (20) must match the size of tensor b (429496730) at non-singleton dimension 1

W0209 09:16:15.877446 24762 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:16:15.878691 24762 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 20],"bool"), Tensor([214748365, 20],"bool"), )
[torch error] paddle.copysign(Tensor([10, 20],"bool"), Tensor([214748365, 20],"bool"), ) 
 The size of tensor a (10) must match the size of tensor b (214748365) at non-singleton dimension 0

W0209 09:17:18.457304 24778 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:17:18.458546 24778 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 20],"float16"), Tensor([10, 429496730],"float16"), )
[torch error] paddle.copysign(Tensor([10, 20],"float16"), Tensor([10, 429496730],"float16"), ) 
 The size of tensor a (20) must match the size of tensor b (429496730) at non-singleton dimension 1

W0209 09:18:47.227172 24805 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:18:47.228391 24805 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 20],"float16"), Tensor([214748365, 20],"float16"), )
[torch error] paddle.copysign(Tensor([10, 20],"float16"), Tensor([214748365, 20],"float16"), ) 
 The size of tensor a (10) must match the size of tensor b (214748365) at non-singleton dimension 0

W0209 09:20:10.052940 24846 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:20:10.054041 24846 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 20],"float32"), Tensor([10, 429496730],"float32"), )
[torch error] paddle.copysign(Tensor([10, 20],"float32"), Tensor([10, 429496730],"float32"), ) 
 The size of tensor a (20) must match the size of tensor b (429496730) at non-singleton dimension 1

W0209 09:21:21.426836 24889 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:21:21.428340 24889 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 20],"float32"), Tensor([214748365, 20],"float32"), )
[torch error] paddle.copysign(Tensor([10, 20],"float32"), Tensor([214748365, 20],"float32"), ) 
 The size of tensor a (10) must match the size of tensor b (214748365) at non-singleton dimension 0

W0209 09:22:40.332167 24917 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:22:40.333379 24917 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 20],"float64"), Tensor([10, 214748365],"float64"), )
[torch error] paddle.copysign(Tensor([10, 20],"float64"), Tensor([10, 214748365],"float64"), ) 
 The size of tensor a (20) must match the size of tensor b (214748365) at non-singleton dimension 1

W0209 09:23:28.783392 24945 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:23:28.784602 24945 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 20],"float64"), Tensor([107374183, 20],"float64"), )
[torch error] paddle.copysign(Tensor([10, 20],"float64"), Tensor([107374183, 20],"float64"), ) 
 The size of tensor a (10) must match the size of tensor b (107374183) at non-singleton dimension 0

W0209 09:24:19.794965 24973 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:24:19.796010 24973 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 20],"int16"), Tensor([10, 429496730],"int16"), )
[torch error] paddle.copysign(Tensor([10, 20],"int16"), Tensor([10, 429496730],"int16"), ) 
 The size of tensor a (20) must match the size of tensor b (429496730) at non-singleton dimension 1

W0209 09:25:31.289224 24987 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:25:31.290411 24987 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 20],"int16"), Tensor([214748365, 20],"int16"), )
[torch error] paddle.copysign(Tensor([10, 20],"int16"), Tensor([214748365, 20],"int16"), ) 
 The size of tensor a (10) must match the size of tensor b (214748365) at non-singleton dimension 0

W0209 09:26:35.673166 25028 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:26:35.674331 25028 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 20],"int32"), Tensor([10, 429496730],"int32"), )
[torch error] paddle.copysign(Tensor([10, 20],"int32"), Tensor([10, 429496730],"int32"), ) 
 The size of tensor a (20) must match the size of tensor b (429496730) at non-singleton dimension 1

W0209 09:27:45.263993 25057 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:27:45.265237 25057 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 20],"int32"), Tensor([214748365, 20],"int32"), )
[torch error] paddle.copysign(Tensor([10, 20],"int32"), Tensor([214748365, 20],"int32"), ) 
 The size of tensor a (10) must match the size of tensor b (214748365) at non-singleton dimension 0

W0209 09:29:01.294641 25072 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:29:01.295785 25072 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 20],"int64"), Tensor([10, 214748365],"int64"), )
[torch error] paddle.copysign(Tensor([10, 20],"int64"), Tensor([10, 214748365],"int64"), ) 
 The size of tensor a (20) must match the size of tensor b (214748365) at non-singleton dimension 1

W0209 09:29:51.792847 25112 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:29:51.794075 25112 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 20],"int64"), Tensor([107374183, 20],"int64"), )
[torch error] paddle.copysign(Tensor([10, 20],"int64"), Tensor([107374183, 20],"int64"), ) 
 The size of tensor a (10) must match the size of tensor b (107374183) at non-singleton dimension 0

W0209 09:30:40.777350 25128 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:30:40.778923 25128 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 20],"int8"), Tensor([10, 429496730],"int8"), )
[torch error] paddle.copysign(Tensor([10, 20],"int8"), Tensor([10, 429496730],"int8"), ) 
 The size of tensor a (20) must match the size of tensor b (429496730) at non-singleton dimension 1

W0209 09:31:45.463140 25155 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:31:45.464129 25155 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 20],"int8"), Tensor([214748365, 20],"int8"), )
[torch error] paddle.copysign(Tensor([10, 20],"int8"), Tensor([214748365, 20],"int8"), ) 
 The size of tensor a (10) must match the size of tensor b (214748365) at non-singleton dimension 0

W0209 09:32:47.067241 25170 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:32:47.068459 25170 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 20],"uint8"), Tensor([10, 429496730],"uint8"), )
[torch error] paddle.copysign(Tensor([10, 20],"uint8"), Tensor([10, 429496730],"uint8"), ) 
 The size of tensor a (20) must match the size of tensor b (429496730) at non-singleton dimension 1

W0209 09:33:53.691452 25210 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:33:53.692713 25210 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 20],"uint8"), Tensor([214748365, 20],"uint8"), )
[torch error] paddle.copysign(Tensor([10, 20],"uint8"), Tensor([214748365, 20],"uint8"), ) 
 The size of tensor a (10) must match the size of tensor b (214748365) at non-singleton dimension 0

W0209 09:35:06.591323 25239 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:35:06.592598 25239 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 214748365],"float64"), Tensor([10, 20],"float64"), )
[torch error] paddle.copysign(Tensor([10, 214748365],"float64"), Tensor([10, 20],"float64"), ) 
 The size of tensor a (214748365) must match the size of tensor b (20) at non-singleton dimension 1

W0209 09:35:59.775573 25267 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:35:59.776695 25267 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 214748365],"float64"), Tensor([10, 214748365],"float64"), )
[paddle error] paddle.copysign(Tensor([10, 214748365],"float64"), Tensor([10, 214748365],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 09:37:43.751204 25308 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:37:43.752146 25308 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 214748365],"int64"), Tensor([10, 20],"int64"), )
[torch error] paddle.copysign(Tensor([10, 214748365],"int64"), Tensor([10, 20],"int64"), ) 
 The size of tensor a (214748365) must match the size of tensor b (20) at non-singleton dimension 1

W0209 09:38:30.010500 25337 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:38:30.011652 25337 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 214748365],"int64"), Tensor([10, 214748365],"int64"), )
[paddle error] paddle.copysign(Tensor([10, 214748365],"int64"), Tensor([10, 214748365],"int64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_copysign(_object*, _object*, _object*)
1   copysign_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::copysign(paddle::Tensor const&, paddle::Tensor const&)
3   void phi::CopySignKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor*)
4   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 73.594666GB memory has been allocated and available memory is only 5.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 09:40:14.777386 25365 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:40:14.778448 25365 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 429496730],"bool"), Tensor([10, 20],"bool"), )
[torch error] paddle.copysign(Tensor([10, 429496730],"bool"), Tensor([10, 20],"bool"), ) 
 The size of tensor a (429496730) must match the size of tensor b (20) at non-singleton dimension 1

W0209 09:41:28.805838 25407 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:41:28.806955 25407 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 429496730],"bool"), Tensor([10, 429496730],"bool"), )
[Pass] paddle.copysign(Tensor([10, 429496730],"bool"), Tensor([10, 429496730],"bool"), )

W0209 09:43:28.952725 25422 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:43:28.953609 25422 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 429496730],"float16"), Tensor([10, 20],"float16"), )
[torch error] paddle.copysign(Tensor([10, 429496730],"float16"), Tensor([10, 20],"float16"), ) 
 The size of tensor a (429496730) must match the size of tensor b (20) at non-singleton dimension 1

W0209 09:46:11.339969 25463 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:46:11.341109 25463 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 429496730],"float16"), Tensor([10, 429496730],"float16"), )
[Pass] paddle.copysign(Tensor([10, 429496730],"float16"), Tensor([10, 429496730],"float16"), )

W0209 09:49:07.826063 25491 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:49:07.826979 25491 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 429496730],"float32"), -3.0, )
[Pass] paddle.copysign(Tensor([10, 429496730],"float32"), -3.0, )

W0209 09:58:03.007891 25604 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 09:58:03.008781 25604 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 429496730],"float32"), Tensor([10, 20],"float32"), )
[torch error] paddle.copysign(Tensor([10, 429496730],"float32"), Tensor([10, 20],"float32"), ) 
 The size of tensor a (429496730) must match the size of tensor b (20) at non-singleton dimension 1

W0209 10:01:56.515230 25646 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:01:56.516322 25646 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 429496730],"float32"), Tensor([10, 429496730],"float32"), )
[paddle error] paddle.copysign(Tensor([10, 429496730],"float32"), Tensor([10, 429496730],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 10:04:39.761802 25686 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:04:39.762735 25686 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 429496730],"int16"), Tensor([10, 20],"int16"), )
[torch error] paddle.copysign(Tensor([10, 429496730],"int16"), Tensor([10, 20],"int16"), ) 
 The size of tensor a (429496730) must match the size of tensor b (20) at non-singleton dimension 1

W0209 10:05:45.711789 25715 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:05:45.713214 25715 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 429496730],"int16"), Tensor([10, 429496730],"int16"), )
[Pass] paddle.copysign(Tensor([10, 429496730],"int16"), Tensor([10, 429496730],"int16"), )

W0209 10:07:58.979496 25743 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:07:58.980427 25743 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 429496730],"int32"), Tensor([10, 20],"int32"), )
[torch error] paddle.copysign(Tensor([10, 429496730],"int32"), Tensor([10, 20],"int32"), ) 
 The size of tensor a (429496730) must match the size of tensor b (20) at non-singleton dimension 1

W0209 10:11:18.320993 25785 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:11:18.322023 25785 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 429496730],"int32"), Tensor([10, 429496730],"int32"), )
[paddle error] paddle.copysign(Tensor([10, 429496730],"int32"), Tensor([10, 429496730],"int32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 10:13:50.437009 25800 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:13:50.438007 25800 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 429496730],"int8"), Tensor([10, 20],"int8"), )
[torch error] paddle.copysign(Tensor([10, 429496730],"int8"), Tensor([10, 20],"int8"), ) 
 The size of tensor a (429496730) must match the size of tensor b (20) at non-singleton dimension 1

W0209 10:14:53.972196 25841 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:14:53.973336 25841 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 429496730],"int8"), Tensor([10, 429496730],"int8"), )
[Pass] paddle.copysign(Tensor([10, 429496730],"int8"), Tensor([10, 429496730],"int8"), )

W0209 10:16:55.984468 26201 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:16:55.985381 26201 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 429496730],"uint8"), Tensor([10, 20],"uint8"), )
[torch error] paddle.copysign(Tensor([10, 429496730],"uint8"), Tensor([10, 20],"uint8"), ) 
 The size of tensor a (429496730) must match the size of tensor b (20) at non-singleton dimension 1

W0209 10:19:58.573442 28023 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:19:58.574594 28023 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([10, 429496730],"uint8"), Tensor([10, 429496730],"uint8"), )
[Pass] paddle.copysign(Tensor([10, 429496730],"uint8"), Tensor([10, 429496730],"uint8"), )

W0209 10:22:04.988700 28500 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:22:04.989768 28500 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([107374183, 20, 2],"float32"), Tensor([107374183, 20, 2],"float32"), )
[paddle error] paddle.copysign(Tensor([107374183, 20, 2],"float32"), Tensor([107374183, 20, 2],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 10:26:50.965384 31050 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:26:50.966290 31050 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([107374183, 20, 2],"float32"), Tensor([12, 20, 2],"float32"), )
[torch error] paddle.copysign(Tensor([107374183, 20, 2],"float32"), Tensor([12, 20, 2],"float32"), ) 
 The size of tensor a (107374183) must match the size of tensor b (12) at non-singleton dimension 0

W0209 10:28:00.036011 32228 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:28:00.037159 32228 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([107374183, 20, 2],"int16"), Tensor([107374183, 20, 2],"int16"), )
[Pass] paddle.copysign(Tensor([107374183, 20, 2],"int16"), Tensor([107374183, 20, 2],"int16"), )

W0209 10:30:14.600863 32731 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:30:14.602252 32731 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([107374183, 20, 2],"int16"), Tensor([12, 20, 2],"int16"), )
[torch error] paddle.copysign(Tensor([107374183, 20, 2],"int16"), Tensor([12, 20, 2],"int16"), ) 
 The size of tensor a (107374183) must match the size of tensor b (12) at non-singleton dimension 0

W0209 10:33:30.901357 34802 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:33:30.902578 34802 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([107374183, 20, 2],"int32"), Tensor([107374183, 20, 2],"int32"), )
[paddle error] paddle.copysign(Tensor([107374183, 20, 2],"int32"), Tensor([107374183, 20, 2],"int32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 10:36:03.431530 35273 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:36:03.432511 35273 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([107374183, 20, 2],"int32"), Tensor([12, 20, 2],"int32"), )
[torch error] paddle.copysign(Tensor([107374183, 20, 2],"int32"), Tensor([12, 20, 2],"int32"), ) 
 The size of tensor a (107374183) must match the size of tensor b (12) at non-singleton dimension 0

W0209 10:37:21.540827 36444 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:37:21.541828 36444 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([107374183, 20, 2],"int8"), Tensor([107374183, 20, 2],"int8"), )
[Pass] paddle.copysign(Tensor([107374183, 20, 2],"int8"), Tensor([107374183, 20, 2],"int8"), )

W0209 10:39:21.312824 37123 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:39:21.313688 37123 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([107374183, 20, 2],"int8"), Tensor([12, 20, 2],"int8"), )
[torch error] paddle.copysign(Tensor([107374183, 20, 2],"int8"), Tensor([12, 20, 2],"int8"), ) 
 The size of tensor a (107374183) must match the size of tensor b (12) at non-singleton dimension 0

W0209 10:42:33.388456 38964 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:42:33.389658 38964 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([107374183, 20, 2],"uint8"), Tensor([107374183, 20, 2],"uint8"), )
[Pass] paddle.copysign(Tensor([107374183, 20, 2],"uint8"), Tensor([107374183, 20, 2],"uint8"), )

W0209 10:44:32.334892 39657 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:44:32.335747 39657 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([107374183, 20, 2],"uint8"), Tensor([12, 20, 2],"uint8"), )
[torch error] paddle.copysign(Tensor([107374183, 20, 2],"uint8"), Tensor([12, 20, 2],"uint8"), ) 
 The size of tensor a (107374183) must match the size of tensor b (12) at non-singleton dimension 0

W0209 10:47:32.775293 41344 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:47:32.776523 41344 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([107374183, 20],"float64"), Tensor([10, 20],"float64"), )
[torch error] paddle.copysign(Tensor([107374183, 20],"float64"), Tensor([10, 20],"float64"), ) 
 The size of tensor a (107374183) must match the size of tensor b (10) at non-singleton dimension 0

W0209 10:48:23.562975 41814 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:48:23.564122 41814 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([107374183, 20],"float64"), Tensor([107374183, 20],"float64"), )
[paddle error] paddle.copysign(Tensor([107374183, 20],"float64"), Tensor([107374183, 20],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 10:50:19.575145 42285 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:50:19.576092 42285 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([107374183, 20],"int64"), Tensor([10, 20],"int64"), )
[torch error] paddle.copysign(Tensor([107374183, 20],"int64"), Tensor([10, 20],"int64"), ) 
 The size of tensor a (107374183) must match the size of tensor b (10) at non-singleton dimension 0

W0209 10:51:09.779752 43210 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:51:09.780900 43210 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([107374183, 20],"int64"), Tensor([107374183, 20],"int64"), )
[paddle error] paddle.copysign(Tensor([107374183, 20],"int64"), Tensor([107374183, 20],"int64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_copysign(_object*, _object*, _object*)
1   copysign_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::copysign(paddle::Tensor const&, paddle::Tensor const&)
3   void phi::CopySignKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor*)
4   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 73.594666GB memory has been allocated and available memory is only 5.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 10:52:52.913898 43665 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:52:52.914793 43665 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([11, 17, 10],"int16"), Tensor([11, 17, 22967740],"int16"), )
[torch error] paddle.copysign(Tensor([11, 17, 10],"int16"), Tensor([11, 17, 22967740],"int16"), ) 
 The size of tensor a (10) must match the size of tensor b (22967740) at non-singleton dimension 2

W0209 10:54:07.009622 44413 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:54:07.010743 44413 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([11, 17, 10],"int16"), Tensor([11, 39045158, 10],"int16"), )
[torch error] paddle.copysign(Tensor([11, 17, 10],"int16"), Tensor([11, 39045158, 10],"int16"), ) 
 The size of tensor a (17) must match the size of tensor b (39045158) at non-singleton dimension 1

W0209 10:55:18.683990 45077 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:55:18.685176 45077 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([11, 17, 10],"int16"), Tensor([25264514, 17, 10],"int16"), )
[torch error] paddle.copysign(Tensor([11, 17, 10],"int16"), Tensor([25264514, 17, 10],"int16"), ) 
 The size of tensor a (11) must match the size of tensor b (25264514) at non-singleton dimension 0

W0209 10:56:23.073114 45560 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:56:23.074358 45560 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([11, 17, 10],"int32"), Tensor([11, 17, 22967740],"int32"), )
[torch error] paddle.copysign(Tensor([11, 17, 10],"int32"), Tensor([11, 17, 22967740],"int32"), ) 
 The size of tensor a (10) must match the size of tensor b (22967740) at non-singleton dimension 2

W0209 10:57:33.258606 46049 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:57:33.259668 46049 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([11, 17, 10],"int32"), Tensor([11, 39045158, 10],"int32"), )
[torch error] paddle.copysign(Tensor([11, 17, 10],"int32"), Tensor([11, 39045158, 10],"int32"), ) 
 The size of tensor a (17) must match the size of tensor b (39045158) at non-singleton dimension 1

W0209 10:58:53.527348 46723 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 10:58:53.528579 46723 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([11, 17, 10],"int32"), Tensor([25264514, 17, 10],"int32"), )
[torch error] paddle.copysign(Tensor([11, 17, 10],"int32"), Tensor([25264514, 17, 10],"int32"), ) 
 The size of tensor a (11) must match the size of tensor b (25264514) at non-singleton dimension 0

W0209 11:00:00.670457 47220 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:00:00.671676 47220 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([11, 17, 22967740],"int16"), Tensor([11, 17, 10],"int16"), )
[torch error] paddle.copysign(Tensor([11, 17, 22967740],"int16"), Tensor([11, 17, 10],"int16"), ) 
 The size of tensor a (22967740) must match the size of tensor b (10) at non-singleton dimension 2

W0209 11:01:13.288621 47719 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:01:13.289719 47719 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([11, 17, 22967740],"int16"), Tensor([11, 17, 22967740],"int16"), )
[Pass] paddle.copysign(Tensor([11, 17, 22967740],"int16"), Tensor([11, 17, 22967740],"int16"), )

W0209 11:03:18.909242 48402 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:03:18.910130 48402 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([11, 17, 22967740],"int32"), Tensor([11, 17, 10],"int32"), )
[torch error] paddle.copysign(Tensor([11, 17, 22967740],"int32"), Tensor([11, 17, 10],"int32"), ) 
 The size of tensor a (22967740) must match the size of tensor b (10) at non-singleton dimension 2

W0209 11:06:35.606626 50259 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:06:35.607633 50259 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([11, 17, 22967740],"int32"), Tensor([11, 17, 22967740],"int32"), )
[paddle error] paddle.copysign(Tensor([11, 17, 22967740],"int32"), Tensor([11, 17, 22967740],"int32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 11:09:13.736305 50945 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:09:13.737210 50945 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([11, 17],"float32"), Tensor([11, 390451573],"float32"), )
[torch error] paddle.copysign(Tensor([11, 17],"float32"), Tensor([11, 390451573],"float32"), ) 
 The size of tensor a (17) must match the size of tensor b (390451573) at non-singleton dimension 1

W0209 11:10:25.039331 52131 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:10:25.040515 52131 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([11, 17],"float32"), Tensor([252645135, 17],"float32"), )
[torch error] paddle.copysign(Tensor([11, 17],"float32"), Tensor([252645135, 17],"float32"), ) 
 The size of tensor a (11) must match the size of tensor b (252645135) at non-singleton dimension 0

W0209 11:11:38.291102 52628 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:11:38.292193 52628 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([11, 390451573],"float32"), Tensor([11, 17],"float32"), )
[torch error] paddle.copysign(Tensor([11, 390451573],"float32"), Tensor([11, 17],"float32"), ) 
 The size of tensor a (390451573) must match the size of tensor b (17) at non-singleton dimension 1

W0209 11:12:50.246999 53319 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:12:50.248386 53319 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([11, 390451573],"float32"), Tensor([11, 390451573],"float32"), )
[paddle error] paddle.copysign(Tensor([11, 390451573],"float32"), Tensor([11, 390451573],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 11:15:18.500056 53803 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:15:18.500890 53803 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([11, 39045158, 10],"int16"), Tensor([11, 17, 10],"int16"), )
[torch error] paddle.copysign(Tensor([11, 39045158, 10],"int16"), Tensor([11, 17, 10],"int16"), ) 
 The size of tensor a (39045158) must match the size of tensor b (17) at non-singleton dimension 1

W0209 11:16:29.125985 54988 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:16:29.126976 54988 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([11, 39045158, 10],"int16"), Tensor([11, 39045158, 10],"int16"), )
[Pass] paddle.copysign(Tensor([11, 39045158, 10],"int16"), Tensor([11, 39045158, 10],"int16"), )

W0209 11:18:38.256762 55471 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:18:38.257823 55471 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([11, 39045158, 10],"int32"), Tensor([11, 17, 10],"int32"), )
[torch error] paddle.copysign(Tensor([11, 39045158, 10],"int32"), Tensor([11, 17, 10],"int32"), ) 
 The size of tensor a (39045158) must match the size of tensor b (17) at non-singleton dimension 1

W0209 11:21:56.416272 57522 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:21:56.417328 57522 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([11, 39045158, 10],"int32"), Tensor([11, 39045158, 10],"int32"), )
[paddle error] paddle.copysign(Tensor([11, 39045158, 10],"int32"), Tensor([11, 39045158, 10],"int32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 11:24:43.761435 58014 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:24:43.763828 58014 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 178956971, 2],"float32"), Tensor([12, 178956971, 2],"float32"), )
[paddle error] paddle.copysign(Tensor([12, 178956971, 2],"float32"), Tensor([12, 178956971, 2],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 11:27:09.590698 59393 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:27:09.591527 59393 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 178956971, 2],"float32"), Tensor([12, 20, 2],"float32"), )
[torch error] paddle.copysign(Tensor([12, 178956971, 2],"float32"), Tensor([12, 20, 2],"float32"), ) 
 The size of tensor a (178956971) must match the size of tensor b (20) at non-singleton dimension 1

W0209 11:28:29.958150 60583 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:28:29.960085 60583 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 178956971, 2],"int16"), Tensor([12, 178956971, 2],"int16"), )
[Pass] paddle.copysign(Tensor([12, 178956971, 2],"int16"), Tensor([12, 178956971, 2],"int16"), )

W0209 11:30:35.002792 61080 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:30:35.003734 61080 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 178956971, 2],"int16"), Tensor([12, 20, 2],"int16"), )
[torch error] paddle.copysign(Tensor([12, 178956971, 2],"int16"), Tensor([12, 20, 2],"int16"), ) 
 The size of tensor a (178956971) must match the size of tensor b (20) at non-singleton dimension 1

W0209 11:33:43.288905 62944 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:33:43.289875 62944 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 178956971, 2],"int32"), Tensor([12, 178956971, 2],"int32"), )
[paddle error] paddle.copysign(Tensor([12, 178956971, 2],"int32"), Tensor([12, 178956971, 2],"int32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 11:36:22.396054 63632 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:36:22.397159 63632 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 178956971, 2],"int32"), Tensor([12, 20, 2],"int32"), )
[torch error] paddle.copysign(Tensor([12, 178956971, 2],"int32"), Tensor([12, 20, 2],"int32"), ) 
 The size of tensor a (178956971) must match the size of tensor b (20) at non-singleton dimension 1

W0209 11:37:39.707630 64815 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:37:39.708742 64815 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 178956971, 2],"int8"), Tensor([12, 178956971, 2],"int8"), )
[Pass] paddle.copysign(Tensor([12, 178956971, 2],"int8"), Tensor([12, 178956971, 2],"int8"), )

W0209 11:39:39.098891 65514 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:39:39.099735 65514 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 178956971, 2],"int8"), Tensor([12, 20, 2],"int8"), )
[torch error] paddle.copysign(Tensor([12, 178956971, 2],"int8"), Tensor([12, 20, 2],"int8"), ) 
 The size of tensor a (178956971) must match the size of tensor b (20) at non-singleton dimension 1

W0209 11:42:37.531976 67380 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:42:37.533115 67380 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 178956971, 2],"uint8"), Tensor([12, 178956971, 2],"uint8"), )
[Pass] paddle.copysign(Tensor([12, 178956971, 2],"uint8"), Tensor([12, 178956971, 2],"uint8"), )

W0209 11:44:33.818357 67860 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:44:33.819245 67860 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 178956971, 2],"uint8"), Tensor([12, 20, 2],"uint8"), )
[torch error] paddle.copysign(Tensor([12, 178956971, 2],"uint8"), Tensor([12, 20, 2],"uint8"), ) 
 The size of tensor a (178956971) must match the size of tensor b (20) at non-singleton dimension 1

W0209 11:47:45.340067 69714 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:47:45.341262 69714 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 17895698],"float32"), Tensor([12, 20, 17895698],"float32"), )
[paddle error] paddle.copysign(Tensor([12, 20, 17895698],"float32"), Tensor([12, 20, 17895698],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 11:50:11.651876 70208 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:50:11.653106 70208 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 17895698],"float32"), Tensor([12, 20, 2],"float32"), )
[torch error] paddle.copysign(Tensor([12, 20, 17895698],"float32"), Tensor([12, 20, 2],"float32"), ) 
 The size of tensor a (17895698) must match the size of tensor b (2) at non-singleton dimension 2

W0209 11:51:22.620573 71368 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:51:22.621759 71368 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 17895698],"int16"), Tensor([12, 20, 17895698],"int16"), )
[Pass] paddle.copysign(Tensor([12, 20, 17895698],"int16"), Tensor([12, 20, 17895698],"int16"), )

W0209 11:53:35.819639 71864 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:53:35.820489 71864 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 17895698],"int16"), Tensor([12, 20, 2],"int16"), )
[torch error] paddle.copysign(Tensor([12, 20, 17895698],"int16"), Tensor([12, 20, 2],"int16"), ) 
 The size of tensor a (17895698) must match the size of tensor b (2) at non-singleton dimension 2

W0209 11:56:41.942097 74264 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:56:41.943112 74264 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 17895698],"int32"), Tensor([12, 20, 17895698],"int32"), )
[paddle error] paddle.copysign(Tensor([12, 20, 17895698],"int32"), Tensor([12, 20, 17895698],"int32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 11:59:27.583547 74756 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 11:59:27.584417 74756 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 17895698],"int32"), Tensor([12, 20, 2],"int32"), )
[torch error] paddle.copysign(Tensor([12, 20, 17895698],"int32"), Tensor([12, 20, 2],"int32"), ) 
 The size of tensor a (17895698) must match the size of tensor b (2) at non-singleton dimension 2

W0209 12:00:39.288151 75939 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:00:39.289328 75939 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 17895698],"int8"), Tensor([12, 20, 17895698],"int8"), )
[Pass] paddle.copysign(Tensor([12, 20, 17895698],"int8"), Tensor([12, 20, 17895698],"int8"), )

W0209 12:02:37.196905 76641 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:02:37.197822 76641 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 17895698],"int8"), Tensor([12, 20, 2],"int8"), )
[torch error] paddle.copysign(Tensor([12, 20, 17895698],"int8"), Tensor([12, 20, 2],"int8"), ) 
 The size of tensor a (17895698) must match the size of tensor b (2) at non-singleton dimension 2

W0209 12:05:37.589133 78294 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:05:37.590296 78294 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 17895698],"uint8"), Tensor([12, 20, 17895698],"uint8"), )
[Pass] paddle.copysign(Tensor([12, 20, 17895698],"uint8"), Tensor([12, 20, 17895698],"uint8"), )

W0209 12:07:49.430666 78953 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:07:49.431857 78953 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 17895698],"uint8"), Tensor([12, 20, 2],"uint8"), )
[torch error] paddle.copysign(Tensor([12, 20, 17895698],"uint8"), Tensor([12, 20, 2],"uint8"), ) 
 The size of tensor a (17895698) must match the size of tensor b (2) at non-singleton dimension 2

W0209 12:10:58.785372 80825 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:10:58.786803 80825 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 2],"float32"), Tensor([107374183, 20, 2],"float32"), )
[torch error] paddle.copysign(Tensor([12, 20, 2],"float32"), Tensor([107374183, 20, 2],"float32"), ) 
 The size of tensor a (12) must match the size of tensor b (107374183) at non-singleton dimension 0

W0209 12:12:15.836433 81322 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:12:15.838296 81322 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 2],"float32"), Tensor([12, 178956971, 2],"float32"), )
[torch error] paddle.copysign(Tensor([12, 20, 2],"float32"), Tensor([12, 178956971, 2],"float32"), ) 
 The size of tensor a (20) must match the size of tensor b (178956971) at non-singleton dimension 1

W0209 12:13:27.721220 82015 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:13:27.722514 82015 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 2],"float32"), Tensor([12, 20, 17895698],"float32"), )
[torch error] paddle.copysign(Tensor([12, 20, 2],"float32"), Tensor([12, 20, 17895698],"float32"), ) 
 The size of tensor a (2) must match the size of tensor b (17895698) at non-singleton dimension 2

W0209 12:14:39.124094 82498 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:14:39.125193 82498 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 2],"float64"), Tensor([12, 20, 8947849],"float64"), )
[torch error] paddle.copysign(Tensor([12, 20, 2],"float64"), Tensor([12, 20, 8947849],"float64"), ) 
 The size of tensor a (2) must match the size of tensor b (8947849) at non-singleton dimension 2

W0209 12:15:33.359302 83192 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:15:33.360632 83192 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 2],"float64"), Tensor([12, 89478486, 2],"float64"), )
[torch error] paddle.copysign(Tensor([12, 20, 2],"float64"), Tensor([12, 89478486, 2],"float64"), ) 
 The size of tensor a (20) must match the size of tensor b (89478486) at non-singleton dimension 1

W0209 12:16:21.834627 83665 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:16:21.835690 83665 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 2],"float64"), Tensor([53687092, 20, 2],"float64"), )
[torch error] paddle.copysign(Tensor([12, 20, 2],"float64"), Tensor([53687092, 20, 2],"float64"), ) 
 The size of tensor a (12) must match the size of tensor b (53687092) at non-singleton dimension 0

W0209 12:17:15.774152 83934 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:17:15.775336 83934 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 2],"int16"), Tensor([107374183, 20, 2],"int16"), )
[torch error] paddle.copysign(Tensor([12, 20, 2],"int16"), Tensor([107374183, 20, 2],"int16"), ) 
 The size of tensor a (12) must match the size of tensor b (107374183) at non-singleton dimension 0

W0209 12:18:27.016316 84392 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:18:27.017563 84392 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 2],"int16"), Tensor([12, 178956971, 2],"int16"), )
[torch error] paddle.copysign(Tensor([12, 20, 2],"int16"), Tensor([12, 178956971, 2],"int16"), ) 
 The size of tensor a (20) must match the size of tensor b (178956971) at non-singleton dimension 1

W0209 12:19:36.431180 84897 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:19:36.432400 84897 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 2],"int16"), Tensor([12, 20, 17895698],"int16"), )
[torch error] paddle.copysign(Tensor([12, 20, 2],"int16"), Tensor([12, 20, 17895698],"int16"), ) 
 The size of tensor a (2) must match the size of tensor b (17895698) at non-singleton dimension 2

W0209 12:20:41.280323 85564 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:20:41.281479 85564 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 2],"int32"), Tensor([107374183, 20, 2],"int32"), )
[torch error] paddle.copysign(Tensor([12, 20, 2],"int32"), Tensor([107374183, 20, 2],"int32"), ) 
 The size of tensor a (12) must match the size of tensor b (107374183) at non-singleton dimension 0

W0209 12:22:14.176137 86040 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:22:14.177340 86040 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 2],"int32"), Tensor([12, 178956971, 2],"int32"), )
[torch error] paddle.copysign(Tensor([12, 20, 2],"int32"), Tensor([12, 178956971, 2],"int32"), ) 
 The size of tensor a (20) must match the size of tensor b (178956971) at non-singleton dimension 1

W0209 12:23:30.477903 86751 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:23:30.479025 86751 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 2],"int32"), Tensor([12, 20, 17895698],"int32"), )
[torch error] paddle.copysign(Tensor([12, 20, 2],"int32"), Tensor([12, 20, 17895698],"int32"), ) 
 The size of tensor a (2) must match the size of tensor b (17895698) at non-singleton dimension 2

W0209 12:24:41.980230 87252 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:24:41.981288 87252 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 2],"int64"), Tensor([12, 20, 8947849],"int64"), )
[torch error] paddle.copysign(Tensor([12, 20, 2],"int64"), Tensor([12, 20, 8947849],"int64"), ) 
 The size of tensor a (2) must match the size of tensor b (8947849) at non-singleton dimension 2

W0209 12:25:27.995376 87934 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:25:27.996486 87934 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 2],"int64"), Tensor([12, 89478486, 2],"int64"), )
[torch error] paddle.copysign(Tensor([12, 20, 2],"int64"), Tensor([12, 89478486, 2],"int64"), ) 
 The size of tensor a (20) must match the size of tensor b (89478486) at non-singleton dimension 1

W0209 12:26:16.688845 88196 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:26:16.690032 88196 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 2],"int64"), Tensor([53687092, 20, 2],"int64"), )
[torch error] paddle.copysign(Tensor([12, 20, 2],"int64"), Tensor([53687092, 20, 2],"int64"), ) 
 The size of tensor a (12) must match the size of tensor b (53687092) at non-singleton dimension 0

W0209 12:27:03.405655 88675 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:27:03.406783 88675 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 2],"int8"), Tensor([107374183, 20, 2],"int8"), )
[torch error] paddle.copysign(Tensor([12, 20, 2],"int8"), Tensor([107374183, 20, 2],"int8"), ) 
 The size of tensor a (12) must match the size of tensor b (107374183) at non-singleton dimension 0

W0209 12:28:04.765306 89136 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:28:04.766477 89136 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 2],"int8"), Tensor([12, 178956971, 2],"int8"), )
[torch error] paddle.copysign(Tensor([12, 20, 2],"int8"), Tensor([12, 178956971, 2],"int8"), ) 
 The size of tensor a (20) must match the size of tensor b (178956971) at non-singleton dimension 1

W0209 12:29:11.686663 89606 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:29:11.688177 89606 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 2],"int8"), Tensor([12, 20, 17895698],"int8"), )
[torch error] paddle.copysign(Tensor([12, 20, 2],"int8"), Tensor([12, 20, 17895698],"int8"), ) 
 The size of tensor a (2) must match the size of tensor b (17895698) at non-singleton dimension 2

W0209 12:30:16.229576 90124 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:30:16.230940 90124 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 2],"uint8"), Tensor([107374183, 20, 2],"uint8"), )
[torch error] paddle.copysign(Tensor([12, 20, 2],"uint8"), Tensor([107374183, 20, 2],"uint8"), ) 
 The size of tensor a (12) must match the size of tensor b (107374183) at non-singleton dimension 0

W0209 12:31:21.646384 90596 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:31:21.647485 90596 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 2],"uint8"), Tensor([12, 178956971, 2],"uint8"), )
[torch error] paddle.copysign(Tensor([12, 20, 2],"uint8"), Tensor([12, 178956971, 2],"uint8"), ) 
 The size of tensor a (20) must match the size of tensor b (178956971) at non-singleton dimension 1

W0209 12:32:26.047497 91073 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:32:26.048821 91073 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 2],"uint8"), Tensor([12, 20, 17895698],"uint8"), )
[torch error] paddle.copysign(Tensor([12, 20, 2],"uint8"), Tensor([12, 20, 17895698],"uint8"), ) 
 The size of tensor a (2) must match the size of tensor b (17895698) at non-singleton dimension 2

W0209 12:33:28.269726 91559 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:33:28.271019 91559 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 8947849],"float64"), Tensor([12, 20, 2],"float64"), )
[torch error] paddle.copysign(Tensor([12, 20, 8947849],"float64"), Tensor([12, 20, 2],"float64"), ) 
 The size of tensor a (8947849) must match the size of tensor b (2) at non-singleton dimension 2

W0209 12:34:20.208541 92048 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:34:20.209560 92048 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 8947849],"float64"), Tensor([12, 20, 8947849],"float64"), )
[paddle error] paddle.copysign(Tensor([12, 20, 8947849],"float64"), Tensor([12, 20, 8947849],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 12:36:07.986588 92506 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:36:07.987437 92506 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 8947849],"int64"), Tensor([12, 20, 2],"int64"), )
[torch error] paddle.copysign(Tensor([12, 20, 8947849],"int64"), Tensor([12, 20, 2],"int64"), ) 
 The size of tensor a (8947849) must match the size of tensor b (2) at non-singleton dimension 2

W0209 12:36:59.576843 93416 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:36:59.584949 93416 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 20, 8947849],"int64"), Tensor([12, 20, 8947849],"int64"), )
[paddle error] paddle.copysign(Tensor([12, 20, 8947849],"int64"), Tensor([12, 20, 8947849],"int64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_copysign(_object*, _object*, _object*)
1   copysign_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::copysign(paddle::Tensor const&, paddle::Tensor const&)
3   void phi::CopySignKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor*)
4   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 73.594666GB memory has been allocated and available memory is only 5.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 12:38:40.868466 93709 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:38:40.869386 93709 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 89478486, 2],"float64"), Tensor([12, 20, 2],"float64"), )
[torch error] paddle.copysign(Tensor([12, 89478486, 2],"float64"), Tensor([12, 20, 2],"float64"), ) 
 The size of tensor a (89478486) must match the size of tensor b (20) at non-singleton dimension 1

W0209 12:39:38.761507 94636 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:39:38.762606 94636 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 89478486, 2],"float64"), Tensor([12, 89478486, 2],"float64"), )
[paddle error] paddle.copysign(Tensor([12, 89478486, 2],"float64"), Tensor([12, 89478486, 2],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 12:41:33.518072 95097 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:41:33.518936 95097 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 89478486, 2],"int64"), Tensor([12, 20, 2],"int64"), )
[torch error] paddle.copysign(Tensor([12, 89478486, 2],"int64"), Tensor([12, 20, 2],"int64"), ) 
 The size of tensor a (89478486) must match the size of tensor b (20) at non-singleton dimension 1

W0209 12:42:20.596808 95843 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:42:20.598122 95843 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([12, 89478486, 2],"int64"), Tensor([12, 89478486, 2],"int64"), )
[paddle error] paddle.copysign(Tensor([12, 89478486, 2],"int64"), Tensor([12, 89478486, 2],"int64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_copysign(_object*, _object*, _object*)
1   copysign_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::copysign(paddle::Tensor const&, paddle::Tensor const&)
3   void phi::CopySignKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor*)
4   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 73.594666GB memory has been allocated and available memory is only 5.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 12:43:57.505740 96329 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:43:57.506596 96329 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([1203073, 17, 5, 6, 7],"float16"), Tensor([1203073, 17, 5, 6, 7],"float16"), )
[Pass] paddle.copysign(Tensor([1203073, 17, 5, 6, 7],"float16"), Tensor([1203073, 17, 5, 6, 7],"float16"), )

W0209 12:47:00.307051 97282 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:47:00.307895 97282 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([1203073, 17, 5, 6, 7],"float16"), Tensor([8, 17, 5, 6, 7],"float16"), )
[torch error] paddle.copysign(Tensor([1203073, 17, 5, 6, 7],"float16"), Tensor([8, 17, 5, 6, 7],"float16"), ) 
 The size of tensor a (1203073) must match the size of tensor b (8) at non-singleton dimension 0

W0209 12:56:01.465279 102283 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:56:01.466434 102283 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([132],"int64"), Tensor([2147483649],"int64"), )
[torch error] paddle.copysign(Tensor([132],"int64"), Tensor([2147483649],"int64"), ) 
 The size of tensor a (132) must match the size of tensor b (2147483649) at non-singleton dimension 0

W0209 12:56:46.232383 102807 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:56:46.233445 102807 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([132],"uint8"), Tensor([4294967295],"uint8"), )
[torch error] paddle.copysign(Tensor([132],"uint8"), Tensor([4294967295],"uint8"), ) 
 The size of tensor a (132) must match the size of tensor b (4294967295) at non-singleton dimension 0

W0209 12:57:53.384209 103272 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 12:57:53.385309 103272 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([2, 107374183, 4, 5],"int8"), Tensor([2, 107374183, 4, 5],"int8"), )
[Pass] paddle.copysign(Tensor([2, 107374183, 4, 5],"int8"), Tensor([2, 107374183, 4, 5],"int8"), )

W0209 13:00:01.514189 103797 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:00:01.515060 103797 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([2, 107374183, 4, 5],"int8"), Tensor([2, 3, 4, 5],"int8"), )
[torch error] paddle.copysign(Tensor([2, 107374183, 4, 5],"int8"), Tensor([2, 3, 4, 5],"int8"), ) 
 The size of tensor a (107374183) must match the size of tensor b (3) at non-singleton dimension 1

W0209 13:03:02.359956 105721 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:03:02.361107 105721 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([2, 3, 143165577, 5],"int8"), Tensor([2, 3, 143165577, 5],"int8"), )
[Pass] paddle.copysign(Tensor([2, 3, 143165577, 5],"int8"), Tensor([2, 3, 143165577, 5],"int8"), )

W0209 13:05:13.774592 106226 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:05:13.775753 106226 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([2, 3, 143165577, 5],"int8"), Tensor([2, 3, 4, 5],"int8"), )
[torch error] paddle.copysign(Tensor([2, 3, 143165577, 5],"int8"), Tensor([2, 3, 4, 5],"int8"), ) 
 The size of tensor a (143165577) must match the size of tensor b (4) at non-singleton dimension 2

W0209 13:08:15.023936 108350 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:08:15.025323 108350 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([2, 3, 4, 178956971],"int8"), Tensor([2, 3, 4, 178956971],"int8"), )
[Pass] paddle.copysign(Tensor([2, 3, 4, 178956971],"int8"), Tensor([2, 3, 4, 178956971],"int8"), )

W0209 13:10:19.756605 108840 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:10:19.757500 108840 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([2, 3, 4, 178956971],"int8"), Tensor([2, 3, 4, 5],"int8"), )
[torch error] paddle.copysign(Tensor([2, 3, 4, 178956971],"int8"), Tensor([2, 3, 4, 5],"int8"), ) 
 The size of tensor a (178956971) must match the size of tensor b (5) at non-singleton dimension 3

W0209 13:13:22.411638 110804 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:13:22.412708 110804 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([2, 3, 4, 5],"float64"), Tensor([2, 3, 4, 89478486],"float64"), )
[torch error] paddle.copysign(Tensor([2, 3, 4, 5],"float64"), Tensor([2, 3, 4, 89478486],"float64"), ) 
 The size of tensor a (5) must match the size of tensor b (89478486) at non-singleton dimension 3

W0209 13:14:07.067265 111305 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:14:07.068390 111305 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([2, 3, 4, 5],"float64"), Tensor([2, 3, 71582789, 5],"float64"), )
[torch error] paddle.copysign(Tensor([2, 3, 4, 5],"float64"), Tensor([2, 3, 71582789, 5],"float64"), ) 
 The size of tensor a (4) must match the size of tensor b (71582789) at non-singleton dimension 2

W0209 13:14:59.586661 111757 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:14:59.587728 111757 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([2, 3, 4, 5],"float64"), Tensor([2, 53687092, 4, 5],"float64"), )
[torch error] paddle.copysign(Tensor([2, 3, 4, 5],"float64"), Tensor([2, 53687092, 4, 5],"float64"), ) 
 The size of tensor a (3) must match the size of tensor b (53687092) at non-singleton dimension 1

W0209 13:15:53.647538 112059 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:15:53.648699 112059 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([2, 3, 4, 5],"float64"), Tensor([35791395, 3, 4, 5],"float64"), )
[torch error] paddle.copysign(Tensor([2, 3, 4, 5],"float64"), Tensor([35791395, 3, 4, 5],"float64"), ) 
 The size of tensor a (2) must match the size of tensor b (35791395) at non-singleton dimension 0

W0209 13:16:41.311630 112542 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:16:41.312692 112542 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([2, 3, 4, 5],"int8"), Tensor([2, 107374183, 4, 5],"int8"), )
[torch error] paddle.copysign(Tensor([2, 3, 4, 5],"int8"), Tensor([2, 107374183, 4, 5],"int8"), ) 
 The size of tensor a (3) must match the size of tensor b (107374183) at non-singleton dimension 1

W0209 13:17:43.762151 113016 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:17:43.763226 113016 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([2, 3, 4, 5],"int8"), Tensor([2, 3, 143165577, 5],"int8"), )
[torch error] paddle.copysign(Tensor([2, 3, 4, 5],"int8"), Tensor([2, 3, 143165577, 5],"int8"), ) 
 The size of tensor a (4) must match the size of tensor b (143165577) at non-singleton dimension 2

W0209 13:18:50.952601 113508 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:18:50.953750 113508 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([2, 3, 4, 5],"int8"), Tensor([2, 3, 4, 178956971],"int8"), )
[torch error] paddle.copysign(Tensor([2, 3, 4, 5],"int8"), Tensor([2, 3, 4, 178956971],"int8"), ) 
 The size of tensor a (5) must match the size of tensor b (178956971) at non-singleton dimension 3

W0209 13:19:53.384514 113562 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:19:53.385619 113562 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([2, 3, 4, 5],"int8"), Tensor([71582789, 3, 4, 5],"int8"), )
[torch error] paddle.copysign(Tensor([2, 3, 4, 5],"int8"), Tensor([71582789, 3, 4, 5],"int8"), ) 
 The size of tensor a (2) must match the size of tensor b (71582789) at non-singleton dimension 0

W0209 13:20:55.619441 113603 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:20:55.620502 113603 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([2, 3, 4, 89478486],"float64"), Tensor([2, 3, 4, 5],"float64"), )
[torch error] paddle.copysign(Tensor([2, 3, 4, 89478486],"float64"), Tensor([2, 3, 4, 5],"float64"), ) 
 The size of tensor a (89478486) must match the size of tensor b (5) at non-singleton dimension 3

W0209 13:21:51.330319 113632 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:21:51.331306 113632 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([2, 3, 4, 89478486],"float64"), Tensor([2, 3, 4, 89478486],"float64"), )
[paddle error] paddle.copysign(Tensor([2, 3, 4, 89478486],"float64"), Tensor([2, 3, 4, 89478486],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 13:23:43.717140 113660 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:23:43.719285 113660 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([2, 3, 71582789, 5],"float64"), Tensor([2, 3, 4, 5],"float64"), )
[torch error] paddle.copysign(Tensor([2, 3, 71582789, 5],"float64"), Tensor([2, 3, 4, 5],"float64"), ) 
 The size of tensor a (71582789) must match the size of tensor b (4) at non-singleton dimension 2

W0209 13:24:30.561512 113715 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:24:30.562625 113715 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([2, 3, 71582789, 5],"float64"), Tensor([2, 3, 71582789, 5],"float64"), )
[paddle error] paddle.copysign(Tensor([2, 3, 71582789, 5],"float64"), Tensor([2, 3, 71582789, 5],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 13:26:18.725602 113744 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:26:18.726508 113744 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([2, 53687092, 4, 5],"float64"), Tensor([2, 3, 4, 5],"float64"), )
[torch error] paddle.copysign(Tensor([2, 53687092, 4, 5],"float64"), Tensor([2, 3, 4, 5],"float64"), ) 
 The size of tensor a (53687092) must match the size of tensor b (3) at non-singleton dimension 1

W0209 13:27:11.684723 113772 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:27:11.686105 113772 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([2, 53687092, 4, 5],"float64"), Tensor([2, 53687092, 4, 5],"float64"), )
[paddle error] paddle.copysign(Tensor([2, 53687092, 4, 5],"float64"), Tensor([2, 53687092, 4, 5],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 13:28:55.397382 113813 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:28:55.398254 113813 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([20, 107374183],"float64"), Tensor([20, 107374183],"float64"), )
[paddle error] paddle.copysign(Tensor([20, 107374183],"float64"), Tensor([20, 107374183],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 13:30:44.158603 113842 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:30:44.159530 113842 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([20, 107374183],"float64"), Tensor([20, 6],"float64"), )
[torch error] paddle.copysign(Tensor([20, 107374183],"float64"), Tensor([20, 6],"float64"), ) 
 The size of tensor a (107374183) must match the size of tensor b (6) at non-singleton dimension 1

W0209 13:31:33.297906 113897 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:31:33.299074 113897 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([20, 6],"float64"), Tensor([20, 107374183],"float64"), )
[torch error] paddle.copysign(Tensor([20, 6],"float64"), Tensor([20, 107374183],"float64"), ) 
 The size of tensor a (6) must match the size of tensor b (107374183) at non-singleton dimension 1

W0209 13:32:21.208913 113912 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:32:21.210088 113912 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([20, 6],"float64"), Tensor([357913942, 6],"float64"), )
[torch error] paddle.copysign(Tensor([20, 6],"float64"), Tensor([357913942, 6],"float64"), ) 
 The size of tensor a (20) must match the size of tensor b (357913942) at non-singleton dimension 0

W0209 13:33:09.197475 113940 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:33:09.198567 113940 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([2147483649],"int64"), Tensor([132],"int64"), )
[torch error] paddle.copysign(Tensor([2147483649],"int64"), Tensor([132],"int64"), ) 
 The size of tensor a (2147483649) must match the size of tensor b (132) at non-singleton dimension 0

W0209 13:33:55.113420 113955 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:33:55.114854 113955 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([2147483649],"int64"), Tensor([2147483649],"int64"), )
[paddle error] paddle.copysign(Tensor([2147483649],"int64"), Tensor([2147483649],"int64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_copysign(_object*, _object*, _object*)
1   copysign_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::copysign(paddle::Tensor const&, paddle::Tensor const&)
3   void phi::CopySignKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor*)
4   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 73.594666GB memory has been allocated and available memory is only 5.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


/usr/local/lib/python3.9/dist-packages/paddle/tensor/math.py:8033: UserWarning: The shape of broadcast output [-1] is different from the input tensor x with shape: [2147483649], please make sure you are using copysign api correctly.
  warnings.warn(
W0209 13:35:27.310890 113995 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:35:27.311829 113995 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([214748365, 20],"bool"), Tensor([10, 20],"bool"), )
[torch error] paddle.copysign(Tensor([214748365, 20],"bool"), Tensor([10, 20],"bool"), ) 
 The size of tensor a (214748365) must match the size of tensor b (10) at non-singleton dimension 0

W0209 13:36:45.978361 114038 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:36:45.979457 114038 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([214748365, 20],"bool"), Tensor([214748365, 20],"bool"), )
[Pass] paddle.copysign(Tensor([214748365, 20],"bool"), Tensor([214748365, 20],"bool"), )

W0209 13:38:46.521204 114066 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:38:46.522138 114066 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([214748365, 20],"float16"), Tensor([10, 20],"float16"), )
[torch error] paddle.copysign(Tensor([214748365, 20],"float16"), Tensor([10, 20],"float16"), ) 
 The size of tensor a (214748365) must match the size of tensor b (10) at non-singleton dimension 0

W0209 13:41:31.226632 114150 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:41:31.227634 114150 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([214748365, 20],"float16"), Tensor([214748365, 20],"float16"), )
[Pass] paddle.copysign(Tensor([214748365, 20],"float16"), Tensor([214748365, 20],"float16"), )

W0209 13:44:22.582265 114205 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:44:22.583137 114205 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([214748365, 20],"float32"), -3.0, )
[Pass] paddle.copysign(Tensor([214748365, 20],"float32"), -3.0, )

W0209 13:53:13.299886 114415 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:53:13.300740 114415 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([214748365, 20],"float32"), Tensor([10, 20],"float32"), )
[torch error] paddle.copysign(Tensor([214748365, 20],"float32"), Tensor([10, 20],"float32"), ) 
 The size of tensor a (214748365) must match the size of tensor b (10) at non-singleton dimension 0

W0209 13:56:39.081323 114499 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:56:39.082569 114499 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([214748365, 20],"float32"), Tensor([214748365, 20],"float32"), )
[paddle error] paddle.copysign(Tensor([214748365, 20],"float32"), Tensor([214748365, 20],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 13:59:06.869881 114515 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 13:59:06.870880 114515 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([214748365, 20],"int16"), Tensor([10, 20],"int16"), )
[torch error] paddle.copysign(Tensor([214748365, 20],"int16"), Tensor([10, 20],"int16"), ) 
 The size of tensor a (214748365) must match the size of tensor b (10) at non-singleton dimension 0

W0209 14:00:17.408146 114583 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:00:17.409159 114583 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([214748365, 20],"int16"), Tensor([214748365, 20],"int16"), )
[Pass] paddle.copysign(Tensor([214748365, 20],"int16"), Tensor([214748365, 20],"int16"), )

W0209 14:02:38.497985 114612 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:02:38.498790 114612 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([214748365, 20],"int32"), Tensor([10, 20],"int32"), )
[torch error] paddle.copysign(Tensor([214748365, 20],"int32"), Tensor([10, 20],"int32"), ) 
 The size of tensor a (214748365) must match the size of tensor b (10) at non-singleton dimension 0

W0209 14:06:01.982072 114710 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:06:01.983079 114710 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([214748365, 20],"int32"), Tensor([214748365, 20],"int32"), )
[paddle error] paddle.copysign(Tensor([214748365, 20],"int32"), Tensor([214748365, 20],"int32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 14:08:37.748157 114744 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:08:37.749035 114744 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([214748365, 20],"int8"), Tensor([10, 20],"int8"), )
[torch error] paddle.copysign(Tensor([214748365, 20],"int8"), Tensor([10, 20],"int8"), ) 
 The size of tensor a (214748365) must match the size of tensor b (10) at non-singleton dimension 0

W0209 14:09:41.938678 114809 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:09:41.940086 114809 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([214748365, 20],"int8"), Tensor([214748365, 20],"int8"), )
[Pass] paddle.copysign(Tensor([214748365, 20],"int8"), Tensor([214748365, 20],"int8"), )

W0209 14:11:43.494366 114850 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:11:43.495254 114850 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([214748365, 20],"uint8"), Tensor([10, 20],"uint8"), )
[torch error] paddle.copysign(Tensor([214748365, 20],"uint8"), Tensor([10, 20],"uint8"), ) 
 The size of tensor a (214748365) must match the size of tensor b (10) at non-singleton dimension 0

W0209 14:14:41.232383 114947 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:14:41.233526 114947 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([214748365, 20],"uint8"), Tensor([214748365, 20],"uint8"), )
[Pass] paddle.copysign(Tensor([214748365, 20],"uint8"), Tensor([214748365, 20],"uint8"), )

W0209 14:16:50.820801 114977 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:16:50.821990 114977 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([214748365, 4, 5],"float16"), Tensor([4, 5],"float16"), )
[Pass] paddle.copysign(Tensor([214748365, 4, 5],"float16"), Tensor([4, 5],"float16"), )

W0209 14:20:25.976958 115075 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:20:25.977787 115075 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([214748365, 4, 5],"float16"), Tensor([5],"float16"), )
[Pass] paddle.copysign(Tensor([214748365, 4, 5],"float16"), Tensor([5],"float16"), )

W0209 14:29:27.235544 115243 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:29:27.236382 115243 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([252645135, 17],"float32"), Tensor([11, 17],"float32"), )
[torch error] paddle.copysign(Tensor([252645135, 17],"float32"), Tensor([11, 17],"float32"), ) 
 The size of tensor a (252645135) must match the size of tensor b (11) at non-singleton dimension 0

W0209 14:38:00.395627 115438 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:38:00.396876 115438 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([252645135, 17],"float32"), Tensor([252645135, 17],"float32"), )
[paddle error] paddle.copysign(Tensor([252645135, 17],"float32"), Tensor([252645135, 17],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 14:40:38.375397 115466 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:40:38.376294 115466 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([25264514, 17, 10],"int16"), Tensor([11, 17, 10],"int16"), )
[torch error] paddle.copysign(Tensor([25264514, 17, 10],"int16"), Tensor([11, 17, 10],"int16"), ) 
 The size of tensor a (25264514) must match the size of tensor b (11) at non-singleton dimension 0

W0209 14:41:41.551168 115536 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:41:41.552294 115536 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([25264514, 17, 10],"int16"), Tensor([25264514, 17, 10],"int16"), )
[Pass] paddle.copysign(Tensor([25264514, 17, 10],"int16"), Tensor([25264514, 17, 10],"int16"), )

W0209 14:43:46.098342 115578 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:43:46.099200 115578 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([25264514, 17, 10],"int32"), Tensor([11, 17, 10],"int32"), )
[torch error] paddle.copysign(Tensor([25264514, 17, 10],"int32"), Tensor([11, 17, 10],"int32"), ) 
 The size of tensor a (25264514) must match the size of tensor b (11) at non-singleton dimension 0

W0209 14:46:59.151711 115662 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:46:59.152907 115662 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([25264514, 17, 10],"int32"), Tensor([25264514, 17, 10],"int32"), )
[paddle error] paddle.copysign(Tensor([25264514, 17, 10],"int32"), Tensor([25264514, 17, 10],"int32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 14:49:31.250274 115704 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:49:31.252732 115704 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([3, 286331153, 5],"float16"), Tensor([4, 5],"float16"), )
[torch error] paddle.copysign(Tensor([3, 286331153, 5],"float16"), Tensor([4, 5],"float16"), ) 
 The size of tensor a (286331153) must match the size of tensor b (4) at non-singleton dimension 1

W0209 14:50:59.494251 115760 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:50:59.495254 115760 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([3, 286331153, 5],"float16"), Tensor([5],"float16"), )
[Pass] paddle.copysign(Tensor([3, 286331153, 5],"float16"), Tensor([5],"float16"), )

W0209 14:52:24.886138 115815 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 14:52:24.887131 115815 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([3, 4, 357913942],"float16"), Tensor([4, 5],"float16"), )
[torch error] paddle.copysign(Tensor([3, 4, 357913942],"float16"), Tensor([4, 5],"float16"), ) 
 The size of tensor a (357913942) must match the size of tensor b (5) at non-singleton dimension 2

W0209 15:01:30.970086 115971 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:01:30.971246 115971 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([3, 4, 357913942],"float16"), Tensor([5],"float16"), )
[torch error] paddle.copysign(Tensor([3, 4, 357913942],"float16"), Tensor([5],"float16"), ) 
 The size of tensor a (357913942) must match the size of tensor b (5) at non-singleton dimension 2

W0209 15:02:54.088269 116025 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:02:54.089453 116025 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([3, 4, 5],"float16"), Tensor([4, 1073741824],"float16"), )
[torch error] paddle.copysign(Tensor([3, 4, 5],"float16"), Tensor([4, 1073741824],"float16"), ) 
 The size of tensor a (5) must match the size of tensor b (1073741824) at non-singleton dimension 2

W0209 15:04:23.566375 116055 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:04:23.567574 116055 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([3, 4, 5],"float16"), Tensor([4294967295],"float16"), )
[torch error] paddle.copysign(Tensor([3, 4, 5],"float16"), Tensor([4294967295],"float16"), ) 
 The size of tensor a (5) must match the size of tensor b (4294967295) at non-singleton dimension 2

W0209 15:05:46.192961 116097 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:05:46.194031 116097 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([3, 4, 5],"float16"), Tensor([858993459, 5],"float16"), )
[torch error] paddle.copysign(Tensor([3, 4, 5],"float16"), Tensor([858993459, 5],"float16"), ) 
 The size of tensor a (4) must match the size of tensor b (858993459) at non-singleton dimension 1

W0209 15:07:08.589054 116125 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:07:08.590198 116125 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([3],"float32"), Tensor([4294967295],"float32"), )
[torch error] paddle.copysign(Tensor([3],"float32"), Tensor([4294967295],"float32"), ) 
 The size of tensor a (3) must match the size of tensor b (4294967295) at non-singleton dimension 0

W0209 15:08:25.722658 116139 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:08:25.723968 116139 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([357913942, 6],"float64"), Tensor([20, 6],"float64"), )
[torch error] paddle.copysign(Tensor([357913942, 6],"float64"), Tensor([20, 6],"float64"), ) 
 The size of tensor a (357913942) must match the size of tensor b (20) at non-singleton dimension 0

W0209 15:09:20.554123 116180 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:09:20.555219 116180 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([357913942, 6],"float64"), Tensor([357913942, 6],"float64"), )
[paddle error] paddle.copysign(Tensor([357913942, 6],"float64"), Tensor([357913942, 6],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 15:11:11.945411 116194 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:11:11.946969 116194 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([35791395, 3, 4, 5],"float64"), Tensor([2, 3, 4, 5],"float64"), )
[torch error] paddle.copysign(Tensor([35791395, 3, 4, 5],"float64"), Tensor([2, 3, 4, 5],"float64"), ) 
 The size of tensor a (35791395) must match the size of tensor b (2) at non-singleton dimension 0

W0209 15:12:04.448118 116209 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:12:04.449232 116209 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([35791395, 3, 4, 5],"float64"), Tensor([35791395, 3, 4, 5],"float64"), )
[paddle error] paddle.copysign(Tensor([35791395, 3, 4, 5],"float64"), Tensor([35791395, 3, 4, 5],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 15:13:50.957150 116223 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:13:50.958073 116223 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([4, 1073741824],"float16"), Tensor([3, 4, 5],"float16"), )
[torch error] paddle.copysign(Tensor([4, 1073741824],"float16"), Tensor([3, 4, 5],"float16"), ) 
 The size of tensor a (1073741824) must match the size of tensor b (5) at non-singleton dimension 2

W0209 15:15:20.752717 116265 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:15:20.753751 116265 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([4, 5],"float16"), Tensor([214748365, 4, 5],"float16"), )
[Pass] paddle.copysign(Tensor([4, 5],"float16"), Tensor([214748365, 4, 5],"float16"), )

/usr/local/lib/python3.9/dist-packages/paddle/tensor/math.py:8033: UserWarning: The shape of broadcast output [214748365, 4, 5] is different from the input tensor x with shape: [4, 5], please make sure you are using copysign api correctly.
  warnings.warn(
W0209 15:16:48.309913 116279 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:16:48.310874 116279 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([4, 5],"float16"), Tensor([3, 286331153, 5],"float16"), )
[torch error] paddle.copysign(Tensor([4, 5],"float16"), Tensor([3, 286331153, 5],"float16"), ) 
 The size of tensor a (4) must match the size of tensor b (286331153) at non-singleton dimension 1

W0209 15:25:48.586498 116363 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:25:48.587769 116363 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([4, 5],"float16"), Tensor([3, 4, 357913942],"float16"), )
[torch error] paddle.copysign(Tensor([4, 5],"float16"), Tensor([3, 4, 357913942],"float16"), ) 
 The size of tensor a (5) must match the size of tensor b (357913942) at non-singleton dimension 2

W0209 15:27:12.832182 116377 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:27:12.833436 116377 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([4294967295],"float32"), Tensor([3],"float32"), )
[torch error] paddle.copysign(Tensor([4294967295],"float32"), Tensor([3],"float32"), ) 
 The size of tensor a (4294967295) must match the size of tensor b (3) at non-singleton dimension 0

W0209 15:28:24.155452 116418 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:28:24.156488 116418 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([4294967295],"float32"), Tensor([4294967295],"float32"), )
[paddle error] paddle.copysign(Tensor([4294967295],"float32"), Tensor([4294967295],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 15:30:58.831900 116433 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:30:58.832870 116433 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([4294967295],"uint8"), Tensor([132],"uint8"), )
[torch error] paddle.copysign(Tensor([4294967295],"uint8"), Tensor([132],"uint8"), ) 
 The size of tensor a (4294967295) must match the size of tensor b (132) at non-singleton dimension 0

W0209 15:31:58.662905 116474 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:31:58.664048 116474 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([4294967295],"uint8"), Tensor([4294967295],"uint8"), )
[Pass] paddle.copysign(Tensor([4294967295],"uint8"), Tensor([4294967295],"uint8"), )

/usr/local/lib/python3.9/dist-packages/paddle/tensor/math.py:8033: UserWarning: The shape of broadcast output [-1] is different from the input tensor x with shape: [4294967295], please make sure you are using copysign api correctly.
  warnings.warn(
W0209 15:33:54.859114 116489 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:33:54.860003 116489 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([53687092, 20, 2],"float64"), Tensor([12, 20, 2],"float64"), )
[torch error] paddle.copysign(Tensor([53687092, 20, 2],"float64"), Tensor([12, 20, 2],"float64"), ) 
 The size of tensor a (53687092) must match the size of tensor b (12) at non-singleton dimension 0

W0209 15:36:40.213738 116531 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:36:40.215008 116531 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([53687092, 20, 2],"float64"), Tensor([53687092, 20, 2],"float64"), )
[paddle error] paddle.copysign(Tensor([53687092, 20, 2],"float64"), Tensor([53687092, 20, 2],"float64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.592712GB memory has been allocated and available memory is only 13.592163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 15:38:24.456387 116545 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:38:24.458658 116545 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([53687092, 20, 2],"int64"), Tensor([12, 20, 2],"int64"), )
[torch error] paddle.copysign(Tensor([53687092, 20, 2],"int64"), Tensor([12, 20, 2],"int64"), ) 
 The size of tensor a (53687092) must match the size of tensor b (12) at non-singleton dimension 0

W0209 15:39:13.559989 116572 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:39:13.561056 116572 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([53687092, 20, 2],"int64"), Tensor([53687092, 20, 2],"int64"), )
[paddle error] paddle.copysign(Tensor([53687092, 20, 2],"int64"), Tensor([53687092, 20, 2],"int64"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_copysign(_object*, _object*, _object*)
1   copysign_ad_func(paddle::Tensor const&, paddle::Tensor const&)
2   paddle::experimental::copysign(paddle::Tensor const&, paddle::Tensor const&)
3   void phi::CopySignKernel<long, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor*)
4   long* phi::DeviceContext::Alloc<long>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 73.594666GB memory has been allocated and available memory is only 5.590210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 15:40:54.389048 116601 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:40:54.390281 116601 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([71582789, 3, 4, 5],"int8"), Tensor([2, 3, 4, 5],"int8"), )
[torch error] paddle.copysign(Tensor([71582789, 3, 4, 5],"int8"), Tensor([2, 3, 4, 5],"int8"), ) 
 The size of tensor a (71582789) must match the size of tensor b (2) at non-singleton dimension 0

W0209 15:42:11.563474 116615 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:42:11.564457 116615 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([71582789, 3, 4, 5],"int8"), Tensor([71582789, 3, 4, 5],"int8"), )
[Pass] paddle.copysign(Tensor([71582789, 3, 4, 5],"int8"), Tensor([71582789, 3, 4, 5],"int8"), )

W0209 15:44:17.730262 116642 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:44:17.731113 116642 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([8, 17, 5, 6, 1052689],"float16"), Tensor([8, 17, 5, 6, 1052689],"float16"), )
[Pass] paddle.copysign(Tensor([8, 17, 5, 6, 1052689],"float16"), Tensor([8, 17, 5, 6, 1052689],"float16"), )

W0209 15:49:10.543547 116685 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:49:10.544373 116685 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([8, 17, 5, 6, 1052689],"float16"), Tensor([8, 17, 5, 6, 7],"float16"), )
[torch error] paddle.copysign(Tensor([8, 17, 5, 6, 1052689],"float16"), Tensor([8, 17, 5, 6, 7],"float16"), ) 
 The size of tensor a (1052689) must match the size of tensor b (7) at non-singleton dimension 4

W0209 15:58:11.504357 116783 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:58:11.505741 116783 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([8, 17, 5, 6, 7],"float16"), Tensor([1203073, 17, 5, 6, 7],"float16"), )
[torch error] paddle.copysign(Tensor([8, 17, 5, 6, 7],"float16"), Tensor([1203073, 17, 5, 6, 7],"float16"), ) 
 The size of tensor a (8) must match the size of tensor b (1203073) at non-singleton dimension 0

W0209 15:59:38.841442 116797 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 15:59:38.842793 116797 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([8, 17, 5, 6, 7],"float16"), Tensor([8, 17, 5, 6, 1052689],"float16"), )
[torch error] paddle.copysign(Tensor([8, 17, 5, 6, 7],"float16"), Tensor([8, 17, 5, 6, 1052689],"float16"), ) 
 The size of tensor a (7) must match the size of tensor b (1052689) at non-singleton dimension 4

W0209 16:01:03.011744 116824 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:01:03.012892 116824 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([8, 17, 5, 6, 7],"float16"), Tensor([8, 17, 5, 902305, 7],"float16"), )
[torch error] paddle.copysign(Tensor([8, 17, 5, 6, 7],"float16"), Tensor([8, 17, 5, 902305, 7],"float16"), ) 
 The size of tensor a (6) must match the size of tensor b (902305) at non-singleton dimension 3

W0209 16:02:30.984035 116852 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:02:30.985199 116852 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([8, 17, 5, 6, 7],"float16"), Tensor([8, 17, 751921, 6, 7],"float16"), )
[torch error] paddle.copysign(Tensor([8, 17, 5, 6, 7],"float16"), Tensor([8, 17, 751921, 6, 7],"float16"), ) 
 The size of tensor a (5) must match the size of tensor b (751921) at non-singleton dimension 2

W0209 16:03:54.511684 116867 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:03:54.512748 116867 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([8, 17, 5, 6, 7],"float16"), Tensor([8, 2556529, 5, 6, 7],"float16"), )
[torch error] paddle.copysign(Tensor([8, 17, 5, 6, 7],"float16"), Tensor([8, 2556529, 5, 6, 7],"float16"), ) 
 The size of tensor a (17) must match the size of tensor b (2556529) at non-singleton dimension 1

W0209 16:05:21.700325 116894 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:05:21.701567 116894 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([8, 17, 5, 902305, 7],"float16"), Tensor([8, 17, 5, 6, 7],"float16"), )
[torch error] paddle.copysign(Tensor([8, 17, 5, 902305, 7],"float16"), Tensor([8, 17, 5, 6, 7],"float16"), ) 
 The size of tensor a (902305) must match the size of tensor b (6) at non-singleton dimension 3

W0209 16:06:48.701987 116921 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:06:48.703246 116921 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([8, 17, 5, 902305, 7],"float16"), Tensor([8, 17, 5, 902305, 7],"float16"), )
[Pass] paddle.copysign(Tensor([8, 17, 5, 902305, 7],"float16"), Tensor([8, 17, 5, 902305, 7],"float16"), )

W0209 16:09:38.834802 116937 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:09:38.836104 116937 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([8, 17, 751921, 6, 7],"float16"), Tensor([8, 17, 5, 6, 7],"float16"), )
[torch error] paddle.copysign(Tensor([8, 17, 751921, 6, 7],"float16"), Tensor([8, 17, 5, 6, 7],"float16"), ) 
 The size of tensor a (751921) must match the size of tensor b (5) at non-singleton dimension 2

W0209 16:18:44.732707 117021 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:18:44.733726 117021 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([8, 17, 751921, 6, 7],"float16"), Tensor([8, 17, 751921, 6, 7],"float16"), )
[Pass] paddle.copysign(Tensor([8, 17, 751921, 6, 7],"float16"), Tensor([8, 17, 751921, 6, 7],"float16"), )

W0209 16:21:48.172134 117048 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:21:48.173214 117048 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([8, 2556529, 5, 6, 7],"float16"), Tensor([8, 17, 5, 6, 7],"float16"), )
[torch error] paddle.copysign(Tensor([8, 2556529, 5, 6, 7],"float16"), Tensor([8, 17, 5, 6, 7],"float16"), ) 
 The size of tensor a (2556529) must match the size of tensor b (17) at non-singleton dimension 1

W0209 16:31:46.853626 117091 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:31:46.854750 117091 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([8, 2556529, 5, 6, 7],"float16"), Tensor([8, 2556529, 5, 6, 7],"float16"), )
[Pass] paddle.copysign(Tensor([8, 2556529, 5, 6, 7],"float16"), Tensor([8, 2556529, 5, 6, 7],"float16"), )

W0209 16:35:11.668408 117118 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:35:11.669353 117118 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.copysign(Tensor([858993459, 5],"float16"), Tensor([3, 4, 5],"float16"), )
[torch error] paddle.copysign(Tensor([858993459, 5],"float16"), Tensor([3, 4, 5],"float16"), ) 
 The size of tensor a (858993459) must match the size of tensor b (4) at non-singleton dimension 1

W0209 16:44:24.819495 117189 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:44:24.820698 117189 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cos(Tensor([1, 128, 1, 33554432],"float32"), )
[Pass] paddle.cos(Tensor([1, 128, 1, 33554432],"float32"), )

W0209 16:45:42.861537 117231 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:45:42.862406 117231 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cos(Tensor([1, 128, 1048576, 32],"float32"), )
[Pass] paddle.cos(Tensor([1, 128, 1048576, 32],"float32"), )

W0209 16:49:18.817691 117273 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:49:18.818629 117273 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cos(Tensor([1, 134217728, 1, 32],"float32"), )
[Pass] paddle.cos(Tensor([1, 134217728, 1, 32],"float32"), )

W0209 16:52:48.303951 117300 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:52:48.304850 117300 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cos(Tensor([10, 20, 21474837],"float32"), )
[Pass] paddle.cos(Tensor([10, 20, 21474837],"float32"), )

W0209 16:56:26.053388 117342 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 16:56:26.054284 117342 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cos(Tensor([10, 429496730, 1],"float32"), )
[Pass] paddle.cos(Tensor([10, 429496730, 1],"float32"), )

W0209 17:00:11.136354 117385 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:00:11.137290 117385 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cos(Tensor([10, 429496730],"float32"), )
[Pass] paddle.cos(Tensor([10, 429496730],"float32"), )

W0209 17:03:47.468267 117427 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:03:47.469090 117427 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cos(Tensor([1048576, 128, 1, 32],"float32"), )
[Pass] paddle.cos(Tensor([1048576, 128, 1, 32],"float32"), )

W0209 17:07:18.630461 117468 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:07:18.631490 117468 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cos(Tensor([134217728, 32],"float16"), )
[Pass] paddle.cos(Tensor([134217728, 32],"float16"), )

W0209 17:11:06.175590 117496 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:11:06.177268 117496 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cos(Tensor([1431655765, 3],"float32"), )
[Pass] paddle.cos(Tensor([1431655765, 3],"float32"), )

W0209 17:20:04.923547 117567 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:20:04.925043 117567 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cos(Tensor([2, 2147483648],"float32"), )
[Pass] paddle.cos(Tensor([2, 2147483648],"float32"), )

W0209 17:24:04.972182 117609 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:24:04.973066 117609 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cos(Tensor([2, 3, 715827883],"float32"), )
[Pass] paddle.cos(Tensor([2, 3, 715827883],"float32"), )

W0209 17:27:50.987037 117651 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:27:50.987967 117651 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cos(Tensor([2, 536870912, 4],"float32"), )
[Pass] paddle.cos(Tensor([2, 536870912, 4],"float32"), )

W0209 17:31:27.035449 117693 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:31:27.036288 117693 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cos(Tensor([2147483649],"float64"), )
[Pass] paddle.cos(Tensor([2147483649],"float64"), )

W0209 17:34:52.951651 117735 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:34:52.952545 117735 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cos(Tensor([214748365, 20, 1],"float32"), )
[Pass] paddle.cos(Tensor([214748365, 20, 1],"float32"), )

W0209 17:38:09.831254 117777 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:38:09.832206 117777 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cos(Tensor([357913942, 3, 4],"float32"), )
[Pass] paddle.cos(Tensor([357913942, 3, 4],"float32"), )

W0209 17:41:53.112746 117805 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:41:53.113981 117805 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cos(Tensor([40, 107374183],"float32"), )
[Pass] paddle.cos(Tensor([40, 107374183],"float32"), )

W0209 17:45:56.614483 117847 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:45:56.615357 117847 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cos(Tensor([4294967295],"float32"), )
[Pass] paddle.cos(Tensor([4294967295],"float32"), )

W0209 17:49:44.971889 117889 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:49:44.972828 117889 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cos(Tensor([429496730, 10],"float32"), )
[Pass] paddle.cos(Tensor([429496730, 10],"float32"), )

W0209 17:53:18.611693 117931 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:53:18.612592 117931 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cos(Tensor([64, 67108864],"float16"), )
[Pass] paddle.cos(Tensor([64, 67108864],"float16"), )

W0209 17:57:13.615666 117973 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 17:57:13.616544 117973 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cos(Tensor([64, 67108864],"float32"), )
[Pass] paddle.cos(Tensor([64, 67108864],"float32"), )

W0209 18:06:17.795370 118057 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:06:17.796234 118057 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cos(Tensor([65, 66076420],"float16"), )
[Pass] paddle.cos(Tensor([65, 66076420],"float16"), )

W0209 18:10:10.368336 118099 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:10:10.369316 118099 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cos(Tensor([67108864, 64],"float32"), )
[Pass] paddle.cos(Tensor([67108864, 64],"float32"), )

W0209 18:18:57.636138 118169 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:18:57.637169 118169 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cosh(Tensor([10, 20, 21474837],"float32"), )
[Pass] paddle.cosh(Tensor([10, 20, 21474837],"float32"), )

W0209 18:22:56.776574 118224 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:22:56.777612 118224 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cosh(Tensor([10, 429496730, 1],"float32"), )
[Pass] paddle.cosh(Tensor([10, 429496730, 1],"float32"), )

W0209 18:26:40.381314 118266 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:26:40.382290 118266 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cosh(Tensor([1431655765, 3],"float32"), )
[Pass] paddle.cosh(Tensor([1431655765, 3],"float32"), )

W0209 18:30:37.682747 118294 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:30:37.683666 118294 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cosh(Tensor([2, 2147483648],"float32"), )
[Pass] paddle.cosh(Tensor([2, 2147483648],"float32"), )

W0209 18:34:26.191872 118336 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:34:26.192803 118336 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cosh(Tensor([214748365, 20, 1],"float32"), )
[Pass] paddle.cosh(Tensor([214748365, 20, 1],"float32"), )

W0209 18:38:03.644042 118378 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:38:03.644976 118378 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([1, 14, 10956550, 14],"float64"), axis=list[1,3,], keepdim=False, name=None, )
[paddle_to_torch] paddle.count_nonzero(Tensor([1, 14, 10956550, 14],"float64"), axis=list[1,3,], keepdim=False, name=None, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:41:08.778360 118421 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:41:08.779387 118421 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([1, 14, 10956550, 14],"float64"), axis=list[1,3,], keepdim=True, name=None, )
[paddle_to_torch] paddle.count_nonzero(Tensor([1, 14, 10956550, 14],"float64"), axis=list[1,3,], keepdim=True, name=None, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:41:15.299448 118435 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:41:15.300451 118435 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([1, 14, 5, 30678338],"float64"), axis=list[1,3,], keepdim=False, name=None, )
[paddle_to_torch] paddle.count_nonzero(Tensor([1, 14, 5, 30678338],"float64"), axis=list[1,3,], keepdim=False, name=None, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:41:21.967113 118449 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:41:21.968164 118449 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([1, 14, 5, 30678338],"float64"), axis=list[1,3,], keepdim=True, name=None, )
[paddle_to_torch] paddle.count_nonzero(Tensor([1, 14, 5, 30678338],"float64"), axis=list[1,3,], keepdim=True, name=None, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:41:28.290634 118463 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:41:28.291654 118463 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([1, 30678338, 5, 14],"float64"), axis=list[1,3,], keepdim=False, name=None, )
[paddle_to_torch] paddle.count_nonzero(Tensor([1, 30678338, 5, 14],"float64"), axis=list[1,3,], keepdim=False, name=None, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:41:35.013413 118477 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:41:35.014436 118477 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([1, 30678338, 5, 14],"float64"), axis=list[1,3,], keepdim=True, name=None, )
[paddle_to_torch] paddle.count_nonzero(Tensor([1, 30678338, 5, 14],"float64"), axis=list[1,3,], keepdim=True, name=None, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:41:41.534041 118491 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:41:41.535043 118491 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([2, 107374183, 4, 5],"float32"), axis=-1, keepdim=False, )
[paddle_to_torch] paddle.count_nonzero(Tensor([2, 107374183, 4, 5],"float32"), axis=-1, keepdim=False, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:41:48.014495 118505 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:41:48.015419 118505 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([2, 107374183, 4, 5],"float32"), axis=2, keepdim=True, )
[paddle_to_torch] paddle.count_nonzero(Tensor([2, 107374183, 4, 5],"float32"), axis=2, keepdim=True, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:41:54.335073 118519 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:41:54.336052 118519 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([2, 107374183, 4, 5],"float32"), axis=list[0,1,2,3,], keepdim=False, )
[paddle_to_torch] paddle.count_nonzero(Tensor([2, 107374183, 4, 5],"float32"), axis=list[0,1,2,3,], keepdim=False, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:42:00.748651 118533 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:42:00.749675 118533 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([2, 107374183, 4, 5],"float32"), axis=list[0,2,], keepdim=False, )
[paddle_to_torch] paddle.count_nonzero(Tensor([2, 107374183, 4, 5],"float32"), axis=list[0,2,], keepdim=False, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:42:07.114388 118547 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:42:07.115391 118547 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([2, 107374183, 4, 5],"float32"), axis=None, keepdim=False, )
[paddle_to_torch] paddle.count_nonzero(Tensor([2, 107374183, 4, 5],"float32"), axis=None, keepdim=False, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:42:13.337786 118561 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:42:13.338778 118561 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([2, 107374183, 4, 5],"float32"), axis=None, keepdim=True, )
[paddle_to_torch] paddle.count_nonzero(Tensor([2, 107374183, 4, 5],"float32"), axis=None, keepdim=True, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:42:19.564426 118575 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:42:19.565454 118575 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([2, 107374183, 4, 5],"float32"), axis=tuple(0,1,3,), keepdim=False, )
[paddle_to_torch] paddle.count_nonzero(Tensor([2, 107374183, 4, 5],"float32"), axis=tuple(0,1,3,), keepdim=False, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:42:25.980115 118589 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:42:25.981073 118589 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([2, 107374183, 4, 5],"float32"), axis=tuple(0,2,), keepdim=False, )
[paddle_to_torch] paddle.count_nonzero(Tensor([2, 107374183, 4, 5],"float32"), axis=tuple(0,2,), keepdim=False, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:42:32.278795 118603 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:42:32.279817 118603 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([2, 3, 143165577, 5],"float32"), axis=-1, keepdim=False, )
[paddle_to_torch] paddle.count_nonzero(Tensor([2, 3, 143165577, 5],"float32"), axis=-1, keepdim=False, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:42:38.711519 118617 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:42:38.712507 118617 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([2, 3, 143165577, 5],"float32"), axis=2, keepdim=True, )
[paddle_to_torch] paddle.count_nonzero(Tensor([2, 3, 143165577, 5],"float32"), axis=2, keepdim=True, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:42:45.118937 118645 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:42:45.119984 118645 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([2, 3, 143165577, 5],"float32"), axis=list[0,1,2,3,], keepdim=False, )
[paddle_to_torch] paddle.count_nonzero(Tensor([2, 3, 143165577, 5],"float32"), axis=list[0,1,2,3,], keepdim=False, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:42:51.389622 118659 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:42:51.390605 118659 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([2, 3, 143165577, 5],"float32"), axis=list[0,2,], keepdim=False, )
[paddle_to_torch] paddle.count_nonzero(Tensor([2, 3, 143165577, 5],"float32"), axis=list[0,2,], keepdim=False, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:42:57.972347 118673 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:42:57.973328 118673 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([2, 3, 143165577, 5],"float32"), axis=None, keepdim=False, )
[paddle_to_torch] paddle.count_nonzero(Tensor([2, 3, 143165577, 5],"float32"), axis=None, keepdim=False, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:43:04.584321 118697 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:43:04.585304 118697 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([2, 3, 143165577, 5],"float32"), axis=None, keepdim=True, )
[paddle_to_torch] paddle.count_nonzero(Tensor([2, 3, 143165577, 5],"float32"), axis=None, keepdim=True, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:43:11.207794 118714 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:43:11.208742 118714 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([2, 3, 143165577, 5],"float32"), axis=tuple(0,1,3,), keepdim=False, )
[paddle_to_torch] paddle.count_nonzero(Tensor([2, 3, 143165577, 5],"float32"), axis=tuple(0,1,3,), keepdim=False, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:43:17.527668 118728 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:43:17.528676 118728 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([2, 3, 143165577, 5],"float32"), axis=tuple(0,2,), keepdim=False, )
[paddle_to_torch] paddle.count_nonzero(Tensor([2, 3, 143165577, 5],"float32"), axis=tuple(0,2,), keepdim=False, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:43:23.998798 118742 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:43:23.999871 118742 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([2, 3, 4, 178956971],"float32"), axis=-1, keepdim=False, )
[paddle_to_torch] paddle.count_nonzero(Tensor([2, 3, 4, 178956971],"float32"), axis=-1, keepdim=False, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:43:30.495909 118756 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:43:30.496918 118756 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([2, 3, 4, 178956971],"float32"), axis=2, keepdim=True, )
[paddle_to_torch] paddle.count_nonzero(Tensor([2, 3, 4, 178956971],"float32"), axis=2, keepdim=True, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:43:37.018834 118770 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:43:37.019850 118770 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([2, 3, 4, 178956971],"float32"), axis=list[0,1,2,3,], keepdim=False, )
[paddle_to_torch] paddle.count_nonzero(Tensor([2, 3, 4, 178956971],"float32"), axis=list[0,1,2,3,], keepdim=False, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:43:43.563181 118784 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:43:43.564181 118784 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([2, 3, 4, 178956971],"float32"), axis=list[0,2,], keepdim=False, )
[paddle_to_torch] paddle.count_nonzero(Tensor([2, 3, 4, 178956971],"float32"), axis=list[0,2,], keepdim=False, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:43:50.211540 118798 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:43:50.212496 118798 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([2, 3, 4, 178956971],"float32"), axis=None, keepdim=False, )
[paddle_to_torch] paddle.count_nonzero(Tensor([2, 3, 4, 178956971],"float32"), axis=None, keepdim=False, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:43:56.731868 118812 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:43:56.732882 118812 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([2, 3, 4, 178956971],"float32"), axis=None, keepdim=True, )
[paddle_to_torch] paddle.count_nonzero(Tensor([2, 3, 4, 178956971],"float32"), axis=None, keepdim=True, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:44:03.203159 118826 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:44:03.204108 118826 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([2, 3, 4, 178956971],"float32"), axis=tuple(0,1,3,), keepdim=False, )
[paddle_to_torch] paddle.count_nonzero(Tensor([2, 3, 4, 178956971],"float32"), axis=tuple(0,1,3,), keepdim=False, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:44:12.243690 118841 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:44:12.244692 118841 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([2, 3, 4, 178956971],"float32"), axis=tuple(0,2,), keepdim=False, )
[paddle_to_torch] paddle.count_nonzero(Tensor([2, 3, 4, 178956971],"float32"), axis=tuple(0,2,), keepdim=False, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:44:18.726071 118855 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:44:18.727083 118855 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([2191310, 14, 5, 14],"float64"), axis=list[1,3,], keepdim=False, name=None, )
[paddle_to_torch] paddle.count_nonzero(Tensor([2191310, 14, 5, 14],"float64"), axis=list[1,3,], keepdim=False, name=None, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:44:25.338647 118869 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:44:25.339660 118869 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([2191310, 14, 5, 14],"float64"), axis=list[1,3,], keepdim=True, name=None, )
[paddle_to_torch] paddle.count_nonzero(Tensor([2191310, 14, 5, 14],"float64"), axis=list[1,3,], keepdim=True, name=None, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:44:31.780530 118883 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:44:31.781560 118883 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([3, 1431655765],"float32"), axis=None, )
[Pass] paddle.count_nonzero(Tensor([3, 1431655765],"float32"), axis=None, )

W0209 18:45:53.847847 118897 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:45:53.848785 118897 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([3, 1431655765],"float32"), keepdim=True, )
[paddle_to_torch] paddle.count_nonzero(Tensor([3, 1431655765],"float32"), keepdim=True, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 18:55:07.335052 118980 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:55:07.336022 118980 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([4294967295],"float32"), axis=0, )


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::platform::EmptyCache()
1   paddle::memory::allocation::StreamSafeCUDAAllocator::ReleaseImpl(phi::Place const&)
2   paddle::memory::allocation::AutoGrowthBestFitAllocator::FreeIdleChunks()
3   paddle::memory::allocation::CUDAAllocator::FreeImpl(phi::Allocation*)

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1739098822 (unix time) try "date -d @1739098822" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x1d0d2) received by PID 118994 (TID 0x7f5d59864740) from PID 118994 ***]


W0209 18:56:31.134379 118994 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 18:56:31.135402 118994 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.
terminate called after throwing an instance of 'common::enforce::EnforceNotMet'
  what():  (External) CUDA error(700), an illegal memory access was encountered. 
  [Hint: 'cudaErrorIllegalAddress'. The device encountered a load or store instruction on an invalid memory address. This leaves the process in an inconsistentstate and any further CUDA work will return the same error. To continue using CUDA, the process must be terminated and relaunched. ] (at ../paddle/phi/core/platform/device/gpu/gpu_info.cc:348)


test begin: paddle.count_nonzero(Tensor([71582789, 3, 4, 5],"float32"), axis=-1, keepdim=False, )
[paddle_to_torch] paddle.count_nonzero(Tensor([71582789, 3, 4, 5],"float32"), axis=-1, keepdim=False, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 19:01:06.373109 119051 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:01:06.374127 119051 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([71582789, 3, 4, 5],"float32"), axis=2, keepdim=True, )
[paddle_to_torch] paddle.count_nonzero(Tensor([71582789, 3, 4, 5],"float32"), axis=2, keepdim=True, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 19:01:12.952908 119065 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:01:12.953927 119065 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([71582789, 3, 4, 5],"float32"), axis=list[0,1,2,3,], keepdim=False, )
[paddle_to_torch] paddle.count_nonzero(Tensor([71582789, 3, 4, 5],"float32"), axis=list[0,1,2,3,], keepdim=False, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 19:01:19.564569 119079 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:01:19.565603 119079 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([71582789, 3, 4, 5],"float32"), axis=list[0,2,], keepdim=False, )
[paddle_to_torch] paddle.count_nonzero(Tensor([71582789, 3, 4, 5],"float32"), axis=list[0,2,], keepdim=False, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 19:01:26.387398 119093 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:01:26.388419 119093 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([71582789, 3, 4, 5],"float32"), axis=None, keepdim=False, )
[paddle_to_torch] paddle.count_nonzero(Tensor([71582789, 3, 4, 5],"float32"), axis=None, keepdim=False, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 19:01:32.766522 119107 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:01:32.767572 119107 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([71582789, 3, 4, 5],"float32"), axis=None, keepdim=True, )
[paddle_to_torch] paddle.count_nonzero(Tensor([71582789, 3, 4, 5],"float32"), axis=None, keepdim=True, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 19:01:39.422762 119121 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:01:39.423808 119121 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([71582789, 3, 4, 5],"float32"), axis=tuple(0,1,3,), keepdim=False, )
[paddle_to_torch] paddle.count_nonzero(Tensor([71582789, 3, 4, 5],"float32"), axis=tuple(0,1,3,), keepdim=False, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 19:01:46.068419 119140 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:01:46.069439 119140 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([71582789, 3, 4, 5],"float32"), axis=tuple(0,2,), keepdim=False, )
[paddle_to_torch] paddle.count_nonzero(Tensor([71582789, 3, 4, 5],"float32"), axis=tuple(0,2,), keepdim=False, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 19:01:52.506839 119162 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:01:52.507819 119162 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([858993459, 5],"float32"), axis=None, )
[Pass] paddle.count_nonzero(Tensor([858993459, 5],"float32"), axis=None, )

W0209 19:03:10.907441 119176 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:03:10.908538 119176 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.count_nonzero(Tensor([858993459, 5],"float32"), keepdim=True, )
[paddle_to_torch] paddle.count_nonzero(Tensor([858993459, 5],"float32"), keepdim=True, ) 
  keepdim not in paddle_to_torch_args_map, can not call torch

W0209 19:14:31.049340 119274 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:14:31.050279 119274 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cross(Tensor([1431655765, 3],"float32"), Tensor([1431655765, 3],"float32"), )
[paddle error] paddle.cross(Tensor([1431655765, 3],"float32"), Tensor([1431655765, 3],"float32"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


/usr/local/lib/python3.9/dist-packages/torch/utils/_device.py:106: UserWarning: Using torch.cross without specifying the dim arg is deprecated.
Please either pass the dim explicitly or simply use torch.linalg.cross.
The default value of dim will change to agree with that of linalg.cross in a future release. (Triggered internally at ../aten/src/ATen/native/Cross.cpp:62.)
  return func(*args, **kwargs)
W0209 19:17:06.662859 119288 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:17:06.663744 119288 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cross(Tensor([1431655765, 3],"float32"), Tensor([1431655765, 3],"float32"), axis=1, )
[paddle error] paddle.cross(Tensor([1431655765, 3],"float32"), Tensor([1431655765, 3],"float32"), axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 65.584900GB memory has been allocated and available memory is only 13.599976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0209 19:19:45.380731 119317 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:19:45.381672 119317 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cross(Tensor([1431655765, 3],"float32"), Tensor([2, 3],"float32"), )
[torch error] paddle.cross(Tensor([1431655765, 3],"float32"), Tensor([2, 3],"float32"), ) 
 The size of tensor a (1431655765) must match the size of tensor b (2) at non-singleton dimension 0

/usr/local/lib/python3.9/dist-packages/torch/utils/_device.py:106: UserWarning: Using torch.cross without specifying the dim arg is deprecated.
Please either pass the dim explicitly or simply use torch.linalg.cross.
The default value of dim will change to agree with that of linalg.cross in a future release. (Triggered internally at ../aten/src/ATen/native/Cross.cpp:62.)
  return func(*args, **kwargs)
W0209 19:21:00.990028 119358 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:21:00.991279 119358 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cross(Tensor([1431655765, 3],"float32"), Tensor([3, 3],"float32"), axis=1, )
[torch error] paddle.cross(Tensor([1431655765, 3],"float32"), Tensor([3, 3],"float32"), axis=1, ) 
 The size of tensor a (1431655765) must match the size of tensor b (3) at non-singleton dimension 0

W0209 19:22:11.555393 119373 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:22:11.556612 119373 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cross(Tensor([2, 2147483648],"float32"), Tensor([2, 2147483648],"float32"), )
[torch error] paddle.cross(Tensor([2, 2147483648],"float32"), Tensor([2, 2147483648],"float32"), ) 
 no dimension of size 3 in input

/usr/local/lib/python3.9/dist-packages/torch/utils/_device.py:106: UserWarning: Using torch.cross without specifying the dim arg is deprecated.
Please either pass the dim explicitly or simply use torch.linalg.cross.
The default value of dim will change to agree with that of linalg.cross in a future release. (Triggered internally at ../aten/src/ATen/native/Cross.cpp:62.)
  return func(*args, **kwargs)
W0209 19:24:26.248453 119387 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:24:26.249683 119387 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cross(Tensor([2, 2147483648],"float32"), Tensor([2, 3],"float32"), )
[torch error] paddle.cross(Tensor([2, 2147483648],"float32"), Tensor([2, 3],"float32"), ) 
 no dimension of size 3 in input

/usr/local/lib/python3.9/dist-packages/torch/utils/_device.py:106: UserWarning: Using torch.cross without specifying the dim arg is deprecated.
Please either pass the dim explicitly or simply use torch.linalg.cross.
The default value of dim will change to agree with that of linalg.cross in a future release. (Triggered internally at ../aten/src/ATen/native/Cross.cpp:62.)
  return func(*args, **kwargs)
W0209 19:25:49.613701 119415 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:25:49.614706 119415 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cross(Tensor([2, 3],"float32"), Tensor([1431655765, 3],"float32"), )
[torch error] paddle.cross(Tensor([2, 3],"float32"), Tensor([1431655765, 3],"float32"), ) 
 The size of tensor a (2) must match the size of tensor b (1431655765) at non-singleton dimension 0

/usr/local/lib/python3.9/dist-packages/torch/utils/_device.py:106: UserWarning: Using torch.cross without specifying the dim arg is deprecated.
Please either pass the dim explicitly or simply use torch.linalg.cross.
The default value of dim will change to agree with that of linalg.cross in a future release. (Triggered internally at ../aten/src/ATen/native/Cross.cpp:62.)
  return func(*args, **kwargs)
W0209 19:27:01.890198 119429 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:27:01.891359 119429 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cross(Tensor([2, 3],"float32"), Tensor([2, 2147483648],"float32"), )
[torch error] paddle.cross(Tensor([2, 3],"float32"), Tensor([2, 2147483648],"float32"), ) 
 linalg.cross: inputs dimension 1 must have length 3. Got 3 and 2147483648

/usr/local/lib/python3.9/dist-packages/torch/utils/_device.py:106: UserWarning: Using torch.cross without specifying the dim arg is deprecated.
Please either pass the dim explicitly or simply use torch.linalg.cross.
The default value of dim will change to agree with that of linalg.cross in a future release. (Triggered internally at ../aten/src/ATen/native/Cross.cpp:62.)
  return func(*args, **kwargs)
W0209 19:28:10.348786 119469 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:28:10.349949 119469 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cross(Tensor([3, 1431655765],"float32"), Tensor([3, 1431655765],"float32"), axis=1, )
[torch error] paddle.cross(Tensor([3, 1431655765],"float32"), Tensor([3, 1431655765],"float32"), axis=1, ) 
 linalg.cross: inputs dimension 1 must have length 3. Got 1431655765 and 1431655765

W0209 19:30:17.300169 119484 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:30:17.301312 119484 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cross(Tensor([3, 1431655765],"float32"), Tensor([3, 3],"float32"), axis=1, )
[torch error] paddle.cross(Tensor([3, 1431655765],"float32"), Tensor([3, 3],"float32"), axis=1, ) 
 linalg.cross: inputs dimension 1 must have length 3. Got 1431655765 and 3

W0209 19:31:33.601480 119512 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:31:33.602540 119512 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cross(Tensor([3, 3],"float32"), Tensor([1431655765, 3],"float32"), axis=1, )
[torch error] paddle.cross(Tensor([3, 3],"float32"), Tensor([1431655765, 3],"float32"), axis=1, ) 
 The size of tensor a (3) must match the size of tensor b (1431655765) at non-singleton dimension 0

W0209 19:32:47.690897 119527 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:32:47.692000 119527 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cross(Tensor([3, 3],"float32"), Tensor([3, 1431655765],"float32"), axis=1, )
[torch error] paddle.cross(Tensor([3, 3],"float32"), Tensor([3, 1431655765],"float32"), axis=1, ) 
 linalg.cross: inputs dimension 1 must have length 3. Got 3 and 1431655765

W0209 19:33:57.611629 119541 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:33:57.612746 119541 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([1, 2, 2147483648],"float32"), dim=-1, )
[Pass] paddle.cumprod(Tensor([1, 2, 2147483648],"float32"), dim=-1, )

W0209 19:35:26.574247 119568 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:35:26.575546 119568 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([1, 2147483648, 2],"float32"), dim=-1, )
[Pass] paddle.cumprod(Tensor([1, 2147483648, 2],"float32"), dim=-1, )

W0209 19:41:12.371846 119611 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:41:12.372700 119611 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([10, 20, 21474837],"float32"), -1, dtype="float32", )
[torch error] paddle.cumprod(Tensor([10, 20, 21474837],"float32"), -1, dtype="float32", ) 
 cumprod() received an invalid combination of arguments - got (dtype=str, input=Tensor, dim=int, ), but expected one of:
 * (Tensor input, int dim, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, name dim, *, torch.dtype dtype = None, Tensor out = None)


W0209 19:44:51.017134 119653 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:44:51.018564 119653 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([10, 429496730, 1],"float32"), -1, dtype="float32", )
[torch error] paddle.cumprod(Tensor([10, 429496730, 1],"float32"), -1, dtype="float32", ) 
 cumprod() received an invalid combination of arguments - got (dtype=str, input=Tensor, dim=int, ), but expected one of:
 * (Tensor input, int dim, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, name dim, *, torch.dtype dtype = None, Tensor out = None)


W0209 19:46:10.900170 119680 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:46:10.901785 119680 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([10, 429496730],"float32"), dim=0, )
[Pass] paddle.cumprod(Tensor([10, 429496730],"float32"), dim=0, )

W0209 19:47:34.086402 119708 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:47:34.087235 119708 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([10, 429496730],"float32"), dim=1, )
[Pass] paddle.cumprod(Tensor([10, 429496730],"float32"), dim=1, )

W0209 19:51:07.849908 119750 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:51:07.850840 119750 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([1073741824, 2, 2],"float32"), dim=-1, )
[Pass] paddle.cumprod(Tensor([1073741824, 2, 2],"float32"), dim=-1, )

W0209 19:55:38.146196 119778 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:55:38.147295 119778 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([1073741824, 4],"float32"), dim=-1, )
[Pass] paddle.cumprod(Tensor([1073741824, 4],"float32"), dim=-1, )

W0209 19:59:18.104702 119819 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 19:59:18.105885 119819 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([119304648, 3, 3, 4],"float32"), dim=0, )
[Pass] paddle.cumprod(Tensor([119304648, 3, 3, 4],"float32"), dim=0, )

W0209 20:04:07.000185 119862 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:04:07.001302 119862 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([119304648, 3, 3, 4],"float32"), dim=1, )
[Pass] paddle.cumprod(Tensor([119304648, 3, 3, 4],"float32"), dim=1, )

W0209 20:08:27.200436 119891 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:08:27.201375 119891 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([119304648, 3, 3, 4],"float32"), dim=2, )
[accuracy error] paddle.cumprod(Tensor([119304648, 3, 3, 4],"float32"), dim=2, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 44 / 4294967328 (1.02e-06%)
Max absolute difference: 0.8517279
Max relative difference: 247.41447
 x: array([[[[2.678180e-01, 2.337467e-01, 8.211917e-02, 1.839643e-01],
         [6.957677e-02, 1.530541e-01, 5.687952e-02, 4.253853e-02],
         [2.800834e-04, 1.083994e-01, 1.104480e-02, 4.620609e-03]],...
 y: array([[[[2.678180e-01, 2.337467e-01, 8.211917e-02, 1.839643e-01],
         [6.957677e-02, 1.530541e-01, 5.687952e-02, 4.253853e-02],
         [4.025531e-03, 7.082423e-01, 1.941789e-01, 1.086217e-01]],...

W0209 20:11:50.088789 119919 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:11:50.089756 119919 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([119304648, 3, 3, 4],"float32"), dim=3, )
[accuracy error] paddle.cumprod(Tensor([119304648, 3, 3, 4],"float32"), dim=3, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 25 / 4294967328 (5.82e-07%)
Max absolute difference: 0.9360452
Max relative difference: 0.
 x: array([[[[1.054221e-01, 9.735661e-02, 2.145853e-02, 7.884411e-03],
         [8.224683e-01, 4.820593e-01, 4.431051e-02, 4.308019e-02],
         [3.010504e-01, 8.503371e-03, 1.060496e-03, 6.391842e-04]],...
 y: array([[[[1.054221e-01, 9.735661e-02, 2.145853e-02, 7.884411e-03],
         [8.224683e-01, 4.820593e-01, 4.431051e-02, 4.308019e-02],
         [3.010504e-01, 8.503371e-03, 1.060496e-03, 6.391842e-04]],...

W0209 20:16:32.315541 119987 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:16:32.316448 119987 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([1431655765, 3],"float32"), dim=-1, )
[Pass] paddle.cumprod(Tensor([1431655765, 3],"float32"), dim=-1, )

W0209 20:21:22.249817 120031 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:21:22.250749 120031 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 1073741824, 2],"float32"), dim=-1, )
[Pass] paddle.cumprod(Tensor([2, 1073741824, 2],"float32"), dim=-1, )

W0209 20:25:20.049160 120073 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:25:20.050105 120073 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 10737419, 10, 10],"float64"), 1, )
[Pass] paddle.cumprod(Tensor([2, 10737419, 10, 10],"float64"), 1, )

W0209 20:28:34.249455 120115 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:28:34.250322 120115 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 178956971, 3, 4],"float32"), dim=0, )
[torch error] paddle.cumprod(Tensor([2, 178956971, 3, 4],"float32"), dim=0, ) 
 CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


W0209 20:31:53.206723 120156 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:31:53.207687 120156 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 178956971, 3, 4],"float32"), dim=1, )
[Pass] paddle.cumprod(Tensor([2, 178956971, 3, 4],"float32"), dim=1, )

W0209 20:34:11.366855 120171 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:34:11.367995 120171 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 178956971, 3, 4],"float32"), dim=2, )
[Pass] paddle.cumprod(Tensor([2, 178956971, 3, 4],"float32"), dim=2, )

W0209 20:39:10.427932 120227 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:39:10.428905 120227 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 178956971, 3, 4],"float32"), dim=3, )
[accuracy error] paddle.cumprod(Tensor([2, 178956971, 3, 4],"float32"), dim=3, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 8 / 4294967304 (1.86e-07%)
Max absolute difference: 0.9392818
Max relative difference: 0.
 x: array([[[[6.309299e-01, 2.573855e-01, 3.496887e-02, 3.397233e-02],
         [5.301854e-01, 3.922742e-01, 3.882098e-01, 3.581474e-01],
         [1.270324e-01, 4.081363e-03, 1.677987e-03, 2.068772e-04]],...
 y: array([[[[6.309299e-01, 2.573855e-01, 3.496887e-02, 3.397233e-02],
         [5.301854e-01, 3.922742e-01, 3.882098e-01, 3.581474e-01],
         [1.270324e-01, 4.081363e-03, 1.677987e-03, 2.068772e-04]],...

W0209 20:42:48.786100 120255 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:42:48.787066 120255 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 2, 1073741824],"float32"), dim=-1, )
[Pass] paddle.cumprod(Tensor([2, 2, 1073741824],"float32"), dim=-1, )

W0209 20:47:23.862419 120296 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:47:23.863266 120296 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 3, 10, 35791395],"float64"), 1, )
[Pass] paddle.cumprod(Tensor([2, 3, 10, 35791395],"float64"), 1, )

W0209 20:51:29.838080 120325 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:51:29.838938 120325 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 3, 178956971, 4],"float32"), dim=0, )
[torch error] paddle.cumprod(Tensor([2, 3, 178956971, 4],"float32"), dim=0, ) 
 CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


W0209 20:55:22.306809 120353 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:55:22.308076 120353 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 3, 178956971, 4],"float32"), dim=1, )
[Pass] paddle.cumprod(Tensor([2, 3, 178956971, 4],"float32"), dim=1, )

W0209 20:56:40.709844 120393 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 20:56:40.710937 120393 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 3, 178956971, 4],"float32"), dim=2, )
[Pass] paddle.cumprod(Tensor([2, 3, 178956971, 4],"float32"), dim=2, )

W0209 21:00:47.579849 120422 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:00:47.581224 120422 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 3, 178956971, 4],"float32"), dim=3, )
[accuracy error] paddle.cumprod(Tensor([2, 3, 178956971, 4],"float32"), dim=3, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 8 / 4294967304 (1.86e-07%)
Max absolute difference: 0.76324046
Max relative difference: 0.
 x: array([[[[3.066182e-02, 2.783913e-02, 1.325104e-02, 5.227670e-03],
         [5.972573e-01, 3.249647e-01, 2.465752e-02, 2.226036e-02],
         [1.330038e-01, 1.617900e-03, 1.083012e-03, 2.065211e-04],...
 y: array([[[[3.066182e-02, 2.783913e-02, 1.325104e-02, 5.227670e-03],
         [5.972573e-01, 3.249647e-01, 2.465752e-02, 2.226036e-02],
         [1.330038e-01, 1.617900e-03, 1.083012e-03, 2.065211e-04],...

W0209 21:05:59.597635 120465 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:05:59.598500 120465 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 3, 3, 238609295],"float32"), dim=0, )
[torch error] paddle.cumprod(Tensor([2, 3, 3, 238609295],"float32"), dim=0, ) 
 CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


W0209 21:11:06.273484 120507 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:11:06.274590 120507 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 3, 3, 238609295],"float32"), dim=1, )
[Pass] paddle.cumprod(Tensor([2, 3, 3, 238609295],"float32"), dim=1, )

W0209 21:12:29.998570 120535 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:12:29.999476 120535 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 3, 3, 238609295],"float32"), dim=2, )
[Pass] paddle.cumprod(Tensor([2, 3, 3, 238609295],"float32"), dim=2, )

W0209 21:16:01.280395 120617 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:16:01.281517 120617 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 3, 3, 238609295],"float32"), dim=3, )
[Pass] paddle.cumprod(Tensor([2, 3, 3, 238609295],"float32"), dim=3, )

W0209 21:19:39.101426 120674 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:19:39.102286 120674 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 3, 3, 4, 59652324],"float32"), dim=0, )
[torch error] paddle.cumprod(Tensor([2, 3, 3, 4, 59652324],"float32"), dim=0, ) 
 CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


W0209 21:23:20.578399 120717 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:23:20.579545 120717 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 3, 3, 4, 59652324],"float32"), dim=1, )
[Pass] paddle.cumprod(Tensor([2, 3, 3, 4, 59652324],"float32"), dim=1, )

W0209 21:24:34.768874 120731 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:24:34.769766 120731 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 3, 3, 4, 59652324],"float32"), dim=2, )
[Pass] paddle.cumprod(Tensor([2, 3, 3, 4, 59652324],"float32"), dim=2, )

W0209 21:28:06.434051 120759 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:28:06.434970 120759 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 3, 3, 4, 59652324],"float32"), dim=3, )
[Pass] paddle.cumprod(Tensor([2, 3, 3, 4, 59652324],"float32"), dim=3, )

W0209 21:31:40.136911 120787 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:31:40.138233 120787 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 3, 3, 4, 59652324],"float32"), dim=4, )
[Pass] paddle.cumprod(Tensor([2, 3, 3, 4, 59652324],"float32"), dim=4, )

W0209 21:35:21.345122 120815 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:35:21.345978 120815 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 3, 3, 47721859, 5],"float32"), dim=0, )
[torch error] paddle.cumprod(Tensor([2, 3, 3, 47721859, 5],"float32"), dim=0, ) 
 CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


W0209 21:38:49.286492 120857 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:38:49.287637 120857 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 3, 3, 47721859, 5],"float32"), dim=1, )
[Pass] paddle.cumprod(Tensor([2, 3, 3, 47721859, 5],"float32"), dim=1, )

W0209 21:40:04.601403 120884 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:40:04.602270 120884 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 3, 3, 47721859, 5],"float32"), dim=2, )
[Pass] paddle.cumprod(Tensor([2, 3, 3, 47721859, 5],"float32"), dim=2, )

W0209 21:43:36.465335 120913 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:43:36.466377 120913 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 3, 3, 47721859, 5],"float32"), dim=3, )
[Pass] paddle.cumprod(Tensor([2, 3, 3, 47721859, 5],"float32"), dim=3, )

W0209 21:47:22.580396 120941 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:47:22.581310 120941 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 3, 3, 47721859, 5],"float32"), dim=4, )
[accuracy error] paddle.cumprod(Tensor([2, 3, 3, 47721859, 5],"float32"), dim=4, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 19 / 4294967310 (4.42e-07%)
Max absolute difference: 0.779943
Max relative difference: 2.7017848
 x: array([[[[[6.186080e-01, 6.167740e-01, 1.488727e-01, 4.181025e-02,
           1.129462e-02],
          [6.254194e-01, 4.949259e-01, 1.364345e-01, 7.203417e-03,...
 y: array([[[[[6.186080e-01, 6.167740e-01, 1.488727e-01, 4.181025e-02,
           2.701400e-01],
          [1.689508e-01, 1.336993e-01, 3.685641e-02, 1.945931e-03,...

W0209 21:51:37.079854 121010 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:51:37.081051 121010 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 3, 35791395, 10],"float64"), 1, )
[Pass] paddle.cumprod(Tensor([2, 3, 35791395, 10],"float64"), 1, )

W0209 21:56:04.694470 121039 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:56:04.695326 121039 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 3, 35791395, 4, 5],"float32"), dim=0, )
[torch error] paddle.cumprod(Tensor([2, 3, 35791395, 4, 5],"float32"), dim=0, ) 
 CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


W0209 21:59:05.188782 121067 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 21:59:05.189934 121067 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 3, 35791395, 4, 5],"float32"), dim=1, )
[Pass] paddle.cumprod(Tensor([2, 3, 35791395, 4, 5],"float32"), dim=1, )

W0209 22:00:18.990012 121081 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:00:18.990849 121081 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 3, 35791395, 4, 5],"float32"), dim=2, )
[Pass] paddle.cumprod(Tensor([2, 3, 35791395, 4, 5],"float32"), dim=2, )

W0209 22:04:11.928254 121122 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:04:11.929479 121122 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 3, 35791395, 4, 5],"float32"), dim=3, )
[accuracy error] paddle.cumprod(Tensor([2, 3, 35791395, 4, 5],"float32"), dim=3, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 156 / 4294967400 (3.63e-06%)
Max absolute difference: 0.93993723
Max relative difference: 176.03542
 x: array([[[[[2.021520e-02, 8.689042e-01, 2.433584e-01, 3.424191e-01,
           5.426682e-01],
          [1.502051e-02, 1.255036e-01, 1.326037e-01, 5.964763e-02,...
 y: array([[[[[2.021520e-02, 8.689042e-01, 2.433584e-01, 3.424191e-01,
           5.426682e-01],
          [7.430308e-01, 1.444389e-01, 5.448908e-01, 1.741948e-01,...

W0209 22:08:03.665745 121151 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:08:03.666692 121151 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 3, 35791395, 4, 5],"float32"), dim=4, )
[accuracy error] paddle.cumprod(Tensor([2, 3, 35791395, 4, 5],"float32"), dim=4, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 157 / 4294967400 (3.66e-06%)
Max absolute difference: 0.9560338
Max relative difference: 184.065
 x: array([[[[[5.447283e-01, 1.558013e-01, 4.881578e-02, 2.787908e-02,
           2.711150e-02],
          [5.212374e-01, 2.058259e-01, 8.867759e-02, 3.803451e-02,...
 y: array([[[[[5.447283e-01, 1.558013e-01, 4.881578e-02, 2.787908e-02,
           9.724677e-01],
          [5.068866e-01, 2.001590e-01, 8.623609e-02, 3.698733e-02,...

W0209 22:12:42.468116 121179 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:12:42.469038 121179 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 3, 715827883],"float32"), dim=0, )
[torch error] paddle.cumprod(Tensor([2, 3, 715827883],"float32"), dim=0, ) 
 CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


W0209 22:17:09.813382 121248 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:17:09.815689 121248 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 3, 715827883],"float32"), dim=1, )
[Pass] paddle.cumprod(Tensor([2, 3, 715827883],"float32"), dim=1, )

W0209 22:18:28.199232 121855 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:18:28.200055 121855 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 3, 715827883],"float32"), dim=2, )
[Pass] paddle.cumprod(Tensor([2, 3, 715827883],"float32"), dim=2, )

W0209 22:22:06.769196 123594 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:22:06.770382 123594 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 35791395, 3, 4, 5],"float32"), dim=0, )
[torch error] paddle.cumprod(Tensor([2, 35791395, 3, 4, 5],"float32"), dim=0, ) 
 CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


W0209 22:26:34.464831 125829 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:26:34.465814 125829 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 35791395, 3, 4, 5],"float32"), dim=1, )
[Pass] paddle.cumprod(Tensor([2, 35791395, 3, 4, 5],"float32"), dim=1, )

W0209 22:28:08.415683 126544 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:28:08.416635 126544 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 35791395, 3, 4, 5],"float32"), dim=2, )
[accuracy error] paddle.cumprod(Tensor([2, 35791395, 3, 4, 5],"float32"), dim=2, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 100 / 4294967400 (2.33e-06%)
Max absolute difference: 0.99837446
Max relative difference: 9.944381
 x: array([[[[[3.569448e-01, 1.491411e-01, 3.318115e-01, 8.920960e-03,
           7.320474e-01],
          [4.981825e-01, 6.423640e-01, 7.574978e-01, 5.195436e-01,...
 y: array([[[[[3.569448e-01, 1.491411e-01, 3.318115e-01, 8.920960e-03,
           7.320474e-01],
          [4.981825e-01, 6.423640e-01, 7.574978e-01, 5.195436e-01,...

W0209 22:32:04.693830 128541 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:32:04.694734 128541 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 35791395, 3, 4, 5],"float32"), dim=3, )
[accuracy error] paddle.cumprod(Tensor([2, 35791395, 3, 4, 5],"float32"), dim=3, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 150 / 4294967400 (3.49e-06%)
Max absolute difference: 0.9655529
Max relative difference: 1227.2408
 x: array([[[[[4.034726e-01, 2.156565e-01, 9.317734e-02, 8.073577e-01,
           3.244292e-01],
          [6.107878e-02, 1.251520e-01, 7.029239e-02, 4.811934e-01,...
 y: array([[[[[4.034726e-01, 2.156565e-01, 9.317734e-02, 8.073577e-01,
           3.244292e-01],
          [1.513827e-01, 5.803301e-01, 7.543936e-01, 5.960101e-01,...

W0209 22:37:12.541894 131019 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:37:12.542838 131019 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 35791395, 3, 4, 5],"float32"), dim=4, )
[accuracy error] paddle.cumprod(Tensor([2, 35791395, 3, 4, 5],"float32"), dim=4, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 164 / 4294967400 (3.82e-06%)
Max absolute difference: 0.9563957
Max relative difference: 26.46714
 x: array([[[[[5.554398e-01, 3.476542e-01, 2.794136e-01, 2.540976e-01,
           1.635963e-01],
          [9.797162e-01, 6.504726e-01, 2.326661e-01, 2.297308e-01,...
 y: array([[[[[5.554398e-01, 3.476542e-01, 2.794136e-01, 2.540976e-01,
           6.438323e-01],
          [6.307729e-01, 4.187953e-01, 1.497980e-01, 1.479081e-01,...

W0209 22:41:58.564819 133780 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:41:58.565698 133780 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 536870912, 4],"float32"), dim=0, )
[torch error] paddle.cumprod(Tensor([2, 536870912, 4],"float32"), dim=0, ) 
 CUDA error: invalid configuration argument
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


W0209 22:46:30.327998 136066 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:46:30.330030 136066 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 536870912, 4],"float32"), dim=1, )
[Pass] paddle.cumprod(Tensor([2, 536870912, 4],"float32"), dim=1, )

W0209 22:49:11.789566 136789 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:49:11.790638 136789 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2, 536870912, 4],"float32"), dim=2, )
[Pass] paddle.cumprod(Tensor([2, 536870912, 4],"float32"), dim=2, )

W0209 22:54:28.352072 139884 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:54:28.352890 139884 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([2147483648, 2],"float32"), dim=-1, )
[Pass] paddle.cumprod(Tensor([2147483648, 2],"float32"), dim=-1, )

W0209 22:58:37.818018 142080 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 22:58:37.818887 142080 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([214748365, 20, 1],"float32"), -1, dtype="float32", )
[torch error] paddle.cumprod(Tensor([214748365, 20, 1],"float32"), -1, dtype="float32", ) 
 cumprod() received an invalid combination of arguments - got (dtype=str, input=Tensor, dim=int, ), but expected one of:
 * (Tensor input, int dim, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, name dim, *, torch.dtype dtype = None, Tensor out = None)


W0209 23:02:09.899967 143851 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 23:02:09.900962 143851 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([23860930, 3, 3, 4, 5],"float32"), dim=0, )
[Pass] paddle.cumprod(Tensor([23860930, 3, 3, 4, 5],"float32"), dim=0, )

W0209 23:03:35.694396 144584 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 23:03:35.695382 144584 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([23860930, 3, 3, 4, 5],"float32"), dim=1, )
[Pass] paddle.cumprod(Tensor([23860930, 3, 3, 4, 5],"float32"), dim=1, )

W0209 23:08:03.445895 146808 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 23:08:03.446785 146808 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([23860930, 3, 3, 4, 5],"float32"), dim=2, )
[accuracy error] paddle.cumprod(Tensor([23860930, 3, 3, 4, 5],"float32"), dim=2, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 100 / 4294967400 (2.33e-06%)
Max absolute difference: 0.9339176
Max relative difference: 24.233982
 x: array([[[[[7.777194e-01, 3.231600e-01, 2.056252e-01, 2.558690e-01,
           2.093622e-01],
          [8.047198e-01, 6.771823e-01, 6.002831e-01, 3.472707e-01,...
 y: array([[[[[7.777194e-01, 3.231600e-01, 2.056252e-01, 2.558690e-01,
           2.093622e-01],
          [8.047198e-01, 6.771823e-01, 6.002831e-01, 3.472707e-01,...

W0209 23:11:35.986783 148557 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 23:11:35.987605 148557 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([23860930, 3, 3, 4, 5],"float32"), dim=3, )
[accuracy error] paddle.cumprod(Tensor([23860930, 3, 3, 4, 5],"float32"), dim=3, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 169 / 4294967400 (3.93e-06%)
Max absolute difference: 0.8911621
Max relative difference: 848.8874
 x: array([[[[[8.211933e-01, 4.359550e-01, 3.429123e-01, 3.834906e-01,
           1.998447e-01],
          [8.101729e-01, 6.771824e-02, 2.570896e-01, 2.567272e-01,...
 y: array([[[[[8.211933e-01, 4.359550e-01, 3.429123e-01, 3.834906e-01,
           1.998447e-01],
          [9.865800e-01, 1.553331e-01, 7.497241e-01, 6.694483e-01,...

W0209 23:16:59.034332 151226 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 23:16:59.035291 151226 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([23860930, 3, 3, 4, 5],"float32"), dim=4, )
[accuracy error] paddle.cumprod(Tensor([23860930, 3, 3, 4, 5],"float32"), dim=4, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 145 / 4294967400 (3.38e-06%)
Max absolute difference: 0.9530001
Max relative difference: 29.577206
 x: array([[[[[6.718112e-01, 3.802485e-01, 1.361211e-02, 1.262941e-02,
           8.853863e-03],
          [1.651968e-01, 2.862644e-02, 1.709143e-02, 7.972574e-03,...
 y: array([[[[[6.718112e-01, 3.802485e-01, 1.361211e-02, 1.262941e-02,
           7.010511e-01],
          [1.158114e-01, 2.006860e-02, 1.198196e-02, 5.589182e-03,...

W0209 23:21:49.426119 153513 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 23:21:49.427110 153513 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([357913942, 3, 4],"float32"), dim=0, )
[Pass] paddle.cumprod(Tensor([357913942, 3, 4],"float32"), dim=0, )

W0209 23:28:52.371086 156245 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 23:28:52.372104 156245 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([357913942, 3, 4],"float32"), dim=1, )
[Pass] paddle.cumprod(Tensor([357913942, 3, 4],"float32"), dim=1, )

W0209 23:34:19.876338 160085 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 23:34:19.877259 160085 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.cumprod(Tensor([357913942, 3, 4],"float32"), dim=2, )
[accuracy error] paddle.cumprod(Tensor([357913942, 3, 4],"float32"), dim=2, ) 
 
Not equal to tolerance rtol=0.01, atol=0.01

Mismatched elements: 8 / 4294967304 (1.86e-07%)
Max absolute difference: 0.91174173
Max relative difference: 0.
 x: array([[[7.329918e-01, 5.581961e-01, 5.286796e-01, 4.756171e-01],
        [9.683173e-01, 5.675536e-01, 2.626121e-01, 1.206207e-02],
        [5.586560e-01, 2.337053e-01, 1.696226e-01, 2.675291e-02]],...
 y: array([[[7.329918e-01, 5.581961e-01, 5.286796e-01, 4.756171e-01],
        [9.683173e-01, 5.675536e-01, 2.626121e-01, 1.206207e-02],
        [5.586560e-01, 2.337053e-01, 1.696226e-01, 2.675291e-02]],...

W0209 23:37:55.004776 161823 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0209 23:37:55.005633 161823 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

Traceback (most recent call last):
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 70, in <module>
    main()
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 65, in main
    print(str(res.stdout.read(), encoding="utf-8"), flush=True)
KeyboardInterrupt
