test begin: paddle.concat(list[Tensor([2, 2400, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2400, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:04:41.490787 89776 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:04:41.491719 89776 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2400, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2400, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0205 10:05:50.592636 90057 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:05:50.593668 90057 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2432, 126145, 7],"float32"),Tensor([2, 32, 126145, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2432, 126145, 7],"float32"),Tensor([2, 32, 126145, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000066GB memory on GPU 0, 66.998962GB memory has been allocated and available memory is only 12.185913GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:07:22.244257 90273 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:07:22.245216 90273 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2432, 126145, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2432, 126145, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 126145 but got size 7 for tensor number 1 in the list.

W0205 10:08:37.933750 90572 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:08:37.934710 90572 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2432, 7, 126145],"float32"),Tensor([2, 32, 7, 126145],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2432, 7, 126145],"float32"),Tensor([2, 32, 7, 126145],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000066GB memory on GPU 0, 66.998962GB memory has been allocated and available memory is only 12.185913GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:10:11.220494 90843 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:10:11.221350 90843 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2432, 7, 126145],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2432, 7, 126145],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 126145 but got size 7 for tensor number 1 in the list.

W0205 10:11:22.454114 91171 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:11:22.455374 91171 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2432, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2432, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 10:12:46.026369 91377 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:12:46.027575 91377 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2432, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2432, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 10:14:02.286037 91661 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:14:02.287343 91661 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2432, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2432, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:15:37.887555 91942 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:15:37.888525 91942 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2432, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2432, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0205 10:16:51.161572 92245 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:16:51.162578 92245 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 244, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 244, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:18:21.902828 92467 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:18:21.904009 92467 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 244, 14, 14],"float32"),Tensor([2, 244, 14, 628655],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 244, 14, 14],"float32"),Tensor([2, 244, 14, 628655],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 628655 for tensor number 1 in the list.

W0205 10:19:37.579888 92810 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:19:37.580889 92810 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 244, 14, 14],"float32"),Tensor([2, 244, 628655, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 244, 14, 14],"float32"),Tensor([2, 244, 628655, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 628655 for tensor number 1 in the list.

W0205 10:20:59.724485 93114 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:20:59.725574 93114 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 244, 14, 14],"float32"),Tensor([89808, 244, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 244, 14, 14],"float32"),Tensor([89808, 244, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 89808 for tensor number 1 in the list.

W0205 10:22:16.157547 93410 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:22:16.158630 93410 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 244, 14, 628655],"float32"),Tensor([2, 244, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 244, 14, 628655],"float32"),Tensor([2, 244, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 628655 but got size 14 for tensor number 1 in the list.

W0205 10:23:31.263243 93618 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:23:31.264236 93618 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 244, 14, 628655],"float32"),Tensor([2, 244, 14, 628655],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 244, 14, 628655],"float32"),Tensor([2, 244, 14, 628655],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 147094 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:25:46.081866 93927 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:25:46.082998 93927 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 244, 628655, 14],"float32"),Tensor([2, 244, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 244, 628655, 14],"float32"),Tensor([2, 244, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 628655 but got size 14 for tensor number 1 in the list.

W0205 10:27:00.668653 94329 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:27:00.669631 94329 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 244, 628655, 14],"float32"),Tensor([2, 244, 628655, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 244, 628655, 14],"float32"),Tensor([2, 244, 628655, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 130498 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 10:29:14.333348 94632 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:29:14.334450 94632 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2464, 124507, 7],"float32"),Tensor([2, 32, 124507, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2464, 124507, 7],"float32"),Tensor([2, 32, 124507, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000098GB memory on GPU 0, 66.995056GB memory has been allocated and available memory is only 12.189819GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:30:42.532877 95070 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:30:42.533866 95070 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2464, 124507, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2464, 124507, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 124507 but got size 7 for tensor number 1 in the list.

W0205 10:31:53.048576 95427 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:31:53.050395 95427 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2464, 7, 124507],"float32"),Tensor([2, 32, 7, 124507],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2464, 7, 124507],"float32"),Tensor([2, 32, 7, 124507],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000098GB memory on GPU 0, 66.995056GB memory has been allocated and available memory is only 12.189819GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:33:25.677453 95625 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:33:25.679683 95625 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2464, 7, 124507],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2464, 7, 124507],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 124507 but got size 7 for tensor number 1 in the list.

W0205 10:34:35.224934 95939 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:34:35.226089 95939 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2464, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2464, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 10:35:56.833356 96249 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:35:56.834596 96249 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2464, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2464, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 10:37:14.769445 96462 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:37:14.770562 96462 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2464, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2464, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:38:45.761250 96777 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:38:45.762176 96777 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2464, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2464, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0205 10:39:54.998947 97071 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:39:55.000339 97071 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2496, 122911, 7],"float32"),Tensor([2, 32, 122911, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2496, 122911, 7],"float32"),Tensor([2, 32, 122911, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000129GB memory on GPU 0, 66.991150GB memory has been allocated and available memory is only 12.193726GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:41:27.294358 97267 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:41:27.296954 97267 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2496, 122911, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2496, 122911, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 122911 but got size 7 for tensor number 1 in the list.

W0205 10:42:37.550289 97585 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:42:37.551601 97585 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2496, 7, 122911],"float32"),Tensor([2, 32, 7, 122911],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2496, 7, 122911],"float32"),Tensor([2, 32, 7, 122911],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000129GB memory on GPU 0, 66.991150GB memory has been allocated and available memory is only 12.193726GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:44:18.065280 97876 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:44:18.066120 97876 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2496, 7, 122911],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2496, 7, 122911],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 122911 but got size 7 for tensor number 1 in the list.

W0205 10:45:26.600279 98194 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:45:26.601428 98194 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2496, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2496, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 10:46:50.618084 98390 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:46:50.619202 98390 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2496, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2496, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 10:48:10.644975 98695 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:48:10.645961 98695 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2496, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2496, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:49:40.009840 99001 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:49:40.010722 99001 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2496, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2496, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0205 10:50:55.090253 99292 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:50:55.091416 99292 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2528, 121355, 7],"float32"),Tensor([2, 32, 121355, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2528, 121355, 7],"float32"),Tensor([2, 32, 121355, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000108GB memory on GPU 0, 66.983337GB memory has been allocated and available memory is only 12.201538GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:52:28.327842 99529 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:52:28.328924 99529 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2528, 121355, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2528, 121355, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 121355 but got size 7 for tensor number 1 in the list.

W0205 10:53:35.770176 99834 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:53:35.771561 99834 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2528, 7, 121355],"float32"),Tensor([2, 32, 7, 121355],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2528, 7, 121355],"float32"),Tensor([2, 32, 7, 121355],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000108GB memory on GPU 0, 66.983337GB memory has been allocated and available memory is only 12.201538GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 10:55:08.743852 100138 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:55:08.744729 100138 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2528, 7, 121355],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2528, 7, 121355],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 121355 but got size 7 for tensor number 1 in the list.

W0205 10:56:17.879434 100445 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:56:17.880623 100445 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2528, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2528, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 10:57:32.270190 100667 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:57:32.271163 100667 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2528, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2528, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 10:58:51.816639 100944 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 10:58:51.817731 100944 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2528, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2528, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:00:22.897120 101161 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:00:22.898370 101161 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2528, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2528, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0205 11:01:32.152940 101482 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:01:32.153941 101482 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 12, 12],"float32"),Tensor([116509, 256, 12, 12],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 12, 12],"float32"),Tensor([116509, 256, 12, 12],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 116509 for tensor number 1 in the list.

W0205 11:02:51.176360 101795 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:02:51.177570 101795 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 12, 12],"float32"),Tensor([2, 14913081, 12, 12],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 12, 12],"float32"),Tensor([2, 14913081, 12, 12],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:04:20.919499 102078 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:04:20.920500 102078 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 12, 12],"float32"),Tensor([2, 256, 12, 699051],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 12, 12],"float32"),Tensor([2, 256, 12, 699051],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 12 but got size 699051 for tensor number 1 in the list.

W0205 11:05:36.248991 102532 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:05:36.250573 102532 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 12, 12],"float32"),Tensor([2, 256, 699051, 12],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 12, 12],"float32"),Tensor([2, 256, 699051, 12],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 12 but got size 699051 for tensor number 1 in the list.

W0205 11:06:51.227622 102925 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:06:51.228660 102925 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 12, 699051],"float32"),Tensor([2, 256, 12, 12],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 12, 699051],"float32"),Tensor([2, 256, 12, 12],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 699051 but got size 12 for tensor number 1 in the list.

W0205 11:08:16.046947 103245 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:08:16.047868 103245 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 12, 699051],"float32"),Tensor([2, 256, 12, 699051],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 12, 699051],"float32"),Tensor([2, 256, 12, 699051],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 20012 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:10:46.865589 103708 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:10:46.873392 103708 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:12:21.864650 104372 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:12:21.865511 104372 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:13:51.258903 104695 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:13:51.259773 104695 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 256, 13, 645278],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 256, 13, 645278],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 13 but got size 645278 for tensor number 1 in the list.

W0205 11:15:04.458618 105054 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:15:04.459926 105054 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 256, 645278, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 256, 645278, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 13 but got size 645278 for tensor number 1 in the list.

W0205 11:16:20.896960 105358 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:16:20.897960 105358 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([198547, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([198547, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 198547 for tensor number 2 in the list.

W0205 11:17:40.975574 105589 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:17:40.976966 105589 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:19:11.009383 105943 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:19:11.010530 105943 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 1290556, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 1290556, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 13 but got size 1290556 for tensor number 2 in the list.

W0205 11:20:28.955976 106248 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:20:28.957119 106248 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 1290556],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 1290556],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 13 but got size 1290556 for tensor number 2 in the list.

W0205 11:21:44.884337 106569 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:21:44.885440 106569 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([198547, 128, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([198547, 128, 13, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 198547 for tensor number 3 in the list.

W0205 11:23:00.489992 106888 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:23:00.490975 106888 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 12707004, 13, 13],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:24:36.269047 107251 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:24:36.269979 107251 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 1290556, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 1290556, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 13 but got size 1290556 for tensor number 3 in the list.

W0205 11:25:46.599086 107603 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:25:46.600185 107603 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 1290556],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 1290556],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 13 but got size 1290556 for tensor number 3 in the list.

W0205 11:27:08.468979 107815 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:27:08.470089 107815 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 516223],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 13, 516223],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 13 but got size 516223 for tensor number 1 in the list.

W0205 11:28:22.771024 108133 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:28:22.771983 108133 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 516223, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([2, 320, 516223, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 13 but got size 516223 for tensor number 1 in the list.

W0205 11:29:45.474067 108343 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:29:45.475137 108343 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([79419, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([79419, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 79419 for tensor number 1 in the list.

W0205 11:31:00.516464 108664 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:31:00.517448 108664 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([99274, 256, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 13],"float32"),Tensor([99274, 256, 13, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 99274 for tensor number 1 in the list.

W0205 11:32:14.418469 108942 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:32:14.419499 108942 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 645278],"float32"),Tensor([2, 256, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 645278],"float32"),Tensor([2, 256, 13, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 645278 but got size 13 for tensor number 1 in the list.

W0205 11:33:30.820067 109176 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:33:30.821180 109176 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 645278],"float32"),Tensor([2, 256, 13, 645278],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 645278],"float32"),Tensor([2, 256, 13, 645278],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 74497 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:36:01.850200 109481 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:36:01.851205 109481 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 645278],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 645278],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 645278 but got size 13 for tensor number 1 in the list.

W0205 11:37:19.638908 109968 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:37:19.660076 109968 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 13, 645278],"float32"),Tensor([2, 320, 13, 645278],"float32"),Tensor([2, 128, 13, 645278],"float32"),Tensor([2, 128, 13, 645278],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 13, 645278],"float32"),Tensor([2, 320, 13, 645278],"float32"),Tensor([2, 128, 13, 645278],"float32"),Tensor([2, 128, 13, 645278],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 115555 has 45.00 GiB memory in use. Of the allocated memory 44.00 GiB is allocated by PyTorch, and 5.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:41:07.854933 110191 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:41:07.856053 110191 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 1398102, 6],"float32"),Tensor([2, 320, 1398102, 6],"float32"),Tensor([2, 128, 1398102, 6],"float32"),Tensor([2, 128, 1398102, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 1398102, 6],"float32"),Tensor([2, 320, 1398102, 6],"float32"),Tensor([2, 128, 1398102, 6],"float32"),Tensor([2, 128, 1398102, 6],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 11847 has 45.00 GiB memory in use. Of the allocated memory 44.00 GiB is allocated by PyTorch, and 5.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 11:44:52.674039 110987 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:44:52.676963 110987 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 1398102, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 1398102, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1398102 but got size 6 for tensor number 1 in the list.

W0205 11:46:17.608805 111723 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:46:17.610232 111723 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:47:47.643743 112029 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:47:47.644726 112029 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0205 11:48:58.348306 112362 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:48:58.349334 112362 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0205 11:50:21.208323 112572 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:50:21.209545 112572 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0205 11:51:40.283525 112877 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:51:40.284775 112877 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 14, 599187],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 14, 599187],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 599187 but got size 14 for tensor number 1 in the list.

W0205 11:53:06.645308 113211 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:53:06.646523 113211 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 14, 599187],"float32"),Tensor([2, 32, 14, 599187],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 14, 599187],"float32"),Tensor([2, 32, 14, 599187],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000019GB memory on GPU 0, 70.580994GB memory has been allocated and available memory is only 8.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:54:46.969012 113532 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:54:46.971644 113532 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 26, 26],"float32"),Tensor([2, 256, 26, 322639],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 26, 26],"float32"),Tensor([2, 256, 26, 322639],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 26 but got size 322639 for tensor number 1 in the list.

W0205 11:56:04.964104 113853 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:56:04.965267 113853 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 26, 26],"float32"),Tensor([2, 256, 322639, 26],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 26, 26],"float32"),Tensor([2, 256, 322639, 26],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 26 but got size 322639 for tensor number 1 in the list.

W0205 11:57:21.163703 114143 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:57:21.164896 114143 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 26, 26],"float32"),Tensor([2, 3176751, 26, 26],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 26, 26],"float32"),Tensor([2, 3176751, 26, 26],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 11:58:52.692756 114393 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 11:58:52.694242 114393 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 26, 26],"float32"),Tensor([24819, 256, 26, 26],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 26, 26],"float32"),Tensor([24819, 256, 26, 26],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 24819 for tensor number 1 in the list.

W0205 12:00:01.083015 114833 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:00:01.084160 114833 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 26, 322639],"float32"),Tensor([2, 256, 26, 26],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 26, 322639],"float32"),Tensor([2, 256, 26, 26],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 322639 but got size 26 for tensor number 1 in the list.

W0205 12:01:18.076074 115235 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:01:18.077450 115235 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 26, 322639],"float32"),Tensor([2, 256, 26, 322639],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 26, 322639],"float32"),Tensor([2, 256, 26, 322639],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 65190 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:03:41.436349 115467 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:03:41.437441 115467 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 28, 28],"float32"),Tensor([171197, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 28, 28],"float32"),Tensor([171197, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 171197 for tensor number 1 in the list.

W0205 12:05:02.865137 115997 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:05:02.866418 115997 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 12:06:41.294332 116301 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:06:41.295603 116301 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 28, 28],"float32"),Tensor([2, 32, 2396746, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 28, 28],"float32"),Tensor([2, 32, 2396746, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 2396746 for tensor number 1 in the list.

W0205 12:07:52.820551 116633 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:07:52.821782 116633 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 28, 28],"float32"),Tensor([2, 32, 28, 2396746],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 28, 28],"float32"),Tensor([2, 32, 28, 2396746],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 2396746 for tensor number 1 in the list.

W0205 12:09:09.660706 116867 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:09:09.661883 116867 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 28, 299594],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 28, 299594],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 299594 but got size 28 for tensor number 1 in the list.

W0205 12:10:40.083469 117177 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:10:40.100169 117177 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 28, 299594],"float32"),Tensor([2, 32, 28, 299594],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 28, 299594],"float32"),Tensor([2, 32, 28, 299594],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000046GB memory on GPU 0, 70.580994GB memory has been allocated and available memory is only 8.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 12:12:29.524408 117520 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:12:29.525381 117520 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 299594, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 299594, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 299594 but got size 28 for tensor number 1 in the list.

W0205 12:13:40.663499 117844 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:13:40.664564 117844 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 299594, 28],"float32"),Tensor([2, 32, 299594, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 299594, 28],"float32"),Tensor([2, 32, 299594, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000046GB memory on GPU 0, 70.580994GB memory has been allocated and available memory is only 8.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 12:15:19.234144 118154 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:15:19.235231 118154 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 322639, 26],"float32"),Tensor([2, 256, 26, 26],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 322639, 26],"float32"),Tensor([2, 256, 26, 26],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 322639 but got size 26 for tensor number 1 in the list.

W0205 12:16:38.091931 118483 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:16:38.093130 118483 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 322639, 26],"float32"),Tensor([2, 256, 322639, 26],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 322639, 26],"float32"),Tensor([2, 256, 322639, 26],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 163384 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:19:03.331729 118802 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:19:03.332891 118802 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 599187, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 599187, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 599187 but got size 14 for tensor number 1 in the list.

W0205 12:20:30.033885 119315 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:20:30.035028 119315 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 599187, 14],"float32"),Tensor([2, 32, 599187, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 599187, 14],"float32"),Tensor([2, 32, 599187, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000019GB memory on GPU 0, 70.580994GB memory has been allocated and available memory is only 8.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 12:22:18.536039 119649 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:22:18.536998 119649 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 6, 1398102],"float32"),Tensor([2, 320, 6, 1398102],"float32"),Tensor([2, 128, 6, 1398102],"float32"),Tensor([2, 128, 6, 1398102],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 6, 1398102],"float32"),Tensor([2, 320, 6, 1398102],"float32"),Tensor([2, 128, 6, 1398102],"float32"),Tensor([2, 128, 6, 1398102],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 105249 has 45.00 GiB memory in use. Of the allocated memory 44.00 GiB is allocated by PyTorch, and 5.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:25:41.917444 119944 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:25:41.918576 119944 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 6, 1398102],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 6, 1398102],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1398102 but got size 6 for tensor number 1 in the list.

W0205 12:27:09.171833 120783 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:27:09.172816 120783 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 1118482, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 1118482, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 6 but got size 1118482 for tensor number 1 in the list.

W0205 12:28:28.896307 121074 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:28:28.897505 121074 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 1118482],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 1118482],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 6 but got size 1118482 for tensor number 1 in the list.

W0205 12:29:52.874212 121366 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:29:52.875514 121366 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 2796203, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 2796203, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 6 but got size 2796203 for tensor number 2 in the list.

W0205 12:31:10.366369 121563 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:31:10.367507 121563 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 2796203],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 2796203],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 6 but got size 2796203 for tensor number 2 in the list.

W0205 12:32:34.384079 121869 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:32:34.385288 121869 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 2796203, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 2796203, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 6 but got size 2796203 for tensor number 3 in the list.

W0205 12:33:57.886493 122159 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:33:57.887745 122159 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 2796203],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 2796203],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 6 but got size 2796203 for tensor number 3 in the list.

W0205 12:35:20.605185 122382 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:35:20.606667 122382 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 59652324, 6, 6],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 59652324, 6, 6],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 12:36:58.067998 122674 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:36:58.069187 122674 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([932068, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([932068, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 932068 for tensor number 3 in the list.

W0205 12:38:12.582800 122954 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:38:12.583974 122954 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 59652324, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 59652324, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 12:39:49.021397 123259 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:39:49.022281 123259 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([932068, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([932068, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 932068 for tensor number 2 in the list.

W0205 12:41:06.744767 123582 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:41:06.745829 123582 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 59652324, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([2, 59652324, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 12:42:38.796976 123872 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:42:38.798154 123872 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([372828, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 6, 6],"float32"),Tensor([372828, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 372828 for tensor number 1 in the list.

W0205 12:43:55.652938 124177 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:43:55.654175 124177 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 645278, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 645278, 13],"float32"),Tensor([2, 256, 13, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 645278 but got size 13 for tensor number 1 in the list.

W0205 12:45:15.202309 124387 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:45:15.203285 124387 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 645278, 13],"float32"),Tensor([2, 256, 645278, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 645278, 13],"float32"),Tensor([2, 256, 645278, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 91800 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:47:47.668007 124693 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:47:47.669021 124693 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 645278, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 645278, 13],"float32"),Tensor([2, 320, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),Tensor([2, 128, 13, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 645278 but got size 13 for tensor number 1 in the list.

W0205 12:49:13.414384 125193 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:49:13.415179 125193 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 645278, 13],"float32"),Tensor([2, 320, 645278, 13],"float32"),Tensor([2, 128, 645278, 13],"float32"),Tensor([2, 128, 645278, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 645278, 13],"float32"),Tensor([2, 320, 645278, 13],"float32"),Tensor([2, 128, 645278, 13],"float32"),Tensor([2, 128, 645278, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 138052 has 45.00 GiB memory in use. Of the allocated memory 44.00 GiB is allocated by PyTorch, and 5.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:52:50.273762 125471 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:52:50.274773 125471 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 699051, 12],"float32"),Tensor([2, 256, 12, 12],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 699051, 12],"float32"),Tensor([2, 256, 12, 12],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 699051 but got size 12 for tensor number 1 in the list.

W0205 12:54:07.434866 126138 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:54:07.435999 126138 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 256, 699051, 12],"float32"),Tensor([2, 256, 699051, 12],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 256, 699051, 12],"float32"),Tensor([2, 256, 699051, 12],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 43758 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 12:56:37.906842 126427 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:56:37.907971 126427 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2560, 119838, 7],"float32"),Tensor([2, 32, 119838, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2560, 119838, 7],"float32"),Tensor([2, 32, 119838, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000099GB memory on GPU 0, 66.979431GB memory has been allocated and available memory is only 12.205444GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 12:58:44.616232 126926 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 12:58:44.617048 126926 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2560, 119838, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2560, 119838, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 119838 but got size 7 for tensor number 1 in the list.

W0205 13:00:10.976326 127324 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:00:10.978061 127324 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2560, 7, 119838],"float32"),Tensor([2, 32, 7, 119838],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2560, 7, 119838],"float32"),Tensor([2, 32, 7, 119838],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000099GB memory on GPU 0, 66.979431GB memory has been allocated and available memory is only 12.205444GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 13:01:41.634253 127616 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:01:41.635203 127616 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2560, 7, 119838],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2560, 7, 119838],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 119838 but got size 7 for tensor number 1 in the list.

W0205 13:02:48.712298 127942 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:02:48.714275 127942 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2560, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2560, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 13:04:09.470252 128151 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:04:09.471416 128151 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2560, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2560, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 13:05:24.456655 128468 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:05:24.457671 128468 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2560, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2560, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 13:07:02.420539 128692 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:07:02.421918 128692 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2560, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2560, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0205 13:08:20.051234 128997 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:08:20.052309 128997 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2592, 118358, 7],"float32"),Tensor([2, 32, 118358, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2592, 118358, 7],"float32"),Tensor([2, 32, 118358, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 66.975525GB memory has been allocated and available memory is only 12.209351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 13:10:00.423848 129288 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:10:00.424736 129288 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2592, 118358, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2592, 118358, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 118358 but got size 7 for tensor number 1 in the list.

W0205 13:11:27.082067 129593 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:11:27.083120 129593 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2592, 7, 118358],"float32"),Tensor([2, 32, 7, 118358],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2592, 7, 118358],"float32"),Tensor([2, 32, 7, 118358],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 66.975525GB memory has been allocated and available memory is only 12.209351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 13:12:59.503046 129873 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:12:59.505394 129873 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2592, 7, 118358],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2592, 7, 118358],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 118358 but got size 7 for tensor number 1 in the list.

W0205 13:14:13.725395 130201 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:14:13.726475 130201 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2592, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2592, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 13:15:34.920887 130501 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:15:34.922068 130501 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2592, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2592, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 13:16:54.768612 130804 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:16:54.769822 130804 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2592, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2592, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 13:18:30.929071 131056 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:18:30.930029 131056 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2592, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2592, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0205 13:19:47.246198 131348 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:19:47.247423 131348 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 262144, 128, 64],"float16"),Tensor([2, 262144, 1, 64],"float16"),], axis=2, )
[Pass] paddle.concat(list[Tensor([2, 262144, 128, 64],"float16"),Tensor([2, 262144, 1, 64],"float16"),], axis=2, )

W0205 13:21:28.338740 131652 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:21:28.340335 131652 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 262144, 128, 64],"float16"),Tensor([2, 8, 1, 64],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 262144, 128, 64],"float16"),Tensor([2, 8, 1, 64],"float16"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 262144 but got size 8 for tensor number 1 in the list.

W0205 13:30:41.006139 133499 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:30:41.007284 133499 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2624, 116915, 7],"float32"),Tensor([2, 32, 116915, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2624, 116915, 7],"float32"),Tensor([2, 32, 116915, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000082GB memory on GPU 0, 66.967712GB memory has been allocated and available memory is only 12.217163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 13:32:22.201395 133776 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:32:22.202528 133776 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2624, 116915, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2624, 116915, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 116915 but got size 7 for tensor number 1 in the list.

W0205 13:33:39.107049 134094 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:33:39.108148 134094 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2624, 7, 116915],"float32"),Tensor([2, 32, 7, 116915],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2624, 7, 116915],"float32"),Tensor([2, 32, 7, 116915],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000082GB memory on GPU 0, 66.967712GB memory has been allocated and available memory is only 12.217163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 13:35:20.013082 134386 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:35:20.015460 134386 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2624, 7, 116915],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2624, 7, 116915],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 116915 but got size 7 for tensor number 1 in the list.

W0205 13:36:32.375223 134719 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:36:32.377877 134719 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2624, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2624, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 13:37:47.039417 135010 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:37:47.040829 135010 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2624, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2624, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 13:39:03.381398 135232 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:39:03.382781 135232 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2624, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2624, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 13:40:37.999650 135538 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:40:38.000541 135538 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2624, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2624, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0205 13:41:55.122406 135844 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:41:55.123941 135844 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2656, 115506, 7],"float32"),Tensor([2, 32, 115506, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2656, 115506, 7],"float32"),Tensor([2, 32, 115506, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 66.963806GB memory has been allocated and available memory is only 12.221069GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 13:43:36.633478 136083 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:43:36.634281 136083 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2656, 115506, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2656, 115506, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 115506 but got size 7 for tensor number 1 in the list.

W0205 13:44:46.202508 136487 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:44:46.203552 136487 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2656, 7, 115506],"float32"),Tensor([2, 32, 7, 115506],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2656, 7, 115506],"float32"),Tensor([2, 32, 7, 115506],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 66.963806GB memory has been allocated and available memory is only 12.221069GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 13:46:20.310261 136696 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:46:20.311334 136696 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2656, 7, 115506],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2656, 7, 115506],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 115506 but got size 7 for tensor number 1 in the list.

W0205 13:47:36.383666 137016 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:47:36.384618 137016 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2656, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2656, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 13:48:56.238644 137333 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:48:56.240135 137333 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2656, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2656, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 13:50:18.180235 137558 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:50:18.181645 137558 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2656, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2656, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 13:51:57.013082 137865 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:51:57.014111 137865 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2656, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2656, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0205 13:53:13.449033 138174 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:53:13.450163 138174 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 268435456, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 268435456, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 13:54:52.489068 138493 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:54:52.490018 138493 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),], axis=2, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 87633 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 13:57:00.703630 138799 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 13:57:00.704658 138799 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),Tensor([2, 268435456, 8],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 26920 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:00:20.887295 139286 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:00:20.888460 139286 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 268435456, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 268435456, 8],"float32"),Tensor([2, 8, 8],"float32"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 268435456 but got size 8 for tensor number 1 in the list.

W0205 14:01:41.302246 139947 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:01:41.303421 139947 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 112, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 112, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:03:16.532773 140261 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:03:16.533661 140261 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 12, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 12, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:04:48.439167 140579 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:04:48.440126 140579 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 16, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 16, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:06:16.738976 140872 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:06:16.739886 140872 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 24, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 24, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:07:43.404860 141164 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:07:43.405774 141164 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 41384 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 14:10:15.664191 141494 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:10:15.665395 141494 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:11:48.456804 141956 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:11:48.457661 141956 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:13:21.474058 142309 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:13:21.475052 142309 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 58, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 58, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:14:47.047461 142617 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:14:47.048261 142617 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 88, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2739138, 28, 28],"float32"),Tensor([2, 88, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:16:16.764703 142908 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:16:16.765718 142908 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 133153, 56],"float32"),Tensor([2, 48, 133153, 56],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 288, 133153, 56],"float32"),Tensor([2, 48, 133153, 56],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000059GB memory on GPU 0, 71.913025GB memory has been allocated and available memory is only 7.271851GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:18:00.741652 143200 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:18:00.742493 143200 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 133153, 56],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 133153, 56],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 133153 but got size 56 for tensor number 1 in the list.

W0205 14:19:10.336166 143535 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:19:10.337338 143535 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 288, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:20:38.110592 143838 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:20:38.111496 143838 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0205 14:21:47.408006 144130 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:21:47.408980 144130 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0205 14:23:15.237429 144325 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:23:15.238652 144325 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0205 14:24:39.794456 144615 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:24:39.795647 144615 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 14, 532611],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 14, 532611],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 532611 but got size 14 for tensor number 1 in the list.

W0205 14:25:56.622778 144893 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:25:56.623970 144893 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 14, 532611],"float32"),Tensor([2, 32, 14, 532611],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 288, 14, 532611],"float32"),Tensor([2, 32, 14, 532611],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 70.135681GB memory has been allocated and available memory is only 9.049194GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:27:33.096263 145089 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:27:33.097240 145089 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 266306, 28],"float32"),Tensor([2, 32, 266306, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 288, 266306, 28],"float32"),Tensor([2, 32, 266306, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000059GB memory on GPU 0, 70.135681GB memory has been allocated and available memory is only 9.049194GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:29:11.803934 145381 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:29:11.804824 145381 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 266306, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 266306, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 266306 but got size 28 for tensor number 1 in the list.

W0205 14:30:21.563694 145752 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:30:21.565086 145752 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 266306, 28],"float32"),Tensor([2, 48, 266306, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 288, 266306, 28],"float32"),Tensor([2, 48, 266306, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000059GB memory on GPU 0, 71.913025GB memory has been allocated and available memory is only 7.271851GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:32:11.150291 145976 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:32:11.152541 145976 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 266306, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 266306, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 266306 but got size 28 for tensor number 1 in the list.

W0205 14:33:20.286223 146345 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:33:20.292788 146345 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 28, 266306],"float32"),Tensor([2, 32, 28, 266306],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 288, 28, 266306],"float32"),Tensor([2, 32, 28, 266306],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000059GB memory on GPU 0, 70.137634GB memory has been allocated and available memory is only 9.047241GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:35:02.712790 146670 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:35:02.713840 146670 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 28, 266306],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 28, 266306],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 266306 but got size 28 for tensor number 1 in the list.

W0205 14:36:22.100405 147656 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:36:22.101244 147656 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 28, 266306],"float32"),Tensor([2, 48, 28, 266306],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 288, 28, 266306],"float32"),Tensor([2, 48, 28, 266306],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000059GB memory on GPU 0, 71.913025GB memory has been allocated and available memory is only 7.271851GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:38:22.747893 148055 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:38:22.748843 148055 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 28, 266306],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 28, 266306],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 266306 but got size 28 for tensor number 1 in the list.

W0205 14:39:40.047263 149319 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:39:40.048463 149319 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 28, 28],"float32"),Tensor([114131, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 28, 28],"float32"),Tensor([114131, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 114131 for tensor number 1 in the list.

W0205 14:40:54.321316 150321 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:40:54.322463 150321 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 28, 28],"float32"),Tensor([171197, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 28, 28],"float32"),Tensor([171197, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 171197 for tensor number 1 in the list.

W0205 14:42:11.519626 150531 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:42:11.520825 150531 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 288, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:43:40.679198 150813 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:43:40.680058 150813 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 28, 28],"float32"),Tensor([2, 32, 2396746, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 28, 28],"float32"),Tensor([2, 32, 2396746, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 2396746 for tensor number 1 in the list.

W0205 14:44:50.176496 151090 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:44:50.177556 151090 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 28, 28],"float32"),Tensor([2, 32, 28, 2396746],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 28, 28],"float32"),Tensor([2, 32, 28, 2396746],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 2396746 for tensor number 1 in the list.

W0205 14:46:04.843008 151313 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:46:04.844147 151313 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 28, 28],"float32"),Tensor([2, 48, 1597831, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 28, 28],"float32"),Tensor([2, 48, 1597831, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 1597831 for tensor number 1 in the list.

W0205 14:47:27.713495 151590 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:47:27.714670 151590 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 28, 28],"float32"),Tensor([2, 48, 28, 1597831],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 28, 28],"float32"),Tensor([2, 48, 28, 1597831],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 1597831 for tensor number 1 in the list.

W0205 14:48:42.385267 151787 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:48:42.386546 151787 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 532611, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 532611, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 532611 but got size 14 for tensor number 1 in the list.

W0205 14:49:58.868003 152077 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:49:58.869516 152077 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 532611, 14],"float32"),Tensor([2, 32, 532611, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 288, 532611, 14],"float32"),Tensor([2, 32, 532611, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 70.135681GB memory has been allocated and available memory is only 9.049194GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:51:38.970201 152286 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:51:38.973749 152286 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 56, 133153],"float32"),Tensor([2, 48, 56, 133153],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 288, 56, 133153],"float32"),Tensor([2, 48, 56, 133153],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000059GB memory on GPU 0, 71.913025GB memory has been allocated and available memory is only 7.271851GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:53:14.500275 152644 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:53:14.501236 152644 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 56, 133153],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 56, 133153],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 133153 but got size 56 for tensor number 1 in the list.

W0205 14:54:23.502254 152937 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:54:23.503259 152937 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 56, 56],"float32"),Tensor([2, 48, 56, 798916],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 56, 56],"float32"),Tensor([2, 48, 56, 798916],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 56 but got size 798916 for tensor number 1 in the list.

W0205 14:55:36.270388 153134 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:55:36.271512 153134 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 56, 56],"float32"),Tensor([2, 48, 798916, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 56, 56],"float32"),Tensor([2, 48, 798916, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 56 but got size 798916 for tensor number 1 in the list.

W0205 14:56:50.946142 153411 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:56:50.947371 153411 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 56, 56],"float32"),Tensor([2, 684785, 56, 56],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 288, 56, 56],"float32"),Tensor([2, 684785, 56, 56],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000016GB memory on GPU 0, 66.612244GB memory has been allocated and available memory is only 12.572632GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 14:58:23.146385 153634 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:58:23.147257 153634 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 288, 56, 56],"float32"),Tensor([28533, 48, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 288, 56, 56],"float32"),Tensor([28533, 48, 56, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 28533 for tensor number 1 in the list.

W0205 14:59:34.345784 153923 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 14:59:34.346999 153923 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 15:01:06.159561 154221 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:01:06.160634 154221 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 15:02:31.890985 154500 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:02:31.891883 154500 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 192, 27, 27],"float32"),Tensor([2, 96, 27, 27],"float32"),Tensor([2, 64, 27, 27],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 192, 27, 27],"float32"),Tensor([2, 96, 27, 27],"float32"),Tensor([2, 64, 27, 27],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 15:03:58.873173 154735 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:03:58.874043 154735 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 72796 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:06:22.938257 155025 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:06:22.939260 155025 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 17515 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:09:52.681571 155513 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:09:52.682693 155513 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3, 4],"float32"),Tensor([2, 3, 715827883],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 3, 4],"float32"),Tensor([2, 3, 715827883],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 4 but got size 715827883 for tensor number 1 in the list.

W0205 15:11:26.109726 156212 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:11:26.110972 156212 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3, 4],"float32"),Tensor([2, 536870912, 4],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 3, 4],"float32"),Tensor([2, 536870912, 4],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 15:13:06.483448 156489 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:13:06.484452 156489 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3, 4],"float32"),Tensor([357913942, 3, 4],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 3, 4],"float32"),Tensor([357913942, 3, 4],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 357913942 for tensor number 1 in the list.

W0205 15:14:19.086810 156890 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:14:19.087946 156890 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3, 715827883],"float32"),Tensor([2, 3, 4],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 3, 715827883],"float32"),Tensor([2, 3, 4],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 715827883 but got size 4 for tensor number 1 in the list.

W0205 15:15:33.738482 157086 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:15:33.739835 157086 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3, 715827883],"float32"),Tensor([2, 3, 715827883],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 3, 715827883],"float32"),Tensor([2, 3, 715827883],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 61111 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:17:55.005237 157375 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:17:55.006289 157375 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3],"float64"),Tensor([2, 1073741825],"float64"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 3],"float64"),Tensor([2, 1073741825],"float64"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 15:19:02.997399 157771 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:19:02.998550 157771 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 3],"float64"),], )
[torch error] paddle.concat(list[Tensor([2, 3],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 3],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 3 but got size 1073741825 for tensor number 1 in the list.

W0205 15:19:53.481817 157975 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:19:53.482995 157975 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 3],"float64"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 3],"float64"),Tensor([2, 1073741825],"float64"),Tensor([2, 3],"float64"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 15:21:07.262290 158181 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:21:07.263187 158181 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3],"float64"),Tensor([2, 3],"float64"),Tensor([2, 1073741825],"float64"),], )
[torch error] paddle.concat(list[Tensor([2, 3],"float64"),Tensor([2, 3],"float64"),Tensor([2, 1073741825],"float64"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 3 but got size 1073741825 for tensor number 2 in the list.

W0205 15:21:56.093554 158453 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:21:56.094652 158453 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3],"float64"),Tensor([2, 3],"float64"),Tensor([2, 1073741825],"float64"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 3],"float64"),Tensor([2, 3],"float64"),Tensor([2, 1073741825],"float64"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 15:23:02.101172 158565 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:23:02.102088 158565 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3],"float64"),Tensor([2, 3],"float64"),Tensor([715827883, 3],"float64"),], )
[paddle error] paddle.concat(list[Tensor([2, 3],"float64"),Tensor([2, 3],"float64"),Tensor([715827883, 3],"float64"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 15:24:05.067617 158761 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:24:05.068490 158761 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3],"float64"),Tensor([2, 3],"float64"),Tensor([715827883, 3],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 3],"float64"),Tensor([2, 3],"float64"),Tensor([715827883, 3],"float64"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 715827883 for tensor number 2 in the list.

W0205 15:24:52.109553 159075 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:24:52.110719 159075 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3],"float64"),Tensor([715827883, 3],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 3],"float64"),Tensor([715827883, 3],"float64"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 715827883 for tensor number 1 in the list.

W0205 15:25:49.277808 159177 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:25:49.278965 159177 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3],"float64"),Tensor([715827883, 3],"float64"),Tensor([2, 3],"float64"),], )
[paddle error] paddle.concat(list[Tensor([2, 3],"float64"),Tensor([715827883, 3],"float64"),Tensor([2, 3],"float64"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 15:26:56.191728 159370 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:26:56.192608 159370 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3],"float64"),Tensor([715827883, 3],"float64"),Tensor([2, 3],"float64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 3],"float64"),Tensor([715827883, 3],"float64"),Tensor([2, 3],"float64"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 715827883 for tensor number 1 in the list.

W0205 15:27:51.613700 159579 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:27:51.614957 159579 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3176751, 26, 26],"float32"),Tensor([2, 128, 26, 26],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 3176751, 26, 26],"float32"),Tensor([2, 128, 26, 26],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 15:29:30.512063 159774 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:29:30.514183 159774 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3176751, 26, 26],"float32"),Tensor([2, 192, 26, 26],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 3176751, 26, 26],"float32"),Tensor([2, 192, 26, 26],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 15:30:58.928316 160065 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:30:58.929194 160065 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3176751, 26, 26],"float32"),Tensor([2, 256, 26, 26],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 3176751, 26, 26],"float32"),Tensor([2, 256, 26, 26],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 15:32:25.603988 160405 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:32:25.604820 160405 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3176751, 26, 26],"float32"),Tensor([2, 3176751, 26, 26],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 3176751, 26, 26],"float32"),Tensor([2, 3176751, 26, 26],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 106705 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:34:34.037369 160716 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:34:34.038426 160716 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 32, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 15:36:12.332023 161219 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:36:12.333025 161219 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 32, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0205 15:37:27.487785 161497 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:37:27.489061 161497 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 32, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0205 15:38:42.578354 161711 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:38:42.579368 161711 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 32, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0205 15:40:04.088513 162037 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:40:04.089792 162037 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 14, 4793491],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 32, 14, 4793491],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 4793491 but got size 14 for tensor number 1 in the list.

W0205 15:41:29.592964 162320 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:41:29.594211 162320 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 14, 4793491],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 32, 14, 4793491],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 3151 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 15:43:52.584667 162673 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:43:52.585779 162673 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 32, 128],"float16"),Tensor([1048576, 32, 1, 128],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 32, 32, 128],"float16"),Tensor([1048576, 32, 1, 128],"float16"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 2 but got size 1048576 for tensor number 1 in the list.

W0205 15:45:27.882597 163587 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:45:27.883630 163587 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 32, 128],"float16"),Tensor([2, 16777216, 1, 128],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 32, 32, 128],"float16"),Tensor([2, 16777216, 1, 128],"float16"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 32 but got size 16777216 for tensor number 1 in the list.

W0205 15:47:05.375339   566 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:47:05.376559   566 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 32, 128],"float16"),Tensor([2, 32, 1, 67108864],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 32, 32, 128],"float16"),Tensor([2, 32, 1, 67108864],"float16"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 128 but got size 67108864 for tensor number 1 in the list.

W0205 15:48:36.063030  1036 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:48:36.064127  1036 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 32, 128],"float16"),Tensor([2, 32, 524288, 128],"float16"),], axis=2, )
[Pass] paddle.concat(list[Tensor([2, 32, 32, 128],"float16"),Tensor([2, 32, 524288, 128],"float16"),], axis=2, )

W0205 15:50:10.961365  1472 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:50:10.962404  1472 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 32, 2097152],"float16"),Tensor([2, 32, 1, 128],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 32, 32, 2097152],"float16"),Tensor([2, 32, 1, 128],"float16"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 2097152 but got size 128 for tensor number 1 in the list.

W0205 15:59:13.758738  4025 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 15:59:13.759835  4025 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 32, 2097152],"float16"),Tensor([2, 32, 1, 2097152],"float16"),], axis=2, )
[Pass] paddle.concat(list[Tensor([2, 32, 32, 2097152],"float16"),Tensor([2, 32, 1, 2097152],"float16"),], axis=2, )

W0205 16:00:52.241819  4551 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:00:52.242729  4551 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 4793491, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 32, 4793491, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 4793491 but got size 14 for tensor number 1 in the list.

W0205 16:09:56.437563  7076 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:09:56.438652  7076 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 4793491, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 32, 4793491, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 140975 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:12:11.556560  7482 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:12:11.566474  7482 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 524288, 128],"float16"),Tensor([2, 32, 1, 128],"float16"),], axis=2, )
[Pass] paddle.concat(list[Tensor([2, 32, 524288, 128],"float16"),Tensor([2, 32, 1, 128],"float16"),], axis=2, )

W0205 16:13:47.415897  8283 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:13:47.416803  8283 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 32, 524288, 128],"float16"),Tensor([2, 32, 524288, 128],"float16"),], axis=2, )
[paddle error] paddle.concat(list[Tensor([2, 32, 524288, 128],"float16"),Tensor([2, 32, 524288, 128],"float16"),], axis=2, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000000GB memory on GPU 0, 74.575134GB memory has been allocated and available memory is only 4.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 16:24:34.890496 10900 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:24:34.892176 10900 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 1342178, 5],"float32"),Tensor([2, 192, 1342178, 5],"float32"),Tensor([2, 768, 1342178, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 1342178, 5],"float32"),Tensor([2, 192, 1342178, 5],"float32"),Tensor([2, 768, 1342178, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 38.40 GiB. GPU 0 has a total capacity of 79.18 GiB of which 19.60 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 133062 has 26.59 GiB memory in use. Of the allocated memory 25.60 GiB is allocated by PyTorch, and 3.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:29:13.527935 11731 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:29:13.528904 11731 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 1342178, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 1342178, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1342178 but got size 5 for tensor number 1 in the list.

W0205 16:30:41.375108 13049 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:30:41.376219 13049 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 1342178, 5],"float32"),Tensor([2, 768, 1342178, 5],"float32"),Tensor([2, 768, 1342178, 5],"float32"),Tensor([2, 192, 1342178, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 1342178, 5],"float32"),Tensor([2, 768, 1342178, 5],"float32"),Tensor([2, 768, 1342178, 5],"float32"),Tensor([2, 192, 1342178, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 38.40 GiB. GPU 0 has a total capacity of 79.18 GiB of which 29.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 97692 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 16:34:19.635877 13480 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:34:19.638535 13480 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 1342178, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 1342178, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1342178 but got size 5 for tensor number 1 in the list.

W0205 16:35:45.868746 14459 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:35:45.869948 14459 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 320, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 16:37:20.768962 14858 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:37:20.769819 14858 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0205 16:38:30.659572 15286 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:38:30.660462 15286 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0205 16:39:45.216661 15591 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:39:45.217630 15591 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0205 16:41:00.432209 15970 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:41:00.433152 15970 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 14, 479350],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 14, 479350],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 479350 but got size 14 for tensor number 1 in the list.

W0205 16:42:26.255810 16276 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:42:26.257035 16276 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 14, 479350],"float32"),Tensor([2, 32, 14, 479350],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 320, 14, 479350],"float32"),Tensor([2, 32, 14, 479350],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000032GB memory on GPU 0, 69.780212GB memory has been allocated and available memory is only 9.404663GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 16:44:04.266422 16689 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:44:04.267364 16689 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 239675, 28],"float32"),Tensor([2, 32, 239675, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 320, 239675, 28],"float32"),Tensor([2, 32, 239675, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000032GB memory on GPU 0, 69.780212GB memory has been allocated and available memory is only 9.404663GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 16:45:44.478600 17117 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:45:44.479487 17117 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 239675, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 239675, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 239675 but got size 28 for tensor number 1 in the list.

W0205 16:46:55.007213 17635 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:46:55.008523 17635 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 28, 239675],"float32"),Tensor([2, 32, 28, 239675],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 320, 28, 239675],"float32"),Tensor([2, 32, 28, 239675],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000032GB memory on GPU 0, 69.780212GB memory has been allocated and available memory is only 9.404663GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 16:48:38.154328 17949 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:48:38.155304 17949 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 28, 239675],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 28, 239675],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 239675 but got size 28 for tensor number 1 in the list.

W0205 16:49:57.332775 18382 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:49:57.333793 18382 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 28, 28],"float32"),Tensor([171197, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 28, 28],"float32"),Tensor([171197, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 171197 for tensor number 1 in the list.

W0205 16:51:12.428470 18773 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:51:12.429654 18773 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 320, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 16:52:51.321943 19178 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:52:51.322925 19178 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 28, 28],"float32"),Tensor([2, 32, 2396746, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 28, 28],"float32"),Tensor([2, 32, 2396746, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 2396746 for tensor number 1 in the list.

W0205 16:54:08.597290 19603 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:54:08.598508 19603 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 28, 28],"float32"),Tensor([2, 32, 28, 2396746],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 28, 28],"float32"),Tensor([2, 32, 28, 2396746],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 2396746 for tensor number 1 in the list.

W0205 16:55:30.585232 19989 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:55:30.586462 19989 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 479350, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 479350, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 479350 but got size 14 for tensor number 1 in the list.

W0205 16:56:56.618700 20320 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:56:56.626207 20320 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 479350, 14],"float32"),Tensor([2, 32, 479350, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 320, 479350, 14],"float32"),Tensor([2, 32, 479350, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000032GB memory on GPU 0, 69.780212GB memory has been allocated and available memory is only 9.404663GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 16:58:33.700219 20752 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 16:58:33.701359 20752 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 1342178],"float32"),Tensor([2, 192, 5, 1342178],"float32"),Tensor([2, 768, 5, 1342178],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 5, 1342178],"float32"),Tensor([2, 192, 5, 1342178],"float32"),Tensor([2, 768, 5, 1342178],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 38.40 GiB. GPU 0 has a total capacity of 79.18 GiB of which 19.60 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 57206 has 26.59 GiB memory in use. Of the allocated memory 25.60 GiB is allocated by PyTorch, and 3.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:02:52.815521 21185 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:02:52.816720 21185 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 1342178],"float32"),Tensor([2, 192, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 5, 1342178],"float32"),Tensor([2, 192, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1342178 but got size 5 for tensor number 1 in the list.

W0205 17:04:19.752085 22394 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:04:19.753278 22394 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 1342178],"float32"),Tensor([2, 768, 5, 1342178],"float32"),Tensor([2, 768, 5, 1342178],"float32"),Tensor([2, 192, 5, 1342178],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 5, 1342178],"float32"),Tensor([2, 768, 5, 1342178],"float32"),Tensor([2, 768, 5, 1342178],"float32"),Tensor([2, 192, 5, 1342178],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 38.40 GiB. GPU 0 has a total capacity of 79.18 GiB of which 29.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 1562 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 1.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:08:03.625514 22819 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:08:03.626823 22819 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 1342178],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 5, 1342178],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1342178 but got size 5 for tensor number 1 in the list.

W0205 17:09:31.600044 23769 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:09:31.601243 23769 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 192, 2236963, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 192, 2236963, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5 but got size 2236963 for tensor number 1 in the list.

W0205 17:10:45.307484 24185 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:10:45.308424 24185 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 192, 5, 2236963],"float32"),Tensor([2, 768, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 192, 5, 2236963],"float32"),Tensor([2, 768, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5 but got size 2236963 for tensor number 1 in the list.

W0205 17:11:59.618238 24556 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:11:59.619238 24556 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),Tensor([2, 768, 5, 559241],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),Tensor([2, 768, 5, 559241],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5 but got size 559241 for tensor number 2 in the list.

W0205 17:13:21.223773 24870 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:13:21.225001 24870 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),Tensor([2, 768, 559241, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),Tensor([2, 768, 559241, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5 but got size 559241 for tensor number 2 in the list.

W0205 17:14:37.438472 25264 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:14:37.440122 25264 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),Tensor([2, 85899346, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),Tensor([2, 85899346, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 17:16:13.435359 25582 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:16:13.436162 25582 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),Tensor([223697, 768, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),Tensor([223697, 768, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 223697 for tensor number 2 in the list.

W0205 17:17:32.173607 25962 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:17:32.174688 25962 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 192, 2236963, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 192, 2236963, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5 but got size 2236963 for tensor number 3 in the list.

W0205 17:18:52.088713 26486 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:18:52.089926 26486 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 192, 5, 2236963],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 192, 5, 2236963],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5 but got size 2236963 for tensor number 3 in the list.

W0205 17:20:08.197752 26962 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:20:08.198779 26962 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 85899346, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 85899346, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 17:21:45.448802 27260 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:21:45.449672 27260 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([894785, 192, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([894785, 192, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 894785 for tensor number 3 in the list.

W0205 17:23:01.652259 27764 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:23:01.653303 27764 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 768, 5, 559241],"float32"),Tensor([2, 192, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 768, 5, 559241],"float32"),Tensor([2, 192, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5 but got size 559241 for tensor number 2 in the list.

W0205 17:24:24.443222 28080 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:24:24.444777 28080 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 768, 559241, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 768, 559241, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5 but got size 559241 for tensor number 2 in the list.

W0205 17:25:41.364878 28478 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:25:41.365971 28478 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 85899346, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 85899346, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 17:27:17.439095 28896 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:27:17.440080 28896 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([223697, 768, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([223697, 768, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 223697 for tensor number 2 in the list.

W0205 17:28:29.857833 29367 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:28:29.858963 29367 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 768, 5, 559241],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 768, 5, 559241],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5 but got size 559241 for tensor number 1 in the list.

W0205 17:29:51.069758 29688 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:29:51.071552 29688 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 768, 559241, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 768, 559241, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5 but got size 559241 for tensor number 1 in the list.

W0205 17:31:13.422323 30085 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:31:13.423449 30085 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 85899346, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 85899346, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 17:32:50.542505 30477 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:32:50.543397 30477 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 85899346, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([2, 85899346, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 17:34:23.714078 30888 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:34:23.715157 30888 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([223697, 768, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([223697, 768, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 223697 for tensor number 1 in the list.

W0205 17:35:39.187705 31290 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:35:39.188912 31290 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([894785, 192, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 320, 5, 5],"float32"),Tensor([894785, 192, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 894785 for tensor number 1 in the list.

W0205 17:36:58.466665 31711 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:36:58.467880 31711 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 33554432, 8, 8],"float32"),Tensor([2, 2, 8, 8],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([2, 33554432, 8, 8],"float32"),Tensor([2, 2, 8, 8],"float32"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 3. Expected size 33554432 but got size 2 for tensor number 1 in the list.

W0205 17:38:22.054761 32010 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:38:22.055800 32010 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 33554432, 8, 8],"float32"),Tensor([2, 33554432, 8, 8],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([2, 33554432, 8, 8],"float32"),Tensor([2, 33554432, 8, 8],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 154440 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 17:40:51.110019 32411 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:40:51.111043 32411 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 336, 114131, 56],"float32"),Tensor([2, 48, 114131, 56],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 336, 114131, 56],"float32"),Tensor([2, 48, 114131, 56],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000039GB memory on GPU 0, 71.151306GB memory has been allocated and available memory is only 8.033569GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 17:42:37.604852 33103 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:42:37.605710 33103 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 336, 114131, 56],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 336, 114131, 56],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 114131 but got size 56 for tensor number 1 in the list.

W0205 17:43:48.529325 33554 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:43:48.530418 33554 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 336, 228262, 28],"float32"),Tensor([2, 48, 228262, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 336, 228262, 28],"float32"),Tensor([2, 48, 228262, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000039GB memory on GPU 0, 71.151306GB memory has been allocated and available memory is only 8.033569GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 17:45:31.056485 33946 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:45:31.057415 33946 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 336, 228262, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 336, 228262, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 228262 but got size 28 for tensor number 1 in the list.

W0205 17:46:40.698657 34372 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:46:40.699534 34372 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 336, 28, 228262],"float32"),Tensor([2, 48, 28, 228262],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 336, 28, 228262],"float32"),Tensor([2, 48, 28, 228262],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000039GB memory on GPU 0, 71.151306GB memory has been allocated and available memory is only 8.033569GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 17:48:21.771500 34761 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:48:21.772347 34761 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 336, 28, 228262],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 336, 28, 228262],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 228262 but got size 28 for tensor number 1 in the list.

W0205 17:49:38.085484 35164 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:49:38.086299 35164 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 336, 28, 28],"float32"),Tensor([114131, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 336, 28, 28],"float32"),Tensor([114131, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 114131 for tensor number 1 in the list.

W0205 17:50:53.542342 35483 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:50:53.543411 35483 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 336, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 336, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.604431GB memory has been allocated and available memory is only 12.580444GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 17:52:28.763985 35864 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:52:28.764919 35864 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 336, 28, 28],"float32"),Tensor([2, 48, 1597831, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 336, 28, 28],"float32"),Tensor([2, 48, 1597831, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 1597831 for tensor number 1 in the list.

W0205 17:53:41.327906 36271 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:53:41.329057 36271 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 336, 28, 28],"float32"),Tensor([2, 48, 28, 1597831],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 336, 28, 28],"float32"),Tensor([2, 48, 28, 1597831],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 1597831 for tensor number 1 in the list.

W0205 17:54:57.389053 36663 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:54:57.390101 36663 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 336, 56, 114131],"float32"),Tensor([2, 48, 56, 114131],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 336, 56, 114131],"float32"),Tensor([2, 48, 56, 114131],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000039GB memory on GPU 0, 71.151306GB memory has been allocated and available memory is only 8.033569GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 17:56:52.749119 36960 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:56:52.750166 36960 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 336, 56, 114131],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 336, 56, 114131],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 114131 but got size 56 for tensor number 1 in the list.

W0205 17:58:08.748601 37485 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:58:08.749547 37485 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 336, 56, 56],"float32"),Tensor([2, 48, 56, 798916],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 336, 56, 56],"float32"),Tensor([2, 48, 56, 798916],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 56 but got size 798916 for tensor number 1 in the list.

W0205 17:59:25.520372 37791 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 17:59:25.521469 37791 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 336, 56, 56],"float32"),Tensor([2, 48, 798916, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 336, 56, 56],"float32"),Tensor([2, 48, 798916, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 56 but got size 798916 for tensor number 1 in the list.

W0205 18:00:41.761452 38163 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:00:41.762552 38163 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 336, 56, 56],"float32"),Tensor([2, 684785, 56, 56],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 336, 56, 56],"float32"),Tensor([2, 684785, 56, 56],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000016GB memory on GPU 0, 66.616150GB memory has been allocated and available memory is only 12.568726GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 18:02:12.975226 38556 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:02:12.976296 38556 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 336, 56, 56],"float32"),Tensor([28533, 48, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 336, 56, 56],"float32"),Tensor([28533, 48, 56, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 28533 for tensor number 1 in the list.

W0205 18:03:26.370071 38867 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:03:26.371291 38867 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3435974, 25, 25],"float32"),Tensor([2, 3435974, 25, 25],"float32"),Tensor([2, 3435974, 25, 25],"float32"),Tensor([2, 3435974, 25, 25],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 3435974, 25, 25],"float32"),Tensor([2, 3435974, 25, 25],"float32"),Tensor([2, 3435974, 25, 25],"float32"),Tensor([2, 3435974, 25, 25],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 85436 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:06:39.220386 39263 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:06:39.221532 39263 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3435974, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 32, 25, 25],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 3435974, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 32, 25, 25],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 18:08:12.266858 40243 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:08:12.267702 40243 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 3435974, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 3435974, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 18:09:41.646481 40556 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:09:41.647362 40556 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 352, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 352, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 18:11:07.351032 41359 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:11:07.352490 41359 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 352, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 352, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0205 18:12:18.488168 42199 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:12:18.489221 42199 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 352, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 352, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0205 18:13:38.562310 42901 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:13:38.563308 42901 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 352, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 352, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0205 18:14:53.801498 43712 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:14:53.802515 43712 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 352, 14, 435772],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 352, 14, 435772],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 435772 but got size 14 for tensor number 1 in the list.

W0205 18:16:24.664852 44181 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:16:24.666253 44181 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 352, 14, 435772],"float32"),Tensor([2, 32, 14, 435772],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 352, 14, 435772],"float32"),Tensor([2, 32, 14, 435772],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000006GB memory on GPU 0, 69.487244GB memory has been allocated and available memory is only 9.697632GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 18:18:02.711812 44616 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:18:02.714040 44616 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 352, 217886, 28],"float32"),Tensor([2, 32, 217886, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 352, 217886, 28],"float32"),Tensor([2, 32, 217886, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000006GB memory on GPU 0, 69.487244GB memory has been allocated and available memory is only 9.697632GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 18:19:39.886543 45159 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:19:39.889009 45159 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 352, 217886, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 352, 217886, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 217886 but got size 28 for tensor number 1 in the list.

W0205 18:20:54.239001 45602 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:20:54.240090 45602 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 352, 28, 217886],"float32"),Tensor([2, 32, 28, 217886],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 352, 28, 217886],"float32"),Tensor([2, 32, 28, 217886],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000006GB memory on GPU 0, 69.487244GB memory has been allocated and available memory is only 9.697632GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 18:22:28.555402 45914 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:22:28.557725 45914 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 352, 28, 217886],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 352, 28, 217886],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 217886 but got size 28 for tensor number 1 in the list.

W0205 18:23:42.653071 46345 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:23:42.654060 46345 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 352, 28, 28],"float32"),Tensor([171197, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 352, 28, 28],"float32"),Tensor([171197, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 171197 for tensor number 1 in the list.

W0205 18:25:04.633025 46750 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:25:04.634202 46750 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 352, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 352, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.604431GB memory has been allocated and available memory is only 12.580444GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 18:26:44.446635 47166 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:26:44.447484 47166 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 352, 28, 28],"float32"),Tensor([2, 32, 2396746, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 352, 28, 28],"float32"),Tensor([2, 32, 2396746, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 2396746 for tensor number 1 in the list.

W0205 18:27:54.707746 47604 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:27:54.708990 47604 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 352, 28, 28],"float32"),Tensor([2, 32, 28, 2396746],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 352, 28, 28],"float32"),Tensor([2, 32, 28, 2396746],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 2396746 for tensor number 1 in the list.

W0205 18:29:10.176268 47931 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:29:10.177418 47931 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 352, 435772, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 352, 435772, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 435772 but got size 14 for tensor number 1 in the list.

W0205 18:30:36.033113 48317 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:30:36.034673 48317 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 352, 435772, 14],"float32"),Tensor([2, 32, 435772, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 352, 435772, 14],"float32"),Tensor([2, 32, 435772, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000006GB memory on GPU 0, 69.487244GB memory has been allocated and available memory is only 9.697632GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 18:32:13.413956 48715 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:32:13.416329 48715 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 352, 7, 7],"float32"),Tensor([2, 352, 7, 871544],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 352, 7, 7],"float32"),Tensor([2, 352, 7, 871544],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 871544 for tensor number 1 in the list.

W0205 18:33:25.108830 49142 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:33:25.110108 49142 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 352, 7, 7],"float32"),Tensor([2, 352, 871544, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 352, 7, 7],"float32"),Tensor([2, 352, 871544, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 871544 for tensor number 1 in the list.

W0205 18:34:47.547292 49565 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:34:47.548777 49565 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 352, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 352, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 18:36:21.384277 49887 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:36:21.385142 49887 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 352, 7, 7],"float32"),Tensor([249013, 352, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 352, 7, 7],"float32"),Tensor([249013, 352, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 249013 for tensor number 1 in the list.

W0205 18:37:30.720798 50307 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:37:30.721877 50307 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 352, 7, 871544],"float32"),Tensor([2, 352, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 352, 7, 871544],"float32"),Tensor([2, 352, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 871544 but got size 7 for tensor number 1 in the list.

W0205 18:38:54.977622 50721 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:38:54.978497 50721 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 352, 7, 871544],"float32"),Tensor([2, 352, 7, 871544],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 352, 7, 871544],"float32"),Tensor([2, 352, 7, 871544],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 93125 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:41:24.608311 51036 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:41:24.609404 51036 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 352, 871544, 7],"float32"),Tensor([2, 352, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 352, 871544, 7],"float32"),Tensor([2, 352, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 871544 but got size 7 for tensor number 1 in the list.

W0205 18:43:00.920109 51752 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:43:00.923085 51752 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 352, 871544, 7],"float32"),Tensor([2, 352, 871544, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 352, 871544, 7],"float32"),Tensor([2, 352, 871544, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 121574 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:45:19.781273 52259 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:45:19.782372 52259 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 1118482, 5],"float32"),Tensor([2, 384, 1118482, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 1118482, 5],"float32"),Tensor([2, 384, 1118482, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 65886 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 18:47:46.620664 52842 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:47:46.621791 52842 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 1118482, 5],"float32"),Tensor([2, 384, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 1118482, 5],"float32"),Tensor([2, 384, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1118482 but got size 5 for tensor number 1 in the list.

W0205 18:49:05.024444 53532 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:49:05.025621 53532 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 12, 12],"float32"),Tensor([2, 14913081, 12, 12],"float32"),Tensor([2, 288, 12, 12],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 384, 12, 12],"float32"),Tensor([2, 14913081, 12, 12],"float32"),Tensor([2, 288, 12, 12],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 18:50:42.293632 53931 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:50:42.294517 53931 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 12, 12],"float32"),Tensor([2, 96, 12, 12],"float32"),Tensor([103564, 288, 12, 12],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 12, 12],"float32"),Tensor([2, 96, 12, 12],"float32"),Tensor([103564, 288, 12, 12],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 103564 for tensor number 2 in the list.

W0205 18:52:01.128810 54336 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:52:01.130055 54336 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 12, 12],"float32"),Tensor([2, 96, 12, 12],"float32"),Tensor([2, 14913081, 12, 12],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 384, 12, 12],"float32"),Tensor([2, 96, 12, 12],"float32"),Tensor([2, 14913081, 12, 12],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 18:53:38.246642 54749 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:53:38.247514 54749 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 12, 12],"float32"),Tensor([2, 96, 12, 12],"float32"),Tensor([2, 288, 12, 621379],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 12, 12],"float32"),Tensor([2, 96, 12, 12],"float32"),Tensor([2, 288, 12, 621379],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 12 but got size 621379 for tensor number 2 in the list.

W0205 18:54:52.652833 55181 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:54:52.654099 55181 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 12, 12],"float32"),Tensor([2, 96, 12, 12],"float32"),Tensor([2, 288, 621379, 12],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 12, 12],"float32"),Tensor([2, 96, 12, 12],"float32"),Tensor([2, 288, 621379, 12],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 12 but got size 621379 for tensor number 2 in the list.

W0205 18:56:13.353819 55514 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:56:13.355062 55514 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 12, 12],"float32"),Tensor([2, 96, 12, 1864136],"float32"),Tensor([2, 288, 12, 12],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 12, 12],"float32"),Tensor([2, 96, 12, 1864136],"float32"),Tensor([2, 288, 12, 12],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 12 but got size 1864136 for tensor number 1 in the list.

W0205 18:57:28.360569 55921 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:57:28.361519 55921 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 12, 12],"float32"),Tensor([2, 96, 1864136, 12],"float32"),Tensor([2, 288, 12, 12],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 12, 12],"float32"),Tensor([2, 96, 1864136, 12],"float32"),Tensor([2, 288, 12, 12],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 12 but got size 1864136 for tensor number 1 in the list.

W0205 18:58:43.758682 56327 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 18:58:43.759616 56327 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 12, 12],"float32"),Tensor([310690, 96, 12, 12],"float32"),Tensor([2, 288, 12, 12],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 12, 12],"float32"),Tensor([310690, 96, 12, 12],"float32"),Tensor([2, 288, 12, 12],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 310690 for tensor number 1 in the list.

W0205 19:00:03.762930 56640 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:00:03.764082 56640 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 12, 466034],"float32"),Tensor([2, 96, 12, 12],"float32"),Tensor([2, 288, 12, 12],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 12, 466034],"float32"),Tensor([2, 96, 12, 12],"float32"),Tensor([2, 288, 12, 12],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 466034 but got size 12 for tensor number 1 in the list.

W0205 19:01:27.754367 57044 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:01:27.755334 57044 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 12, 466034],"float32"),Tensor([2, 96, 12, 466034],"float32"),Tensor([2, 288, 12, 466034],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 12, 466034],"float32"),Tensor([2, 96, 12, 466034],"float32"),Tensor([2, 288, 12, 466034],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 163716 has 33.00 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 5.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:03:44.407061 57446 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:03:44.409574 57446 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 384, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 19:05:16.385342 58039 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:05:16.386215 58039 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0205 19:06:26.024948 58436 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:06:26.025982 58436 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0205 19:07:42.476931 58834 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:07:42.478016 58834 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 3195661 for tensor number 1 in the list.

W0205 19:08:58.459928 59135 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:08:58.460914 59135 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 3195661 for tensor number 1 in the list.

W0205 19:10:16.787514 59532 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:10:16.788779 59532 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 456523 for tensor number 1 in the list.

W0205 19:11:43.694247 59860 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:11:43.695286 59860 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0205 19:13:02.920058 60278 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:13:02.921308 60278 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 14, 399458],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 14, 399458],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 399458 but got size 14 for tensor number 1 in the list.

W0205 19:14:23.235783 60668 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:14:23.245044 60668 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 14, 399458],"float32"),Tensor([2, 32, 14, 399458],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 384, 14, 399458],"float32"),Tensor([2, 32, 14, 399458],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000019GB memory on GPU 0, 69.245056GB memory has been allocated and available memory is only 9.939819GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 19:16:02.695492 60990 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:16:02.696305 60990 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 14, 399458],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 14, 399458],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 399458 but got size 14 for tensor number 1 in the list.

W0205 19:17:16.985749 61528 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:17:16.986649 61528 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 14, 399458],"float32"),Tensor([2, 48, 14, 399458],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 384, 14, 399458],"float32"),Tensor([2, 48, 14, 399458],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000019GB memory on GPU 0, 70.580994GB memory has been allocated and available memory is only 8.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 19:19:00.646955 61851 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:19:00.649382 61851 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 199729, 28],"float32"),Tensor([2, 32, 199729, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 384, 199729, 28],"float32"),Tensor([2, 32, 199729, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000019GB memory on GPU 0, 69.245056GB memory has been allocated and available memory is only 9.939819GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 19:20:35.034456 62296 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:20:35.035318 62296 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 199729, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 199729, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 199729 but got size 28 for tensor number 1 in the list.

W0205 19:21:49.375787 62820 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:21:49.376610 62820 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 199729, 28],"float32"),Tensor([2, 48, 199729, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 384, 199729, 28],"float32"),Tensor([2, 48, 199729, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000019GB memory on GPU 0, 70.580994GB memory has been allocated and available memory is only 8.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 19:23:29.454859 63153 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:23:29.455731 63153 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 199729, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 199729, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 199729 but got size 28 for tensor number 1 in the list.

W0205 19:24:42.788158 63575 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:24:42.788930 63575 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 28, 199729],"float32"),Tensor([2, 32, 28, 199729],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 384, 28, 199729],"float32"),Tensor([2, 32, 28, 199729],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000019GB memory on GPU 0, 69.245056GB memory has been allocated and available memory is only 9.939819GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 19:26:22.210260 63967 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:26:22.211163 63967 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 28, 199729],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 28, 199729],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 199729 but got size 28 for tensor number 1 in the list.

W0205 19:27:35.465698 64383 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:27:35.467011 64383 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 28, 199729],"float32"),Tensor([2, 48, 28, 199729],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 384, 28, 199729],"float32"),Tensor([2, 48, 28, 199729],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000019GB memory on GPU 0, 70.580994GB memory has been allocated and available memory is only 8.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 19:29:15.734644 64786 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:29:15.735592 64786 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 28, 199729],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 28, 199729],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 199729 but got size 28 for tensor number 1 in the list.

W0205 19:30:30.066819 65224 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:30:30.067579 65224 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 28, 28],"float32"),Tensor([114131, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 28, 28],"float32"),Tensor([114131, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 114131 for tensor number 1 in the list.

W0205 19:31:49.031667 65628 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:31:49.032826 65628 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 28, 28],"float32"),Tensor([171197, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 28, 28],"float32"),Tensor([171197, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 171197 for tensor number 1 in the list.

W0205 19:33:09.221365 65958 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:33:09.234515 65958 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 384, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.604431GB memory has been allocated and available memory is only 12.580444GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 19:34:53.356783 66357 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:34:53.357637 66357 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 28, 28],"float32"),Tensor([2, 32, 2396746, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 28, 28],"float32"),Tensor([2, 32, 2396746, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 2396746 for tensor number 1 in the list.

W0205 19:36:15.982445 66798 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:36:15.983597 66798 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 28, 28],"float32"),Tensor([2, 32, 28, 2396746],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 28, 28],"float32"),Tensor([2, 32, 28, 2396746],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 2396746 for tensor number 1 in the list.

W0205 19:37:43.110918 67221 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:37:43.112151 67221 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 28, 28],"float32"),Tensor([2, 48, 1597831, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 28, 28],"float32"),Tensor([2, 48, 1597831, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 1597831 for tensor number 1 in the list.

W0205 19:39:09.296015 67643 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:39:09.297606 67643 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 28, 28],"float32"),Tensor([2, 48, 28, 1597831],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 28, 28],"float32"),Tensor([2, 48, 28, 1597831],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 1597831 for tensor number 1 in the list.

W0205 19:40:28.881225 68068 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:40:28.882431 68068 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 399458, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 399458, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 399458 but got size 14 for tensor number 1 in the list.

W0205 19:41:46.918988 68477 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:41:46.920233 68477 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 399458, 14],"float32"),Tensor([2, 32, 399458, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 384, 399458, 14],"float32"),Tensor([2, 32, 399458, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000019GB memory on GPU 0, 69.245056GB memory has been allocated and available memory is only 9.939819GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 19:43:26.298924 68797 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:43:26.299793 68797 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 399458, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 399458, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 399458 but got size 14 for tensor number 1 in the list.

W0205 19:44:34.711681 69240 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:44:34.713280 69240 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 399458, 14],"float32"),Tensor([2, 48, 399458, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 384, 399458, 14],"float32"),Tensor([2, 48, 399458, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000019GB memory on GPU 0, 70.580994GB memory has been allocated and available memory is only 8.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 19:46:13.363669 69630 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:46:13.364567 69630 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 466034, 12],"float32"),Tensor([2, 96, 12, 12],"float32"),Tensor([2, 288, 12, 12],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 466034, 12],"float32"),Tensor([2, 96, 12, 12],"float32"),Tensor([2, 288, 12, 12],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 466034 but got size 12 for tensor number 1 in the list.

W0205 19:47:26.118044 70061 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:47:26.118991 70061 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 466034, 12],"float32"),Tensor([2, 96, 466034, 12],"float32"),Tensor([2, 288, 466034, 12],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 466034, 12],"float32"),Tensor([2, 96, 466034, 12],"float32"),Tensor([2, 288, 466034, 12],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 32797 has 33.00 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 5.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:49:47.493850 70372 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:49:47.494946 70372 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 5, 1118482],"float32"),Tensor([2, 384, 5, 1118482],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 5, 1118482],"float32"),Tensor([2, 384, 5, 1118482],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 143001 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 19:52:06.407207 71067 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:52:06.408242 71067 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 5, 1118482],"float32"),Tensor([2, 384, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 5, 1118482],"float32"),Tensor([2, 384, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1118482 but got size 5 for tensor number 1 in the list.

W0205 19:53:28.987022 71748 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:53:28.988222 71748 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 5, 5],"float32"),Tensor([2, 384, 1118482, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 5, 5],"float32"),Tensor([2, 384, 1118482, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5 but got size 1118482 for tensor number 1 in the list.

W0205 19:54:48.487159 72151 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:54:48.488366 72151 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 5, 5],"float32"),Tensor([2, 384, 5, 1118482],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 5, 5],"float32"),Tensor([2, 384, 5, 1118482],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5 but got size 1118482 for tensor number 1 in the list.

W0205 19:56:13.925832 72469 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:56:13.926867 72469 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 5, 5],"float32"),Tensor([2, 85899346, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 384, 5, 5],"float32"),Tensor([2, 85899346, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 19:58:09.522770 72892 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:58:09.523689 72892 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 5, 5],"float32"),Tensor([447393, 384, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 5, 5],"float32"),Tensor([447393, 384, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 447393 for tensor number 1 in the list.

W0205 19:59:20.654664 73452 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 19:59:20.655798 73452 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 6, 6],"float32"),Tensor([2, 384, 6, 6],"float32"),Tensor([2, 128, 2796203, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 6, 6],"float32"),Tensor([2, 384, 6, 6],"float32"),Tensor([2, 128, 2796203, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 6 but got size 2796203 for tensor number 2 in the list.

W0205 20:00:42.935933 73766 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:00:42.936981 73766 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 6, 6],"float32"),Tensor([2, 384, 6, 6],"float32"),Tensor([2, 128, 6, 2796203],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 6, 6],"float32"),Tensor([2, 384, 6, 6],"float32"),Tensor([2, 128, 6, 2796203],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 6 but got size 2796203 for tensor number 2 in the list.

W0205 20:01:58.236616 74195 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:01:58.237761 74195 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 6, 6],"float32"),Tensor([2, 384, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 2796203, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 6, 6],"float32"),Tensor([2, 384, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 2796203, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 6 but got size 2796203 for tensor number 3 in the list.

W0205 20:03:11.152201 74604 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:03:11.153213 74604 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 6, 6],"float32"),Tensor([2, 384, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 2796203],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 6, 6],"float32"),Tensor([2, 384, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 2796203],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 6 but got size 2796203 for tensor number 3 in the list.

W0205 20:04:24.605239 74923 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:04:24.606281 74923 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 6, 6],"float32"),Tensor([2, 384, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 59652324, 6, 6],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 384, 6, 6],"float32"),Tensor([2, 384, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 59652324, 6, 6],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 20:05:58.906093 75250 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:05:58.907022 75250 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 6, 6],"float32"),Tensor([2, 384, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([932068, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 6, 6],"float32"),Tensor([2, 384, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([932068, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 932068 for tensor number 3 in the list.

W0205 20:07:13.322295 75673 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:07:13.323725 75673 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 6, 6],"float32"),Tensor([2, 384, 6, 6],"float32"),Tensor([2, 59652324, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 384, 6, 6],"float32"),Tensor([2, 384, 6, 6],"float32"),Tensor([2, 59652324, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 20:08:45.313133 76088 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:08:45.314137 76088 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 6, 6],"float32"),Tensor([2, 384, 6, 6],"float32"),Tensor([932068, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 6, 6],"float32"),Tensor([2, 384, 6, 6],"float32"),Tensor([932068, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 932068 for tensor number 2 in the list.

W0205 20:09:55.040609 76511 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:09:55.041622 76511 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 6, 6],"float32"),Tensor([2, 384, 6, 932068],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 6, 6],"float32"),Tensor([2, 384, 6, 932068],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 6 but got size 932068 for tensor number 1 in the list.

W0205 20:11:17.861193 76846 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:11:17.862290 76846 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 6, 6],"float32"),Tensor([2, 384, 932068, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 6, 6],"float32"),Tensor([2, 384, 932068, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 6 but got size 932068 for tensor number 1 in the list.

W0205 20:12:38.736693 77250 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:12:38.737890 77250 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 6, 6],"float32"),Tensor([2, 59652324, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 384, 6, 6],"float32"),Tensor([2, 59652324, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 20:14:09.198669 77652 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:14:09.199892 77652 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 6, 6],"float32"),Tensor([310690, 384, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 6, 6],"float32"),Tensor([310690, 384, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 310690 for tensor number 1 in the list.

W0205 20:15:19.492360 78060 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:15:19.493359 78060 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 6, 932068],"float32"),Tensor([2, 384, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 6, 932068],"float32"),Tensor([2, 384, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 932068 but got size 6 for tensor number 1 in the list.

W0205 20:16:35.260624 78366 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:16:35.261750 78366 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 6, 932068],"float32"),Tensor([2, 384, 6, 932068],"float32"),Tensor([2, 128, 6, 932068],"float32"),Tensor([2, 128, 6, 932068],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 6, 932068],"float32"),Tensor([2, 384, 6, 932068],"float32"),Tensor([2, 128, 6, 932068],"float32"),Tensor([2, 128, 6, 932068],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 42.67 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.53 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 73804 has 43.66 GiB memory in use. Of the allocated memory 42.67 GiB is allocated by PyTorch, and 3.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:19:45.220093 78761 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:19:45.221216 78761 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 932068, 6],"float32"),Tensor([2, 384, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 932068, 6],"float32"),Tensor([2, 384, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 932068 but got size 6 for tensor number 1 in the list.

W0205 20:21:10.568393 79610 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:21:10.569969 79610 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 384, 932068, 6],"float32"),Tensor([2, 384, 932068, 6],"float32"),Tensor([2, 128, 932068, 6],"float32"),Tensor([2, 128, 932068, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 384, 932068, 6],"float32"),Tensor([2, 384, 932068, 6],"float32"),Tensor([2, 128, 932068, 6],"float32"),Tensor([2, 128, 932068, 6],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 42.67 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.53 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 129637 has 43.66 GiB memory in use. Of the allocated memory 42.67 GiB is allocated by PyTorch, and 3.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:24:21.398299 80020 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:24:21.399333 80020 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 4, 134217728, 4],"float32"),Tensor([2, 4, 134217728, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([2, 4, 134217728, 4],"float32"),Tensor([2, 4, 134217728, 4],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 99199 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:26:56.911823 80884 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:26:56.912868 80884 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 4, 134217728, 4],"float32"),Tensor([2, 4, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([2, 4, 134217728, 4],"float32"),Tensor([2, 4, 8, 4],"float32"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 3. Expected size 134217728 but got size 8 for tensor number 1 in the list.

W0205 20:28:23.269424 81678 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:28:23.270722 81678 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 4, 8, 4],"float32"),Tensor([2, 4, 134217728, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([2, 4, 8, 4],"float32"),Tensor([2, 4, 134217728, 4],"float32"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 3. Expected size 8 but got size 134217728 for tensor number 1 in the list.

W0205 20:29:40.321549 82033 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:29:40.322737 82033 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 4, 8, 4],"float32"),Tensor([2, 4, 8, 67108864],"float32"),], axis=-1, )
[paddle error] paddle.concat(list[Tensor([2, 4, 8, 4],"float32"),Tensor([2, 4, 8, 67108864],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 20:31:13.127933 82442 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:31:13.128894 82442 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 4, 8, 4],"float32"),Tensor([2, 67108864, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([2, 4, 8, 4],"float32"),Tensor([2, 67108864, 8, 4],"float32"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 3. Expected size 4 but got size 67108864 for tensor number 1 in the list.

W0205 20:32:23.878101 82866 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:32:23.879313 82866 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 4, 8, 4],"float32"),Tensor([33554432, 4, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([2, 4, 8, 4],"float32"),Tensor([33554432, 4, 8, 4],"float32"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 3. Expected size 2 but got size 33554432 for tensor number 1 in the list.

W0205 20:33:38.991756 83204 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:33:38.992936 83204 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 4, 8, 67108864],"float32"),Tensor([2, 4, 8, 4],"float32"),], axis=-1, )
[paddle error] paddle.concat(list[Tensor([2, 4, 8, 67108864],"float32"),Tensor([2, 4, 8, 4],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 20:35:07.891548 83610 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:35:07.892445 83610 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 4, 8, 67108864],"float32"),Tensor([2, 4, 8, 67108864],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([2, 4, 8, 67108864],"float32"),Tensor([2, 4, 8, 67108864],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 90615 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 20:37:34.472436 84026 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:37:34.473453 84026 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 416, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 416, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 20:39:04.047307 84743 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:39:04.048337 84743 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 416, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 416, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0205 20:40:14.230938 85160 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:40:14.231941 85160 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 416, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 416, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0205 20:41:27.351523 85483 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:41:27.352450 85483 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 416, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 416, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0205 20:42:48.882367 85907 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:42:48.883612 85907 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 416, 14, 368731],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 416, 14, 368731],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 368731 but got size 14 for tensor number 1 in the list.

W0205 20:44:11.304067 86235 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:44:11.305022 86235 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 416, 14, 368731],"float32"),Tensor([2, 32, 14, 368731],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 416, 14, 368731],"float32"),Tensor([2, 32, 14, 368731],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000042GB memory on GPU 0, 69.041931GB memory has been allocated and available memory is only 10.142944GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 20:45:44.885088 86631 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:45:44.887811 86631 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 416, 184366, 28],"float32"),Tensor([2, 32, 184366, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 416, 184366, 28],"float32"),Tensor([2, 32, 184366, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000086GB memory on GPU 0, 69.041931GB memory has been allocated and available memory is only 10.142944GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 20:47:26.511675 87067 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:47:26.512638 87067 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 416, 184366, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 416, 184366, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 184366 but got size 28 for tensor number 1 in the list.

W0205 20:48:40.203145 87501 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:48:40.204093 87501 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 416, 28, 184366],"float32"),Tensor([2, 32, 28, 184366],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 416, 28, 184366],"float32"),Tensor([2, 32, 28, 184366],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000086GB memory on GPU 0, 69.041931GB memory has been allocated and available memory is only 10.142944GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 20:50:18.121125 87911 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:50:18.121955 87911 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 416, 28, 184366],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 416, 28, 184366],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 184366 but got size 28 for tensor number 1 in the list.

W0205 20:51:32.587424 88333 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:51:32.588438 88333 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 416, 28, 28],"float32"),Tensor([171197, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 416, 28, 28],"float32"),Tensor([171197, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 171197 for tensor number 1 in the list.

W0205 20:52:49.660241 88742 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:52:49.661614 88742 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 416, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 416, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.604431GB memory has been allocated and available memory is only 12.580444GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 20:54:27.368786 89075 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:54:27.369686 89075 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 416, 28, 28],"float32"),Tensor([2, 32, 2396746, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 416, 28, 28],"float32"),Tensor([2, 32, 2396746, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 2396746 for tensor number 1 in the list.

W0205 20:55:41.630826 89494 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:55:41.632295 89494 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 416, 28, 28],"float32"),Tensor([2, 32, 28, 2396746],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 416, 28, 28],"float32"),Tensor([2, 32, 28, 2396746],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 2396746 for tensor number 1 in the list.

W0205 20:57:03.810968 89913 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:57:03.812258 89913 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 416, 368731, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 416, 368731, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 368731 but got size 14 for tensor number 1 in the list.

W0205 20:58:20.729467 90342 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 20:58:20.730636 90342 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 416, 368731, 14],"float32"),Tensor([2, 32, 368731, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 416, 368731, 14],"float32"),Tensor([2, 32, 368731, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000042GB memory on GPU 0, 69.041931GB memory has been allocated and available memory is only 10.142944GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 21:00:04.444828 90649 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:00:04.447199 90649 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 429496730, 5],"float32"),Tensor([2, 10, 5],"float32"),], )
[torch error] paddle.concat(list[Tensor([2, 429496730, 5],"float32"),Tensor([2, 10, 5],"float32"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 429496730 but got size 10 for tensor number 1 in the list.

W0205 21:01:14.186033 91190 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:01:14.187384 91190 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 429496730, 5],"float32"),Tensor([2, 429496730, 5],"float32"),], )
[torch error] paddle.concat(list[Tensor([2, 429496730, 5],"float32"),Tensor([2, 429496730, 5],"float32"),], ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 142793 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:03:32.900141 91511 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:03:32.901226 91511 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 432, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 432, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 21:05:05.464280 92203 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:05:05.465188 92203 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 432, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 432, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 3195661 for tensor number 1 in the list.

W0205 21:06:15.526945 92630 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:06:15.528019 92630 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 432, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 432, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 3195661 for tensor number 1 in the list.

W0205 21:07:33.721561 92952 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:07:33.722713 92952 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 432, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 432, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 456523 for tensor number 1 in the list.

W0205 21:08:51.080886 93384 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:08:51.081966 93384 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 432, 14, 355074],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 432, 14, 355074],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 355074 but got size 14 for tensor number 1 in the list.

W0205 21:10:14.338944 93724 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:10:14.340013 93724 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 432, 14, 355074],"float32"),Tensor([2, 48, 14, 355074],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 432, 14, 355074],"float32"),Tensor([2, 48, 14, 355074],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 70.135681GB memory has been allocated and available memory is only 9.049194GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 21:11:51.851926 94171 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:11:51.854462 94171 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 432, 177537, 28],"float32"),Tensor([2, 48, 177537, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 432, 177537, 28],"float32"),Tensor([2, 48, 177537, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 70.135681GB memory has been allocated and available memory is only 9.049194GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 21:13:30.634833 94633 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:13:30.635761 94633 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 432, 177537, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 432, 177537, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 177537 but got size 28 for tensor number 1 in the list.

W0205 21:14:40.693799 95069 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:14:40.694887 95069 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 432, 28, 177537],"float32"),Tensor([2, 48, 28, 177537],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 432, 28, 177537],"float32"),Tensor([2, 48, 28, 177537],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 70.135681GB memory has been allocated and available memory is only 9.049194GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 21:16:26.590440 95513 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:16:26.591323 95513 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 432, 28, 177537],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 432, 28, 177537],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 177537 but got size 28 for tensor number 1 in the list.

W0205 21:17:37.704839 95950 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:17:37.705960 95950 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 432, 28, 28],"float32"),Tensor([114131, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 432, 28, 28],"float32"),Tensor([114131, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 114131 for tensor number 1 in the list.

W0205 21:18:51.339414 96372 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:18:51.340891 96372 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 432, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 432, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.604431GB memory has been allocated and available memory is only 12.580444GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 21:20:26.228824 96694 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:20:26.229799 96694 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 432, 28, 28],"float32"),Tensor([2, 48, 1597831, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 432, 28, 28],"float32"),Tensor([2, 48, 1597831, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 1597831 for tensor number 1 in the list.

W0205 21:21:43.419610 97132 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:21:43.421061 97132 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 432, 28, 28],"float32"),Tensor([2, 48, 28, 1597831],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 432, 28, 28],"float32"),Tensor([2, 48, 28, 1597831],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 1597831 for tensor number 1 in the list.

W0205 21:22:59.164263 97559 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:22:59.165460 97559 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 432, 355074, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 432, 355074, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 355074 but got size 14 for tensor number 1 in the list.

W0205 21:24:27.430204 97969 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:24:27.431785 97969 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 432, 355074, 14],"float32"),Tensor([2, 48, 355074, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 432, 355074, 14],"float32"),Tensor([2, 48, 355074, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 70.135681GB memory has been allocated and available memory is only 9.049194GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 21:26:05.362043 98395 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:26:05.362921 98395 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 43826197, 7, 7],"float32"),Tensor([2, 232, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 43826197, 7, 7],"float32"),Tensor([2, 232, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 21:27:27.604820 98849 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:27:27.605657 98849 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 43826197, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 43826197, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 21:29:03.068326 99183 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:29:03.070812 99183 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 43826197, 7, 7],"float32"),Tensor([2, 352, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 43826197, 7, 7],"float32"),Tensor([2, 352, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 21:30:34.789472 99711 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:30:34.790289 99711 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 43826197, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 43826197, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 71964 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 21:33:01.572669 100155 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:33:01.573706 100155 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 43826197, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 43826197, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 21:34:36.723850 100865 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:34:36.724710 100865 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 43826197, 7, 7],"float32"),Tensor([2, 488, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 43826197, 7, 7],"float32"),Tensor([2, 488, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 21:36:09.894766 101274 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:36:09.895610 101274 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 43826197, 7, 7],"float32"),Tensor([2, 64, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 43826197, 7, 7],"float32"),Tensor([2, 64, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 21:37:40.868148 101703 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:37:40.869040 101703 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 43826197, 7, 7],"float32"),Tensor([2, 96, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 43826197, 7, 7],"float32"),Tensor([2, 96, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 21:39:08.563866 102132 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:39:08.564760 102132 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 448, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 448, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 21:40:31.034920 102555 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:40:31.036250 102555 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 448, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 448, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0205 21:41:41.256805 102957 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:41:41.257910 102957 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 448, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 448, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0205 21:43:01.274606 103278 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:43:01.275738 103278 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 448, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 448, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0205 21:44:21.620761 103675 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:44:21.621877 103675 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 448, 14, 342393],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 448, 14, 342393],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 342393 but got size 14 for tensor number 1 in the list.

W0205 21:45:39.854517 103994 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:45:39.855775 103994 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 448, 14, 342393],"float32"),Tensor([2, 32, 14, 342393],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 448, 14, 342393],"float32"),Tensor([2, 32, 14, 342393],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000039GB memory on GPU 0, 68.866150GB memory has been allocated and available memory is only 10.318726GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 21:47:13.752249 104384 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:47:13.754474 104384 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 448, 171197, 28],"float32"),Tensor([2, 32, 171197, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 448, 171197, 28],"float32"),Tensor([2, 32, 171197, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000086GB memory on GPU 0, 68.866150GB memory has been allocated and available memory is only 10.318726GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 21:48:47.475042 104819 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:48:47.477208 104819 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 448, 171197, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 448, 171197, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 171197 but got size 28 for tensor number 1 in the list.

W0205 21:50:01.609128 105249 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:50:01.610344 105249 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 448, 28, 171197],"float32"),Tensor([2, 32, 28, 171197],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 448, 28, 171197],"float32"),Tensor([2, 32, 28, 171197],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000086GB memory on GPU 0, 68.866150GB memory has been allocated and available memory is only 10.318726GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 21:51:42.167989 105653 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:51:42.169003 105653 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 448, 28, 171197],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 448, 28, 171197],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 171197 but got size 28 for tensor number 1 in the list.

W0205 21:52:53.959703 106126 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:52:53.960594 106126 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 448, 28, 28],"float32"),Tensor([171197, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 448, 28, 28],"float32"),Tensor([171197, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 171197 for tensor number 1 in the list.

W0205 21:54:07.040244 106446 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:54:07.041574 106446 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 448, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 448, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.604431GB memory has been allocated and available memory is only 12.580444GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 21:55:35.402912 106848 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:55:35.403970 106848 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 448, 28, 28],"float32"),Tensor([2, 32, 2396746, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 448, 28, 28],"float32"),Tensor([2, 32, 2396746, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 2396746 for tensor number 1 in the list.

W0205 21:56:50.865911 107269 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:56:50.867059 107269 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 448, 28, 28],"float32"),Tensor([2, 32, 28, 2396746],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 448, 28, 28],"float32"),Tensor([2, 32, 28, 2396746],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 2396746 for tensor number 1 in the list.

W0205 21:58:10.370110 107581 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:58:10.371366 107581 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 448, 342393, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 448, 342393, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 342393 but got size 14 for tensor number 1 in the list.

W0205 21:59:25.937217 107990 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 21:59:25.938357 107990 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 448, 342393, 14],"float32"),Tensor([2, 32, 342393, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 448, 342393, 14],"float32"),Tensor([2, 32, 342393, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000039GB memory on GPU 0, 68.866150GB memory has been allocated and available memory is only 10.318726GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 22:01:08.801436 108317 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:01:08.803673 108317 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 48, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 48, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 22:02:35.931854 108838 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:02:35.932771 108838 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 48, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 48, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 3195661 for tensor number 1 in the list.

W0205 22:03:51.335049 109260 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:03:51.336208 109260 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 48, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 48, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 3195661 for tensor number 1 in the list.

W0205 22:05:05.834981 109600 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:05:05.835991 109600 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 48, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 48, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 456523 for tensor number 1 in the list.

W0205 22:06:25.858161 110004 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:06:25.859345 110004 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 48, 14, 3195661],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 48, 14, 3195661],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 3195661 but got size 14 for tensor number 1 in the list.

W0205 22:07:43.487192 110331 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:07:43.488319 110331 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 48, 14, 3195661],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 48, 14, 3195661],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 139374 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:10:15.709900 110764 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:10:15.721442 110764 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 48, 3195661, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 48, 3195661, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 3195661 but got size 14 for tensor number 1 in the list.

W0205 22:11:31.111508 111535 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:11:31.113332 111535 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 48, 3195661, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 48, 3195661, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 58289 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:13:58.585340 111940 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:13:58.586499 111940 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 48, 6391321, 7],"float32"),Tensor([2, 48, 6391321, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 48, 6391321, 7],"float32"),Tensor([2, 48, 6391321, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 105856 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:16:19.621155 112659 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:16:19.622249 112659 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 48, 6391321, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 48, 6391321, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 6391321 but got size 7 for tensor number 1 in the list.

W0205 22:17:44.687836 113310 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:17:44.689065 113310 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 48, 7, 6391321],"float32"),Tensor([2, 48, 7, 6391321],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 48, 7, 6391321],"float32"),Tensor([2, 48, 7, 6391321],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 34373 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 22:20:07.943097 113741 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:20:07.944198 113741 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 48, 7, 6391321],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 48, 7, 6391321],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 6391321 but got size 7 for tensor number 1 in the list.

W0205 22:21:27.475420 114452 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:21:27.476636 114452 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 48, 7, 7],"float32"),Tensor([1826092, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 48, 7, 7],"float32"),Tensor([1826092, 48, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 1826092 for tensor number 1 in the list.

W0205 22:22:46.016319 114880 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:22:46.017439 114880 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 48, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 48, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 22:24:20.378537 115204 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:24:20.379526 115204 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 48, 7, 7],"float32"),Tensor([2, 48, 6391321, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 48, 7, 7],"float32"),Tensor([2, 48, 6391321, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 6391321 for tensor number 1 in the list.

W0205 22:25:29.682137 115640 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:25:29.683349 115640 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 48, 7, 7],"float32"),Tensor([2, 48, 7, 6391321],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 48, 7, 7],"float32"),Tensor([2, 48, 7, 6391321],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 6391321 for tensor number 1 in the list.

W0205 22:26:49.299883 116031 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:26:49.301156 116031 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 480, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 22:28:23.946732 116365 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:28:23.947697 116365 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 480, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0205 22:29:38.901507 116803 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:29:38.902696 116803 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 480, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0205 22:31:02.119673 117202 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:31:02.120677 117202 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 480, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 3195661 for tensor number 1 in the list.

W0205 22:32:19.691133 117624 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:32:19.692257 117624 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 480, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 3195661 for tensor number 1 in the list.

W0205 22:33:34.865381 117940 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:33:34.866649 117940 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 480, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 456523 for tensor number 1 in the list.

W0205 22:34:54.673267 118343 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:34:54.674391 118343 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 480, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0205 22:36:14.662011 118690 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:36:14.663071 118690 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 14, 319567],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 480, 14, 319567],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 319567 but got size 14 for tensor number 1 in the list.

W0205 22:37:33.183365 119103 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:37:33.184670 119103 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 14, 319567],"float32"),Tensor([2, 32, 14, 319567],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 480, 14, 319567],"float32"),Tensor([2, 32, 14, 319567],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000049GB memory on GPU 0, 68.713806GB memory has been allocated and available memory is only 10.471069GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 22:39:12.333684 119403 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:39:12.334533 119403 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 14, 319567],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 480, 14, 319567],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 319567 but got size 14 for tensor number 1 in the list.

W0205 22:40:31.518184 119713 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:40:31.519204 119713 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 14, 319567],"float32"),Tensor([2, 48, 14, 319567],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 480, 14, 319567],"float32"),Tensor([2, 48, 14, 319567],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000049GB memory on GPU 0, 69.780212GB memory has been allocated and available memory is only 9.404663GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 22:42:06.421022 120016 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:42:06.422032 120016 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 159784, 28],"float32"),Tensor([2, 32, 159784, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 480, 159784, 28],"float32"),Tensor([2, 32, 159784, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000099GB memory on GPU 0, 68.713806GB memory has been allocated and available memory is only 10.471069GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 22:43:38.971966 120319 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:43:38.974617 120319 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 159784, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 480, 159784, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 159784 but got size 28 for tensor number 1 in the list.

W0205 22:44:49.900887 120650 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:44:49.901993 120650 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 159784, 28],"float32"),Tensor([2, 48, 159784, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 480, 159784, 28],"float32"),Tensor([2, 48, 159784, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000099GB memory on GPU 0, 69.780212GB memory has been allocated and available memory is only 9.404663GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 22:46:24.308163 120855 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:46:24.310600 120855 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 159784, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 480, 159784, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 159784 but got size 28 for tensor number 1 in the list.

W0205 22:47:41.801023 121172 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:47:41.801887 121172 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 28, 159784],"float32"),Tensor([2, 32, 28, 159784],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 480, 28, 159784],"float32"),Tensor([2, 32, 28, 159784],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000099GB memory on GPU 0, 68.713806GB memory has been allocated and available memory is only 10.471069GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 22:49:15.596290 121487 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:49:15.597168 121487 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 28, 159784],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 480, 28, 159784],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 159784 but got size 28 for tensor number 1 in the list.

W0205 22:50:34.421097 121804 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:50:34.422247 121804 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 28, 159784],"float32"),Tensor([2, 48, 28, 159784],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 480, 28, 159784],"float32"),Tensor([2, 48, 28, 159784],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000099GB memory on GPU 0, 69.780212GB memory has been allocated and available memory is only 9.404663GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 22:52:07.091254 122120 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:52:07.093446 122120 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 28, 159784],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 480, 28, 159784],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 159784 but got size 28 for tensor number 1 in the list.

W0205 22:53:25.896147 122438 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:53:25.896991 122438 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 28, 28],"float32"),Tensor([114131, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 480, 28, 28],"float32"),Tensor([114131, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 114131 for tensor number 1 in the list.

W0205 22:54:37.298568 122656 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:54:37.299885 122656 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 28, 28],"float32"),Tensor([171197, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 480, 28, 28],"float32"),Tensor([171197, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 171197 for tensor number 1 in the list.

W0205 22:55:59.624887 122944 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:55:59.626072 122944 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 480, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.604431GB memory has been allocated and available memory is only 12.580444GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 22:57:34.927220 123260 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:57:34.928176 123260 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 28, 28],"float32"),Tensor([2, 32, 2396746, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 480, 28, 28],"float32"),Tensor([2, 32, 2396746, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 2396746 for tensor number 1 in the list.

W0205 22:58:51.992185 123564 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 22:58:51.993239 123564 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 28, 28],"float32"),Tensor([2, 32, 28, 2396746],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 480, 28, 28],"float32"),Tensor([2, 32, 28, 2396746],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 2396746 for tensor number 1 in the list.

W0205 23:00:15.188594 123796 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:00:15.189783 123796 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 28, 28],"float32"),Tensor([2, 48, 1597831, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 480, 28, 28],"float32"),Tensor([2, 48, 1597831, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 1597831 for tensor number 1 in the list.

W0205 23:01:29.489163 124100 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:01:29.490269 124100 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 28, 28],"float32"),Tensor([2, 48, 28, 1597831],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 480, 28, 28],"float32"),Tensor([2, 48, 28, 1597831],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 1597831 for tensor number 1 in the list.

W0205 23:02:41.835779 124416 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:02:41.836890 124416 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 319567, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 480, 319567, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 319567 but got size 14 for tensor number 1 in the list.

W0205 23:03:56.355155 124633 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:03:56.356362 124633 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 319567, 14],"float32"),Tensor([2, 32, 319567, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 480, 319567, 14],"float32"),Tensor([2, 32, 319567, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000049GB memory on GPU 0, 68.713806GB memory has been allocated and available memory is only 10.471069GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 23:05:39.749002 124852 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:05:39.751281 124852 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 319567, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 480, 319567, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 319567 but got size 14 for tensor number 1 in the list.

W0205 23:06:51.996306 125254 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:06:51.997416 125254 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 480, 319567, 14],"float32"),Tensor([2, 48, 319567, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 480, 319567, 14],"float32"),Tensor([2, 48, 319567, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000049GB memory on GPU 0, 69.780212GB memory has been allocated and available memory is only 9.404663GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 23:08:34.552634 125473 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:08:34.553572 125473 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 488, 628655, 7],"float32"),Tensor([2, 488, 628655, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 488, 628655, 7],"float32"),Tensor([2, 488, 628655, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 159637 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:10:50.414397 125887 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:10:50.415452 125887 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 488, 628655, 7],"float32"),Tensor([2, 488, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 488, 628655, 7],"float32"),Tensor([2, 488, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 628655 but got size 7 for tensor number 1 in the list.

W0205 23:12:04.386071 126324 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:12:04.387023 126324 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 488, 7, 628655],"float32"),Tensor([2, 488, 7, 628655],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 488, 7, 628655],"float32"),Tensor([2, 488, 7, 628655],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 65751 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0205 23:14:24.086644 126640 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:14:24.087878 126640 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 488, 7, 628655],"float32"),Tensor([2, 488, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 488, 7, 628655],"float32"),Tensor([2, 488, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 628655 but got size 7 for tensor number 1 in the list.

W0205 23:15:48.111501 127060 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:15:48.112519 127060 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 488, 7, 7],"float32"),Tensor([179616, 488, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 488, 7, 7],"float32"),Tensor([179616, 488, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 179616 for tensor number 1 in the list.

W0205 23:17:05.587960 127377 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:17:05.589084 127377 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 488, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 488, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 23:18:53.572573 127680 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:18:53.573417 127680 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 488, 7, 7],"float32"),Tensor([2, 488, 628655, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 488, 7, 7],"float32"),Tensor([2, 488, 628655, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 628655 for tensor number 1 in the list.

W0205 23:20:08.050757 127986 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:20:08.051844 127986 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 488, 7, 7],"float32"),Tensor([2, 488, 7, 628655],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 488, 7, 7],"float32"),Tensor([2, 488, 7, 628655],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 628655 for tensor number 1 in the list.

W0205 23:21:31.502388 128306 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:21:31.503506 128306 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 5],"float32"),Tensor([1431655765, 3],"float32"),Tensor([2, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 5],"float32"),Tensor([1431655765, 3],"float32"),Tensor([2, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 1431655765 for tensor number 1 in the list.

W0205 23:22:50.489542 128616 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:22:50.490684 128616 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 5],"float32"),Tensor([2, 2147483648],"float32"),Tensor([2, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 5],"float32"),Tensor([2, 2147483648],"float32"),Tensor([2, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 23:24:28.128902 128852 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:24:28.129861 128852 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 5],"float32"),Tensor([2, 3],"float32"),Tensor([2, 2147483648],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 5],"float32"),Tensor([2, 3],"float32"),Tensor([2, 2147483648],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 23:25:59.953657 129159 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:25:59.954773 129159 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 5],"float32"),Tensor([2, 3],"float32"),Tensor([858993459, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 5],"float32"),Tensor([2, 3],"float32"),Tensor([858993459, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 858993459 for tensor number 2 in the list.

W0205 23:27:12.814077 129478 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:27:12.815258 129478 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 512, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 512, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 23:28:47.531503 129793 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:28:47.532347 129793 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 512, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 512, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0205 23:30:09.769989 130111 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:30:09.770982 130111 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 512, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 512, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0205 23:31:38.930193 130414 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:31:38.931267 130414 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 512, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 512, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0205 23:32:54.863950 130719 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:32:54.864920 130719 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 512, 14, 299594],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 512, 14, 299594],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 299594 but got size 14 for tensor number 1 in the list.

W0205 23:34:14.862187 130950 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:34:14.863548 130950 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 512, 14, 299594],"float32"),Tensor([2, 32, 14, 299594],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 512, 14, 299594],"float32"),Tensor([2, 32, 14, 299594],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000046GB memory on GPU 0, 68.580994GB memory has been allocated and available memory is only 10.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 23:35:53.922928 131252 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:35:53.923811 131252 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 512, 299594, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 512, 299594, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 299594 but got size 14 for tensor number 1 in the list.

W0205 23:37:07.114902 131598 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:37:07.116032 131598 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 512, 299594, 14],"float32"),Tensor([2, 32, 299594, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 512, 299594, 14],"float32"),Tensor([2, 32, 299594, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000046GB memory on GPU 0, 68.580994GB memory has been allocated and available memory is only 10.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 23:38:45.261323 131899 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:38:45.262640 131899 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 512, 599187, 7],"float32"),Tensor([2, 32, 599187, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 512, 599187, 7],"float32"),Tensor([2, 32, 599187, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000019GB memory on GPU 0, 68.580994GB memory has been allocated and available memory is only 10.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 23:40:20.834592 132218 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:40:20.835638 132218 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 512, 599187, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 512, 599187, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 599187 but got size 7 for tensor number 1 in the list.

W0205 23:41:34.200822 132523 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:41:34.202060 132523 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 512, 7, 599187],"float32"),Tensor([2, 32, 7, 599187],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 512, 7, 599187],"float32"),Tensor([2, 32, 7, 599187],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000019GB memory on GPU 0, 68.580994GB memory has been allocated and available memory is only 10.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 23:43:08.032549 132855 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:43:08.033434 132855 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 512, 7, 599187],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 512, 7, 599187],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 599187 but got size 7 for tensor number 1 in the list.

W0205 23:44:21.545331 133161 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:44:21.546527 133161 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 512, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 512, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 23:45:34.281464 133379 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:45:34.282549 133379 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 512, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 512, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0205 23:46:54.650686 133687 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:46:54.651979 133687 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 512, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 512, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0205 23:48:25.778815 133919 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:48:25.779850 133919 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 512, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 512, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0205 23:49:49.817883 134231 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:49:49.819079 134231 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 512],"float16"),Tensor([2, 128],"float16"),Tensor([2, 2147483648],"float16"),], axis=1, )
[Pass] paddle.concat(list[Tensor([2, 512],"float16"),Tensor([2, 128],"float16"),Tensor([2, 2147483648],"float16"),], axis=1, )

W0205 23:51:25.379307 134562 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0205 23:51:25.380164 134562 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 512],"float16"),Tensor([2, 128],"float16"),Tensor([33554432, 128],"float16"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 512],"float16"),Tensor([2, 128],"float16"),Tensor([33554432, 128],"float16"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 33554432 for tensor number 2 in the list.

W0206 00:00:25.503652 136454 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:00:25.504778 136454 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 512],"float16"),Tensor([2, 2147483648],"float16"),Tensor([2, 128],"float16"),], axis=1, )
[Pass] paddle.concat(list[Tensor([2, 512],"float16"),Tensor([2, 2147483648],"float16"),Tensor([2, 128],"float16"),], axis=1, )

W0206 00:02:07.776997 136676 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:02:07.777930 136676 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 512],"float16"),Tensor([33554432, 128],"float16"),Tensor([2, 128],"float16"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 512],"float16"),Tensor([33554432, 128],"float16"),Tensor([2, 128],"float16"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 33554432 for tensor number 1 in the list.

W0206 00:11:08.591576 138630 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:11:08.592657 138630 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 512],"int32"),Tensor([2, 128],"int32"),Tensor([2, 2147483648],"int32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 512],"int32"),Tensor([2, 128],"int32"),Tensor([2, 2147483648],"int32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 00:12:43.024434 138948 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:12:43.025282 138948 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 512],"int32"),Tensor([2, 128],"int32"),Tensor([33554432, 128],"int32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 512],"int32"),Tensor([2, 128],"int32"),Tensor([33554432, 128],"int32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 33554432 for tensor number 2 in the list.

W0206 00:13:52.435319 139266 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:13:52.436380 139266 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 512],"int32"),Tensor([2, 2147483648],"int32"),Tensor([2, 128],"int32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 512],"int32"),Tensor([2, 2147483648],"int32"),Tensor([2, 128],"int32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 00:15:22.559370 139484 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:15:22.560421 139484 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 512],"int32"),Tensor([33554432, 128],"int32"),Tensor([2, 128],"int32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 512],"int32"),Tensor([33554432, 128],"int32"),Tensor([2, 128],"int32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 33554432 for tensor number 1 in the list.

W0206 00:16:34.141106 139801 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:16:34.142508 139801 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 524288, 32, 128],"float16"),Tensor([2, 32, 1, 128],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 524288, 32, 128],"float16"),Tensor([2, 32, 1, 128],"float16"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 524288 but got size 32 for tensor number 1 in the list.

W0206 00:18:03.172708 140133 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:18:03.173769 140133 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 524288, 32, 128],"float16"),Tensor([2, 524288, 1, 128],"float16"),], axis=2, )
[Pass] paddle.concat(list[Tensor([2, 524288, 32, 128],"float16"),Tensor([2, 524288, 1, 128],"float16"),], axis=2, )

W0206 00:19:40.399534 140454 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:19:40.400478 140454 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 524288, 64, 64],"float16"),Tensor([2, 524288, 1, 64],"float16"),], axis=2, )
[Pass] paddle.concat(list[Tensor([2, 524288, 64, 64],"float16"),Tensor([2, 524288, 1, 64],"float16"),], axis=2, )

W0206 00:29:12.647528 142364 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:29:12.648468 142364 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 524288, 64, 64],"float16"),Tensor([2, 524288, 64, 64],"float16"),], axis=2, )
[paddle error] paddle.concat(list[Tensor([2, 524288, 64, 64],"float16"),Tensor([2, 524288, 64, 64],"float16"),], axis=2, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000000GB memory on GPU 0, 74.575134GB memory has been allocated and available memory is only 4.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 00:40:28.180670 144117 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:40:28.181727 144117 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 524288, 64, 64],"float16"),Tensor([2, 8, 1, 64],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 524288, 64, 64],"float16"),Tensor([2, 8, 1, 64],"float16"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 524288 but got size 8 for tensor number 1 in the list.

W0206 00:41:59.739527 144801 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:41:59.740969 144801 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 524288, 64, 64],"float16"),Tensor([2, 8, 64, 64],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 524288, 64, 64],"float16"),Tensor([2, 8, 64, 64],"float16"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 524288 but got size 8 for tensor number 1 in the list.

W0206 00:43:30.741614 145175 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:43:30.742725 145175 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 528, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 528, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 00:45:03.486604 145478 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:45:03.487459 145478 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 528, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 528, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 3195661 for tensor number 1 in the list.

W0206 00:46:12.311874 145782 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:46:12.312837 145782 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 528, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 528, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 3195661 for tensor number 1 in the list.

W0206 00:47:38.478346 145994 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:47:38.479423 145994 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 528, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 528, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 456523 for tensor number 1 in the list.

W0206 00:48:58.995096 146110 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:48:58.996367 146110 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 528, 14, 290515],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 528, 14, 290515],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 290515 but got size 14 for tensor number 1 in the list.

W0206 00:50:23.974560 146139 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:50:23.975533 146139 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 528, 14, 290515],"float32"),Tensor([2, 48, 14, 290515],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 528, 14, 290515],"float32"),Tensor([2, 48, 14, 290515],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000024GB memory on GPU 0, 69.487244GB memory has been allocated and available memory is only 9.697632GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 00:52:09.630443 146206 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:52:09.631325 146206 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 528, 145258, 28],"float32"),Tensor([2, 48, 145258, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 528, 145258, 28],"float32"),Tensor([2, 48, 145258, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000079GB memory on GPU 0, 69.487244GB memory has been allocated and available memory is only 9.697632GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 00:53:40.675181 146249 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:53:40.677660 146249 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 528, 145258, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 528, 145258, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 145258 but got size 28 for tensor number 1 in the list.

W0206 00:54:49.897823 146319 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:54:49.898792 146319 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 528, 28, 145258],"float32"),Tensor([2, 48, 28, 145258],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 528, 28, 145258],"float32"),Tensor([2, 48, 28, 145258],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000079GB memory on GPU 0, 69.487244GB memory has been allocated and available memory is only 9.697632GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 00:56:24.306267 146361 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:56:24.307201 146361 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 528, 28, 145258],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 528, 28, 145258],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 145258 but got size 28 for tensor number 1 in the list.

W0206 00:57:32.285645 146390 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:57:32.286816 146390 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 528, 28, 28],"float32"),Tensor([114131, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 528, 28, 28],"float32"),Tensor([114131, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 114131 for tensor number 1 in the list.

W0206 00:58:47.919948 146431 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 00:58:47.921082 146431 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 528, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 528, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.604431GB memory has been allocated and available memory is only 12.580444GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 01:00:17.624428 146478 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:00:17.625367 146478 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 528, 28, 28],"float32"),Tensor([2, 48, 1597831, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 528, 28, 28],"float32"),Tensor([2, 48, 1597831, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 1597831 for tensor number 1 in the list.

W0206 01:01:26.058982 146521 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:01:26.060179 146521 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 528, 28, 28],"float32"),Tensor([2, 48, 28, 1597831],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 528, 28, 28],"float32"),Tensor([2, 48, 28, 1597831],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 1597831 for tensor number 1 in the list.

W0206 01:02:41.008390 146563 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:02:41.009531 146563 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 528, 290515, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 528, 290515, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 290515 but got size 14 for tensor number 1 in the list.

W0206 01:03:56.333963 146620 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:03:56.335094 146620 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 528, 290515, 14],"float32"),Tensor([2, 48, 290515, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 528, 290515, 14],"float32"),Tensor([2, 48, 290515, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000024GB memory on GPU 0, 69.487244GB memory has been allocated and available memory is only 9.697632GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 01:05:36.749380 146662 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:05:36.750487 146662 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 536870912, 4],"float32"),Tensor([2, 3, 4],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 536870912, 4],"float32"),Tensor([2, 3, 4],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 01:07:05.376642 146731 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:07:05.377527 146731 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 536870912, 4],"float32"),Tensor([2, 536870912, 4],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 536870912, 4],"float32"),Tensor([2, 536870912, 4],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 17132 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 01:09:20.836566 146786 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:09:20.837699 146786 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 544, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 544, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 01:10:57.460947 146857 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:10:57.461910 146857 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 544, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 544, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 01:12:07.847986 146899 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:12:07.849036 146899 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 544, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 544, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 01:13:26.220844 146957 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:13:26.222121 146957 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 544, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 544, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0206 01:14:40.121876 147005 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:14:40.123339 147005 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 544, 14, 281971],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 544, 14, 281971],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 281971 but got size 14 for tensor number 1 in the list.

W0206 01:16:02.254899 147055 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:16:02.255975 147055 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 544, 14, 281971],"float32"),Tensor([2, 32, 14, 281971],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 544, 14, 281971],"float32"),Tensor([2, 32, 14, 281971],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000056GB memory on GPU 0, 68.459900GB memory has been allocated and available memory is only 10.724976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 01:17:37.493216 147111 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:17:37.494524 147111 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 544, 281971, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 544, 281971, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 281971 but got size 14 for tensor number 1 in the list.

W0206 01:18:50.657636 147153 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:18:50.658733 147153 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 544, 281971, 14],"float32"),Tensor([2, 32, 281971, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 544, 281971, 14],"float32"),Tensor([2, 32, 281971, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000056GB memory on GPU 0, 68.459900GB memory has been allocated and available memory is only 10.724976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 01:20:33.763433 147208 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:20:33.765697 147208 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 544, 563941, 7],"float32"),Tensor([2, 32, 563941, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 544, 563941, 7],"float32"),Tensor([2, 32, 563941, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000027GB memory on GPU 0, 68.459900GB memory has been allocated and available memory is only 10.724976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 01:22:10.826850 147270 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:22:10.828087 147270 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 544, 563941, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 544, 563941, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 563941 but got size 7 for tensor number 1 in the list.

W0206 01:23:20.269771 147321 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:23:20.270942 147321 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 544, 7, 563941],"float32"),Tensor([2, 32, 7, 563941],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 544, 7, 563941],"float32"),Tensor([2, 32, 7, 563941],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000027GB memory on GPU 0, 68.459900GB memory has been allocated and available memory is only 10.724976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 01:24:52.067188 147379 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:24:52.068110 147379 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 544, 7, 563941],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 544, 7, 563941],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 563941 but got size 7 for tensor number 1 in the list.

W0206 01:26:08.912926 147435 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:26:08.914212 147435 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 544, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 544, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 01:27:24.328881 147477 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:27:24.329896 147477 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 544, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 544, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 01:28:38.282032 147533 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:28:38.283048 147533 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 544, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 544, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 01:30:15.287011 147575 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:30:15.288144 147575 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 544, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 544, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0206 01:31:30.789988 147630 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:31:30.791143 147630 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 133153, 28],"float32"),Tensor([2, 48, 133153, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 576, 133153, 28],"float32"),Tensor([2, 48, 133153, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000059GB memory on GPU 0, 69.245056GB memory has been allocated and available memory is only 9.939819GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 01:33:13.645977 147673 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:33:13.648067 147673 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 133153, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 576, 133153, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 133153 but got size 28 for tensor number 1 in the list.

W0206 01:34:25.120740 147715 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:34:25.121822 147715 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 576, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 01:35:53.746348 147757 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:35:53.747427 147757 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 576, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 01:37:09.831195 147798 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:37:09.832412 147798 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 576, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 01:38:26.967031 147840 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:38:26.968014 147840 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 576, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 3195661 for tensor number 1 in the list.

W0206 01:39:42.664077 147897 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:39:42.664974 147897 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 576, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 3195661 for tensor number 1 in the list.

W0206 01:41:04.788870 147925 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:41:04.789930 147925 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 576, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 456523 for tensor number 1 in the list.

W0206 01:42:28.176056 147981 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:42:28.177124 147981 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 576, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0206 01:43:47.229141 148022 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:43:47.230276 148022 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 14, 266306],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 576, 14, 266306],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 266306 but got size 14 for tensor number 1 in the list.

W0206 01:45:15.798707 148064 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:45:15.799784 148064 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 14, 266306],"float32"),Tensor([2, 32, 14, 266306],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 576, 14, 266306],"float32"),Tensor([2, 32, 14, 266306],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000059GB memory on GPU 0, 68.358337GB memory has been allocated and available memory is only 10.826538GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 01:47:13.255291 148107 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:47:13.256170 148107 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 14, 266306],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 576, 14, 266306],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 266306 but got size 14 for tensor number 1 in the list.

W0206 01:48:34.451459 148176 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:48:34.452445 148176 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 14, 266306],"float32"),Tensor([2, 48, 14, 266306],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 576, 14, 266306],"float32"),Tensor([2, 48, 14, 266306],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000059GB memory on GPU 0, 69.245056GB memory has been allocated and available memory is only 9.939819GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 01:50:18.250159 148219 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:50:18.251286 148219 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 266306, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 576, 266306, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 266306 but got size 14 for tensor number 1 in the list.

W0206 01:51:28.325992 148263 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:51:28.327215 148263 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 266306, 14],"float32"),Tensor([2, 32, 266306, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 576, 266306, 14],"float32"),Tensor([2, 32, 266306, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000059GB memory on GPU 0, 68.358337GB memory has been allocated and available memory is only 10.826538GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 01:53:11.345558 148319 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:53:11.347774 148319 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 266306, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 576, 266306, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 266306 but got size 14 for tensor number 1 in the list.

W0206 01:54:29.215305 148389 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:54:29.216450 148389 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 266306, 14],"float32"),Tensor([2, 48, 266306, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 576, 266306, 14],"float32"),Tensor([2, 48, 266306, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000059GB memory on GPU 0, 69.245056GB memory has been allocated and available memory is only 9.939819GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 01:56:12.179867 148431 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:56:12.182130 148431 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 28, 133153],"float32"),Tensor([2, 48, 28, 133153],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 576, 28, 133153],"float32"),Tensor([2, 48, 28, 133153],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000059GB memory on GPU 0, 69.245056GB memory has been allocated and available memory is only 9.939819GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 01:57:49.993844 148486 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:57:49.996174 148486 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 28, 133153],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 576, 28, 133153],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 133153 but got size 28 for tensor number 1 in the list.

W0206 01:59:09.826162 148542 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 01:59:09.827593 148542 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 28, 28],"float32"),Tensor([114131, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 576, 28, 28],"float32"),Tensor([114131, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 114131 for tensor number 1 in the list.

W0206 02:00:23.603057 148584 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:00:23.604198 148584 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 576, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.604431GB memory has been allocated and available memory is only 12.580444GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 02:01:57.817456 148613 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:01:57.818403 148613 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 28, 28],"float32"),Tensor([2, 48, 1597831, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 576, 28, 28],"float32"),Tensor([2, 48, 1597831, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 1597831 for tensor number 1 in the list.

W0206 02:03:06.589895 148641 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:03:06.591154 148641 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 28, 28],"float32"),Tensor([2, 48, 28, 1597831],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 576, 28, 28],"float32"),Tensor([2, 48, 28, 1597831],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 1597831 for tensor number 1 in the list.

W0206 02:04:25.489444 148682 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:04:25.490702 148682 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 532611, 7],"float32"),Tensor([2, 32, 532611, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 576, 532611, 7],"float32"),Tensor([2, 32, 532611, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 68.358337GB memory has been allocated and available memory is only 10.826538GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 02:06:09.102087 148726 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:06:09.104635 148726 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 532611, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 576, 532611, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 532611 but got size 7 for tensor number 1 in the list.

W0206 02:07:19.856657 148781 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:07:19.858173 148781 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 7, 532611],"float32"),Tensor([2, 32, 7, 532611],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 576, 7, 532611],"float32"),Tensor([2, 32, 7, 532611],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 68.358337GB memory has been allocated and available memory is only 10.826538GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 02:08:56.297698 148823 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:08:56.298622 148823 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 7, 532611],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 576, 7, 532611],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 532611 but got size 7 for tensor number 1 in the list.

W0206 02:10:15.354950 148865 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:10:15.356393 148865 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 576, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 02:11:27.651922 148894 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:11:27.653107 148894 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 576, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 02:12:49.452585 148922 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:12:49.453796 148922 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 576, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 02:14:26.177871 148964 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:14:26.178834 148964 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 576, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 576, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0206 02:15:43.433315 148992 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:15:43.434413 148992 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 58, 1322343, 28],"float32"),Tensor([2, 58, 1322343, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 58, 1322343, 28],"float32"),Tensor([2, 58, 1322343, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 52616 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:18:01.219703 149033 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:18:01.220716 149033 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 58, 1322343, 28],"float32"),Tensor([2, 58, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 58, 1322343, 28],"float32"),Tensor([2, 58, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1322343 but got size 28 for tensor number 1 in the list.

W0206 02:19:16.689296 149089 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:19:16.690755 149089 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 58, 28, 1322343],"float32"),Tensor([2, 58, 28, 1322343],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 58, 28, 1322343],"float32"),Tensor([2, 58, 28, 1322343],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 125842 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:21:46.675838 149131 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:21:46.676849 149131 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 58, 28, 1322343],"float32"),Tensor([2, 58, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 58, 28, 1322343],"float32"),Tensor([2, 58, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1322343 but got size 28 for tensor number 1 in the list.

W0206 02:23:06.968168 149187 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:23:06.969092 149187 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 58, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 58, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 02:24:44.018267 149230 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:24:44.019119 149230 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 58, 28, 28],"float32"),Tensor([2, 58, 1322343, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 58, 28, 28],"float32"),Tensor([2, 58, 1322343, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 1322343 for tensor number 1 in the list.

W0206 02:25:58.999292 149271 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:25:59.000319 149271 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 58, 28, 28],"float32"),Tensor([2, 58, 28, 1322343],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 58, 28, 28],"float32"),Tensor([2, 58, 28, 1322343],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 1322343 for tensor number 1 in the list.

W0206 02:27:10.560968 149313 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:27:10.561980 149313 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 58, 28, 28],"float32"),Tensor([94454, 58, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 58, 28, 28],"float32"),Tensor([94454, 58, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 94454 for tensor number 1 in the list.

W0206 02:28:26.389763 149342 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:28:26.390776 149342 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 59652324, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 59652324, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 02:30:06.470176 149370 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:30:06.472888 149370 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 59652324, 6, 6],"float32"),Tensor([2, 384, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 59652324, 6, 6],"float32"),Tensor([2, 384, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 02:31:30.936319 149412 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:31:30.937202 149412 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 59652324, 6, 6],"float32"),Tensor([2, 59652324, 6, 6],"float32"),Tensor([2, 59652324, 6, 6],"float32"),Tensor([2, 59652324, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 59652324, 6, 6],"float32"),Tensor([2, 59652324, 6, 6],"float32"),Tensor([2, 59652324, 6, 6],"float32"),Tensor([2, 59652324, 6, 6],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 55647 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 02:34:40.839561 149482 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:34:40.841945 149482 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 608, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 608, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 02:36:11.528040 149552 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:36:11.529114 149552 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 608, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 608, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 02:37:24.613413 149621 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:37:24.614984 149621 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 608, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 608, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 02:38:39.815088 149664 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:38:39.816072 149664 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 608, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 608, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0206 02:39:59.966113 149732 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:39:59.967101 149732 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 608, 14, 252289],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 608, 14, 252289],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 252289 but got size 14 for tensor number 1 in the list.

W0206 02:41:23.679510 149789 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:41:23.680560 149789 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 608, 14, 252289],"float32"),Tensor([2, 32, 14, 252289],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 608, 14, 252289],"float32"),Tensor([2, 32, 14, 252289],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000002GB memory on GPU 0, 68.264587GB memory has been allocated and available memory is only 10.920288GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 02:43:00.624604 149832 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:43:00.625717 149832 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 608, 252289, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 608, 252289, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 252289 but got size 14 for tensor number 1 in the list.

W0206 02:44:10.704805 149902 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:44:10.706424 149902 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 608, 252289, 14],"float32"),Tensor([2, 32, 252289, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 608, 252289, 14],"float32"),Tensor([2, 32, 252289, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000002GB memory on GPU 0, 68.264587GB memory has been allocated and available memory is only 10.920288GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 02:45:55.849622 149949 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:45:55.850478 149949 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 608, 504578, 7],"float32"),Tensor([2, 32, 504578, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 608, 504578, 7],"float32"),Tensor([2, 32, 504578, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000002GB memory on GPU 0, 68.264587GB memory has been allocated and available memory is only 10.920288GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 02:47:24.900451 149999 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:47:24.901376 149999 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 608, 504578, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 608, 504578, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 504578 but got size 7 for tensor number 1 in the list.

W0206 02:48:36.730072 150055 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:48:36.731225 150055 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 608, 7, 504578],"float32"),Tensor([2, 32, 7, 504578],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 608, 7, 504578],"float32"),Tensor([2, 32, 7, 504578],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000002GB memory on GPU 0, 68.264587GB memory has been allocated and available memory is only 10.920288GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 02:50:23.680516 150085 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:50:23.683140 150085 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 608, 7, 504578],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 608, 7, 504578],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 504578 but got size 7 for tensor number 1 in the list.

W0206 02:51:34.832154 150141 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:51:34.833214 150141 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 608, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 608, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 02:52:53.003695 150183 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:52:53.004972 150183 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 608, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 608, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 02:54:07.489189 150238 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:54:07.490242 150238 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 608, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 608, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 02:55:36.794622 150294 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:55:36.795737 150294 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 608, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 608, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0206 02:56:49.991822 150364 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:56:49.993036 150364 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 624, 122911, 28],"float32"),Tensor([2, 48, 122911, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 624, 122911, 28],"float32"),Tensor([2, 48, 122911, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000129GB memory on GPU 0, 69.041931GB memory has been allocated and available memory is only 10.142944GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 02:58:25.341192 150420 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:58:25.342118 150420 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 624, 122911, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 624, 122911, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 122911 but got size 28 for tensor number 1 in the list.

W0206 02:59:33.929715 150492 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 02:59:33.930706 150492 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 624, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 624, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 03:01:08.686954 150533 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:01:08.687862 150533 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 624, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 624, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 3195661 for tensor number 1 in the list.

W0206 03:02:23.681902 150576 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:02:23.683373 150576 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 624, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 624, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 3195661 for tensor number 1 in the list.

W0206 03:03:44.953259 150617 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:03:44.954403 150617 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 624, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 624, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 456523 for tensor number 1 in the list.

W0206 03:05:05.045027 150660 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:05:05.046109 150660 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 624, 14, 245821],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 624, 14, 245821],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 245821 but got size 14 for tensor number 1 in the list.

W0206 03:06:26.814071 150702 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:06:26.815023 150702 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 624, 14, 245821],"float32"),Tensor([2, 48, 14, 245821],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 624, 14, 245821],"float32"),Tensor([2, 48, 14, 245821],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000064GB memory on GPU 0, 69.041931GB memory has been allocated and available memory is only 10.142944GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 03:08:11.030225 150758 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:08:11.031160 150758 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 624, 245821, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 624, 245821, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 245821 but got size 14 for tensor number 1 in the list.

W0206 03:09:28.182219 150799 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:09:28.183298 150799 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 624, 245821, 14],"float32"),Tensor([2, 48, 245821, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 624, 245821, 14],"float32"),Tensor([2, 48, 245821, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000064GB memory on GPU 0, 69.041931GB memory has been allocated and available memory is only 10.142944GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 03:11:04.320683 150828 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:11:04.322010 150828 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 624, 28, 122911],"float32"),Tensor([2, 48, 28, 122911],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 624, 28, 122911],"float32"),Tensor([2, 48, 28, 122911],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000129GB memory on GPU 0, 69.041931GB memory has been allocated and available memory is only 10.142944GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 03:12:41.525563 150875 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:12:41.528190 150875 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 624, 28, 122911],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 624, 28, 122911],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 122911 but got size 28 for tensor number 1 in the list.

W0206 03:14:00.704627 150941 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:14:00.705555 150941 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 624, 28, 28],"float32"),Tensor([114131, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 624, 28, 28],"float32"),Tensor([114131, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 114131 for tensor number 1 in the list.

W0206 03:15:19.453697 150995 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:15:19.454850 150995 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 624, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 624, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.604431GB memory has been allocated and available memory is only 12.580444GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 03:16:54.031435 151039 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:16:54.032311 151039 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 624, 28, 28],"float32"),Tensor([2, 48, 1597831, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 624, 28, 28],"float32"),Tensor([2, 48, 1597831, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 1597831 for tensor number 1 in the list.

W0206 03:18:09.804761 151094 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:18:09.805964 151094 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 624, 28, 28],"float32"),Tensor([2, 48, 28, 1597831],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 624, 28, 28],"float32"),Tensor([2, 48, 28, 1597831],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 1597831 for tensor number 1 in the list.

W0206 03:19:31.927784 151155 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:19:31.928997 151155 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 1242757, 27],"float32"),Tensor([2, 128, 1242757, 27],"float32"),Tensor([2, 32, 1242757, 27],"float32"),Tensor([2, 32, 1242757, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 1242757, 27],"float32"),Tensor([2, 128, 1242757, 27],"float32"),Tensor([2, 32, 1242757, 27],"float32"),Tensor([2, 32, 1242757, 27],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 29.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 112248 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:22:53.819113 151206 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:22:53.821524 151206 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 1242757, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 1242757, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1242757 but got size 27 for tensor number 1 in the list.

W0206 03:24:10.274358 151318 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:24:10.275421 151318 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 1342178, 25],"float32"),Tensor([2, 64, 1342178, 25],"float32"),Tensor([2, 96, 1342178, 25],"float32"),Tensor([2, 32, 1342178, 25],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 1342178, 25],"float32"),Tensor([2, 64, 1342178, 25],"float32"),Tensor([2, 96, 1342178, 25],"float32"),Tensor([2, 32, 1342178, 25],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 24.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 31200 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:27:52.685504 151374 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:27:52.686569 151374 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 1342178, 25],"float32"),Tensor([2, 64, 1342178, 25],"float32"),Tensor([2, 96, 1342178, 25],"float32"),Tensor([2, 64, 1342178, 25],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 1342178, 25],"float32"),Tensor([2, 64, 1342178, 25],"float32"),Tensor([2, 96, 1342178, 25],"float32"),Tensor([2, 64, 1342178, 25],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 24.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 108563 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:31:34.734856 151500 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:31:34.735976 151500 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 1342178, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 32, 25, 25],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 1342178, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 32, 25, 25],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1342178 but got size 25 for tensor number 1 in the list.

W0206 03:32:52.696431 151612 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:32:52.697520 151612 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 1342178, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 1342178, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1342178 but got size 25 for tensor number 1 in the list.

W0206 03:34:11.554265 151641 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:34:11.555228 151641 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 25, 1342178],"float32"),Tensor([2, 64, 25, 1342178],"float32"),Tensor([2, 96, 25, 1342178],"float32"),Tensor([2, 32, 25, 1342178],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 25, 1342178],"float32"),Tensor([2, 64, 25, 1342178],"float32"),Tensor([2, 96, 25, 1342178],"float32"),Tensor([2, 32, 25, 1342178],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 24.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 58084 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:38:08.937171 151682 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:38:08.938272 151682 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 25, 1342178],"float32"),Tensor([2, 64, 25, 1342178],"float32"),Tensor([2, 96, 25, 1342178],"float32"),Tensor([2, 64, 25, 1342178],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 25, 1342178],"float32"),Tensor([2, 64, 25, 1342178],"float32"),Tensor([2, 96, 25, 1342178],"float32"),Tensor([2, 64, 25, 1342178],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 24.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 148091 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 03:41:59.383554 151780 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:41:59.384770 151780 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 25, 1342178],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 32, 25, 25],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 25, 1342178],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 32, 25, 25],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1342178 but got size 25 for tensor number 1 in the list.

W0206 03:43:26.301540 151880 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:43:26.302472 151880 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 25, 1342178],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 25, 1342178],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1342178 but got size 25 for tensor number 1 in the list.

W0206 03:44:49.759770 151923 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:44:49.760596 151923 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([107375, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 32, 25, 25],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([107375, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 32, 25, 25],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 107375 for tensor number 1 in the list.

W0206 03:46:12.215849 151991 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:46:12.216890 151991 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([107375, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([107375, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 107375 for tensor number 1 in the list.

W0206 03:47:28.386822 152034 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:47:28.387845 152034 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 3435974, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 32, 25, 25],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 3435974, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 32, 25, 25],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 03:49:31.618611 152089 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:49:31.619462 152089 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 3435974, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 3435974, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 03:51:06.346830 152159 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:51:06.347694 152159 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 1342178, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 32, 25, 25],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 1342178, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 32, 25, 25],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 25 but got size 1342178 for tensor number 1 in the list.

W0206 03:52:23.795953 152225 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:52:23.797530 152225 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 1342178, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 1342178, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 25 but got size 1342178 for tensor number 1 in the list.

W0206 03:53:45.151533 152272 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:53:45.152529 152272 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 1342178],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 32, 25, 25],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 1342178],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 32, 25, 25],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 25 but got size 1342178 for tensor number 1 in the list.

W0206 03:55:03.941586 152340 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:55:03.942530 152340 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 1342178],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 1342178],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 25 but got size 1342178 for tensor number 1 in the list.

W0206 03:56:23.927516 152383 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:56:23.928675 152383 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 3435974, 25, 25],"float32"),Tensor([2, 32, 25, 25],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 3435974, 25, 25],"float32"),Tensor([2, 32, 25, 25],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 03:57:53.210757 152440 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:57:53.211740 152440 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 3435974, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 3435974, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 03:59:20.109206 152468 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 03:59:20.110085 152468 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([107375, 64, 25, 25],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([107375, 64, 25, 25],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 107375 for tensor number 3 in the list.

W0206 04:00:36.157954 152510 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:00:36.159301 152510 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 32, 25, 2684355],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 32, 25, 2684355],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 25 but got size 2684355 for tensor number 3 in the list.

W0206 04:01:56.244501 152552 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:01:56.245383 152552 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 32, 2684355, 25],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 32, 2684355, 25],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 25 but got size 2684355 for tensor number 3 in the list.

W0206 04:03:12.819691 152593 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:03:12.820678 152593 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 3435974, 25, 25],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 3435974, 25, 25],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 04:04:48.763059 152650 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:04:48.763955 152650 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 64, 1342178, 25],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 64, 1342178, 25],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 25 but got size 1342178 for tensor number 3 in the list.

W0206 04:06:05.726064 152692 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:06:05.727075 152692 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 64, 25, 1342178],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([2, 64, 25, 1342178],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 25 but got size 1342178 for tensor number 3 in the list.

W0206 04:07:23.494880 152734 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:07:23.495978 152734 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([214749, 32, 25, 25],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 25],"float32"),Tensor([214749, 32, 25, 25],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 214749 for tensor number 3 in the list.

W0206 04:08:43.632149 152776 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:08:43.633195 152776 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 894785],"float32"),Tensor([2, 32, 25, 25],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 894785],"float32"),Tensor([2, 32, 25, 25],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 25 but got size 894785 for tensor number 2 in the list.

W0206 04:09:59.999444 152819 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:10:00.000519 152819 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 894785],"float32"),Tensor([2, 64, 25, 25],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 25, 894785],"float32"),Tensor([2, 64, 25, 25],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 25 but got size 894785 for tensor number 2 in the list.

W0206 04:11:26.283097 152861 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:11:26.284219 152861 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 894785, 25],"float32"),Tensor([2, 32, 25, 25],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 894785, 25],"float32"),Tensor([2, 32, 25, 25],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 25 but got size 894785 for tensor number 2 in the list.

W0206 04:12:47.623322 152915 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:12:47.624248 152915 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 894785, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([2, 96, 894785, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 25 but got size 894785 for tensor number 2 in the list.

W0206 04:14:02.510835 152970 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:14:02.511798 152970 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([71583, 96, 25, 25],"float32"),Tensor([2, 32, 25, 25],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([71583, 96, 25, 25],"float32"),Tensor([2, 32, 25, 25],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 71583 for tensor number 2 in the list.

W0206 04:15:17.911334 153014 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:15:17.912246 153014 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([71583, 96, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),Tensor([71583, 96, 25, 25],"float32"),Tensor([2, 64, 25, 25],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 71583 for tensor number 2 in the list.

W0206 04:16:31.584939 153060 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:16:31.585909 153060 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 27, 1242757],"float32"),Tensor([2, 128, 27, 1242757],"float32"),Tensor([2, 32, 27, 1242757],"float32"),Tensor([2, 32, 27, 1242757],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 27, 1242757],"float32"),Tensor([2, 128, 27, 1242757],"float32"),Tensor([2, 32, 27, 1242757],"float32"),Tensor([2, 32, 27, 1242757],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 29.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 23810 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:20:04.634552 153098 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:20:04.637387 153098 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 27, 1242757],"float32"),Tensor([2, 128, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 27, 1242757],"float32"),Tensor([2, 128, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 1242757 but got size 27 for tensor number 1 in the list.

W0206 04:21:25.337604 153237 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:21:25.338379 153237 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 27, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),Tensor([184113, 32, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 27, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),Tensor([184113, 32, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 184113 for tensor number 2 in the list.

W0206 04:22:43.927256 153285 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:22:43.928313 153285 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 27, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 64, 27, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 04:24:17.833166 153348 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:24:17.834057 153348 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 27, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),Tensor([2, 32, 2485514, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 27, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),Tensor([2, 32, 2485514, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 27 but got size 2485514 for tensor number 2 in the list.

W0206 04:25:57.377867 153391 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:25:57.379354 153391 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 27, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),Tensor([2, 32, 27, 2485514],"float32"),Tensor([2, 32, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 27, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),Tensor([2, 32, 27, 2485514],"float32"),Tensor([2, 32, 27, 27],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 27 but got size 2485514 for tensor number 2 in the list.

W0206 04:27:17.736943 153461 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:27:17.738097 153461 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 27, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),Tensor([184113, 32, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 27, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),Tensor([184113, 32, 27, 27],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 184113 for tensor number 3 in the list.

W0206 04:28:32.073179 153503 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:28:32.074086 153503 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 27, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 64, 27, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 04:30:08.224435 153545 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:30:08.225268 153545 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 27, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),Tensor([2, 32, 2485514, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 27, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),Tensor([2, 32, 2485514, 27],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 27 but got size 2485514 for tensor number 3 in the list.

W0206 04:31:18.228148 153587 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:31:18.229194 153587 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 27, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),Tensor([2, 32, 27, 2485514],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 27, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),Tensor([2, 32, 27, 2485514],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 27 but got size 2485514 for tensor number 3 in the list.

W0206 04:32:36.507104 153616 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:32:36.508272 153616 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 27, 27],"float32"),Tensor([2, 128, 27, 621379],"float32"),Tensor([2, 32, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 27, 27],"float32"),Tensor([2, 128, 27, 621379],"float32"),Tensor([2, 32, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 27 but got size 621379 for tensor number 1 in the list.

W0206 04:33:57.047405 153658 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:33:57.048779 153658 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 27, 27],"float32"),Tensor([2, 128, 621379, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 27, 27],"float32"),Tensor([2, 128, 621379, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 27 but got size 621379 for tensor number 1 in the list.

W0206 04:35:17.762804 153700 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:35:17.763845 153700 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 64, 27, 27],"float32"),Tensor([2, 2945794, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 04:36:48.309914 153741 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:36:48.311076 153741 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 27, 27],"float32"),Tensor([46029, 128, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 27, 27],"float32"),Tensor([46029, 128, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),Tensor([2, 32, 27, 27],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 46029 for tensor number 1 in the list.

W0206 04:38:16.911170 153797 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:38:16.912256 153797 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 4793491, 7],"float32"),Tensor([2, 64, 4793491, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 4793491, 7],"float32"),Tensor([2, 64, 4793491, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 88773 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:40:38.609778 153839 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:40:38.610774 153839 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 4793491, 7],"float32"),Tensor([2, 64, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 4793491, 7],"float32"),Tensor([2, 64, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 4793491 but got size 7 for tensor number 1 in the list.

W0206 04:42:13.107185 153895 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:42:13.108314 153895 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 54, 54],"float32"),Tensor([2, 64, 54, 621379],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 54, 54],"float32"),Tensor([2, 64, 54, 621379],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 54 but got size 621379 for tensor number 1 in the list.

W0206 04:43:27.225615 153937 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:43:27.226812 153937 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 54, 54],"float32"),Tensor([2, 64, 621379, 54],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 54, 54],"float32"),Tensor([2, 64, 621379, 54],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 54 but got size 621379 for tensor number 1 in the list.

W0206 04:44:49.792152 153979 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:44:49.793334 153979 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 54, 54],"float32"),Tensor([2, 736449, 54, 54],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 64, 54, 54],"float32"),Tensor([2, 736449, 54, 54],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000012GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 04:46:19.799925 154035 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:46:19.800784 154035 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 54, 54],"float32"),Tensor([23015, 64, 54, 54],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 54, 54],"float32"),Tensor([23015, 64, 54, 54],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 23015 for tensor number 1 in the list.

W0206 04:47:33.290599 154078 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:47:33.291703 154078 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 54, 621379],"float32"),Tensor([2, 64, 54, 54],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 54, 621379],"float32"),Tensor([2, 64, 54, 54],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 621379 but got size 54 for tensor number 1 in the list.

W0206 04:48:48.259786 154133 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:48:48.260991 154133 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 54, 621379],"float32"),Tensor([2, 64, 54, 621379],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 54, 621379],"float32"),Tensor([2, 64, 54, 621379],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 123309 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 04:51:03.661350 154162 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:51:03.662531 154162 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 55, 55],"float32"),Tensor([2, 64, 55, 610081],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 55, 55],"float32"),Tensor([2, 64, 55, 610081],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 55 but got size 610081 for tensor number 1 in the list.

W0206 04:52:21.435739 154218 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:52:21.436844 154218 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 55, 55],"float32"),Tensor([2, 64, 610081, 55],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 55, 55],"float32"),Tensor([2, 64, 610081, 55],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 55 but got size 610081 for tensor number 1 in the list.

W0206 04:53:45.142529 154246 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:53:45.143719 154246 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 55, 55],"float32"),Tensor([2, 709912, 55, 55],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 64, 55, 55],"float32"),Tensor([2, 709912, 55, 55],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 04:55:21.012610 154274 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:55:21.013626 154274 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 55, 55],"float32"),Tensor([22185, 64, 55, 55],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 55, 55],"float32"),Tensor([22185, 64, 55, 55],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 22185 for tensor number 1 in the list.

W0206 04:56:37.626547 154302 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:56:37.627710 154302 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 55, 610081],"float32"),Tensor([2, 64, 55, 55],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 55, 610081],"float32"),Tensor([2, 64, 55, 55],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 610081 but got size 55 for tensor number 1 in the list.

W0206 04:57:59.110586 154330 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 04:57:59.111907 154330 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 55, 610081],"float32"),Tensor([2, 64, 55, 610081],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 55, 610081],"float32"),Tensor([2, 64, 55, 610081],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 124488 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:00:21.963889 154358 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:00:21.964882 154358 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 56, 56],"float32"),Tensor([2, 32, 1198373, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 56, 56],"float32"),Tensor([2, 32, 1198373, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 56 but got size 1198373 for tensor number 1 in the list.

W0206 05:01:44.925814 154400 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:01:44.926820 154400 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 56, 56],"float32"),Tensor([2, 32, 56, 1198373],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 56, 56],"float32"),Tensor([2, 32, 56, 1198373],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 56 but got size 1198373 for tensor number 1 in the list.

W0206 05:03:06.241677 154428 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:03:06.242976 154428 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 56, 56],"float32"),Tensor([2, 684785, 56, 56],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 64, 56, 56],"float32"),Tensor([2, 684785, 56, 56],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000016GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 05:04:47.323360 154456 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:04:47.324278 154456 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 56, 56],"float32"),Tensor([42800, 32, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 56, 56],"float32"),Tensor([42800, 32, 56, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 42800 for tensor number 1 in the list.

W0206 05:06:24.012372 154503 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:06:24.013661 154503 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 56, 599187],"float32"),Tensor([2, 32, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 56, 599187],"float32"),Tensor([2, 32, 56, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 599187 but got size 56 for tensor number 1 in the list.

W0206 05:07:48.573321 154554 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:07:48.574316 154554 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 56, 599187],"float32"),Tensor([2, 32, 56, 599187],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 56, 599187],"float32"),Tensor([2, 32, 56, 599187],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 24.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 21.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 136094 has 24.99 GiB memory in use. Of the allocated memory 24.00 GiB is allocated by PyTorch, and 3.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:09:51.125380 154596 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:09:51.126459 154596 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 599187, 56],"float32"),Tensor([2, 32, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 599187, 56],"float32"),Tensor([2, 32, 56, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 599187 but got size 56 for tensor number 1 in the list.

W0206 05:11:25.636054 154638 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:11:25.637324 154638 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 599187, 56],"float32"),Tensor([2, 32, 599187, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 599187, 56],"float32"),Tensor([2, 32, 599187, 56],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 24.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 21.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 37008 has 24.99 GiB memory in use. Of the allocated memory 24.00 GiB is allocated by PyTorch, and 3.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:13:26.920706 154680 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:13:26.921736 154680 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 610081, 55],"float32"),Tensor([2, 64, 55, 55],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 610081, 55],"float32"),Tensor([2, 64, 55, 55],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 610081 but got size 55 for tensor number 1 in the list.

W0206 05:14:52.765722 154736 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:14:52.766772 154736 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 610081, 55],"float32"),Tensor([2, 64, 610081, 55],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 610081, 55],"float32"),Tensor([2, 64, 610081, 55],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 98478 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:17:15.035020 154790 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:17:15.036062 154790 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 621379, 54],"float32"),Tensor([2, 64, 54, 54],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 621379, 54],"float32"),Tensor([2, 64, 54, 54],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 621379 but got size 54 for tensor number 1 in the list.

W0206 05:18:29.413103 154862 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:18:29.414300 154862 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 621379, 54],"float32"),Tensor([2, 64, 621379, 54],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 621379, 54],"float32"),Tensor([2, 64, 621379, 54],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 162018 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:20:53.015621 154903 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:20:53.016600 154903 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 7, 4793491],"float32"),Tensor([2, 64, 7, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 7, 4793491],"float32"),Tensor([2, 64, 7, 4793491],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 45391 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 05:23:12.611361 154970 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:23:12.612762 154970 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 7, 4793491],"float32"),Tensor([2, 64, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 7, 4793491],"float32"),Tensor([2, 64, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 4793491 but got size 7 for tensor number 1 in the list.

W0206 05:24:36.051793 155030 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:24:36.053300 155030 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 7, 7],"float32"),Tensor([1369569, 64, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 7, 7],"float32"),Tensor([1369569, 64, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 1369569 for tensor number 1 in the list.

W0206 05:25:49.249766 155071 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:25:49.250878 155071 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 64, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 05:27:23.706010 155100 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:27:23.706911 155100 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 7, 7],"float32"),Tensor([2, 64, 4793491, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 7, 7],"float32"),Tensor([2, 64, 4793491, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 4793491 for tensor number 1 in the list.

W0206 05:28:33.138634 155134 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:28:33.139828 155134 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 64, 7, 7],"float32"),Tensor([2, 64, 7, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 64, 7, 7],"float32"),Tensor([2, 64, 7, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 4793491 for tensor number 1 in the list.

W0206 05:29:47.230013 155183 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:29:47.231122 155183 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 640, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 640, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 05:31:17.359292 155225 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:31:17.360146 155225 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 640, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 640, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 05:32:31.399474 155267 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:32:31.400621 155267 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 640, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 640, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 05:33:44.230156 155309 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:33:44.231254 155309 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 640, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 640, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0206 05:34:59.002734 155339 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:34:59.003820 155339 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 640, 14, 239675],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 640, 14, 239675],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 239675 but got size 14 for tensor number 1 in the list.

W0206 05:36:14.062623 155380 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:36:14.064288 155380 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 640, 14, 239675],"float32"),Tensor([2, 32, 14, 239675],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 640, 14, 239675],"float32"),Tensor([2, 32, 14, 239675],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000032GB memory on GPU 0, 68.178650GB memory has been allocated and available memory is only 11.006226GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 05:37:46.017138 155423 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:37:46.018096 155423 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 640, 239675, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 640, 239675, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 239675 but got size 14 for tensor number 1 in the list.

W0206 05:38:59.089859 155478 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:38:59.090893 155478 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 640, 239675, 14],"float32"),Tensor([2, 32, 239675, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 640, 239675, 14],"float32"),Tensor([2, 32, 239675, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000032GB memory on GPU 0, 68.178650GB memory has been allocated and available memory is only 11.006226GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 05:40:39.497655 155520 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:40:39.498661 155520 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 640, 479350, 7],"float32"),Tensor([2, 32, 479350, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 640, 479350, 7],"float32"),Tensor([2, 32, 479350, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000032GB memory on GPU 0, 68.178650GB memory has been allocated and available memory is only 11.006226GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 05:42:09.268648 155563 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:42:09.269724 155563 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 640, 479350, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 640, 479350, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 479350 but got size 7 for tensor number 1 in the list.

W0206 05:43:18.525560 155604 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:43:18.526854 155604 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 640, 7, 479350],"float32"),Tensor([2, 32, 7, 479350],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 640, 7, 479350],"float32"),Tensor([2, 32, 7, 479350],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000032GB memory on GPU 0, 68.178650GB memory has been allocated and available memory is only 11.006226GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 05:44:59.813231 155660 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:44:59.814287 155660 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 640, 7, 479350],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 640, 7, 479350],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 479350 but got size 7 for tensor number 1 in the list.

W0206 05:46:16.112179 155703 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:46:16.113313 155703 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 640, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 640, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 05:47:37.375835 155745 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:47:37.376914 155745 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 640, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 640, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 05:48:59.602269 155798 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:48:59.603363 155798 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 640, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 640, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 05:50:33.229033 155841 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:50:33.230026 155841 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 640, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 640, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0206 05:51:42.756769 155898 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:51:42.757735 155898 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 66],"float32"),Tensor([2, 2147483648],"float32"),Tensor([2, 66],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 66],"float32"),Tensor([2, 2147483648],"float32"),Tensor([2, 66],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 05:53:16.913343 155955 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:53:16.914264 155955 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 66],"float32"),Tensor([2, 66],"float32"),Tensor([2, 2147483648],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 66],"float32"),Tensor([2, 66],"float32"),Tensor([2, 2147483648],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 05:54:41.784360 156010 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:54:41.785199 156010 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 66],"float32"),Tensor([2, 66],"float32"),Tensor([65075263, 66],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 66],"float32"),Tensor([2, 66],"float32"),Tensor([65075263, 66],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 65075263 for tensor number 2 in the list.

W0206 05:55:52.420954 156053 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:55:52.422101 156053 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 66],"float32"),Tensor([65075263, 66],"float32"),Tensor([2, 66],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 66],"float32"),Tensor([65075263, 66],"float32"),Tensor([2, 66],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 65075263 for tensor number 1 in the list.

W0206 05:57:08.302753 156108 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:57:08.303979 156108 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 67108864, 8, 4],"float32"),Tensor([2, 1, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([2, 67108864, 8, 4],"float32"),Tensor([2, 1, 8, 4],"float32"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 3. Expected size 67108864 but got size 1 for tensor number 1 in the list.

W0206 05:58:23.687054 156163 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:58:23.688107 156163 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 67108864, 8, 4],"float32"),Tensor([2, 4, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([2, 67108864, 8, 4],"float32"),Tensor([2, 4, 8, 4],"float32"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 3. Expected size 67108864 but got size 4 for tensor number 1 in the list.

W0206 05:59:41.703318 156203 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 05:59:41.704290 156203 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 67108864, 8, 4],"float32"),Tensor([2, 67108864, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([2, 67108864, 8, 4],"float32"),Tensor([2, 67108864, 8, 4],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 22616 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:02:03.530773 156248 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:02:03.531807 156248 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 114131, 28],"float32"),Tensor([2, 48, 114131, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 672, 114131, 28],"float32"),Tensor([2, 48, 114131, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000039GB memory on GPU 0, 68.866150GB memory has been allocated and available memory is only 10.318726GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 06:03:38.929558 156319 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:03:38.930598 156319 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 114131, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 672, 114131, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 114131 but got size 28 for tensor number 1 in the list.

W0206 06:04:49.016865 156360 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:04:49.017760 156360 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 672, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 06:06:22.710623 156415 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:06:22.711524 156415 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 672, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 06:07:36.924068 156458 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:07:36.925117 156458 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 672, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 06:08:51.330034 156500 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:08:51.331084 156500 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 672, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 3195661 for tensor number 1 in the list.

W0206 06:10:07.636466 156556 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:10:07.637359 156556 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 672, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 3195661 for tensor number 1 in the list.

W0206 06:11:22.305614 156611 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:11:22.306701 156611 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 672, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 456523 for tensor number 1 in the list.

W0206 06:12:41.626435 156668 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:12:41.627554 156668 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 672, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0206 06:13:58.339829 156724 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:13:58.340737 156724 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 14, 228262],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 672, 14, 228262],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 228262 but got size 14 for tensor number 1 in the list.

W0206 06:15:13.099205 156765 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:15:13.100252 156765 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 14, 228262],"float32"),Tensor([2, 32, 14, 228262],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 672, 14, 228262],"float32"),Tensor([2, 32, 14, 228262],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000039GB memory on GPU 0, 68.104431GB memory has been allocated and available memory is only 11.080444GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 06:16:44.094858 156821 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:16:44.095712 156821 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 14, 228262],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 672, 14, 228262],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 228262 but got size 14 for tensor number 1 in the list.

W0206 06:17:52.759466 156864 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:17:52.760668 156864 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 14, 228262],"float32"),Tensor([2, 48, 14, 228262],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 672, 14, 228262],"float32"),Tensor([2, 48, 14, 228262],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000039GB memory on GPU 0, 68.866150GB memory has been allocated and available memory is only 10.318726GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 06:19:27.110920 156907 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:19:27.111804 156907 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 228262, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 672, 228262, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 228262 but got size 14 for tensor number 1 in the list.

W0206 06:20:38.442996 156976 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:20:38.444172 156976 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 228262, 14],"float32"),Tensor([2, 32, 228262, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 672, 228262, 14],"float32"),Tensor([2, 32, 228262, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000039GB memory on GPU 0, 68.104431GB memory has been allocated and available memory is only 11.080444GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 06:22:11.124086 157019 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:22:11.126364 157019 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 228262, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 672, 228262, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 228262 but got size 14 for tensor number 1 in the list.

W0206 06:23:22.729764 157075 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:23:22.730779 157075 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 228262, 14],"float32"),Tensor([2, 48, 228262, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 672, 228262, 14],"float32"),Tensor([2, 48, 228262, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000039GB memory on GPU 0, 68.866150GB memory has been allocated and available memory is only 10.318726GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 06:24:55.655644 157117 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:24:55.656519 157117 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 28, 114131],"float32"),Tensor([2, 48, 28, 114131],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 672, 28, 114131],"float32"),Tensor([2, 48, 28, 114131],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000039GB memory on GPU 0, 68.866150GB memory has been allocated and available memory is only 10.318726GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 06:26:34.966012 157173 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:26:34.966956 157173 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 28, 114131],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 672, 28, 114131],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 114131 but got size 28 for tensor number 1 in the list.

W0206 06:27:48.634853 157243 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:27:48.635737 157243 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 28, 28],"float32"),Tensor([114131, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 672, 28, 28],"float32"),Tensor([114131, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 114131 for tensor number 1 in the list.

W0206 06:29:03.178830 157298 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:29:03.179937 157298 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 672, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.608337GB memory has been allocated and available memory is only 12.576538GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 06:30:32.627724 157355 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:30:32.628618 157355 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 28, 28],"float32"),Tensor([2, 48, 1597831, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 672, 28, 28],"float32"),Tensor([2, 48, 1597831, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 1597831 for tensor number 1 in the list.

W0206 06:31:48.605767 157396 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:31:48.606892 157396 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 28, 28],"float32"),Tensor([2, 48, 28, 1597831],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 672, 28, 28],"float32"),Tensor([2, 48, 28, 1597831],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 1597831 for tensor number 1 in the list.

W0206 06:33:04.628273 157452 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:33:04.629369 157452 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 456523, 7],"float32"),Tensor([2, 32, 456523, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 672, 456523, 7],"float32"),Tensor([2, 32, 456523, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 68.104431GB memory has been allocated and available memory is only 11.080444GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 06:34:38.876276 157495 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:34:38.878679 157495 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 456523, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 672, 456523, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 456523 but got size 7 for tensor number 1 in the list.

W0206 06:35:50.623392 157549 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:35:50.624439 157549 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 7, 456523],"float32"),Tensor([2, 32, 7, 456523],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 672, 7, 456523],"float32"),Tensor([2, 32, 7, 456523],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 68.104431GB memory has been allocated and available memory is only 11.080444GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 06:37:22.796236 157578 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:37:22.797057 157578 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 7, 456523],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 672, 7, 456523],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 456523 but got size 7 for tensor number 1 in the list.

W0206 06:38:35.656371 157634 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:38:35.658385 157634 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 672, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 06:39:54.953948 157690 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:39:54.955035 157690 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 672, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 06:41:18.275576 157719 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:41:18.276757 157719 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 672, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 06:42:47.979276 157761 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:42:47.980335 157761 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 672, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 672, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0206 06:43:57.473680 157815 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:43:57.474872 157815 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 684785, 56, 56],"float32"),Tensor([2, 32, 56, 56],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 684785, 56, 56],"float32"),Tensor([2, 32, 56, 56],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000016GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 06:45:37.814977 157858 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:45:37.815852 157858 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 684785, 56, 56],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 684785, 56, 56],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000016GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 06:47:03.845181 157914 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:47:03.846057 157914 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 684785, 56, 56],"float32"),Tensor([2, 684785, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 684785, 56, 56],"float32"),Tensor([2, 684785, 56, 56],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 57995 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 06:49:21.985670 157970 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:49:21.986717 157970 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 704, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 704, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 06:50:57.088351 158055 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:50:57.089206 158055 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 704, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 704, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 06:52:16.901183 158110 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:52:16.902733 158110 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 704, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 704, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 06:53:33.289610 158166 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:53:33.290596 158166 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 704, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 704, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0206 06:54:47.575284 158208 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:54:47.576354 158208 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 704, 14, 217886],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 704, 14, 217886],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 217886 but got size 14 for tensor number 1 in the list.

W0206 06:56:12.900301 158263 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:56:12.901659 158263 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 704, 14, 217886],"float32"),Tensor([2, 32, 14, 217886],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 704, 14, 217886],"float32"),Tensor([2, 32, 14, 217886],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000006GB memory on GPU 0, 68.034119GB memory has been allocated and available memory is only 11.150757GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 06:57:45.203200 158319 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:57:45.205471 158319 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 704, 217886, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 704, 217886, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 217886 but got size 14 for tensor number 1 in the list.

W0206 06:59:05.439853 158361 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 06:59:05.441533 158361 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 704, 217886, 14],"float32"),Tensor([2, 32, 217886, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 704, 217886, 14],"float32"),Tensor([2, 32, 217886, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000006GB memory on GPU 0, 68.034119GB memory has been allocated and available memory is only 11.150757GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 07:00:37.666522 158403 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:00:37.667436 158403 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 704, 435772, 7],"float32"),Tensor([2, 32, 435772, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 704, 435772, 7],"float32"),Tensor([2, 32, 435772, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000006GB memory on GPU 0, 68.034119GB memory has been allocated and available memory is only 11.150757GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 07:02:05.490438 158460 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:02:05.491392 158460 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 704, 435772, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 704, 435772, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 435772 but got size 7 for tensor number 1 in the list.

W0206 07:03:17.553499 158515 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:03:17.554823 158515 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 704, 7, 435772],"float32"),Tensor([2, 32, 7, 435772],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 704, 7, 435772],"float32"),Tensor([2, 32, 7, 435772],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000006GB memory on GPU 0, 68.034119GB memory has been allocated and available memory is only 11.150757GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 07:05:01.537422 158544 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:05:01.538342 158544 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 704, 7, 435772],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 704, 7, 435772],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 435772 but got size 7 for tensor number 1 in the list.

W0206 07:06:21.903100 158600 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:06:21.904163 158600 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 704, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 704, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 07:07:35.420459 158656 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:07:35.421533 158656 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 704, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 704, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 07:08:50.420668 158697 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:08:50.421759 158697 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 704, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 704, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 07:10:32.953179 158727 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:10:32.954187 158727 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 704, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 704, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0206 07:11:47.291622 158782 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:11:47.292856 158782 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 709912, 55, 55],"float32"),Tensor([2, 64, 55, 55],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 709912, 55, 55],"float32"),Tensor([2, 64, 55, 55],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 07:13:25.335364 158811 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:13:25.337949 158811 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 709912, 55, 55],"float32"),Tensor([2, 709912, 55, 55],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 709912, 55, 55],"float32"),Tensor([2, 709912, 55, 55],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 46266 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 07:15:43.362286 158866 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:15:43.363420 158866 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 720, 106523, 28],"float32"),Tensor([2, 48, 106523, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 720, 106523, 28],"float32"),Tensor([2, 48, 106523, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000149GB memory on GPU 0, 68.713806GB memory has been allocated and available memory is only 10.471069GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 07:17:20.685082 158949 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:17:20.686010 158949 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 720, 106523, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 720, 106523, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 106523 but got size 28 for tensor number 1 in the list.

W0206 07:18:39.874032 158998 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:18:39.874873 158998 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 720, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 720, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 07:20:16.839396 159075 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:20:16.840272 159075 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 720, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 720, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 3195661 for tensor number 1 in the list.

W0206 07:21:31.679911 159117 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:21:31.680908 159117 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 720, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 720, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 3195661 for tensor number 1 in the list.

W0206 07:22:47.413017 159173 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:22:47.414104 159173 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 720, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 720, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 456523 for tensor number 1 in the list.

W0206 07:24:08.605124 159216 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:24:08.606173 159216 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 720, 14, 213045],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 720, 14, 213045],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 213045 but got size 14 for tensor number 1 in the list.

W0206 07:25:23.700243 159271 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:25:23.701431 159271 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 720, 14, 213045],"float32"),Tensor([2, 48, 14, 213045],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 720, 14, 213045],"float32"),Tensor([2, 48, 14, 213045],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000074GB memory on GPU 0, 68.713806GB memory has been allocated and available memory is only 10.471069GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 07:26:59.530336 159314 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:26:59.532902 159314 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 720, 213045, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 720, 213045, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 213045 but got size 14 for tensor number 1 in the list.

W0206 07:28:19.629320 159369 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:28:19.630381 159369 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 720, 213045, 14],"float32"),Tensor([2, 48, 213045, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 720, 213045, 14],"float32"),Tensor([2, 48, 213045, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000074GB memory on GPU 0, 68.713806GB memory has been allocated and available memory is only 10.471069GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 07:29:55.449016 159403 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:29:55.450009 159403 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 720, 28, 106523],"float32"),Tensor([2, 48, 28, 106523],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 720, 28, 106523],"float32"),Tensor([2, 48, 28, 106523],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000149GB memory on GPU 0, 68.713806GB memory has been allocated and available memory is only 10.471069GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 07:31:25.009450 159451 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:31:25.012125 159451 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 720, 28, 106523],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 720, 28, 106523],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 106523 but got size 28 for tensor number 1 in the list.

W0206 07:32:37.246801 159496 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:32:37.247853 159496 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 720, 28, 28],"float32"),Tensor([114131, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 720, 28, 28],"float32"),Tensor([114131, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 114131 for tensor number 1 in the list.

W0206 07:33:50.670110 159538 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:33:50.671209 159538 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 720, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 720, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.608337GB memory has been allocated and available memory is only 12.576538GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 07:35:20.866923 159580 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:35:20.867918 159580 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 720, 28, 28],"float32"),Tensor([2, 48, 1597831, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 720, 28, 28],"float32"),Tensor([2, 48, 1597831, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 1597831 for tensor number 1 in the list.

W0206 07:36:30.209136 159635 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:36:30.210261 159635 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 720, 28, 28],"float32"),Tensor([2, 48, 28, 1597831],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 720, 28, 28],"float32"),Tensor([2, 48, 28, 1597831],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 1597831 for tensor number 1 in the list.

W0206 07:37:47.575732 159665 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:37:47.576979 159665 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 736, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 736, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 07:39:18.370944 159720 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:39:18.371984 159720 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 736, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 736, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 07:40:28.306020 159776 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:40:28.306918 159776 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 736, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 736, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 07:41:42.440881 159830 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:41:42.442042 159830 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 736, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 736, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0206 07:42:55.173166 159888 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:42:55.174201 159888 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 736, 14, 208413],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 736, 14, 208413],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 208413 but got size 14 for tensor number 1 in the list.

W0206 07:44:15.840111 159957 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:44:15.841331 159957 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 736, 14, 208413],"float32"),Tensor([2, 32, 14, 208413],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 736, 14, 208413],"float32"),Tensor([2, 32, 14, 208413],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 67.971619GB memory has been allocated and available memory is only 11.213257GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 07:45:55.532776 160006 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:45:55.533744 160006 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 736, 208413, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 736, 208413, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 208413 but got size 14 for tensor number 1 in the list.

W0206 07:47:08.879412 160084 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:47:08.880517 160084 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 736, 208413, 14],"float32"),Tensor([2, 32, 208413, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 736, 208413, 14],"float32"),Tensor([2, 32, 208413, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 67.971619GB memory has been allocated and available memory is only 11.213257GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 07:48:43.895663 160140 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:48:43.896507 160140 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 736, 416826, 7],"float32"),Tensor([2, 32, 416826, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 736, 416826, 7],"float32"),Tensor([2, 32, 416826, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 67.971619GB memory has been allocated and available memory is only 11.213257GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 07:50:10.138793 160196 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:50:10.139812 160196 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 736, 416826, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 736, 416826, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 416826 but got size 7 for tensor number 1 in the list.

W0206 07:51:19.794829 160252 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:51:19.796028 160252 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 736, 7, 416826],"float32"),Tensor([2, 32, 7, 416826],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 736, 7, 416826],"float32"),Tensor([2, 32, 7, 416826],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 67.971619GB memory has been allocated and available memory is only 11.213257GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 07:53:03.122536 160295 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:53:03.123499 160295 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 736, 7, 416826],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 736, 7, 416826],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 416826 but got size 7 for tensor number 1 in the list.

W0206 07:54:13.670967 160364 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:54:13.672214 160364 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 736, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 736, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 07:55:32.512502 160406 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:55:32.513724 160406 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 736, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 736, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 07:56:46.423028 160447 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:56:46.424090 160447 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 736, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 736, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 07:58:16.410326 160504 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:58:16.411314 160504 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 736, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 736, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0206 07:59:31.683764 160587 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 07:59:31.684973 160587 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 736449, 54, 54],"float32"),Tensor([2, 128, 54, 54],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 736449, 54, 54],"float32"),Tensor([2, 128, 54, 54],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000012GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 08:01:03.193132 160639 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:01:03.195650 160639 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 736449, 54, 54],"float32"),Tensor([2, 64, 54, 54],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 736449, 54, 54],"float32"),Tensor([2, 64, 54, 54],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000012GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 08:02:38.254444 160686 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:02:38.255326 160686 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 736449, 54, 54],"float32"),Tensor([2, 736449, 54, 54],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 736449, 54, 54],"float32"),Tensor([2, 736449, 54, 54],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 156778 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 08:04:46.670310 160770 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:04:46.671381 160770 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 768, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 768, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 08:06:17.141937 160853 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:06:17.142906 160853 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 768, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 768, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 08:07:26.478132 160922 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:07:26.478988 160922 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 768, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 768, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 08:08:41.447187 160953 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:08:41.448100 160953 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 768, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 768, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 3195661 for tensor number 1 in the list.

W0206 08:10:00.009166 161008 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:10:00.010249 161008 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 768, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 768, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 3195661 for tensor number 1 in the list.

W0206 08:11:19.801185 161050 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:11:19.802170 161050 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 768, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 768, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 456523 for tensor number 1 in the list.

W0206 08:12:41.408087 161093 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:12:41.409153 161093 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 768, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 768, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0206 08:13:55.283100 161149 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:13:55.284121 161149 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 768, 14, 199729],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 768, 14, 199729],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 199729 but got size 14 for tensor number 1 in the list.

W0206 08:15:09.157444 161190 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:15:09.158679 161190 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 768, 14, 199729],"float32"),Tensor([2, 32, 14, 199729],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 768, 14, 199729],"float32"),Tensor([2, 32, 14, 199729],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000019GB memory on GPU 0, 67.913025GB memory has been allocated and available memory is only 11.271851GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 08:16:40.449822 161233 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:16:40.450701 161233 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 768, 14, 199729],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 768, 14, 199729],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 199729 but got size 14 for tensor number 1 in the list.

W0206 08:17:51.852100 161289 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:17:51.853284 161289 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 768, 14, 199729],"float32"),Tensor([2, 48, 14, 199729],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 768, 14, 199729],"float32"),Tensor([2, 48, 14, 199729],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000019GB memory on GPU 0, 68.580994GB memory has been allocated and available memory is only 10.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 08:19:29.949795 161330 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:19:29.950699 161330 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 768, 199729, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 768, 199729, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 199729 but got size 14 for tensor number 1 in the list.

W0206 08:20:54.586155 161372 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:20:54.587363 161372 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 768, 199729, 14],"float32"),Tensor([2, 32, 199729, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 768, 199729, 14],"float32"),Tensor([2, 32, 199729, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000019GB memory on GPU 0, 67.913025GB memory has been allocated and available memory is only 11.271851GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 08:22:40.085274 161414 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:22:40.086620 161414 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 768, 199729, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 768, 199729, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 199729 but got size 14 for tensor number 1 in the list.

W0206 08:23:49.236426 161470 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:23:49.237810 161470 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 768, 199729, 14],"float32"),Tensor([2, 48, 199729, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 768, 199729, 14],"float32"),Tensor([2, 48, 199729, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000019GB memory on GPU 0, 68.580994GB memory has been allocated and available memory is only 10.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 08:25:22.184311 161525 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:25:22.185213 161525 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 768, 399458, 7],"float32"),Tensor([2, 32, 399458, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 768, 399458, 7],"float32"),Tensor([2, 32, 399458, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000019GB memory on GPU 0, 67.913025GB memory has been allocated and available memory is only 11.271851GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 08:26:50.499717 161595 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:26:50.500752 161595 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 768, 399458, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 768, 399458, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 399458 but got size 7 for tensor number 1 in the list.

W0206 08:28:01.599252 161662 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:28:01.600414 161662 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 768, 7, 399458],"float32"),Tensor([2, 32, 7, 399458],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 768, 7, 399458],"float32"),Tensor([2, 32, 7, 399458],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000019GB memory on GPU 0, 67.913025GB memory has been allocated and available memory is only 11.271851GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 08:29:34.912592 161708 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:29:34.913551 161708 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 768, 7, 399458],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 768, 7, 399458],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 399458 but got size 7 for tensor number 1 in the list.

W0206 08:30:59.556631 161777 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:30:59.557858 161777 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 768, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 768, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 08:32:20.822202 161861 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:32:20.823335 161861 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 768, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 768, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 08:33:41.853596 161918 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:33:41.854840 161918 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 768, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 768, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 08:35:17.783787 161973 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:35:17.784727 161973 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 768, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 768, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0206 08:36:32.452977 162043 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:36:32.454154 162043 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 8, 128, 2097152],"float16"),Tensor([2, 8, 1, 2097152],"float16"),], axis=2, )
[Pass] paddle.concat(list[Tensor([2, 8, 128, 2097152],"float16"),Tensor([2, 8, 1, 2097152],"float16"),], axis=2, )

W0206 08:38:12.238452 162086 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:38:12.239566 162086 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 8, 128, 2097152],"float16"),Tensor([2, 8, 1, 64],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 8, 128, 2097152],"float16"),Tensor([2, 8, 1, 64],"float16"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 2097152 but got size 64 for tensor number 1 in the list.

W0206 08:47:27.847231 162408 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:47:27.848256 162408 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 8, 128, 64],"float16"),Tensor([2, 33554432, 1, 64],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 8, 128, 64],"float16"),Tensor([2, 33554432, 1, 64],"float16"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 8 but got size 33554432 for tensor number 1 in the list.

W0206 08:49:10.187646 162479 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:49:10.188943 162479 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 8, 128, 64],"float16"),Tensor([2, 8, 1, 268435456],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 8, 128, 64],"float16"),Tensor([2, 8, 1, 268435456],"float16"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 64 but got size 268435456 for tensor number 1 in the list.

W0206 08:50:45.475534 162562 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:50:45.476754 162562 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 8, 128, 64],"float16"),Tensor([2, 8, 4194304, 64],"float16"),], axis=2, )
[Pass] paddle.concat(list[Tensor([2, 8, 128, 64],"float16"),Tensor([2, 8, 4194304, 64],"float16"),], axis=2, )

W0206 08:52:19.963719 162618 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 08:52:19.964679 162618 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 8, 128, 64],"float16"),Tensor([8388608, 8, 1, 64],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 8, 128, 64],"float16"),Tensor([8388608, 8, 1, 64],"float16"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 2 but got size 8388608 for tensor number 1 in the list.

W0206 09:01:22.368636 162845 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:01:22.369869 162845 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 268435456],"float32"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 268435456],"float32"),], axis=2, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 96399 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 09:03:41.830284 162874 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:03:41.831408 162874 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 8],"float32"),], axis=2, )
[paddle error] paddle.concat(list[Tensor([2, 8, 268435456],"float32"),Tensor([2, 8, 8],"float32"),], axis=2, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 09:05:13.023751 162930 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:05:13.024590 162930 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 8, 4194304, 64],"float16"),Tensor([2, 8, 1, 64],"float16"),], axis=2, )
[Pass] paddle.concat(list[Tensor([2, 8, 4194304, 64],"float16"),Tensor([2, 8, 1, 64],"float16"),], axis=2, )

W0206 09:06:48.809880 162971 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:06:48.810784 162971 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 8, 4194304, 64],"float16"),Tensor([2, 8, 4194304, 64],"float16"),], axis=2, )
[paddle error] paddle.concat(list[Tensor([2, 8, 4194304, 64],"float16"),Tensor([2, 8, 4194304, 64],"float16"),], axis=2, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000000GB memory on GPU 0, 74.575134GB memory has been allocated and available memory is only 4.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 09:17:41.023483 163220 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:17:41.024363 163220 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 8, 4194304, 64],"float16"),Tensor([2, 8, 64, 64],"float16"),], axis=2, )
[Pass] paddle.concat(list[Tensor([2, 8, 4194304, 64],"float16"),Tensor([2, 8, 64, 64],"float16"),], axis=2, )

W0206 09:19:13.707726 163333 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:19:13.708529 163333 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 8, 64, 4194304],"float16"),Tensor([2, 8, 1, 4194304],"float16"),], axis=2, )
[Pass] paddle.concat(list[Tensor([2, 8, 64, 4194304],"float16"),Tensor([2, 8, 1, 4194304],"float16"),], axis=2, )

W0206 09:28:16.739212 163572 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:28:16.740092 163572 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 8, 64, 4194304],"float16"),Tensor([2, 8, 1, 64],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 8, 64, 4194304],"float16"),Tensor([2, 8, 1, 64],"float16"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 4194304 but got size 64 for tensor number 1 in the list.

W0206 09:37:17.462942 163755 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:37:17.463968 163755 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 8, 64, 4194304],"float16"),Tensor([2, 8, 64, 4194304],"float16"),], axis=2, )
[paddle error] paddle.concat(list[Tensor([2, 8, 64, 4194304],"float16"),Tensor([2, 8, 64, 4194304],"float16"),], axis=2, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000000GB memory on GPU 0, 74.575134GB memory has been allocated and available memory is only 4.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 09:40:24.373502   995 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:40:24.374378   995 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 8, 64, 4194304],"float16"),Tensor([2, 8, 64, 64],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 8, 64, 4194304],"float16"),Tensor([2, 8, 64, 64],"float16"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 4194304 but got size 64 for tensor number 1 in the list.

W0206 09:41:48.667927  1894 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:41:48.669448  1894 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 8, 64, 64],"float16"),Tensor([131072, 8, 64, 64],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 8, 64, 64],"float16"),Tensor([131072, 8, 64, 64],"float16"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 2 but got size 131072 for tensor number 1 in the list.

W0206 09:43:16.423041  2312 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:43:16.424099  2312 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 8, 64, 64],"float16"),Tensor([2, 33554432, 1, 64],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 8, 64, 64],"float16"),Tensor([2, 33554432, 1, 64],"float16"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 8 but got size 33554432 for tensor number 1 in the list.

W0206 09:44:44.945487  2738 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:44:44.946501  2738 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 8, 64, 64],"float16"),Tensor([2, 524288, 64, 64],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 8, 64, 64],"float16"),Tensor([2, 524288, 64, 64],"float16"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 8 but got size 524288 for tensor number 1 in the list.

W0206 09:46:26.396061  3160 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:46:26.397285  3160 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 8, 64, 64],"float16"),Tensor([2, 8, 1, 268435456],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 8, 64, 64],"float16"),Tensor([2, 8, 1, 268435456],"float16"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 64 but got size 268435456 for tensor number 1 in the list.

W0206 09:47:53.870332  3635 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:47:53.871366  3635 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 8, 64, 64],"float16"),Tensor([2, 8, 4194304, 64],"float16"),], axis=2, )
[Pass] paddle.concat(list[Tensor([2, 8, 64, 64],"float16"),Tensor([2, 8, 4194304, 64],"float16"),], axis=2, )

W0206 09:49:35.321817  4039 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:49:35.322758  4039 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 8, 64, 64],"float16"),Tensor([2, 8, 64, 4194304],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 8, 64, 64],"float16"),Tensor([2, 8, 64, 4194304],"float16"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 64 but got size 4194304 for tensor number 1 in the list.

W0206 09:58:45.062544  6729 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 09:58:45.063757  6729 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 8, 64, 64],"float16"),Tensor([8388608, 8, 1, 64],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 8, 64, 64],"float16"),Tensor([8388608, 8, 1, 64],"float16"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 2 but got size 8388608 for tensor number 1 in the list.

W0206 10:00:12.754657  7154 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:00:12.755731  7154 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 8, 8],"float32"),Tensor([2, 268435456, 8],"float32"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 8, 8],"float32"),Tensor([2, 268435456, 8],"float32"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 8 but got size 268435456 for tensor number 1 in the list.

W0206 10:01:33.745234  7594 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:01:33.746405  7594 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 268435456],"float32"),], axis=2, )
[paddle error] paddle.concat(list[Tensor([2, 8, 8],"float32"),Tensor([2, 8, 268435456],"float32"),], axis=2, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 10:03:03.498332  8015 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:03:03.499230  8015 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),], axis=2, )
[torch error] paddle.concat(list[Tensor([2, 8, 8],"float32"),Tensor([67108864, 8, 8],"float32"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 2 but got size 67108864 for tensor number 1 in the list.

W0206 10:04:14.481954  8359 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:04:14.483222  8359 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 800, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 800, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 10:05:51.551079  8782 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:05:51.552000  8782 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 800, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 800, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 10:07:01.677181  9245 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:07:01.678217  9245 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 800, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 800, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 10:08:16.090613  9657 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:08:16.091607  9657 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 800, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 800, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0206 10:09:36.253844 10013 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:09:36.254966 10013 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 800, 14, 191740],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 800, 14, 191740],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 191740 but got size 14 for tensor number 1 in the list.

W0206 10:10:53.510298 10437 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:10:53.511438 10437 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 800, 14, 191740],"float32"),Tensor([2, 32, 14, 191740],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 800, 14, 191740],"float32"),Tensor([2, 32, 14, 191740],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000032GB memory on GPU 0, 67.858337GB memory has been allocated and available memory is only 11.326538GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 10:12:31.140714 10775 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:12:31.141695 10775 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 800, 191740, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 800, 191740, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 191740 but got size 14 for tensor number 1 in the list.

W0206 10:13:40.603089 11241 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:13:40.605603 11241 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 800, 191740, 14],"float32"),Tensor([2, 32, 191740, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 800, 191740, 14],"float32"),Tensor([2, 32, 191740, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000032GB memory on GPU 0, 67.858337GB memory has been allocated and available memory is only 11.326538GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 10:15:25.776955 11651 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:15:25.778923 11651 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 800, 383480, 7],"float32"),Tensor([2, 32, 383480, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 800, 383480, 7],"float32"),Tensor([2, 32, 383480, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000032GB memory on GPU 0, 67.858337GB memory has been allocated and available memory is only 11.326538GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 10:16:55.595381 12140 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:16:55.597870 12140 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 800, 383480, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 800, 383480, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 383480 but got size 7 for tensor number 1 in the list.

W0206 10:18:09.826174 12606 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:18:09.828807 12606 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 800, 7, 383480],"float32"),Tensor([2, 32, 7, 383480],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 800, 7, 383480],"float32"),Tensor([2, 32, 7, 383480],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000032GB memory on GPU 0, 67.858337GB memory has been allocated and available memory is only 11.326538GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 10:19:48.353096 13040 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:19:48.355567 13040 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 800, 7, 383480],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 800, 7, 383480],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 383480 but got size 7 for tensor number 1 in the list.

W0206 10:21:00.016291 13513 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:21:00.017452 13513 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 800, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 800, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 10:22:15.148213 13835 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:22:15.149258 13835 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 800, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 800, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 10:23:31.088789 14252 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:23:31.090128 14252 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 800, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 800, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 10:25:01.233983 14668 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:25:01.234903 14668 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 800, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 800, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0206 10:26:12.047880 15003 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:26:12.049031 15003 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 816, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 816, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 10:27:44.355439 15420 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:27:44.356323 15420 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 816, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 816, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 3195661 for tensor number 1 in the list.

W0206 10:28:50.940402 15871 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:28:50.941346 15871 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 816, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 816, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 3195661 for tensor number 1 in the list.

W0206 10:30:04.130267 16188 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:30:04.131371 16188 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 816, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 816, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 456523 for tensor number 1 in the list.

W0206 10:31:17.926463 16603 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:31:17.927429 16603 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 816, 14, 187981],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 816, 14, 187981],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 187981 but got size 14 for tensor number 1 in the list.

W0206 10:32:40.424479 16944 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:32:40.425912 16944 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 816, 14, 187981],"float32"),Tensor([2, 48, 14, 187981],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 816, 14, 187981],"float32"),Tensor([2, 48, 14, 187981],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000084GB memory on GPU 0, 68.459900GB memory has been allocated and available memory is only 10.724976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 10:34:13.170496 17363 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:34:13.172942 17363 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 816, 187981, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 816, 187981, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 187981 but got size 14 for tensor number 1 in the list.

W0206 10:35:30.188095 17817 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:35:30.195686 17817 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 816, 187981, 14],"float32"),Tensor([2, 48, 187981, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 816, 187981, 14],"float32"),Tensor([2, 48, 187981, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000084GB memory on GPU 0, 68.459900GB memory has been allocated and available memory is only 10.724976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 10:37:23.549927 18166 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:37:23.550901 18166 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 832, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 832, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 10:38:49.214677 18769 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:38:49.216113 18769 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 832, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 832, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 10:39:58.586942 19199 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:39:58.588059 19199 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 832, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 832, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 10:41:14.065548 19556 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:41:14.066439 19556 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 832, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 832, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0206 10:42:35.634451 19967 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:42:35.635537 19967 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 832, 14, 184366],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 832, 14, 184366],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 184366 but got size 14 for tensor number 1 in the list.

W0206 10:44:00.256067 20424 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:44:00.257179 20424 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 832, 14, 184366],"float32"),Tensor([2, 32, 14, 184366],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 832, 14, 184366],"float32"),Tensor([2, 32, 14, 184366],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000086GB memory on GPU 0, 67.811462GB memory has been allocated and available memory is only 11.373413GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 10:45:36.034521 20854 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:45:36.038724 20854 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 832, 184366, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 832, 184366, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 184366 but got size 14 for tensor number 1 in the list.

W0206 10:47:37.610612 21337 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:47:37.612453 21337 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 832, 184366, 14],"float32"),Tensor([2, 32, 184366, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 832, 184366, 14],"float32"),Tensor([2, 32, 184366, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000086GB memory on GPU 0, 67.811462GB memory has been allocated and available memory is only 11.373413GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 10:50:13.465549 21909 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:50:13.467105 21909 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 832, 368731, 7],"float32"),Tensor([2, 32, 368731, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 832, 368731, 7],"float32"),Tensor([2, 32, 368731, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000042GB memory on GPU 0, 67.811462GB memory has been allocated and available memory is only 11.373413GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 10:52:42.548875 22613 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:52:42.550527 22613 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 832, 368731, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 832, 368731, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 368731 but got size 7 for tensor number 1 in the list.

W0206 10:54:38.019135 23302 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:54:38.020820 23302 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 832, 7, 368731],"float32"),Tensor([2, 32, 7, 368731],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 832, 7, 368731],"float32"),Tensor([2, 32, 7, 368731],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000042GB memory on GPU 0, 67.811462GB memory has been allocated and available memory is only 11.373413GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 10:56:56.648710 23847 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:56:56.649698 23847 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 832, 7, 368731],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 832, 7, 368731],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 368731 but got size 7 for tensor number 1 in the list.

W0206 10:58:14.503154 24433 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:58:14.504662 24433 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 832, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 832, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 10:59:40.206712 24837 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 10:59:40.207909 24837 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 832, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 832, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 11:01:02.208809 25274 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:01:02.210191 25274 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 832, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 832, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 11:02:40.864441 25677 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:02:40.865413 25677 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 832, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 832, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0206 11:03:58.989130 26113 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:03:58.990336 26113 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 85899346, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 85899346, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 11:05:32.329475 26445 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:05:32.330404 26445 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 85899346, 5, 5],"float32"),Tensor([2, 384, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 85899346, 5, 5],"float32"),Tensor([2, 384, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 11:07:05.724368 26899 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:07:05.725534 26899 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 85899346, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 85899346, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 11:08:35.352048 27434 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:08:35.353197 27434 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 85899346, 5, 5],"float32"),Tensor([2, 85899346, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 85899346, 5, 5],"float32"),Tensor([2, 85899346, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 77740 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:10:47.094754 27874 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:10:47.095803 27874 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 85899346, 5, 5],"float32"),Tensor([2, 85899346, 5, 5],"float32"),Tensor([2, 85899346, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 85899346, 5, 5],"float32"),Tensor([2, 85899346, 5, 5],"float32"),Tensor([2, 85899346, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 19460 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:14:14.129823 28466 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:14:14.130931 28466 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 85899346, 5, 5],"float32"),Tensor([2, 85899346, 5, 5],"float32"),Tensor([2, 85899346, 5, 5],"float32"),Tensor([2, 85899346, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 85899346, 5, 5],"float32"),Tensor([2, 85899346, 5, 5],"float32"),Tensor([2, 85899346, 5, 5],"float32"),Tensor([2, 85899346, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 17835 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:17:33.815382 29474 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:17:33.816510 29474 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 864, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 864, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 11:19:10.666687 30419 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:19:10.667630 30419 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 864, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 864, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 11:20:20.399256 30855 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:20:20.400264 30855 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 864, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 864, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 11:21:36.252444 31168 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:21:36.253333 31168 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 864, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 864, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 3195661 for tensor number 1 in the list.

W0206 11:22:59.091392 31576 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:22:59.092533 31576 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 864, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 864, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 3195661 for tensor number 1 in the list.

W0206 11:24:14.702442 31986 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:24:14.703476 31986 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 864, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 864, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 456523 for tensor number 1 in the list.

W0206 11:25:29.011598 32291 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:25:29.012492 32291 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 864, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 864, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0206 11:26:43.026062 32598 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:26:43.027122 32598 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 864, 14, 177537],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 864, 14, 177537],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 177537 but got size 14 for tensor number 1 in the list.

W0206 11:27:59.540028 32996 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:27:59.541132 32996 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 864, 14, 177537],"float32"),Tensor([2, 32, 14, 177537],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 864, 14, 177537],"float32"),Tensor([2, 32, 14, 177537],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 67.764587GB memory has been allocated and available memory is only 11.420288GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 11:29:41.427639 33305 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:29:41.428954 33305 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 864, 14, 177537],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 864, 14, 177537],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 177537 but got size 14 for tensor number 1 in the list.

W0206 11:30:53.094959 33859 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:30:53.096356 33859 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 864, 14, 177537],"float32"),Tensor([2, 48, 14, 177537],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 864, 14, 177537],"float32"),Tensor([2, 48, 14, 177537],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 68.358337GB memory has been allocated and available memory is only 10.826538GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 11:32:28.220039 34188 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:32:28.222869 34188 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 864, 177537, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 864, 177537, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 177537 but got size 14 for tensor number 1 in the list.

W0206 11:33:37.904304 34616 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:33:37.905525 34616 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 864, 177537, 14],"float32"),Tensor([2, 32, 177537, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 864, 177537, 14],"float32"),Tensor([2, 32, 177537, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 67.764587GB memory has been allocated and available memory is only 11.420288GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 11:35:17.980360 35012 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:35:17.981251 35012 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 864, 177537, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 864, 177537, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 177537 but got size 14 for tensor number 1 in the list.

W0206 11:36:27.937153 35425 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:36:27.938421 35425 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 864, 177537, 14],"float32"),Tensor([2, 48, 177537, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 864, 177537, 14],"float32"),Tensor([2, 48, 177537, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 68.358337GB memory has been allocated and available memory is only 10.826538GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 11:38:00.893831 35762 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:38:00.894747 35762 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 864, 355074, 7],"float32"),Tensor([2, 32, 355074, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 864, 355074, 7],"float32"),Tensor([2, 32, 355074, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 67.764587GB memory has been allocated and available memory is only 11.420288GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 11:39:36.895505 36190 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:39:36.896306 36190 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 864, 355074, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 864, 355074, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 355074 but got size 7 for tensor number 1 in the list.

W0206 11:40:46.775223 36703 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:40:46.777256 36703 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 864, 7, 355074],"float32"),Tensor([2, 32, 7, 355074],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 864, 7, 355074],"float32"),Tensor([2, 32, 7, 355074],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 67.764587GB memory has been allocated and available memory is only 11.420288GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 11:42:19.643445 37015 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:42:19.644273 37015 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 864, 7, 355074],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 864, 7, 355074],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 355074 but got size 7 for tensor number 1 in the list.

W0206 11:43:30.093040 37439 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:43:30.094126 37439 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 864, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 864, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 11:44:42.759035 37751 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:44:42.760105 37751 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 864, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 864, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 11:46:04.658269 38143 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:46:04.659353 38143 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 864, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 864, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 11:47:35.204502 38561 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:47:35.205389 38561 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 864, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 864, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0206 11:48:44.658246 38985 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:48:44.659178 38985 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 88, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 88, 28, 28],"float32"),Tensor([2, 2739138, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000004GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 11:50:16.557441 39310 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:50:16.558456 39310 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 88, 28, 28],"float32"),Tensor([2, 88, 28, 871544],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 88, 28, 28],"float32"),Tensor([2, 88, 28, 871544],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 871544 for tensor number 1 in the list.

W0206 11:51:26.109205 39722 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:51:26.110343 39722 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 88, 28, 28],"float32"),Tensor([2, 88, 871544, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 88, 28, 28],"float32"),Tensor([2, 88, 871544, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28 but got size 871544 for tensor number 1 in the list.

W0206 11:52:46.933120 40034 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:52:46.934281 40034 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 88, 28, 28],"float32"),Tensor([62254, 88, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 88, 28, 28],"float32"),Tensor([62254, 88, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 62254 for tensor number 1 in the list.

W0206 11:54:03.845178 40452 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:54:03.846264 40452 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 88, 28, 871544],"float32"),Tensor([2, 88, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 88, 28, 871544],"float32"),Tensor([2, 88, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 871544 but got size 28 for tensor number 1 in the list.

W0206 11:55:28.260579 40850 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:55:28.261545 40850 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 88, 28, 871544],"float32"),Tensor([2, 88, 28, 871544],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 88, 28, 871544],"float32"),Tensor([2, 88, 28, 871544],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 109309 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 11:57:53.467525 41200 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:57:53.468537 41200 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 88, 871544, 28],"float32"),Tensor([2, 88, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 88, 871544, 28],"float32"),Tensor([2, 88, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 871544 but got size 28 for tensor number 1 in the list.

W0206 11:59:12.874715 41893 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 11:59:12.875813 41893 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 88, 871544, 28],"float32"),Tensor([2, 88, 871544, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 88, 871544, 28],"float32"),Tensor([2, 88, 871544, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 128761 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:01:30.530920 42297 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:01:30.531927 42297 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 896, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 896, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 12:03:02.190985 42966 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:03:02.192077 42966 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 896, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 896, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 12:04:18.728608 43296 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:04:18.729755 43296 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 896, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 896, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 12:05:32.028081 43700 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:05:32.029202 43700 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 896, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 896, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0206 12:06:54.028082 44092 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:06:54.029331 44092 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 896, 14, 171197],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 896, 14, 171197],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 171197 but got size 14 for tensor number 1 in the list.

W0206 12:08:09.771546 44444 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:08:09.772807 44444 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 896, 14, 171197],"float32"),Tensor([2, 32, 14, 171197],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 896, 14, 171197],"float32"),Tensor([2, 32, 14, 171197],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000086GB memory on GPU 0, 67.721619GB memory has been allocated and available memory is only 11.463257GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 12:09:43.526355 44828 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:09:43.529095 44828 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 896, 171197, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 896, 171197, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 171197 but got size 14 for tensor number 1 in the list.

W0206 12:10:55.533047 45245 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:10:55.534210 45245 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 896, 171197, 14],"float32"),Tensor([2, 32, 171197, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 896, 171197, 14],"float32"),Tensor([2, 32, 171197, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000086GB memory on GPU 0, 67.721619GB memory has been allocated and available memory is only 11.463257GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 12:12:25.278440 45557 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:12:25.279345 45557 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 896, 342393, 7],"float32"),Tensor([2, 32, 342393, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 896, 342393, 7],"float32"),Tensor([2, 32, 342393, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000039GB memory on GPU 0, 67.721619GB memory has been allocated and available memory is only 11.463257GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 12:13:57.657950 45962 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:13:57.658862 45962 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 896, 342393, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 896, 342393, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 342393 but got size 7 for tensor number 1 in the list.

W0206 12:15:08.542400 46386 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:15:08.543648 46386 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 896, 7, 342393],"float32"),Tensor([2, 32, 7, 342393],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 896, 7, 342393],"float32"),Tensor([2, 32, 7, 342393],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000039GB memory on GPU 0, 67.721619GB memory has been allocated and available memory is only 11.463257GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 12:16:40.683938 46783 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:16:40.684948 46783 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 896, 7, 342393],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 896, 7, 342393],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 342393 but got size 7 for tensor number 1 in the list.

W0206 12:17:51.287778 47201 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:17:51.288745 47201 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 896, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 896, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 12:19:08.457585 47529 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:19:08.458624 47529 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 896, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 896, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 12:20:22.888412 47934 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:20:22.889509 47934 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 896, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 896, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 12:21:53.230638 48254 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:21:53.231714 48254 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 896, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 896, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0206 12:23:03.958845 48692 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:23:03.959972 48692 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 912, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 912, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 12:24:40.593262 49099 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:24:40.594219 49099 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 912, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 912, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 3195661 for tensor number 1 in the list.

W0206 12:25:50.677625 49536 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:25:50.678669 49536 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 912, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 912, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 3195661 for tensor number 1 in the list.

W0206 12:27:10.174458 49875 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:27:10.175679 49875 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 912, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 912, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 456523 for tensor number 1 in the list.

W0206 12:28:24.813421 50295 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:28:24.814563 50295 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 912, 14, 168193],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 912, 14, 168193],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 168193 but got size 14 for tensor number 1 in the list.

W0206 12:29:45.049118 50611 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:29:45.050789 50611 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 912, 14, 168193],"float32"),Tensor([2, 48, 14, 168193],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 912, 14, 168193],"float32"),Tensor([2, 48, 14, 168193],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000034GB memory on GPU 0, 68.264587GB memory has been allocated and available memory is only 10.920288GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 12:31:24.784261 51042 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:31:24.786067 51042 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 912, 168193, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 912, 168193, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 168193 but got size 14 for tensor number 1 in the list.

W0206 12:32:36.715646 51480 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:32:36.717092 51480 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 912, 168193, 14],"float32"),Tensor([2, 48, 168193, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 912, 168193, 14],"float32"),Tensor([2, 48, 168193, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000034GB memory on GPU 0, 68.264587GB memory has been allocated and available memory is only 10.920288GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 12:34:11.611454 51897 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:34:11.612391 51897 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 928, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 928, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 12:35:37.735066 52346 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:35:37.735987 52346 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 928, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 928, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 12:36:52.594429 52777 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:36:52.595750 52777 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 928, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 928, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 12:38:08.229197 53124 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:38:08.230373 53124 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 928, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 928, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0206 12:39:23.342298 53541 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:39:23.343420 53541 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 928, 14, 165293],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 928, 14, 165293],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 165293 but got size 14 for tensor number 1 in the list.

W0206 12:40:41.654175 53853 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:40:41.655182 53853 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 928, 14, 165293],"float32"),Tensor([2, 32, 14, 165293],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 928, 14, 165293],"float32"),Tensor([2, 32, 14, 165293],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000022GB memory on GPU 0, 67.682556GB memory has been allocated and available memory is only 11.502319GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 12:42:16.207971 54270 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:42:16.208910 54270 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 928, 165293, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 928, 165293, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 165293 but got size 14 for tensor number 1 in the list.

W0206 12:43:27.561338 54701 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:43:27.562448 54701 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 928, 165293, 14],"float32"),Tensor([2, 32, 165293, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 928, 165293, 14],"float32"),Tensor([2, 32, 165293, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000022GB memory on GPU 0, 67.682556GB memory has been allocated and available memory is only 11.502319GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 12:45:01.882378 55019 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:45:01.883262 55019 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 928, 330586, 7],"float32"),Tensor([2, 32, 330586, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 928, 330586, 7],"float32"),Tensor([2, 32, 330586, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000022GB memory on GPU 0, 67.682556GB memory has been allocated and available memory is only 11.502319GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 12:46:34.440857 55449 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:46:34.441890 55449 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 928, 330586, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 928, 330586, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 330586 but got size 7 for tensor number 1 in the list.

W0206 12:47:49.369325 55890 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:47:49.370517 55890 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 928, 7, 330586],"float32"),Tensor([2, 32, 7, 330586],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 928, 7, 330586],"float32"),Tensor([2, 32, 7, 330586],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000022GB memory on GPU 0, 67.682556GB memory has been allocated and available memory is only 11.502319GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 12:49:26.005184 56323 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:49:26.007869 56323 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 928, 7, 330586],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 928, 7, 330586],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 330586 but got size 7 for tensor number 1 in the list.

W0206 12:50:42.656605 56750 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:50:42.657730 56750 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 928, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 928, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 12:51:59.022652 57161 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:51:59.023929 57161 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 928, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 928, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 12:53:18.674412 57491 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:53:18.675473 57491 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 928, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 928, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 12:54:49.242170 57896 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:54:49.243052 57896 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 928, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 928, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0206 12:55:58.959246 58327 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:55:58.960294 58327 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 96, 3195661, 7],"float32"),Tensor([2, 96, 3195661, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 96, 3195661, 7],"float32"),Tensor([2, 96, 3195661, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 102653 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 12:58:13.707859 58651 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:58:13.709909 58651 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 96, 3195661, 7],"float32"),Tensor([2, 96, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 96, 3195661, 7],"float32"),Tensor([2, 96, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 3195661 but got size 7 for tensor number 1 in the list.

W0206 12:59:29.454918 59335 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 12:59:29.456045 59335 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 96, 399458, 56],"float32"),Tensor([2, 32, 399458, 56],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 96, 399458, 56],"float32"),Tensor([2, 32, 399458, 56],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000019GB memory on GPU 0, 77.245056GB memory has been allocated and available memory is only 1.939819GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 13:01:19.429692 59660 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:01:19.430532 59660 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 96, 399458, 56],"float32"),Tensor([2, 32, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 96, 399458, 56],"float32"),Tensor([2, 32, 56, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 399458 but got size 56 for tensor number 1 in the list.

W0206 13:02:39.265065 60205 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:02:39.266125 60205 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 96, 399458, 56],"float32"),Tensor([2, 48, 399458, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 96, 399458, 56],"float32"),Tensor([2, 48, 399458, 56],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 24.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 21.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 78347 has 24.99 GiB memory in use. Of the allocated memory 24.00 GiB is allocated by PyTorch, and 3.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:04:30.827625 60636 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:04:30.828630 60636 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 96, 399458, 56],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 96, 399458, 56],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 399458 but got size 56 for tensor number 1 in the list.

W0206 13:05:46.208447 61185 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:05:46.210021 61185 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 96, 56, 399458],"float32"),Tensor([2, 32, 56, 399458],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 96, 56, 399458],"float32"),Tensor([2, 32, 56, 399458],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000019GB memory on GPU 0, 77.245056GB memory has been allocated and available memory is only 1.939819GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 13:07:41.059311 61506 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:07:41.060168 61506 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 96, 56, 399458],"float32"),Tensor([2, 32, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 96, 56, 399458],"float32"),Tensor([2, 32, 56, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 399458 but got size 56 for tensor number 1 in the list.

W0206 13:08:50.998440 62084 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:08:50.999366 62084 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 96, 56, 399458],"float32"),Tensor([2, 48, 56, 399458],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 96, 56, 399458],"float32"),Tensor([2, 48, 56, 399458],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 24.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 21.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 31245 has 24.99 GiB memory in use. Of the allocated memory 24.00 GiB is allocated by PyTorch, and 3.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:10:34.587522 62397 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:10:34.588522 62397 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 96, 56, 399458],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 96, 56, 399458],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 399458 but got size 56 for tensor number 1 in the list.

W0206 13:11:50.427703 62941 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:11:50.428784 62941 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 96, 56, 56],"float32"),Tensor([2, 32, 1198373, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 96, 56, 56],"float32"),Tensor([2, 32, 1198373, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 56 but got size 1198373 for tensor number 1 in the list.

W0206 13:13:11.409759 63259 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:13:11.410991 63259 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 96, 56, 56],"float32"),Tensor([2, 32, 56, 1198373],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 96, 56, 56],"float32"),Tensor([2, 32, 56, 1198373],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 56 but got size 1198373 for tensor number 1 in the list.

W0206 13:14:26.249094 63686 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:14:26.250301 63686 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 96, 56, 56],"float32"),Tensor([2, 48, 56, 798916],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 96, 56, 56],"float32"),Tensor([2, 48, 56, 798916],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 56 but got size 798916 for tensor number 1 in the list.

W0206 13:15:40.802276 63998 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:15:40.803340 63998 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 96, 56, 56],"float32"),Tensor([2, 48, 798916, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 96, 56, 56],"float32"),Tensor([2, 48, 798916, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 56 but got size 798916 for tensor number 1 in the list.

W0206 13:16:55.817911 64401 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:16:55.819097 64401 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 96, 56, 56],"float32"),Tensor([2, 684785, 56, 56],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 96, 56, 56],"float32"),Tensor([2, 684785, 56, 56],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000016GB memory on GPU 0, 66.604431GB memory has been allocated and available memory is only 12.580444GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 13:18:25.271378 64732 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:18:25.272259 64732 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 96, 56, 56],"float32"),Tensor([28533, 48, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 96, 56, 56],"float32"),Tensor([28533, 48, 56, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 28533 for tensor number 1 in the list.

W0206 13:19:37.505329 65158 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:19:37.506538 65158 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 96, 56, 56],"float32"),Tensor([42800, 32, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 96, 56, 56],"float32"),Tensor([42800, 32, 56, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 42800 for tensor number 1 in the list.

W0206 13:20:51.959586 65575 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:20:51.960646 65575 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 96, 7, 3195661],"float32"),Tensor([2, 96, 7, 3195661],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 96, 7, 3195661],"float32"),Tensor([2, 96, 7, 3195661],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 89090 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 13:23:05.803882 65887 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:23:05.804880 65887 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 96, 7, 3195661],"float32"),Tensor([2, 96, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 96, 7, 3195661],"float32"),Tensor([2, 96, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 3195661 but got size 7 for tensor number 1 in the list.

W0206 13:24:22.087143 66588 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:24:22.088466 66588 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 96, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 96, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 13:25:56.763309 66907 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:25:56.764278 66907 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 96, 7, 7],"float32"),Tensor([2, 96, 3195661, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 96, 7, 7],"float32"),Tensor([2, 96, 3195661, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 3195661 for tensor number 1 in the list.

W0206 13:27:12.071872 67340 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:27:12.073263 67340 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 96, 7, 7],"float32"),Tensor([2, 96, 7, 3195661],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 96, 7, 7],"float32"),Tensor([2, 96, 7, 3195661],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 3195661 for tensor number 1 in the list.

W0206 13:28:31.622951 67760 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:28:31.624095 67760 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 96, 7, 7],"float32"),Tensor([913046, 96, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 96, 7, 7],"float32"),Tensor([913046, 96, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 913046 for tensor number 1 in the list.

W0206 13:29:52.609618 68183 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:29:52.610733 68183 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 960, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 960, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 13:31:23.657213 68521 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:31:23.658133 68521 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 960, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 960, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 13:32:33.589411 68932 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:32:33.590453 68932 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 960, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 960, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 13:33:51.410866 69351 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:33:51.412212 69351 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 960, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 960, 14, 14],"float32"),Tensor([2, 48, 14, 3195661],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 3195661 for tensor number 1 in the list.

W0206 13:35:07.901805 69682 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:35:07.903129 69682 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 960, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 960, 14, 14],"float32"),Tensor([2, 48, 3195661, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 3195661 for tensor number 1 in the list.

W0206 13:36:22.267910 70100 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:36:22.269110 70100 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 960, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 960, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 456523 for tensor number 1 in the list.

W0206 13:37:37.501253 70429 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:37:37.502362 70429 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 960, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 960, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0206 13:38:59.200399 70861 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:38:59.201649 70861 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 960, 14, 159784],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 960, 14, 159784],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 159784 but got size 14 for tensor number 1 in the list.

W0206 13:40:27.879830 71192 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:40:27.880797 71192 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 960, 14, 159784],"float32"),Tensor([2, 32, 14, 159784],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 960, 14, 159784],"float32"),Tensor([2, 32, 14, 159784],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000099GB memory on GPU 0, 67.647400GB memory has been allocated and available memory is only 11.537476GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 13:42:00.443405 71637 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:42:00.444330 71637 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 960, 14, 159784],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 960, 14, 159784],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 159784 but got size 14 for tensor number 1 in the list.

W0206 13:43:17.876024 72083 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:43:17.876981 72083 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 960, 14, 159784],"float32"),Tensor([2, 48, 14, 159784],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 960, 14, 159784],"float32"),Tensor([2, 48, 14, 159784],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000099GB memory on GPU 0, 68.178650GB memory has been allocated and available memory is only 11.006226GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 13:44:52.961094 72506 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:44:52.962538 72506 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 960, 159784, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 960, 159784, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 159784 but got size 14 for tensor number 1 in the list.

W0206 13:46:04.016759 72938 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:46:04.017933 72938 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 960, 159784, 14],"float32"),Tensor([2, 32, 159784, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 960, 159784, 14],"float32"),Tensor([2, 32, 159784, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000099GB memory on GPU 0, 67.647400GB memory has been allocated and available memory is only 11.537476GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 13:47:35.006156 73356 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:47:35.007059 73356 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 960, 159784, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 960, 159784, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 159784 but got size 14 for tensor number 1 in the list.

W0206 13:48:45.688443 73717 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:48:45.689787 73717 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 960, 159784, 14],"float32"),Tensor([2, 48, 159784, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 960, 159784, 14],"float32"),Tensor([2, 48, 159784, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000099GB memory on GPU 0, 68.178650GB memory has been allocated and available memory is only 11.006226GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 13:50:22.521159 74142 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:50:22.522078 74142 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 960, 319567, 7],"float32"),Tensor([2, 32, 319567, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 960, 319567, 7],"float32"),Tensor([2, 32, 319567, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000049GB memory on GPU 0, 67.647400GB memory has been allocated and available memory is only 11.537476GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 13:51:49.471586 74572 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:51:49.472477 74572 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 960, 319567, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 960, 319567, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 319567 but got size 7 for tensor number 1 in the list.

W0206 13:52:58.981535 75003 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:52:58.982743 75003 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 960, 7, 319567],"float32"),Tensor([2, 32, 7, 319567],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 960, 7, 319567],"float32"),Tensor([2, 32, 7, 319567],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000049GB memory on GPU 0, 67.647400GB memory has been allocated and available memory is only 11.537476GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 13:54:29.696723 75359 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:54:29.697651 75359 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 960, 7, 319567],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 960, 7, 319567],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 319567 but got size 7 for tensor number 1 in the list.

W0206 13:55:39.760396 75778 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:55:39.761699 75778 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 960, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 960, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 13:56:56.787882 76196 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:56:56.788980 76196 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 960, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 960, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 13:58:32.063412 76527 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 13:58:32.065608 76527 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 960, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 960, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 14:00:16.009474 77059 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:00:16.010983 77059 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 960, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 960, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0206 14:02:20.104879 77478 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:02:20.106945 77478 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 992, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 992, 14, 14],"float32"),Tensor([2, 10956550, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 14:04:55.917987 78045 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:04:55.919262 78045 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 992, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 992, 14, 14],"float32"),Tensor([2, 32, 14, 4793491],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 14:07:06.394411 78712 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:07:06.396116 78712 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 992, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 992, 14, 14],"float32"),Tensor([2, 32, 4793491, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 14 but got size 4793491 for tensor number 1 in the list.

W0206 14:08:49.754240 79358 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:08:49.755537 79358 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 992, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 992, 14, 14],"float32"),Tensor([684785, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 684785 for tensor number 1 in the list.

W0206 14:10:09.492305 79782 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:10:09.493764 79782 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 992, 14, 154629],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 992, 14, 154629],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 154629 but got size 14 for tensor number 1 in the list.

W0206 14:11:27.456655 80176 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:11:27.457823 80176 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 992, 14, 154629],"float32"),Tensor([2, 32, 14, 154629],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 992, 14, 154629],"float32"),Tensor([2, 32, 14, 154629],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 67.612244GB memory has been allocated and available memory is only 11.572632GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 14:13:02.173745 80491 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:13:02.174659 80491 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 992, 154629, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 992, 154629, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 154629 but got size 14 for tensor number 1 in the list.

W0206 14:14:13.489483 80891 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:14:13.491032 80891 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 992, 154629, 14],"float32"),Tensor([2, 32, 154629, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 992, 154629, 14],"float32"),Tensor([2, 32, 154629, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 67.612244GB memory has been allocated and available memory is only 11.572632GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 14:15:49.781387 81289 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:15:49.782361 81289 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 992, 309258, 7],"float32"),Tensor([2, 32, 309258, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 992, 309258, 7],"float32"),Tensor([2, 32, 309258, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 67.612244GB memory has been allocated and available memory is only 11.572632GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 14:17:19.302668 81728 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:17:19.303562 81728 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 992, 309258, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 992, 309258, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 309258 but got size 7 for tensor number 1 in the list.

W0206 14:18:35.231498 82154 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:18:35.232743 82154 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 992, 7, 309258],"float32"),Tensor([2, 32, 7, 309258],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 992, 7, 309258],"float32"),Tensor([2, 32, 7, 309258],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 67.612244GB memory has been allocated and available memory is only 11.572632GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 14:20:16.089942 82570 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:20:16.090901 82570 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 992, 7, 309258],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 992, 7, 309258],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 309258 but got size 7 for tensor number 1 in the list.

W0206 14:21:33.980015 83022 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:21:33.981094 83022 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 992, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 992, 7, 7],"float32"),Tensor([2, 32, 7, 9586981],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 14:22:53.207243 83441 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:22:53.208408 83441 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 992, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 992, 7, 7],"float32"),Tensor([2, 32, 9586981, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 7 but got size 9586981 for tensor number 1 in the list.

W0206 14:24:07.649498 83766 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:24:07.650651 83766 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 992, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2, 992, 7, 7],"float32"),Tensor([2, 43826197, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 14:25:45.750841 84178 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:25:45.751801 84178 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2, 992, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2, 992, 7, 7],"float32"),Tensor([2739138, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 2739138 for tensor number 1 in the list.

W0206 14:26:56.113664 84609 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:26:56.114673 84609 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2],"float64"),Tensor([2147483649],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([2],"float64"),Tensor([2147483649],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 14:28:09.868647 84928 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:28:09.869735 84928 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2],"int64"),Tensor([2147483649],"int64"),], -1, )
[paddle error] paddle.concat(list[Tensor([2],"int64"),Tensor([2147483649],"int64"),], -1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 14:29:10.873766 85323 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:29:10.874900 85323 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2],"int64"),Tensor([2147483649],"int64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([2],"int64"),Tensor([2147483649],"int64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 14:30:14.669857 85628 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:30:14.670782 85628 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([200],"float16"),Tensor([4294967295],"float16"),], )
[Pass] paddle.concat(list[Tensor([200],"float16"),Tensor([4294967295],"float16"),], )

W0206 14:31:51.840435 85936 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:31:51.841418 85936 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([200],"float32"),Tensor([4294967295],"float32"),], )
[paddle error] paddle.concat(list[Tensor([200],"float32"),Tensor([4294967295],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 14:40:57.552147 88464 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:40:57.553174 88464 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([200],"float64"),Tensor([2147483649],"float64"),], )
[paddle error] paddle.concat(list[Tensor([200],"float64"),Tensor([2147483649],"float64"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 14:42:05.318069 88912 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:42:05.318962 88912 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([200],"int32"),Tensor([4294967295],"int32"),], )
[paddle error] paddle.concat(list[Tensor([200],"int32"),Tensor([4294967295],"int32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 14:43:33.596474 89303 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:43:33.597399 89303 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([200],"int64"),Tensor([2147483649],"int64"),], )
[paddle error] paddle.concat(list[Tensor([200],"int64"),Tensor([2147483649],"int64"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 14:44:37.126931 89649 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:44:37.127837 89649 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([20141, 1088, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([20141, 1088, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 20141 but got size 2 for tensor number 1 in the list.

W0206 14:45:47.594343 90046 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:45:47.595395 90046 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([20141, 1088, 14, 14],"float32"),Tensor([20141, 32, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([20141, 1088, 14, 14],"float32"),Tensor([20141, 32, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000226GB memory on GPU 0, 67.520447GB memory has been allocated and available memory is only 11.664429GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 14:47:24.417714 90344 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:47:24.420275 90344 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2048, 2097152],"float32"),Tensor([2048, 2097152],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([2048, 2097152],"float32"),Tensor([2048, 2097152],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 82871 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 14:49:47.864768 90770 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:49:47.865965 90770 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2048, 2097152],"float32"),Tensor([2048, 64],"float32"),], axis=-1, )
[paddle error] paddle.concat(list[Tensor([2048, 2097152],"float32"),Tensor([2048, 64],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 14:51:22.438627 91469 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:51:22.452414 91469 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2048, 64],"float32"),Tensor([2048, 2097152],"float32"),], axis=-1, )
[paddle error] paddle.concat(list[Tensor([2048, 64],"float32"),Tensor([2048, 2097152],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 14:52:47.101986 91881 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:52:47.103169 91881 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2048, 64],"float32"),Tensor([67108864, 64],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([2048, 64],"float32"),Tensor([67108864, 64],"float32"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2048 but got size 67108864 for tensor number 1 in the list.

W0206 14:53:55.732614 92288 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:53:55.733599 92288 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([206489, 832, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([206489, 832, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 206489 but got size 1 for tensor number 1 in the list.

W0206 14:55:17.812173 92515 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:55:17.813278 92515 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([206489, 832, 5, 5],"float32"),Tensor([206489, 32, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([206489, 832, 5, 5],"float32"),Tensor([206489, 32, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000015GB memory on GPU 0, 67.811462GB memory has been allocated and available memory is only 11.373413GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 14:56:49.060956 92922 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:56:49.061931 92922 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([20752, 1056, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([20752, 1056, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 20752 but got size 2 for tensor number 1 in the list.

W0206 14:57:58.918949 93326 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:57:58.920306 93326 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([20752, 1056, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([20752, 1056, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 20752 but got size 2 for tensor number 1 in the list.

W0206 14:59:14.270419 93630 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 14:59:14.274878 93630 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([20752, 1056, 14, 14],"float32"),Tensor([20752, 32, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([20752, 1056, 14, 14],"float32"),Tensor([20752, 32, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000740GB memory on GPU 0, 67.549744GB memory has been allocated and available memory is only 11.635132GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 15:00:56.242515 94057 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:00:56.243508 94057 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([20752, 1056, 14, 14],"float32"),Tensor([20752, 48, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([20752, 1056, 14, 14],"float32"),Tensor([20752, 48, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000740GB memory on GPU 0, 68.034119GB memory has been allocated and available memory is only 11.150757GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 15:02:23.022485 94489 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:02:23.023339 94489 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2097152, 512, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2097152, 512, 2, 2],"float32"),Tensor([1, 32, 2, 2],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2097152 but got size 1 for tensor number 1 in the list.

W0206 15:03:33.412688 94914 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:03:33.414012 94914 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2097152, 512, 2, 2],"float32"),Tensor([2097152, 32, 2, 2],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2097152, 512, 2, 2],"float32"),Tensor([2097152, 32, 2, 2],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 68.575134GB memory has been allocated and available memory is only 10.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 15:05:07.754297 95340 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:05:07.755246 95340 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([21262215, 101],"float64"),Tensor([21262215, 101],"float64"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([21262215, 101],"float64"),Tensor([21262215, 101],"float64"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 113272 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:06:44.192464 95774 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:06:44.193492 95774 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([21262215, 101],"float64"),Tensor([4, 101],"float64"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([21262215, 101],"float64"),Tensor([4, 101],"float64"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 21262215 but got size 4 for tensor number 1 in the list.

W0206 15:07:36.141407 96238 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:07:36.142686 96238 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([21400, 1024, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([21400, 1024, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 21400 but got size 2 for tensor number 1 in the list.

W0206 15:08:55.294092 96515 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:08:55.295149 96515 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([21400, 1024, 14, 14],"float32"),Tensor([21400, 32, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([21400, 1024, 14, 14],"float32"),Tensor([21400, 32, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000366GB memory on GPU 0, 67.580994GB memory has been allocated and available memory is only 11.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 15:10:27.947451 96847 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:10:27.948406 96847 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([21400, 256, 28, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([21400, 256, 28, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 21400 but got size 2 for tensor number 1 in the list.

W0206 15:11:38.254484 97271 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:11:38.255514 97271 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([21400, 256, 28, 28],"float32"),Tensor([21400, 32, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([21400, 256, 28, 28],"float32"),Tensor([21400, 32, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000366GB memory on GPU 0, 70.580994GB memory has been allocated and available memory is only 8.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 15:13:27.502465 97668 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:13:27.503365 97668 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([21400, 64, 56, 56],"float32"),Tensor([2, 32, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([21400, 64, 56, 56],"float32"),Tensor([2, 32, 56, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 21400 but got size 2 for tensor number 1 in the list.

W0206 15:14:36.281900 98132 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:14:36.283654 98132 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([21400, 64, 56, 56],"float32"),Tensor([21400, 32, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([21400, 64, 56, 56],"float32"),Tensor([21400, 32, 56, 56],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 24.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 21.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 93325 has 24.99 GiB memory in use. Of the allocated memory 24.00 GiB is allocated by PyTorch, and 3.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:16:21.362900 98544 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:16:21.364027 98544 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483648, 1, 2],"float32"),Tensor([1, 1, 2],"float32"),], axis=-2, )
[torch error] paddle.concat(list[Tensor([2147483648, 1, 2],"float32"),Tensor([1, 1, 2],"float32"),], axis=-2, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2147483648 but got size 1 for tensor number 1 in the list.

W0206 15:17:35.839948 99009 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:17:35.841145 99009 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483648, 1, 2],"float32"),Tensor([2, 1, 2],"float32"),], axis=-2, )
[torch error] paddle.concat(list[Tensor([2147483648, 1, 2],"float32"),Tensor([2, 1, 2],"float32"),], axis=-2, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2147483648 but got size 2 for tensor number 1 in the list.

W0206 15:18:52.332832 99402 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:18:52.334199 99402 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483648, 1, 2],"float32"),Tensor([2147483648, 1, 2],"float32"),], axis=-2, )
[torch error] paddle.concat(list[Tensor([2147483648, 1, 2],"float32"),Tensor([2147483648, 1, 2],"float32"),], axis=-2, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 133297 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:21:19.850452 99741 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:21:19.872771 99741 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483648, 2],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([2147483648, 2],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 15:22:50.216845 100450 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:22:50.217712 100450 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483648, 2],"float32"),Tensor([1, 2],"float32"),], )
[paddle error] paddle.concat(list[Tensor([2147483648, 2],"float32"),Tensor([1, 2],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 15:24:16.125274 100862 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:24:16.126129 100862 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483648, 2],"float32"),Tensor([1, 2],"float32"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([2147483648, 2],"float32"),Tensor([1, 2],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 15:25:42.789021 101287 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:25:42.791599 101287 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483648, 2],"float32"),Tensor([1, 2],"float32"),], axis=-2, )
[paddle error] paddle.concat(list[Tensor([2147483648, 2],"float32"),Tensor([1, 2],"float32"),], axis=-2, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 15:27:09.400879 101740 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:27:09.401846 101740 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483648, 2],"float32"),Tensor([10, 2],"float32"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([2147483648, 2],"float32"),Tensor([10, 2],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 15:28:34.170078 102165 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:28:34.172495 102165 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483648, 2],"float32"),Tensor([2, 2],"float32"),], )
[paddle error] paddle.concat(list[Tensor([2147483648, 2],"float32"),Tensor([2, 2],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 15:29:58.981840 102529 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:29:58.982842 102529 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483648, 2],"float32"),Tensor([2, 2],"float32"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([2147483648, 2],"float32"),Tensor([2, 2],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 15:31:34.977072 102958 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:31:34.978029 102958 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483648, 2],"float32"),Tensor([2147483648, 2],"float32"),], )
[torch error] paddle.concat(list[Tensor([2147483648, 2],"float32"),Tensor([2147483648, 2],"float32"),], ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 77873 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:33:43.048089 103422 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:33:43.052098 103422 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483648, 2],"float32"),Tensor([2147483648, 2],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([2147483648, 2],"float32"),Tensor([2147483648, 2],"float32"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 27136 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:35:57.967217 104113 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:35:57.968222 104113 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483648, 2],"float32"),Tensor([2147483648, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2147483648, 2],"float32"),Tensor([2147483648, 2],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 130848 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:38:11.432848 104712 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:38:11.433846 104712 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483648, 2],"float32"),Tensor([2147483648, 2],"float32"),], axis=-2, )
[torch error] paddle.concat(list[Tensor([2147483648, 2],"float32"),Tensor([2147483648, 2],"float32"),], axis=-2, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 87708 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:40:34.012259 105418 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:40:34.013377 105418 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483648, 2],"float32"),Tensor([5, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2147483648, 2],"float32"),Tensor([5, 2],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2147483648 but got size 5 for tensor number 1 in the list.

W0206 15:41:54.534417 106116 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:41:54.535725 106116 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1, 1, 1],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([2147483649, 1, 1, 1],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 15:43:06.364069 106450 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:43:06.364967 106450 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1, 1, 1],"float64"),], axis=1, name=None, )
[paddle error] paddle.concat(list[Tensor([2147483649, 1, 1, 1],"float64"),], axis=1, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 15:44:12.396057 106849 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:44:12.398734 106849 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1, 1, 1],"float64"),], axis=2, name=None, )
[paddle error] paddle.concat(list[Tensor([2147483649, 1, 1, 1],"float64"),], axis=2, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 15:45:23.287237 107155 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:45:23.288159 107155 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([2147483649, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 15:46:27.260623 107474 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:46:27.261524 107474 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([2147483649, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=1, name=None, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2147483649 but got size 1 for tensor number 1 in the list.

W0206 15:47:17.398350 107784 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:47:17.399416 107784 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([2147483649, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),Tensor([1, 1, 1, 1],"float64"),], axis=2, name=None, ) 
 Sizes of tensors must match except in dimension 2. Expected size 2147483649 but got size 1 for tensor number 1 in the list.

W0206 15:48:14.883003 108059 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:48:14.886018 108059 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([2147483649, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 74723 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:50:32.203208 108337 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:50:32.204396 108337 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([2147483649, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 23979 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:52:56.529376 109019 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:52:56.530478 109019 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([2147483649, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),Tensor([2147483649, 1, 1, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 132210 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 15:55:02.083966 109633 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:55:02.085086 109633 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1, 1],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([2147483649, 1, 1],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 15:56:19.070680 110285 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:56:19.071620 110285 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1, 1],"float64"),], axis=1, name=None, )
[paddle error] paddle.concat(list[Tensor([2147483649, 1, 1],"float64"),], axis=1, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 15:57:28.199579 110590 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:57:28.200444 110590 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1, 1],"float64"),], axis=2, name=None, )
[paddle error] paddle.concat(list[Tensor([2147483649, 1, 1],"float64"),], axis=2, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 15:58:32.471328 110893 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:58:32.472231 110893 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([2147483649, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 15:59:38.166965 111188 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 15:59:38.167876 111188 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([2147483649, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=1, name=None, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2147483649 but got size 1 for tensor number 1 in the list.

W0206 16:00:30.431233 111573 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:00:30.432348 111573 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([2147483649, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),Tensor([1, 1, 1],"float64"),], axis=2, name=None, ) 
 Sizes of tensors must match except in dimension 2. Expected size 2147483649 but got size 1 for tensor number 1 in the list.

W0206 16:01:23.914026 111760 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:01:23.915186 111760 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 50192 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:03:28.918427 112047 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:03:28.919507 112047 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 144639 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:05:39.459995 112596 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:05:39.461179 112596 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),Tensor([2147483649, 1, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 97801 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:07:52.289284 113239 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:07:52.290274 113239 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1, 1],"int64"),], axis=2, name=None, )
[paddle error] paddle.concat(list[Tensor([2147483649, 1, 1],"int64"),], axis=2, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 16:08:59.510535 113817 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:08:59.512871 113817 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([2147483649, 1],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 16:10:04.792171 114096 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:10:04.793191 114096 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1],"float64"),], axis=1, name=None, )
[paddle error] paddle.concat(list[Tensor([2147483649, 1],"float64"),], axis=1, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 16:11:11.323566 114386 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:11:11.324515 114386 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1],"float64"),Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([2147483649, 1],"float64"),Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 16:12:14.935278 114758 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:12:14.936297 114758 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1],"float64"),Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([2147483649, 1],"float64"),Tensor([1, 1],"float64"),Tensor([1, 1],"float64"),], axis=1, name=None, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2147483649 but got size 1 for tensor number 1 in the list.

W0206 16:13:04.953289 115056 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:13:04.954427 115056 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1],"float64"),Tensor([2, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([2147483649, 1],"float64"),Tensor([2, 1],"float64"),], axis=1, name=None, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2147483649 but got size 2 for tensor number 1 in the list.

W0206 16:13:59.330976 115336 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:13:59.332325 115336 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1],"float64"),Tensor([2147483649, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([2147483649, 1],"float64"),Tensor([2147483649, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 154731 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:15:30.176149 115507 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:15:30.177281 115507 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1],"float64"),Tensor([2147483649, 1],"float64"),Tensor([2147483649, 1],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([2147483649, 1],"float64"),Tensor([2147483649, 1],"float64"),Tensor([2147483649, 1],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 67258 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:17:49.548593 116023 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:17:49.549751 116023 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1],"float64"),Tensor([2147483649, 1],"float64"),Tensor([2147483649, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([2147483649, 1],"float64"),Tensor([2147483649, 1],"float64"),Tensor([2147483649, 1],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 18455 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:19:53.884864 116607 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:19:53.885907 116607 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1],"float64"),Tensor([5, 1],"float64"),Tensor([5, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([2147483649, 1],"float64"),Tensor([5, 1],"float64"),Tensor([5, 1],"float64"),], axis=1, name=None, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2147483649 but got size 5 for tensor number 1 in the list.

W0206 16:20:55.406432 117172 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:20:55.408121 117172 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1],"int64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([2147483649, 1],"int64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 16:22:01.389245 117443 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:22:01.390197 117443 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1],"int64"),], axis=1, name=None, )
[paddle error] paddle.concat(list[Tensor([2147483649, 1],"int64"),], axis=1, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 16:23:03.744098 117723 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:23:03.745782 117723 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1],"int64"),Tensor([1, 2],"int64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2147483649, 1],"int64"),Tensor([1, 2],"int64"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2147483649 but got size 1 for tensor number 1 in the list.

W0206 16:23:49.385946 118018 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:23:49.387019 118018 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1],"int64"),Tensor([2, 2],"int64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2147483649, 1],"int64"),Tensor([2, 2],"int64"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2147483649 but got size 2 for tensor number 1 in the list.

W0206 16:24:39.656910 118284 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:24:39.658001 118284 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649, 1],"int64"),Tensor([2147483649, 2],"int64"),], axis=1, )
[torch error] paddle.concat(list[Tensor([2147483649, 1],"int64"),Tensor([2147483649, 2],"int64"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 29.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 26034 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:26:41.896286 118556 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:26:41.897388 118556 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([2147483649],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 16:27:50.688463 119118 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:27:50.689481 119118 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"float64"),Tensor([1],"float64"),Tensor([1],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([2147483649],"float64"),Tensor([1],"float64"),Tensor([1],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 16:28:53.292544 119399 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:28:53.294947 119399 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"float64"),Tensor([100],"float64"),], )
[paddle error] paddle.concat(list[Tensor([2147483649],"float64"),Tensor([100],"float64"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 16:29:54.524495 119683 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:29:54.525416 119683 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"float64"),Tensor([2],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([2147483649],"float64"),Tensor([2],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 16:30:58.660594 119966 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:30:58.661454 119966 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"float64"),Tensor([2],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([2147483649],"float64"),Tensor([2],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 16:32:09.762305 120260 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:32:09.763195 120260 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),], )
[torch error] paddle.concat(list[Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 56834 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:33:41.902458 120645 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:33:41.903604 120645 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),], axis=0, )
[torch error] paddle.concat(list[Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 138604 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:35:14.222429 121073 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:35:14.223450 121073 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 44060 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:36:55.967648 121493 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:36:55.968741 121493 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),], )
[torch error] paddle.concat(list[Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 133694 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:39:01.642858 121930 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:39:01.643880 121930 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 69199 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:41:19.818529 122588 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:41:19.819705 122588 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),], axis=0, )
[torch error] paddle.concat(list[Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 23990 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:43:30.655061 123156 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:43:30.656119 123156 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),], axis=0, )
[torch error] paddle.concat(list[Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 126737 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:45:37.965644 123844 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:45:37.968353 123844 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),], axis=0, )
[torch error] paddle.concat(list[Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),Tensor([2147483649],"float64"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 74977 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 16:47:38.484860 124432 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:47:38.485946 124432 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"float64"),Tensor([24],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([2147483649],"float64"),Tensor([24],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 16:48:55.970633 125007 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:48:55.971515 125007 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 16:50:05.590865 125312 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:50:05.591804 125312 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"float64"),Tensor([256],"float64"),], )
[paddle error] paddle.concat(list[Tensor([2147483649],"float64"),Tensor([256],"float64"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 16:51:13.296298 125617 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:51:13.297245 125617 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"float64"),Tensor([4],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([2147483649],"float64"),Tensor([4],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 16:52:18.640568 126023 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:52:18.641480 126023 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"float64"),Tensor([5],"float64"),Tensor([5],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([2147483649],"float64"),Tensor([5],"float64"),Tensor([5],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 16:53:23.811923 126329 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:53:23.814569 126329 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"float64"),Tensor([500],"float64"),], )
[paddle error] paddle.concat(list[Tensor([2147483649],"float64"),Tensor([500],"float64"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 16:54:29.805326 126627 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:54:29.806263 126627 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"float64"),Tensor([511],"float64"),Tensor([1],"float64"),], )
[paddle error] paddle.concat(list[Tensor([2147483649],"float64"),Tensor([511],"float64"),Tensor([1],"float64"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 16:55:40.096802 126932 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:55:40.097752 126932 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"float64"),Tensor([6],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([2147483649],"float64"),Tensor([6],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 16:56:44.087666 127323 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:56:44.088667 127323 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([2147483649],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 16:57:46.627350 127608 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:57:46.628276 127608 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"float64"),Tensor([8],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([2147483649],"float64"),Tensor([8],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 16:58:52.551070 127905 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:58:52.552002 127905 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"float64"),Tensor([8],"float64"),Tensor([8],"float64"),Tensor([8],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([2147483649],"float64"),Tensor([8],"float64"),Tensor([8],"float64"),Tensor([8],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 16:59:56.360199 128210 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 16:59:56.361059 128210 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"int64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([2147483649],"int64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 17:01:05.062116 128525 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:01:05.063030 128525 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"int64"),Tensor([1],"int64"),Tensor([1],"int64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([2147483649],"int64"),Tensor([1],"int64"),Tensor([1],"int64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 17:02:06.182315 128818 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:02:06.183254 128818 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"int64"),Tensor([100],"int64"),], )
[paddle error] paddle.concat(list[Tensor([2147483649],"int64"),Tensor([100],"int64"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 17:03:15.544463 129195 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:03:15.545440 129195 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"int64"),Tensor([2],"int64"),], -1, )
[paddle error] paddle.concat(list[Tensor([2147483649],"int64"),Tensor([2],"int64"),], -1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 17:04:20.392509 129521 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:04:20.393520 129521 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"int64"),Tensor([2],"int64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([2147483649],"int64"),Tensor([2],"int64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 17:05:24.502673 129822 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:05:24.505331 129822 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"int64"),Tensor([2147483649],"int64"),], )
[torch error] paddle.concat(list[Tensor([2147483649],"int64"),Tensor([2147483649],"int64"),], ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 53220 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:06:44.467622 130122 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:06:44.468727 130122 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"int64"),Tensor([2147483649],"int64"),], -1, )
[torch error] paddle.concat(list[Tensor([2147483649],"int64"),Tensor([2147483649],"int64"),], -1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 134329 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:08:11.870810 130540 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:08:11.871847 130540 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"int64"),Tensor([2147483649],"int64"),], axis=0, )
[torch error] paddle.concat(list[Tensor([2147483649],"int64"),Tensor([2147483649],"int64"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 44575 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:09:51.142764 130971 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:09:51.143911 130971 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"int64"),Tensor([2147483649],"int64"),Tensor([2147483649],"int64"),], axis=0, )
[torch error] paddle.concat(list[Tensor([2147483649],"int64"),Tensor([2147483649],"int64"),Tensor([2147483649],"int64"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 124837 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:11:49.864403 131415 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:11:49.865512 131415 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([2147483649],"int64"),Tensor([500],"int64"),], )
[paddle error] paddle.concat(list[Tensor([2147483649],"int64"),Tensor([500],"int64"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 17:12:57.682236 131985 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:12:57.683267 131985 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([214748365, 20],"float32"),Tensor([11, 20],"float32"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([214748365, 20],"float32"),Tensor([11, 20],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 17:14:23.202347 132256 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:14:23.205050 132256 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([214748365, 20],"float32"),Tensor([214748365, 20],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([214748365, 20],"float32"),Tensor([214748365, 20],"float32"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 10047 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:16:41.262841 132680 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:16:41.263937 132680 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([21474837, 100],"float64"),Tensor([21474837, 100],"float64"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([21474837, 100],"float64"),Tensor([21474837, 100],"float64"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 141017 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:18:09.999059 133367 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:18:10.000238 133367 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([21474837, 100],"float64"),Tensor([8, 100],"float64"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([21474837, 100],"float64"),Tensor([8, 100],"float64"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 21474837 but got size 8 for tensor number 1 in the list.

W0206 17:19:12.727120 133784 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:19:12.728752 133784 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([21474837, 200],"float32"),Tensor([100, 200],"float32"),], )
[paddle error] paddle.concat(list[Tensor([21474837, 200],"float32"),Tensor([100, 200],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 17:20:42.776328 134078 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:20:42.777254 134078 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([21474837, 200],"float32"),Tensor([21474837, 200],"float32"),], )
[torch error] paddle.concat(list[Tensor([21474837, 200],"float32"),Tensor([21474837, 200],"float32"),], ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 7266 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:22:59.825701 134484 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:22:59.826751 134484 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([214749, 800, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([214749, 800, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 214749 but got size 1 for tensor number 1 in the list.

W0206 17:24:15.531765 135104 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:24:15.533427 135104 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([214749, 800, 5, 5],"float32"),Tensor([214749, 32, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([214749, 800, 5, 5],"float32"),Tensor([214749, 32, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000047GB memory on GPU 0, 67.858337GB memory has been allocated and available memory is only 11.326538GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 17:25:47.301447 135488 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:25:47.302353 135488 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([21740, 1008, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([21740, 1008, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 21740 but got size 2 for tensor number 1 in the list.

W0206 17:26:55.082108 135932 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:26:55.083452 135932 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([21740, 1008, 14, 14],"float32"),Tensor([21740, 48, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([21740, 1008, 14, 14],"float32"),Tensor([21740, 48, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000600GB memory on GPU 0, 68.104431GB memory has been allocated and available memory is only 11.080444GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 17:28:29.160634 136226 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:28:29.161530 136226 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([21846, 3, 256, 256],"float32"),Tensor([1, 10, 256, 256],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([21846, 3, 256, 256],"float32"),Tensor([1, 10, 256, 256],"float32"),], 1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 21846 but got size 1 for tensor number 1 in the list.

W0206 17:29:49.228924 136644 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:29:49.230685 136644 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([21846, 3, 256, 256],"float32"),Tensor([21846, 10, 256, 256],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([21846, 3, 256, 256],"float32"),Tensor([21846, 10, 256, 256],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 53.34 GiB. GPU 0 has a total capacity of 79.18 GiB of which 29.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 132472 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 1.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:34:29.488457 137062 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:34:29.491304 137062 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([22090, 992, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([22090, 992, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 22090 but got size 2 for tensor number 1 in the list.

W0206 17:35:50.991550 138398 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:35:50.992858 138398 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([22090, 992, 14, 14],"float32"),Tensor([22090, 32, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([22090, 992, 14, 14],"float32"),Tensor([22090, 32, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000133GB memory on GPU 0, 67.612244GB memory has been allocated and available memory is only 11.572632GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 17:37:22.891883 138698 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:37:22.892825 138698 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([22185, 64, 55, 55],"float32"),Tensor([2, 64, 55, 55],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([22185, 64, 55, 55],"float32"),Tensor([2, 64, 55, 55],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 22185 but got size 2 for tensor number 1 in the list.

W0206 17:38:34.159047 139139 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:38:34.160142 139139 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([22185, 64, 55, 55],"float32"),Tensor([22185, 64, 55, 55],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([22185, 64, 55, 55],"float32"),Tensor([22185, 64, 55, 55],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 38912 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:40:56.642463 139536 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:40:56.643455 139536 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([22369622, 12, 8],"float64"),Tensor([22369622, 12, 8],"float64"),], -1, )
[torch error] paddle.concat(list[Tensor([22369622, 12, 8],"float64"),Tensor([22369622, 12, 8],"float64"),], -1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 55281 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:42:39.649140 140149 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:42:39.650135 140149 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([22369622, 12, 8],"float64"),Tensor([4, 12, 8],"float64"),], -1, )
[torch error] paddle.concat(list[Tensor([22369622, 12, 8],"float64"),Tensor([4, 12, 8],"float64"),], -1, ) 
 Sizes of tensors must match except in dimension 2. Expected size 22369622 but got size 4 for tensor number 1 in the list.

W0206 17:43:37.840555 140662 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:43:37.841712 140662 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([223697, 192, 10, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([223697, 192, 10, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 223697 but got size 1 for tensor number 1 in the list.

W0206 17:44:54.773614 140935 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:44:54.777973 140935 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([223697, 192, 10, 10],"float32"),Tensor([223697, 32, 10, 10],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([223697, 192, 10, 10],"float32"),Tensor([223697, 32, 10, 10],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000056GB memory on GPU 0, 71.913025GB memory has been allocated and available memory is only 7.271851GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 17:46:44.572774 141253 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:46:44.573676 141253 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([223697, 768, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([223697, 768, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 223697 but got size 1 for tensor number 1 in the list.

W0206 17:47:56.136328 141768 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:47:56.137435 141768 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([223697, 768, 5, 5],"float32"),Tensor([223697, 32, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([223697, 768, 5, 5],"float32"),Tensor([223697, 32, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000056GB memory on GPU 0, 67.913025GB memory has been allocated and available memory is only 11.271851GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 17:49:31.333393 142071 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:49:31.334375 142071 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([226911, 112, 13, 13],"float32"),Tensor([2, 288, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([226911, 112, 13, 13],"float32"),Tensor([2, 288, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),Tensor([2, 64, 13, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 226911 but got size 2 for tensor number 1 in the list.

W0206 17:50:41.715786 142512 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:50:41.716768 142512 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([226911, 112, 13, 13],"float32"),Tensor([226911, 288, 13, 13],"float32"),Tensor([226911, 64, 13, 13],"float32"),Tensor([226911, 64, 13, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([226911, 112, 13, 13],"float32"),Tensor([226911, 288, 13, 13],"float32"),Tensor([226911, 64, 13, 13],"float32"),Tensor([226911, 64, 13, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 41.14 GiB. GPU 0 has a total capacity of 79.18 GiB of which 29.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 133734 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:54:40.183238 142904 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:54:40.184377 142904 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([228262, 24, 28, 28],"float32"),Tensor([2, 24, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([228262, 24, 28, 28],"float32"),Tensor([2, 24, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 228262 but got size 2 for tensor number 1 in the list.

W0206 17:56:07.288118 143992 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:56:07.289547 143992 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([228262, 24, 28, 28],"float32"),Tensor([228262, 24, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([228262, 24, 28, 28],"float32"),Tensor([228262, 24, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 105968 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 17:58:38.789111 144390 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 17:58:38.819475 144390 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([22827, 240, 28, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([22827, 240, 28, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 22827 but got size 2 for tensor number 1 in the list.

W0206 18:00:00.043808 145094 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:00:00.045265 145094 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([22827, 240, 28, 28],"float32"),Tensor([22827, 48, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([22827, 240, 28, 28],"float32"),Tensor([22827, 48, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000600GB memory on GPU 0, 72.979431GB memory has been allocated and available memory is only 6.205444GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:01:48.960490 145425 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:01:48.961395 145425 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([22827, 960, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([22827, 960, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 22827 but got size 2 for tensor number 1 in the list.

W0206 18:03:01.006150 145944 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:03:01.007344 145944 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([22827, 960, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([22827, 960, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 22827 but got size 2 for tensor number 1 in the list.

W0206 18:04:18.877718 146337 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:04:18.878970 146337 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([22827, 960, 14, 14],"float32"),Tensor([22827, 32, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([22827, 960, 14, 14],"float32"),Tensor([22827, 32, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000600GB memory on GPU 0, 67.647400GB memory has been allocated and available memory is only 11.537476GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:05:54.023265 146656 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:05:54.024097 146656 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([22827, 960, 14, 14],"float32"),Tensor([22827, 48, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([22827, 960, 14, 14],"float32"),Tensor([22827, 48, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000600GB memory on GPU 0, 68.178650GB memory has been allocated and available memory is only 11.006226GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:07:24.060902 147089 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:07:24.061836 147089 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([23015, 64, 54, 54],"float32"),Tensor([2, 64, 54, 54],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([23015, 64, 54, 54],"float32"),Tensor([2, 64, 54, 54],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 23015 but got size 2 for tensor number 1 in the list.

W0206 18:08:40.628854 147514 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:08:40.629972 147514 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([23015, 64, 54, 54],"float32"),Tensor([23015, 64, 54, 54],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([23015, 64, 54, 54],"float32"),Tensor([23015, 64, 54, 54],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 75650 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 2.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:10:54.166436 147936 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:10:54.167544 147936 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([233423, 736, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([233423, 736, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 233423 but got size 1 for tensor number 1 in the list.

W0206 18:12:13.393476 148516 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:12:13.394845 148516 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([233423, 736, 5, 5],"float32"),Tensor([233423, 32, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([233423, 736, 5, 5],"float32"),Tensor([233423, 32, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000059GB memory on GPU 0, 67.971619GB memory has been allocated and available memory is only 11.213257GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:13:54.277112 148919 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:13:54.278033 148919 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([23614, 928, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([23614, 928, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 23614 but got size 2 for tensor number 1 in the list.

W0206 18:15:13.114169 149345 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:15:13.115208 149345 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([23614, 928, 14, 14],"float32"),Tensor([23614, 32, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([23614, 928, 14, 14],"float32"),Tensor([23614, 32, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000506GB memory on GPU 0, 67.682556GB memory has been allocated and available memory is only 11.502319GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:16:47.487990 149764 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:16:47.489627 149764 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24],"float64"),Tensor([2147483649],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([24],"float64"),Tensor([2147483649],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:17:51.221087 150170 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:17:51.222246 150170 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:18:53.925911 150455 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:18:53.927127 150455 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:19:57.280846 150766 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:19:57.281976 150766 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:21:00.522320 151068 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:21:00.523607 151068 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:22:01.308303 151360 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:22:01.309576 151360 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:23:10.595932 151644 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:23:10.597273 151644 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:24:17.472829 152036 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:24:17.473690 152036 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:25:21.759287 152355 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:25:21.760564 152355 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:26:27.790038 152654 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:26:27.790941 152654 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:27:31.489377 152966 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:27:31.490773 152966 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:28:33.667675 153265 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:28:33.668788 153265 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:29:36.962088 153572 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:29:36.963003 153572 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:30:46.695111 153974 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:30:46.696089 153974 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:31:51.834834 154284 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:31:51.835747 154284 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:32:59.078023 154584 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:32:59.079391 154584 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:34:02.574375 154888 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:34:02.575521 154888 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:35:07.877095 155201 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:35:07.878137 155201 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:36:13.101217 155587 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:36:13.102169 155587 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:37:16.921005 155888 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:37:16.921957 155888 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:38:25.823994 156172 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:38:25.825301 156172 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:39:30.595382 156491 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:39:30.596670 156491 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:40:33.684140 156790 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:40:33.685034 156790 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),Tensor([24],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:41:37.268185 157100 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:41:37.269098 157100 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([24],"float64"),Tensor([2147483649],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:42:40.849319 157486 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:42:40.850510 157486 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24028, 912, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([24028, 912, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 24028 but got size 2 for tensor number 1 in the list.

W0206 18:43:51.394197 157781 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:43:51.395229 157781 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24028, 912, 14, 14],"float32"),Tensor([24028, 48, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([24028, 912, 14, 14],"float32"),Tensor([24028, 48, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000319GB memory on GPU 0, 68.264587GB memory has been allocated and available memory is only 10.920288GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:45:27.326232 158085 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:45:27.327121 158085 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([244033, 704, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([244033, 704, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 244033 but got size 1 for tensor number 1 in the list.

W0206 18:46:46.741779 158517 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:46:46.742880 158517 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([244033, 704, 5, 5],"float32"),Tensor([244033, 32, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([244033, 704, 5, 5],"float32"),Tensor([244033, 32, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000050GB memory on GPU 0, 68.034119GB memory has been allocated and available memory is only 11.150757GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:48:24.399624 158932 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:48:24.400538 158932 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24457, 224, 28, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([24457, 224, 28, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 24457 but got size 2 for tensor number 1 in the list.

W0206 18:49:44.136737 159356 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:49:44.138337 159356 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24457, 224, 28, 28],"float32"),Tensor([24457, 32, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([24457, 224, 28, 28],"float32"),Tensor([24457, 32, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000273GB memory on GPU 0, 71.151306GB memory has been allocated and available memory is only 8.033569GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:51:22.914677 159780 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:51:22.915572 159780 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24457, 896, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([24457, 896, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 24457 but got size 2 for tensor number 1 in the list.

W0206 18:52:33.277326 160196 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:52:33.278398 160196 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24457, 896, 14, 14],"float32"),Tensor([24457, 32, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([24457, 896, 14, 14],"float32"),Tensor([24457, 32, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000273GB memory on GPU 0, 67.721619GB memory has been allocated and available memory is only 11.463257GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 18:54:07.993741 160595 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:54:07.994640 160595 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24819, 256, 26, 26],"float32"),Tensor([2, 256, 26, 26],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([24819, 256, 26, 26],"float32"),Tensor([2, 256, 26, 26],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 24819 but got size 2 for tensor number 1 in the list.

W0206 18:55:27.264076 161035 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:55:27.265362 161035 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([24819, 256, 26, 26],"float32"),Tensor([24819, 256, 26, 26],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([24819, 256, 26, 26],"float32"),Tensor([24819, 256, 26, 26],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 120092 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 18:57:55.675695 161360 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:57:55.676774 161360 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([249013, 352, 7, 7],"float32"),Tensor([2, 352, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([249013, 352, 7, 7],"float32"),Tensor([2, 352, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 249013 but got size 2 for tensor number 1 in the list.

W0206 18:59:10.353163 162044 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 18:59:10.354410 162044 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([249013, 352, 7, 7],"float32"),Tensor([249013, 352, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([249013, 352, 7, 7],"float32"),Tensor([249013, 352, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 86061 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:01:28.304828 162437 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:01:28.305991 162437 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([25363, 864, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([25363, 864, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 25363 but got size 2 for tensor number 1 in the list.

W0206 19:02:44.044016 163061 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:02:44.045521 163061 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([25363, 864, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([25363, 864, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 25363 but got size 2 for tensor number 1 in the list.

W0206 19:04:07.734445 163467 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:04:07.735633 163467 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([25363, 864, 14, 14],"float32"),Tensor([25363, 32, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([25363, 864, 14, 14],"float32"),Tensor([25363, 32, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000390GB memory on GPU 0, 67.764587GB memory has been allocated and available memory is only 11.420288GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 19:05:40.690567   555 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:05:40.691470   555 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([25363, 864, 14, 14],"float32"),Tensor([25363, 48, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([25363, 864, 14, 14],"float32"),Tensor([25363, 48, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000390GB memory on GPU 0, 68.358337GB memory has been allocated and available memory is only 10.826538GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 19:07:09.082453   991 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:07:09.083442   991 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([255653, 672, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([255653, 672, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 255653 but got size 1 for tensor number 1 in the list.

W0206 19:08:18.374261  1418 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:08:18.375562  1418 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([255653, 672, 5, 5],"float32"),Tensor([255653, 32, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([255653, 672, 5, 5],"float32"),Tensor([255653, 32, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000012GB memory on GPU 0, 68.104431GB memory has been allocated and available memory is only 11.080444GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 19:09:52.299944  1746 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:09:52.302263  1746 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([257],"float64"),Tensor([2147483649],"float64"),], )
[paddle error] paddle.concat(list[Tensor([257],"float64"),Tensor([2147483649],"float64"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 19:10:54.505286  2171 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:10:54.506413  2171 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([26338, 832, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([26338, 832, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 26338 but got size 2 for tensor number 1 in the list.

W0206 19:12:06.193372  2468 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:12:06.194468  2468 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([26338, 832, 14, 14],"float32"),Tensor([26338, 32, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([26338, 832, 14, 14],"float32"),Tensor([26338, 32, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000086GB memory on GPU 0, 67.811462GB memory has been allocated and available memory is only 11.373413GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 19:13:46.869362  2894 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:13:46.870301  2894 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([268435456, 16],"float32"),Tensor([268435456, 8],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([268435456, 16],"float32"),Tensor([268435456, 8],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 24.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 21.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 25922 has 24.99 GiB memory in use. Of the allocated memory 24.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:15:39.056221  3326 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:15:39.057324  3326 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([268435456, 16],"float32"),Tensor([8, 8],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([268435456, 16],"float32"),Tensor([8, 8],"float32"),], 1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 268435456 but got size 8 for tensor number 1 in the list.

W0206 19:16:59.637017  3896 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:16:59.638217  3896 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([268435457, 4, 2],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([268435457, 4, 2],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 19:18:14.426715  4224 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:18:14.427961  4224 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([268435457, 4, 2],"float64"),], axis=1, name=None, )
[paddle error] paddle.concat(list[Tensor([268435457, 4, 2],"float64"),], axis=1, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 19:19:17.919751  4549 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:19:17.922329  4549 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([268435457, 4, 2],"float64"),], axis=2, name=None, )
[paddle error] paddle.concat(list[Tensor([268435457, 4, 2],"float64"),], axis=2, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 19:20:24.747944  4781 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:20:24.748843  4781 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([268435457, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([268435457, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 22070 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:22:27.326094  5067 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:22:27.327258  5067 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([268435457, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([268435457, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 9699 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:24:38.038074  5663 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:24:38.039183  5663 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([268435457, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([268435457, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 22271 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 19:26:42.836601  6329 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:26:42.837669  6329 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([268435457, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([268435457, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 19:28:00.035128  6917 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:28:00.037612  6917 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([268435457, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([268435457, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=1, name=None, ) 
 Sizes of tensors must match except in dimension 1. Expected size 268435457 but got size 3 for tensor number 1 in the list.

W0206 19:28:48.034104  7217 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:28:48.035624  7217 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([268435457, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([268435457, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=2, name=None, ) 
 Sizes of tensors must match except in dimension 2. Expected size 268435457 but got size 3 for tensor number 1 in the list.

W0206 19:29:41.576339  7478 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:29:41.581244  7478 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([268436, 160, 10, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([268436, 160, 10, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 268436 but got size 1 for tensor number 1 in the list.

W0206 19:30:56.994192  7774 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:30:56.995384  7774 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([268436, 160, 10, 10],"float32"),Tensor([268436, 32, 10, 10],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([268436, 160, 10, 10],"float32"),Tensor([268436, 32, 10, 10],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000032GB memory on GPU 0, 72.979431GB memory has been allocated and available memory is only 6.205444GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 19:32:40.770951  8076 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:32:40.771867  8076 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([268436, 640, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([268436, 640, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 268436 but got size 1 for tensor number 1 in the list.

W0206 19:33:53.658517  8594 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:33:53.659819  8594 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([268436, 640, 5, 5],"float32"),Tensor([268436, 32, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([268436, 640, 5, 5],"float32"),Tensor([268436, 32, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000032GB memory on GPU 0, 68.178650GB memory has been allocated and available memory is only 11.006226GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 19:35:29.796707  8927 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:35:29.797634  8927 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([26855, 816, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([26855, 816, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 26855 but got size 2 for tensor number 1 in the list.

W0206 19:36:49.305894  9333 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:36:49.306877  9333 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([26855, 816, 14, 14],"float32"),Tensor([26855, 48, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([26855, 816, 14, 14],"float32"),Tensor([26855, 48, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000425GB memory on GPU 0, 68.461853GB memory has been allocated and available memory is only 10.723022GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 19:38:32.725386  9765 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:38:32.726258  9765 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([27392, 800, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([27392, 800, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 27392 but got size 2 for tensor number 1 in the list.

W0206 19:39:51.963083 10199 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:39:51.964293 10199 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([27392, 800, 14, 14],"float32"),Tensor([27392, 32, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([27392, 800, 14, 14],"float32"),Tensor([27392, 32, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000366GB memory on GPU 0, 67.858337GB memory has been allocated and available memory is only 11.326538GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 19:41:33.876595 10608 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:41:33.877509 10608 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([282564, 608, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([282564, 608, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 282564 but got size 1 for tensor number 1 in the list.

W0206 19:42:48.215404 11041 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:42:48.216720 11041 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([282564, 608, 5, 5],"float32"),Tensor([282564, 32, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([282564, 608, 5, 5],"float32"),Tensor([282564, 32, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000021GB memory on GPU 0, 68.264587GB memory has been allocated and available memory is only 10.920288GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 19:44:30.649519 11445 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:44:30.652199 11445 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([28533, 192, 28, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([28533, 192, 28, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28533 but got size 2 for tensor number 1 in the list.

W0206 19:45:41.890692 11875 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:45:41.891836 11875 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([28533, 192, 28, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([28533, 192, 28, 28],"float32"),Tensor([2, 48, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28533 but got size 2 for tensor number 1 in the list.

W0206 19:47:05.536671 12264 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:47:05.537624 12264 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([28533, 192, 28, 28],"float32"),Tensor([28533, 32, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([28533, 192, 28, 28],"float32"),Tensor([28533, 32, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000179GB memory on GPU 0, 71.913025GB memory has been allocated and available memory is only 7.271851GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 19:48:55.892306 12671 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:48:55.894798 12671 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([28533, 192, 28, 28],"float32"),Tensor([28533, 48, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([28533, 192, 28, 28],"float32"),Tensor([28533, 48, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000179GB memory on GPU 0, 74.580994GB memory has been allocated and available memory is only 4.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 19:50:45.333807 13121 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:50:45.334707 13121 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([28533, 768, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([28533, 768, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28533 but got size 2 for tensor number 1 in the list.

W0206 19:52:01.620347 13653 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:52:01.621377 13653 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([28533, 768, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([28533, 768, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 28533 but got size 2 for tensor number 1 in the list.

W0206 19:53:16.890245 14063 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:53:16.891417 14063 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([28533, 768, 14, 14],"float32"),Tensor([28533, 32, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([28533, 768, 14, 14],"float32"),Tensor([28533, 32, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000179GB memory on GPU 0, 67.913025GB memory has been allocated and available memory is only 11.271851GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 19:54:52.705132 14378 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:54:52.706066 14378 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([28533, 768, 14, 14],"float32"),Tensor([28533, 48, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([28533, 768, 14, 14],"float32"),Tensor([28533, 48, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000179GB memory on GPU 0, 68.580994GB memory has been allocated and available memory is only 10.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 19:56:22.591236 14795 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:56:22.592136 14795 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([29774, 736, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([29774, 736, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 29774 but got size 2 for tensor number 1 in the list.

W0206 19:57:41.764328 15212 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:57:41.765390 15212 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([29774, 736, 14, 14],"float32"),Tensor([29774, 32, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([29774, 736, 14, 14],"float32"),Tensor([29774, 32, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000413GB memory on GPU 0, 67.971619GB memory has been allocated and available memory is only 11.213257GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 19:59:24.173110 15611 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 19:59:24.175851 15611 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([298262, 576, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([298262, 576, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 298262 but got size 1 for tensor number 1 in the list.

W0206 20:00:34.706218 16056 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:00:34.707435 16056 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([298262, 576, 5, 5],"float32"),Tensor([298262, 32, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([298262, 576, 5, 5],"float32"),Tensor([298262, 32, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000021GB memory on GPU 0, 68.358337GB memory has been allocated and available memory is only 10.826538GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 20:02:10.164642 16443 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:02:10.165539 16443 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 100, 120],"float64"),Tensor([178957, 100, 120],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([3, 100, 120],"float64"),Tensor([178957, 100, 120],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000003GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 20:03:12.397096 16873 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:03:12.398089 16873 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 100, 120],"float64"),Tensor([3, 100, 7158279],"float64"),], axis=0, )
[torch error] paddle.concat(list[Tensor([3, 100, 120],"float64"),Tensor([3, 100, 7158279],"float64"),], axis=0, ) 
 Sizes of tensors must match except in dimension 0. Expected size 120 but got size 7158279 for tensor number 1 in the list.

W0206 20:04:05.524423 17152 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:04:05.526043 17152 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 100, 120],"float64"),Tensor([3, 5965233, 120],"float64"),], axis=0, )
[torch error] paddle.concat(list[Tensor([3, 100, 120],"float64"),Tensor([3, 5965233, 120],"float64"),], axis=0, ) 
 Sizes of tensors must match except in dimension 0. Expected size 100 but got size 5965233 for tensor number 1 in the list.

W0206 20:05:04.156229 17431 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:05:04.157495 17431 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 100, 7158279],"float64"),Tensor([3, 100, 120],"float64"),], axis=0, )
[torch error] paddle.concat(list[Tensor([3, 100, 7158279],"float64"),Tensor([3, 100, 120],"float64"),], axis=0, ) 
 Sizes of tensors must match except in dimension 0. Expected size 7158279 but got size 120 for tensor number 1 in the list.

W0206 20:06:00.754561 17709 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:06:00.756011 17709 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 100, 7158279],"float64"),Tensor([3, 100, 7158279],"float64"),], axis=0, )
[torch error] paddle.concat(list[Tensor([3, 100, 7158279],"float64"),Tensor([3, 100, 7158279],"float64"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 136840 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:07:40.905725 17920 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:07:40.906733 17920 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 1431655765],"float32"),Tensor([1, 1431655765],"float32"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([3, 1431655765],"float32"),Tensor([1, 1431655765],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 77.243103GB memory has been allocated and available memory is only 1.941772GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 20:09:40.628280 18452 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:09:40.629168 18452 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 1431655765],"float32"),Tensor([1, 2],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([3, 1431655765],"float32"),Tensor([1, 2],"float32"),], axis=0, ) 
 Sizes of tensors must match except in dimension 0. Expected size 1431655765 but got size 2 for tensor number 1 in the list.

W0206 20:11:00.486289 19023 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:11:00.487566 19023 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 1431655765],"float32"),Tensor([3, 1431655765],"float32"),Tensor([3, 1431655765],"float32"),], )
[torch error] paddle.concat(list[Tensor([3, 1431655765],"float32"),Tensor([3, 1431655765],"float32"),Tensor([3, 1431655765],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 13878 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:14:28.590700 19348 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:14:28.591846 19348 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 1431655765],"float32"),Tensor([3, 4],"float32"),Tensor([3, 4],"float32"),], )
[torch error] paddle.concat(list[Tensor([3, 1431655765],"float32"),Tensor([3, 4],"float32"),Tensor([3, 4],"float32"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 1431655765 but got size 4 for tensor number 1 in the list.

W0206 20:15:54.163803 20355 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:15:54.164921 20355 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 2, 1],"float64"),Tensor([1073741825, 2, 1],"float64"),Tensor([3, 2, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([3, 2, 1],"float64"),Tensor([1073741825, 2, 1],"float64"),Tensor([3, 2, 1],"float64"),], axis=2, name=None, ) 
 Sizes of tensors must match except in dimension 2. Expected size 3 but got size 1073741825 for tensor number 1 in the list.

W0206 20:16:49.785392 20755 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:16:49.786721 20755 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 2, 1],"float64"),Tensor([3, 2, 1],"float64"),Tensor([1073741825, 2, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([3, 2, 1],"float64"),Tensor([3, 2, 1],"float64"),Tensor([1073741825, 2, 1],"float64"),], axis=2, name=None, ) 
 Sizes of tensors must match except in dimension 2. Expected size 3 but got size 1073741825 for tensor number 2 in the list.

W0206 20:17:45.899606 21044 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:17:45.900836 21044 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 2, 1],"float64"),Tensor([3, 2, 1],"float64"),Tensor([3, 2, 357913942],"float64"),], axis=2, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 2, 1],"float64"),Tensor([3, 2, 1],"float64"),Tensor([3, 2, 357913942],"float64"),], axis=2, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 20:19:00.793514 21330 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:19:00.794513 21330 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 2, 1],"float64"),Tensor([3, 2, 1],"float64"),Tensor([3, 715827883, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([3, 2, 1],"float64"),Tensor([3, 2, 1],"float64"),Tensor([3, 715827883, 1],"float64"),], axis=2, name=None, ) 
 Sizes of tensors must match except in dimension 2. Expected size 2 but got size 715827883 for tensor number 2 in the list.

W0206 20:19:54.648304 21623 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:19:54.649420 21623 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 2, 1],"float64"),Tensor([3, 2, 357913942],"float64"),Tensor([3, 2, 1],"float64"),], axis=2, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 2, 1],"float64"),Tensor([3, 2, 357913942],"float64"),Tensor([3, 2, 1],"float64"),], axis=2, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 20:21:05.656282 21916 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:21:05.657536 21916 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 2, 1],"float64"),Tensor([3, 715827883, 1],"float64"),Tensor([3, 2, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([3, 2, 1],"float64"),Tensor([3, 715827883, 1],"float64"),Tensor([3, 2, 1],"float64"),], axis=2, name=None, ) 
 Sizes of tensors must match except in dimension 2. Expected size 2 but got size 715827883 for tensor number 1 in the list.

W0206 20:21:55.341673 22306 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:21:55.342773 22306 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 2, 357913942],"float64"),], axis=2, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 2, 357913942],"float64"),], axis=2, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 20:23:09.537858 22476 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:23:09.538870 22476 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 2, 357913942],"float64"),Tensor([3, 2, 1],"float64"),Tensor([3, 2, 1],"float64"),], axis=2, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 2, 357913942],"float64"),Tensor([3, 2, 1],"float64"),Tensor([3, 2, 1],"float64"),], axis=2, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 20:24:16.698400 22853 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:24:16.699268 22853 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 2, 357913942],"float64"),Tensor([3, 2, 357913942],"float64"),Tensor([3, 2, 357913942],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([3, 2, 357913942],"float64"),Tensor([3, 2, 357913942],"float64"),Tensor([3, 2, 357913942],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 22074 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:26:18.719975 23166 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:26:18.721117 23166 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 2],"float32"),Tensor([1, 4294967295],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([3, 2],"float32"),Tensor([1, 4294967295],"float32"),], axis=0, ) 
 Sizes of tensors must match except in dimension 0. Expected size 2 but got size 4294967295 for tensor number 1 in the list.

W0206 20:27:40.269326 23750 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:27:40.270529 23750 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 2],"float32"),Tensor([2147483648, 2],"float32"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([3, 2],"float32"),Tensor([2147483648, 2],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 20:29:12.584125 24159 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:29:12.585073 24159 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 2],"float64"),Tensor([1073741825, 2],"float64"),Tensor([3, 2],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 2],"float64"),Tensor([1073741825, 2],"float64"),Tensor([3, 2],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 20:30:18.400592 24573 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:30:18.401597 24573 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 2],"float64"),Tensor([1073741825, 2],"float64"),Tensor([3, 2],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([3, 2],"float64"),Tensor([1073741825, 2],"float64"),Tensor([3, 2],"float64"),], axis=1, name=None, ) 
 Sizes of tensors must match except in dimension 1. Expected size 3 but got size 1073741825 for tensor number 1 in the list.

W0206 20:31:07.534495 24859 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:31:07.535763 24859 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),Tensor([1073741825, 2],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),Tensor([1073741825, 2],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 20:32:13.659041 25143 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:32:13.659960 25143 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),Tensor([1073741825, 2],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),Tensor([1073741825, 2],"float64"),], axis=1, name=None, ) 
 Sizes of tensors must match except in dimension 1. Expected size 3 but got size 1073741825 for tensor number 2 in the list.

W0206 20:33:03.876579 25449 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:33:03.877753 25449 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),Tensor([3, 715827883],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),Tensor([3, 715827883],"float64"),], axis=0, name=None, ) 
 Sizes of tensors must match except in dimension 0. Expected size 2 but got size 715827883 for tensor number 2 in the list.

W0206 20:33:57.348920 25741 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:33:57.350149 25741 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),Tensor([3, 715827883],"float64"),], axis=1, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),Tensor([3, 715827883],"float64"),], axis=1, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 20:35:05.208621 25940 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:35:05.209928 25940 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 2],"float64"),Tensor([3, 715827883],"float64"),Tensor([3, 2],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([3, 2],"float64"),Tensor([3, 715827883],"float64"),Tensor([3, 2],"float64"),], axis=0, name=None, ) 
 Sizes of tensors must match except in dimension 0. Expected size 2 but got size 715827883 for tensor number 1 in the list.

W0206 20:35:52.606040 26225 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:35:52.607118 26225 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 2],"float64"),Tensor([3, 715827883],"float64"),Tensor([3, 2],"float64"),], axis=1, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 2],"float64"),Tensor([3, 715827883],"float64"),Tensor([3, 2],"float64"),], axis=1, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 20:37:01.346153 26489 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:37:01.347466 26489 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 357913942, 2],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 357913942, 2],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 20:38:05.485387 26804 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:38:05.488013 26804 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 357913942, 2],"float64"),], axis=1, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 357913942, 2],"float64"),], axis=1, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 20:39:14.521067 27090 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:39:14.521978 27090 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 357913942, 2],"float64"),], axis=2, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 357913942, 2],"float64"),], axis=2, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 20:40:17.976557 27493 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:40:17.977576 27493 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 64138 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:42:28.122972 27781 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:42:28.123989 27781 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 53874 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:44:34.416410 28364 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:44:34.417447 28364 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 64842 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:46:51.481096 29027 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:46:51.482159 29027 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=0, name=None, ) 
 Sizes of tensors must match except in dimension 0. Expected size 357913942 but got size 4 for tensor number 1 in the list.

W0206 20:47:46.912830 29616 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:47:46.914047 29616 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=1, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=1, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 20:48:55.865370 29893 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:48:55.866233 29893 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=2, name=None, ) 
 Sizes of tensors must match except in dimension 2. Expected size 357913942 but got size 4 for tensor number 1 in the list.

W0206 20:49:48.095201 30191 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:49:48.096568 30191 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 178956971],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 4, 178956971],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 20:51:07.563848 30485 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:51:07.565050 30485 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 178956971],"float64"),], axis=1, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 4, 178956971],"float64"),], axis=1, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 20:52:13.231691 30896 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:52:13.232563 30896 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 178956971],"float64"),], axis=2, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 4, 178956971],"float64"),], axis=2, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 20:53:16.822166 31194 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:53:16.823076 31194 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 44580 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:55:24.565814 31487 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:55:24.566926 31487 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 30361 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:57:38.543682 32091 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:57:38.544729 32091 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 178956971],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 53420 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 20:59:45.949911 32769 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 20:59:45.950937 32769 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=0, name=None, ) 
 Sizes of tensors must match except in dimension 0. Expected size 178956971 but got size 2 for tensor number 1 in the list.

W0206 21:00:41.098752 33366 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:00:41.100215 33366 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=1, name=None, ) 
 Sizes of tensors must match except in dimension 1. Expected size 178956971 but got size 2 for tensor number 1 in the list.

W0206 21:01:34.357662 33641 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:01:34.358867 33641 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=2, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=2, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 21:02:42.615625 33914 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:02:42.616575 33914 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], axis=0, name=None, ) 
 Sizes of tensors must match except in dimension 0. Expected size 5 but got size 89478486 for tensor number 2 in the list.

W0206 21:03:30.400594 34225 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:03:30.401717 34225 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], axis=1, name=None, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5 but got size 89478486 for tensor number 2 in the list.

W0206 21:04:26.889210 34511 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:04:26.890568 34511 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], axis=2, name=None, ) 
 Sizes of tensors must match except in dimension 2. Expected size 5 but got size 89478486 for tensor number 2 in the list.

W0206 21:05:22.533335 34689 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:05:22.534449 34689 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], axis=0, name=None, ) 
 Sizes of tensors must match except in dimension 0. Expected size 2 but got size 35791395 for tensor number 2 in the list.

W0206 21:06:19.831878 34974 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:06:19.833521 34974 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], axis=1, name=None, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 35791395 for tensor number 2 in the list.

W0206 21:07:12.497344 35265 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:07:12.498505 35265 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], axis=2, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], axis=2, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 21:08:20.666136 35539 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:08:20.667424 35539 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], axis=0, name=None, ) 
 Sizes of tensors must match except in dimension 0. Expected size 4 but got size 71582789 for tensor number 2 in the list.

W0206 21:09:13.675690 35838 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:09:13.679212 35838 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], axis=1, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], axis=1, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 21:10:29.505859 36133 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:10:29.506762 36133 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], axis=2, name=None, ) 
 Sizes of tensors must match except in dimension 2. Expected size 4 but got size 71582789 for tensor number 2 in the list.

W0206 21:11:18.291481 36430 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:11:18.292562 36430 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 21:12:30.521323 36702 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:12:30.522281 36702 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], axis=1, name=None, ) 
 Sizes of tensors must match except in dimension 1. Expected size 3 but got size 53687092 for tensor number 2 in the list.

W0206 21:13:20.671901 37008 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:13:20.672930 37008 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], axis=2, name=None, ) 
 Sizes of tensors must match except in dimension 2. Expected size 3 but got size 53687092 for tensor number 2 in the list.

W0206 21:14:14.722316 37306 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:14:14.723520 37306 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=0, name=None, ) 
 Sizes of tensors must match except in dimension 0. Expected size 5 but got size 89478486 for tensor number 1 in the list.

W0206 21:15:12.322435 37579 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:15:12.323949 37579 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=1, name=None, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5 but got size 89478486 for tensor number 1 in the list.

W0206 21:16:05.882576 37857 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:16:05.883801 37857 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=2, name=None, ) 
 Sizes of tensors must match except in dimension 2. Expected size 5 but got size 89478486 for tensor number 1 in the list.

W0206 21:16:58.455152 38129 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:16:58.456341 38129 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=0, name=None, ) 
 Sizes of tensors must match except in dimension 0. Expected size 2 but got size 35791395 for tensor number 1 in the list.

W0206 21:17:57.329195 38313 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:17:57.330406 38313 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=1, name=None, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 35791395 for tensor number 1 in the list.

W0206 21:18:53.947233 38592 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:18:53.948480 38592 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=2, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=2, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 21:20:02.004293 38870 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:20:02.005266 38870 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=0, name=None, ) 
 Sizes of tensors must match except in dimension 0. Expected size 4 but got size 71582789 for tensor number 1 in the list.

W0206 21:20:54.825210 39154 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:20:54.826349 39154 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=1, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=1, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 21:22:03.254932 39447 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:22:03.256042 39447 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=2, name=None, ) 
 Sizes of tensors must match except in dimension 2. Expected size 4 but got size 71582789 for tensor number 1 in the list.

W0206 21:22:51.650796 39732 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:22:51.651952 39732 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 21:23:59.609881 39983 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:23:59.610867 39983 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=1, name=None, ) 
 Sizes of tensors must match except in dimension 1. Expected size 3 but got size 53687092 for tensor number 1 in the list.

W0206 21:24:51.144018 40268 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:24:51.145046 40268 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=2, name=None, ) 
 Sizes of tensors must match except in dimension 2. Expected size 3 but got size 53687092 for tensor number 1 in the list.

W0206 21:25:44.826735 40559 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:25:44.827838 40559 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 89478486],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 4, 2, 89478486],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 21:26:54.973001 40832 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:26:54.973951 40832 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 89478486],"float64"),], axis=1, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 4, 2, 89478486],"float64"),], axis=1, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 21:27:58.779083 41128 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:27:58.781507 41128 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 89478486],"float64"),], axis=2, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 4, 2, 89478486],"float64"),], axis=2, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 21:29:02.767748 41412 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:29:02.768688 41412 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=0, name=None, ) 
 Sizes of tensors must match except in dimension 0. Expected size 89478486 but got size 5 for tensor number 1 in the list.

W0206 21:29:58.846097 41720 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:29:58.847396 41720 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=1, name=None, ) 
 Sizes of tensors must match except in dimension 1. Expected size 89478486 but got size 5 for tensor number 1 in the list.

W0206 21:30:53.022163 42005 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:30:53.023301 42005 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=2, name=None, ) 
 Sizes of tensors must match except in dimension 2. Expected size 89478486 but got size 5 for tensor number 1 in the list.

W0206 21:31:49.911098 42267 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:31:49.912178 42267 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 112756 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:33:55.361855 42568 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:33:55.362882 42568 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 96515 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:36:07.055326 43133 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:36:07.056427 43133 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),Tensor([3, 4, 2, 89478486],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 111080 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 21:38:14.864027 43824 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:38:14.865084 43824 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 21:39:27.085536 44410 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:39:27.086751 44410 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=1, name=None, ) 
 Sizes of tensors must match except in dimension 1. Expected size 3 but got size 268435457 for tensor number 1 in the list.

W0206 21:40:15.108242 44723 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:40:15.109424 44723 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=2, name=None, ) 
 Sizes of tensors must match except in dimension 2. Expected size 3 but got size 268435457 for tensor number 1 in the list.

W0206 21:41:08.315101 45003 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:41:08.316098 45003 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=0, name=None, ) 
 Sizes of tensors must match except in dimension 0. Expected size 4 but got size 357913942 for tensor number 1 in the list.

W0206 21:41:59.738420 45273 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:41:59.739702 45273 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=1, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=1, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 21:43:13.915652 45453 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:43:13.916594 45453 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),Tensor([3, 4, 2],"float64"),], axis=2, name=None, ) 
 Sizes of tensors must match except in dimension 2. Expected size 4 but got size 357913942 for tensor number 1 in the list.

W0206 21:44:02.781221 45859 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:44:02.782447 45859 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),], axis=0, name=None, ) 
 Sizes of tensors must match except in dimension 0. Expected size 2 but got size 178956971 for tensor number 1 in the list.

W0206 21:44:56.164052 46136 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:44:56.165285 46136 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),], axis=1, name=None, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 178956971 for tensor number 1 in the list.

W0206 21:45:48.229569 46322 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:45:48.230666 46322 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),], axis=2, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),Tensor([3, 4, 2],"float64"),], axis=2, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 21:47:03.259680 46579 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:47:03.260600 46579 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 21:48:13.347571 46898 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:48:13.348680 46898 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),], axis=1, name=None, ) 
 Sizes of tensors must match except in dimension 1. Expected size 3 but got size 268435457 for tensor number 2 in the list.

W0206 21:49:01.628679 47285 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:49:01.629855 47285 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([268435457, 4, 2],"float64"),], axis=2, name=None, ) 
 Sizes of tensors must match except in dimension 2. Expected size 3 but got size 268435457 for tensor number 2 in the list.

W0206 21:49:52.225510 47556 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:49:52.226984 47556 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], axis=0, name=None, ) 
 Sizes of tensors must match except in dimension 0. Expected size 4 but got size 357913942 for tensor number 2 in the list.

W0206 21:50:45.178107 47748 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:50:45.179252 47748 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], axis=1, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], axis=1, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 21:51:51.504107 48034 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:51:51.505429 48034 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 357913942, 2],"float64"),], axis=2, name=None, ) 
 Sizes of tensors must match except in dimension 2. Expected size 4 but got size 357913942 for tensor number 2 in the list.

W0206 21:52:42.465092 48318 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:52:42.466341 48318 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),], axis=0, name=None, ) 
 Sizes of tensors must match except in dimension 0. Expected size 2 but got size 178956971 for tensor number 2 in the list.

W0206 21:53:34.526710 48577 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:53:34.527848 48577 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),], axis=1, name=None, ) 
 Sizes of tensors must match except in dimension 1. Expected size 2 but got size 178956971 for tensor number 2 in the list.

W0206 21:54:26.089982 48849 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:54:26.091215 48849 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),], axis=2, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 4, 2],"float64"),Tensor([3, 4, 2],"float64"),Tensor([3, 4, 178956971],"float64"),], axis=2, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 21:55:39.390401 49047 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:55:39.391423 49047 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 35791395, 5],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 4, 35791395, 5],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 21:56:43.520146 49433 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:56:43.521193 49433 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 35791395, 5],"float64"),], axis=1, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 4, 35791395, 5],"float64"),], axis=1, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 21:57:55.174316 49744 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:57:55.175575 49744 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 35791395, 5],"float64"),], axis=2, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 4, 35791395, 5],"float64"),], axis=2, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 21:58:59.028911 50070 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:58:59.029824 50070 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=0, name=None, ) 
 Sizes of tensors must match except in dimension 0. Expected size 35791395 but got size 2 for tensor number 1 in the list.

W0206 21:59:47.217080 50370 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 21:59:47.218458 50370 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=1, name=None, ) 
 Sizes of tensors must match except in dimension 1. Expected size 35791395 but got size 2 for tensor number 1 in the list.

W0206 22:00:40.453480 50645 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:00:40.454629 50645 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=2, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=2, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 22:01:48.820641 50917 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:01:48.821522 50917 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 47968 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:03:54.470897 51228 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:03:54.471980 51228 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 32924 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:06:01.239605 51807 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:06:01.240613 51807 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),Tensor([3, 4, 35791395, 5],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 32710 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:08:08.836516 52482 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:08:08.839058 52482 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4],"float32"),Tensor([1073741824, 4],"float32"),Tensor([3, 4],"float32"),], )
[paddle error] paddle.concat(list[Tensor([3, 4],"float32"),Tensor([1073741824, 4],"float32"),Tensor([3, 4],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 22:09:48.304986 53043 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:09:48.306118 53043 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4],"float32"),Tensor([3, 1431655765],"float32"),Tensor([3, 4],"float32"),], )
[torch error] paddle.concat(list[Tensor([3, 4],"float32"),Tensor([3, 1431655765],"float32"),Tensor([3, 4],"float32"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 4 but got size 1431655765 for tensor number 1 in the list.

W0206 22:11:10.213344 53466 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:11:10.214406 53466 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4],"float32"),Tensor([3, 4],"float32"),Tensor([1073741824, 4],"float32"),], )
[paddle error] paddle.concat(list[Tensor([3, 4],"float32"),Tensor([3, 4],"float32"),Tensor([1073741824, 4],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 22:12:40.769047 53869 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:12:40.769968 53869 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 4],"float32"),Tensor([3, 4],"float32"),Tensor([3, 1431655765],"float32"),], )
[torch error] paddle.concat(list[Tensor([3, 4],"float32"),Tensor([3, 4],"float32"),Tensor([3, 1431655765],"float32"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 4 but got size 1431655765 for tensor number 2 in the list.

W0206 22:14:06.282181 54299 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:14:06.283424 54299 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 5965233, 120],"float64"),Tensor([3, 100, 120],"float64"),], axis=0, )
[torch error] paddle.concat(list[Tensor([3, 5965233, 120],"float64"),Tensor([3, 100, 120],"float64"),], axis=0, ) 
 Sizes of tensors must match except in dimension 0. Expected size 5965233 but got size 100 for tensor number 1 in the list.

W0206 22:15:01.619590 54722 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:15:01.620805 54722 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 5965233, 120],"float64"),Tensor([3, 5965233, 120],"float64"),], axis=0, )
[torch error] paddle.concat(list[Tensor([3, 5965233, 120],"float64"),Tensor([3, 5965233, 120],"float64"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 44048 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:16:34.004201 55001 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:16:34.005149 55001 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 715827883, 1],"float64"),], axis=2, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 715827883, 1],"float64"),], axis=2, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 22:17:41.318096 55439 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:17:41.319356 55439 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 715827883, 1],"float64"),Tensor([3, 2, 1],"float64"),Tensor([3, 2, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([3, 715827883, 1],"float64"),Tensor([3, 2, 1],"float64"),Tensor([3, 2, 1],"float64"),], axis=2, name=None, ) 
 Sizes of tensors must match except in dimension 2. Expected size 715827883 but got size 2 for tensor number 1 in the list.

W0206 22:18:40.564320 55718 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:18:40.565613 55718 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 715827883, 1],"float64"),Tensor([3, 715827883, 1],"float64"),Tensor([3, 715827883, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([3, 715827883, 1],"float64"),Tensor([3, 715827883, 1],"float64"),Tensor([3, 715827883, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 157069 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:20:44.555039 56033 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:20:44.556139 56033 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 715827883],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 715827883],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 22:21:55.439330 56587 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:21:55.440258 56587 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 715827883],"float64"),], axis=1, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 715827883],"float64"),], axis=1, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 22:22:59.052317 56871 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:22:59.053189 56871 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 715827883],"float64"),Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([3, 715827883],"float64"),Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),], axis=0, name=None, ) 
 Sizes of tensors must match except in dimension 0. Expected size 715827883 but got size 2 for tensor number 1 in the list.

W0206 22:23:52.506609 57157 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:23:52.507787 57157 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 715827883],"float64"),Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),], axis=1, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 715827883],"float64"),Tensor([3, 2],"float64"),Tensor([3, 2],"float64"),], axis=1, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 22:25:09.094879 57449 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:25:09.095775 57449 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 715827883],"float64"),Tensor([3, 715827883],"float64"),Tensor([3, 715827883],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([3, 715827883],"float64"),Tensor([3, 715827883],"float64"),Tensor([3, 715827883],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 128183 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:27:26.745968 57861 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:27:26.748610 57861 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 715827883],"float64"),Tensor([3, 715827883],"float64"),Tensor([3, 715827883],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([3, 715827883],"float64"),Tensor([3, 715827883],"float64"),Tensor([3, 715827883],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 134146 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:29:34.219377 58492 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:29:34.220513 58492 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 71582789, 2, 5],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 71582789, 2, 5],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 22:30:43.917305 59173 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:30:43.918467 59173 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 71582789, 2, 5],"float64"),], axis=1, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 71582789, 2, 5],"float64"),], axis=1, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 22:31:55.816973 59480 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:31:55.817836 59480 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 71582789, 2, 5],"float64"),], axis=2, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 71582789, 2, 5],"float64"),], axis=2, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 22:32:59.793198 59806 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:32:59.795517 59806 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=0, name=None, ) 
 Sizes of tensors must match except in dimension 0. Expected size 71582789 but got size 4 for tensor number 1 in the list.

W0206 22:33:47.453024 60104 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:33:47.454217 60104 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=1, name=None, )
[paddle error] paddle.concat(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=1, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 22:34:55.886183 60373 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:34:55.887008 60373 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=2, name=None, ) 
 Sizes of tensors must match except in dimension 2. Expected size 71582789 but got size 4 for tensor number 1 in the list.

W0206 22:35:43.598681 60681 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:35:43.599885 60681 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 91795 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:37:58.130125 60969 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:37:58.131230 60969 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 84977 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:40:13.359937 61615 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:40:13.361104 61615 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),Tensor([3, 71582789, 2, 5],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 94172 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:42:19.626451 62295 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:42:19.627504 62295 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3],"float32"),Tensor([3],"float32"),Tensor([4294967295],"float32"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([3],"float32"),Tensor([3],"float32"),Tensor([4294967295],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 22:43:55.445946 62903 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:43:55.446875 62903 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3],"float32"),Tensor([4294967295],"float32"),Tensor([3],"float32"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([3],"float32"),Tensor([4294967295],"float32"),Tensor([3],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 22:45:26.115130 63341 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:45:26.116034 63341 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([30435, 720, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([30435, 720, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 30435 but got size 2 for tensor number 1 in the list.

W0206 22:46:38.206599 63759 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:46:38.207664 63759 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([30435, 720, 14, 14],"float32"),Tensor([30435, 48, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([30435, 720, 14, 14],"float32"),Tensor([30435, 48, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000074GB memory on GPU 0, 68.713806GB memory has been allocated and available memory is only 10.471069GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 22:48:23.285609 64193 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:48:23.286641 64193 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([310690, 384, 6, 6],"float32"),Tensor([2, 384, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([310690, 384, 6, 6],"float32"),Tensor([2, 384, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 310690 but got size 2 for tensor number 1 in the list.

W0206 22:49:36.021914 64638 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:49:36.023072 64638 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([310690, 384, 6, 6],"float32"),Tensor([310690, 384, 6, 6],"float32"),Tensor([310690, 128, 6, 6],"float32"),Tensor([310690, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([310690, 384, 6, 6],"float32"),Tensor([310690, 384, 6, 6],"float32"),Tensor([310690, 128, 6, 6],"float32"),Tensor([310690, 128, 6, 6],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 42.67 GiB. GPU 0 has a total capacity of 79.18 GiB of which 2.53 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 131915 has 43.66 GiB memory in use. Of the allocated memory 42.67 GiB is allocated by PyTorch, and 3.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 22:52:44.717335 65051 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:52:44.718462 65051 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([31127, 704, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([31127, 704, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 31127 but got size 2 for tensor number 1 in the list.

W0206 22:54:04.040649 65933 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:54:04.041870 65933 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([31127, 704, 14, 14],"float32"),Tensor([31127, 32, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([31127, 704, 14, 14],"float32"),Tensor([31127, 32, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000226GB memory on GPU 0, 68.034119GB memory has been allocated and available memory is only 11.150757GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 22:55:42.251459 66385 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:55:42.254539 66385 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([315807, 544, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([315807, 544, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 315807 but got size 1 for tensor number 1 in the list.

W0206 22:56:55.304265 66831 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:56:55.305335 66831 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([315807, 544, 5, 5],"float32"),Tensor([315807, 32, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([315807, 544, 5, 5],"float32"),Tensor([315807, 32, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000030GB memory on GPU 0, 68.459900GB memory has been allocated and available memory is only 10.724976GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 22:58:39.306331 67163 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 22:58:39.307561 67163 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([32, 134217728],"float32"),Tensor([32, 134217728],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([32, 134217728],"float32"),Tensor([32, 134217728],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 129155 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:00:47.142066 67717 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:00:47.143159 67717 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([32, 134217728],"float32"),Tensor([32, 8],"float32"),], 1, )
[paddle error] paddle.concat(list[Tensor([32, 134217728],"float32"),Tensor([32, 8],"float32"),], 1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 23:02:18.843166 68321 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:02:18.844175 68321 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([32, 8],"float32"),Tensor([32, 134217728],"float32"),], 1, )
[paddle error] paddle.concat(list[Tensor([32, 8],"float32"),Tensor([32, 134217728],"float32"),], 1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 23:03:43.325309 68764 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:03:43.326268 68764 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([32, 8],"float32"),Tensor([536870912, 8],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([32, 8],"float32"),Tensor([536870912, 8],"float32"),], 1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 32 but got size 536870912 for tensor number 1 in the list.

W0206 23:04:53.567533 69175 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:04:53.568702 69175 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([32609, 672, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([32609, 672, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 32609 but got size 2 for tensor number 1 in the list.

W0206 23:06:16.002254 69506 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:06:16.003396 69506 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([32609, 672, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([32609, 672, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 32609 but got size 2 for tensor number 1 in the list.

W0206 23:07:33.427961 69937 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:07:33.429178 69937 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([32609, 672, 14, 14],"float32"),Tensor([32609, 32, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([32609, 672, 14, 14],"float32"),Tensor([32609, 32, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000109GB memory on GPU 0, 68.104431GB memory has been allocated and available memory is only 11.080444GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 23:09:14.317262 70343 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:09:14.318297 70343 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([32609, 672, 14, 14],"float32"),Tensor([32609, 48, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([32609, 672, 14, 14],"float32"),Tensor([32609, 48, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000109GB memory on GPU 0, 68.866150GB memory has been allocated and available memory is only 10.318726GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 23:10:45.255674 70781 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:10:45.256671 70781 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([32768, 16, 128, 64],"float32"),Tensor([32768, 16, 1, 64],"float32"),], axis=-2, )
[paddle error] paddle.concat(list[Tensor([32768, 16, 128, 64],"float32"),Tensor([32768, 16, 1, 64],"float32"),], axis=-2, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.825134GB memory has been allocated and available memory is only 12.359741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 23:12:21.831846 71246 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:12:21.832943 71246 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([32768, 16, 128, 64],"float32"),Tensor([8, 16, 1, 64],"float32"),], axis=-2, )
[torch error] paddle.concat(list[Tensor([32768, 16, 128, 64],"float32"),Tensor([8, 16, 1, 64],"float32"),], axis=-2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 32768 but got size 8 for tensor number 1 in the list.

W0206 23:13:41.799275 71693 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:13:41.800473 71693 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([32768, 32, 32, 128],"float16"),Tensor([2, 32, 1, 128],"float16"),], axis=2, )
[torch error] paddle.concat(list[Tensor([32768, 32, 32, 128],"float16"),Tensor([2, 32, 1, 128],"float16"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 32768 but got size 2 for tensor number 1 in the list.

W0206 23:15:18.128623 72119 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:15:18.129770 72119 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([32768, 32, 32, 128],"float16"),Tensor([32768, 32, 1, 128],"float16"),], axis=2, )
[Pass] paddle.concat(list[Tensor([32768, 32, 32, 128],"float16"),Tensor([32768, 32, 1, 128],"float16"),], axis=2, )

W0206 23:16:56.255645 72591 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:16:56.256500 72591 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([33002, 2656, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([33002, 2656, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 33002 but got size 2 for tensor number 1 in the list.

W0206 23:25:58.911705 75278 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:25:58.912935 75278 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([33002, 2656, 7, 7],"float32"),Tensor([33002, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([33002, 2656, 7, 7],"float32"),Tensor([33002, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000168GB memory on GPU 0, 66.963806GB memory has been allocated and available memory is only 12.221069GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 23:27:30.815634 75614 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:27:30.816457 75614 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([330382100, 13],"float32"),Tensor([330382100, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([330382100, 13],"float32"),Tensor([330382100, 13],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 102951 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:29:38.671481 76053 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:29:38.672461 76053 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([330382100, 13],"float32"),Tensor([34, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([330382100, 13],"float32"),Tensor([34, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 330382100 but got size 34 for tensor number 1 in the list.

W0206 23:31:01.337918 76738 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:31:01.339023 76738 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([33092, 192, 26, 26],"float32"),Tensor([2, 192, 26, 26],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([33092, 192, 26, 26],"float32"),Tensor([2, 192, 26, 26],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 33092 but got size 2 for tensor number 1 in the list.

W0206 23:32:26.349682 77083 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:32:26.350484 77083 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([33092, 192, 26, 26],"float32"),Tensor([33092, 192, 26, 26],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([33092, 192, 26, 26],"float32"),Tensor([33092, 192, 26, 26],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 144055 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:34:43.372206 77515 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:34:43.373227 77515 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([33405, 2624, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([33405, 2624, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 33405 but got size 2 for tensor number 1 in the list.

W0206 23:35:59.748929 78218 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:35:59.750059 78218 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([33405, 2624, 7, 7],"float32"),Tensor([33405, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([33405, 2624, 7, 7],"float32"),Tensor([33405, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000425GB memory on GPU 0, 66.969666GB memory has been allocated and available memory is only 12.215210GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 23:37:35.867396 78545 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:37:35.869786 78545 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([33554432, 2, 8, 8],"float32"),Tensor([2, 2, 8, 8],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([33554432, 2, 8, 8],"float32"),Tensor([2, 2, 8, 8],"float32"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 3. Expected size 33554432 but got size 2 for tensor number 1 in the list.

W0206 23:38:48.846174 78984 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:38:48.847463 78984 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([33554432, 2, 8, 8],"float32"),Tensor([33554432, 2, 8, 8],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([33554432, 2, 8, 8],"float32"),Tensor([33554432, 2, 8, 8],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 140369 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:41:00.802821 79376 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:41:00.803810 79376 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([33554432, 4, 8, 4],"float32"),Tensor([1, 4, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([33554432, 4, 8, 4],"float32"),Tensor([1, 4, 8, 4],"float32"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 3. Expected size 33554432 but got size 1 for tensor number 1 in the list.

W0206 23:42:16.227165 79951 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:42:16.228612 79951 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([33554432, 4, 8, 4],"float32"),Tensor([2, 4, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([33554432, 4, 8, 4],"float32"),Tensor([2, 4, 8, 4],"float32"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 3. Expected size 33554432 but got size 2 for tensor number 1 in the list.

W0206 23:43:36.193396 80335 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:43:36.194526 80335 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([33554432, 4, 8, 4],"float32"),Tensor([33554432, 4, 8, 4],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([33554432, 4, 8, 4],"float32"),Tensor([33554432, 4, 8, 4],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 161947 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:45:50.270537 80757 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:45:50.271520 80757 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([335545, 128, 10, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([335545, 128, 10, 10],"float32"),Tensor([1, 32, 10, 10],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 335545 but got size 1 for tensor number 1 in the list.

W0206 23:47:08.258311 81326 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:47:08.259366 81326 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([335545, 128, 10, 10],"float32"),Tensor([335545, 32, 10, 10],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([335545, 128, 10, 10],"float32"),Tensor([335545, 32, 10, 10],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000032GB memory on GPU 0, 74.580994GB memory has been allocated and available memory is only 4.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 23:49:03.860502 81725 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:49:03.861434 81725 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([335545, 512, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([335545, 512, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 335545 but got size 1 for tensor number 1 in the list.

W0206 23:50:16.325335 82174 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:50:16.330629 82174 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([335545, 512, 5, 5],"float32"),Tensor([335545, 32, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([335545, 512, 5, 5],"float32"),Tensor([335545, 32, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000032GB memory on GPU 0, 68.580994GB memory has been allocated and available memory is only 10.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 23:52:04.375936 82565 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:52:04.376868 82565 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([33817, 2592, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([33817, 2592, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 33817 but got size 2 for tensor number 1 in the list.

W0206 23:53:14.781098 83019 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:53:14.782256 83019 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([33817, 2592, 7, 7],"float32"),Tensor([33817, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([33817, 2592, 7, 7],"float32"),Tensor([33817, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000232GB memory on GPU 0, 66.975525GB memory has been allocated and available memory is only 12.209351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 23:54:46.457639 83411 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:54:46.458478 83411 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([34, 126322568],"float32"),Tensor([34, 126322568],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([34, 126322568],"float32"),Tensor([34, 126322568],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 151814 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0206 23:57:06.048162 83835 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:57:06.049363 83835 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([34, 126322568],"float32"),Tensor([34, 13],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([34, 126322568],"float32"),Tensor([34, 13],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0206 23:58:45.243321 84507 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0206 23:58:45.244180 84507 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([34, 13],"float32"),Tensor([330382100, 13],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([34, 13],"float32"),Tensor([330382100, 13],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 34 but got size 330382100 for tensor number 1 in the list.

W0207 00:00:00.523656 84930 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:00:00.525231 84930 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([34, 13],"float32"),Tensor([34, 126322568],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([34, 13],"float32"),Tensor([34, 126322568],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 00:01:30.838680 85263 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:01:30.839567 85263 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([342393, 16, 28, 28],"float32"),Tensor([2, 16, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([342393, 16, 28, 28],"float32"),Tensor([2, 16, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 342393 but got size 2 for tensor number 1 in the list.

W0207 00:02:42.102072 85669 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:02:42.103142 85669 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([342393, 16, 28, 28],"float32"),Tensor([342393, 16, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([342393, 16, 28, 28],"float32"),Tensor([342393, 16, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 83018 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:05:08.344466 86068 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:05:08.345590 86068 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([34240, 160, 28, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([34240, 160, 28, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 34240 but got size 2 for tensor number 1 in the list.

W0207 00:06:27.640985 86750 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:06:27.642032 86750 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([34240, 160, 28, 28],"float32"),Tensor([34240, 32, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([34240, 160, 28, 28],"float32"),Tensor([34240, 32, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000366GB memory on GPU 0, 72.979431GB memory has been allocated and available memory is only 6.205444GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 00:08:14.535630 87069 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:08:14.536667 87069 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([34240, 2560, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([34240, 2560, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 34240 but got size 2 for tensor number 1 in the list.

W0207 00:09:28.225590 87591 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:09:28.226666 87591 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([34240, 2560, 7, 7],"float32"),Tensor([34240, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([34240, 2560, 7, 7],"float32"),Tensor([34240, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000366GB memory on GPU 0, 66.979431GB memory has been allocated and available memory is only 12.205444GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 00:11:03.709594 87908 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:11:03.710507 87908 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([34240, 640, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([34240, 640, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 34240 but got size 2 for tensor number 1 in the list.

W0207 00:12:14.916371 88333 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:12:14.917730 88333 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([34240, 640, 14, 14],"float32"),Tensor([34240, 32, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([34240, 640, 14, 14],"float32"),Tensor([34240, 32, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000366GB memory on GPU 0, 68.178650GB memory has been allocated and available memory is only 11.006226GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 00:13:51.282361 88738 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:13:51.283398 88738 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([343598, 50, 50, 5],"float32"),Tensor([343598, 50, 50, 5],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([343598, 50, 50, 5],"float32"),Tensor([343598, 50, 50, 5],"float32"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 74111 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:16:12.202637 89176 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:16:12.225795 89176 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([343598, 50, 50, 5],"float32"),Tensor([60, 50, 50, 5],"float32"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([343598, 50, 50, 5],"float32"),Tensor([60, 50, 50, 5],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 00:17:45.287570 89893 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:17:45.288475 89893 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([34673, 2528, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([34673, 2528, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 34673 but got size 2 for tensor number 1 in the list.

W0207 00:18:57.265522 90332 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:18:57.267165 90332 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([34673, 2528, 7, 7],"float32"),Tensor([34673, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([34673, 2528, 7, 7],"float32"),Tensor([34673, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000174GB memory on GPU 0, 66.983337GB memory has been allocated and available memory is only 12.201538GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 00:20:38.166839 90666 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:20:38.167714 90666 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([35118, 2496, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([35118, 2496, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 35118 but got size 2 for tensor number 1 in the list.

W0207 00:21:48.430635 91205 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:21:48.431967 91205 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([35118, 2496, 7, 7],"float32"),Tensor([35118, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([35118, 2496, 7, 7],"float32"),Tensor([35118, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000390GB memory on GPU 0, 66.991150GB memory has been allocated and available memory is only 12.193726GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 00:23:29.772852 91534 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:23:29.775197 91534 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([35118, 624, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([35118, 624, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 35118 but got size 2 for tensor number 1 in the list.

W0207 00:24:41.796057 91991 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:24:41.797225 91991 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([35118, 624, 14, 14],"float32"),Tensor([35118, 48, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([35118, 624, 14, 14],"float32"),Tensor([35118, 48, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000390GB memory on GPU 0, 69.041931GB memory has been allocated and available memory is only 10.142944GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 00:26:27.918009 92403 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:26:27.918823 92403 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([35574, 2464, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([35574, 2464, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 35574 but got size 2 for tensor number 1 in the list.

W0207 00:27:39.222972 92853 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:27:39.224200 92853 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([35574, 2464, 7, 7],"float32"),Tensor([35574, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([35574, 2464, 7, 7],"float32"),Tensor([35574, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000355GB memory on GPU 0, 66.995056GB memory has been allocated and available memory is only 12.189819GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 00:29:11.382422 93271 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:29:11.383240 93271 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([357913942, 3, 4],"float32"),Tensor([2, 3, 4],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([357913942, 3, 4],"float32"),Tensor([2, 3, 4],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 357913942 but got size 2 for tensor number 1 in the list.

W0207 00:30:35.447201 93716 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:30:35.448470 93716 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([357913942, 3, 4],"float32"),Tensor([357913942, 3, 4],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([357913942, 3, 4],"float32"),Tensor([357913942, 3, 4],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 2913 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:32:48.278913 94146 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:32:48.279985 94146 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([357914, 480, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([357914, 480, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 357914 but got size 1 for tensor number 1 in the list.

W0207 00:34:04.201105 94744 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:34:04.202387 94744 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([357914, 480, 5, 5],"float32"),Tensor([357914, 32, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([357914, 480, 5, 5],"float32"),Tensor([357914, 32, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000003GB memory on GPU 0, 68.713806GB memory has been allocated and available memory is only 10.471069GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 00:35:45.455564 95143 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:35:45.456557 95143 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3579140, 12, 10, 10],"float32"),Tensor([1, 12, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([3579140, 12, 10, 10],"float32"),Tensor([1, 12, 10, 10],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 3579140 but got size 1 for tensor number 1 in the list.

W0207 00:37:04.590490 95583 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:37:04.591449 95583 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([3579140, 12, 10, 10],"float32"),Tensor([3579140, 12, 10, 10],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([3579140, 12, 10, 10],"float32"),Tensor([3579140, 12, 10, 10],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 154361 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:39:30.021095 96025 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:39:30.022185 96025 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([36042, 2432, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([36042, 2432, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 36042 but got size 2 for tensor number 1 in the list.

W0207 00:40:54.317011 96643 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:40:54.317981 96643 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([36042, 2432, 7, 7],"float32"),Tensor([36042, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([36042, 2432, 7, 7],"float32"),Tensor([36042, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000319GB memory on GPU 0, 66.998962GB memory has been allocated and available memory is only 12.185913GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 00:42:38.585404 97061 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:42:38.586308 97061 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([36042, 608, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([36042, 608, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 36042 but got size 2 for tensor number 1 in the list.

W0207 00:43:56.992723 97600 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:43:56.993832 97600 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([36042, 608, 14, 14],"float32"),Tensor([36042, 32, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([36042, 608, 14, 14],"float32"),Tensor([36042, 32, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000319GB memory on GPU 0, 68.264587GB memory has been allocated and available memory is only 10.920288GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 00:45:36.422648 97939 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:45:36.423641 97939 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([36522, 2400, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([36522, 2400, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 36522 but got size 2 for tensor number 1 in the list.

W0207 00:46:55.570439 98385 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:46:55.571988 98385 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([36522, 2400, 7, 7],"float32"),Tensor([36522, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([36522, 2400, 7, 7],"float32"),Tensor([36522, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000074GB memory on GPU 0, 67.006775GB memory has been allocated and available memory is only 12.178101GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 00:48:35.883496 98791 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:48:35.884569 98791 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([37016, 2368, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([37016, 2368, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 37016 but got size 2 for tensor number 1 in the list.

W0207 00:49:49.523780 99228 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:49:49.524757 99228 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([37016, 2368, 7, 7],"float32"),Tensor([37016, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([37016, 2368, 7, 7],"float32"),Tensor([37016, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000273GB memory on GPU 0, 67.010681GB memory has been allocated and available memory is only 12.174194GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 00:51:23.381314 99648 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:51:23.382130 99648 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([37523, 2336, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([37523, 2336, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 37523 but got size 2 for tensor number 1 in the list.

W0207 00:52:36.865685 100080 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:52:36.866683 100080 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([37523, 2336, 7, 7],"float32"),Tensor([37523, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([37523, 2336, 7, 7],"float32"),Tensor([37523, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000244GB memory on GPU 0, 67.018494GB memory has been allocated and available memory is only 12.166382GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 00:54:11.121274 100500 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:54:11.124727 100500 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([377813, 232, 7, 7],"float32"),Tensor([2, 232, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([377813, 232, 7, 7],"float32"),Tensor([2, 232, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 377813 but got size 2 for tensor number 1 in the list.

W0207 00:55:24.287318 100918 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:55:24.288319 100918 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([377813, 232, 7, 7],"float32"),Tensor([377813, 232, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([377813, 232, 7, 7],"float32"),Tensor([377813, 232, 7, 7],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 6040 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 00:57:40.268797 101248 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:57:40.269951 101248 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([38044, 2304, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([38044, 2304, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 38044 but got size 2 for tensor number 1 in the list.

W0207 00:58:58.021924 101932 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 00:58:58.023080 101932 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([38044, 2304, 7, 7],"float32"),Tensor([38044, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([38044, 2304, 7, 7],"float32"),Tensor([38044, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000179GB memory on GPU 0, 67.022400GB memory has been allocated and available memory is only 12.162476GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 01:00:31.186295 102252 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:00:31.187193 102252 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([38044, 576, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([38044, 576, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 38044 but got size 2 for tensor number 1 in the list.

W0207 01:01:40.055428 102684 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:01:40.056427 102684 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([38044, 576, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([38044, 576, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 38044 but got size 2 for tensor number 1 in the list.

W0207 01:03:04.160547 103086 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:03:04.161475 103086 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([38044, 576, 14, 14],"float32"),Tensor([38044, 32, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([38044, 576, 14, 14],"float32"),Tensor([38044, 32, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000179GB memory on GPU 0, 68.358337GB memory has been allocated and available memory is only 10.826538GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 01:04:38.440523 103517 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:04:38.443171 103517 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([38044, 576, 14, 14],"float32"),Tensor([38044, 48, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([38044, 576, 14, 14],"float32"),Tensor([38044, 48, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000179GB memory on GPU 0, 69.245056GB memory has been allocated and available memory is only 9.939819GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 01:06:17.702677 103937 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:06:17.703702 103937 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([383480, 448, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([383480, 448, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 383480 but got size 1 for tensor number 1 in the list.

W0207 01:07:30.023020 104371 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:07:30.024163 104371 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([383480, 448, 5, 5],"float32"),Tensor([383480, 32, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([383480, 448, 5, 5],"float32"),Tensor([383480, 32, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000032GB memory on GPU 0, 68.866150GB memory has been allocated and available memory is only 10.318726GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 01:09:11.795884 104725 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:09:11.796734 104725 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([38580, 2272, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([38580, 2272, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 38580 but got size 2 for tensor number 1 in the list.

W0207 01:10:30.968513 105244 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:10:30.970134 105244 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([38580, 2272, 7, 7],"float32"),Tensor([38580, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([38580, 2272, 7, 7],"float32"),Tensor([38580, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000249GB memory on GPU 0, 67.030212GB memory has been allocated and available memory is only 12.154663GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 01:12:11.471213 105581 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:12:11.472150 105581 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([39131, 2240, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([39131, 2240, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 39131 but got size 2 for tensor number 1 in the list.

W0207 01:13:23.146719 106093 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:13:23.148236 106093 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([39131, 2240, 7, 7],"float32"),Tensor([39131, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([39131, 2240, 7, 7],"float32"),Tensor([39131, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000191GB memory on GPU 0, 67.038025GB memory has been allocated and available memory is only 12.146851GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 01:14:57.480481 106415 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:14:57.482806 106415 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([39698, 2208, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([39698, 2208, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 39698 but got size 2 for tensor number 1 in the list.

W0207 01:16:09.545897 106853 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:16:09.547088 106853 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([39698, 2208, 7, 7],"float32"),Tensor([39698, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([39698, 2208, 7, 7],"float32"),Tensor([39698, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000144GB memory on GPU 0, 67.041931GB memory has been allocated and available memory is only 12.142944GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 01:17:40.626572 107255 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:17:40.627451 107255 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 10],"float32"),Tensor([4, 10],"float32"),Tensor([4, 1073741824],"float32"),], 1, )
[paddle error] paddle.concat(list[Tensor([4, 10],"float32"),Tensor([4, 10],"float32"),Tensor([4, 1073741824],"float32"),], 1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 01:19:10.531169 107682 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:19:10.532202 107682 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 10],"float32"),Tensor([4, 10],"float32"),Tensor([429496730, 10],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([4, 10],"float32"),Tensor([4, 10],"float32"),Tensor([429496730, 10],"float32"),], 1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 4 but got size 429496730 for tensor number 2 in the list.

W0207 01:20:21.716517 108121 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:20:21.717664 108121 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 10],"float32"),Tensor([4, 1073741824],"float32"),], 1, )
[paddle error] paddle.concat(list[Tensor([4, 10],"float32"),Tensor([4, 1073741824],"float32"),], 1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 01:21:51.960069 108437 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:21:51.961233 108437 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 10],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 10],"float32"),], 1, )
[paddle error] paddle.concat(list[Tensor([4, 10],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 10],"float32"),], 1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 01:23:18.952471 108877 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:23:18.953687 108877 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 10],"float32"),Tensor([429496730, 10],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([4, 10],"float32"),Tensor([429496730, 10],"float32"),], 1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 4 but got size 429496730 for tensor number 1 in the list.

W0207 01:24:28.930737 109294 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:24:28.931947 109294 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 10],"float32"),Tensor([429496730, 10],"float32"),Tensor([4, 10],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([4, 10],"float32"),Tensor([429496730, 10],"float32"),Tensor([4, 10],"float32"),], 1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 4 but got size 429496730 for tensor number 1 in the list.

W0207 01:25:51.283128 109606 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:25:51.284487 109606 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 101],"float16"),Tensor([4, 1073741824],"float16"),], axis=-1, )
[Pass] paddle.concat(list[Tensor([4, 101],"float16"),Tensor([4, 1073741824],"float16"),], axis=-1, )

W0207 01:27:28.201606 110025 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:27:28.202486 110025 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 101],"float16"),Tensor([42524429, 101],"float16"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([4, 101],"float16"),Tensor([42524429, 101],"float16"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 4 but got size 42524429 for tensor number 1 in the list.

W0207 01:36:29.590662 112577 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:36:29.591835 112577 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 101],"float32"),Tensor([4, 1073741824],"float32"),], axis=-1, )
[paddle error] paddle.concat(list[Tensor([4, 101],"float32"),Tensor([4, 1073741824],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 01:37:59.725986 112719 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:37:59.727627 112719 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 101],"float32"),Tensor([42524429, 101],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([4, 101],"float32"),Tensor([42524429, 101],"float32"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 4 but got size 42524429 for tensor number 1 in the list.

W0207 01:39:15.833359 112761 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:39:15.834609 112761 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 101],"float64"),Tensor([21262215, 101],"float64"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([4, 101],"float64"),Tensor([21262215, 101],"float64"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 4 but got size 21262215 for tensor number 1 in the list.

W0207 01:40:10.888151 112817 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:40:10.889458 112817 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 101],"float64"),Tensor([4, 536870913],"float64"),], axis=-1, )
[paddle error] paddle.concat(list[Tensor([4, 101],"float64"),Tensor([4, 536870913],"float64"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 01:41:23.392562 112845 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:41:23.393462 112845 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 1073741824],"float16"),Tensor([4, 101],"float16"),], axis=-1, )
[Pass] paddle.concat(list[Tensor([4, 1073741824],"float16"),Tensor([4, 101],"float16"),], axis=-1, )

W0207 01:42:55.255066 112887 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:42:55.255956 112887 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 1073741824],"float16"),Tensor([4, 1073741824],"float16"),], axis=-1, )
[paddle error] paddle.concat(list[Tensor([4, 1073741824],"float16"),Tensor([4, 1073741824],"float16"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000000GB memory on GPU 0, 74.575134GB memory has been allocated and available memory is only 4.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 01:53:23.855731 113181 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:53:23.856633 113181 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 1073741824],"float32"),], 1, )
[paddle error] paddle.concat(list[Tensor([4, 1073741824],"float32"),], 1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 01:54:51.479806 113292 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:54:51.482379 113292 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 1073741824],"float32"),Tensor([1, 1073741824],"float32"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([4, 1073741824],"float32"),Tensor([1, 1073741824],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 74.575134GB memory has been allocated and available memory is only 4.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 01:56:31.074889 113335 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:56:31.075836 113335 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 1073741824],"float32"),Tensor([1, 2],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([4, 1073741824],"float32"),Tensor([1, 2],"float32"),], axis=0, ) 
 Sizes of tensors must match except in dimension 0. Expected size 1073741824 but got size 2 for tensor number 1 in the list.

W0207 01:57:46.394662 113404 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:57:46.395790 113404 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 1073741824],"float32"),Tensor([4, 10],"float32"),], 1, )
[paddle error] paddle.concat(list[Tensor([4, 1073741824],"float32"),Tensor([4, 10],"float32"),], 1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 01:59:20.213897 113447 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 01:59:20.214836 113447 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 1073741824],"float32"),Tensor([4, 10],"float32"),Tensor([4, 10],"float32"),], 1, )
[paddle error] paddle.concat(list[Tensor([4, 1073741824],"float32"),Tensor([4, 10],"float32"),Tensor([4, 10],"float32"),], 1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 02:00:50.491014 113489 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:00:50.491897 113489 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 1073741824],"float32"),Tensor([4, 101],"float32"),], axis=-1, )
[paddle error] paddle.concat(list[Tensor([4, 1073741824],"float32"),Tensor([4, 101],"float32"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 02:02:16.072553 113544 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:02:16.074894 113544 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),], )
[torch error] paddle.concat(list[Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),], ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 138128 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:04:23.958635 113601 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:04:23.959578 113601 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 119268 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:06:48.189029 113643 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:06:48.190135 113643 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 133293 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:09:09.443037 113712 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:09:09.444070 113712 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),], )
[torch error] paddle.concat(list[Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 146098 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:12:25.792207 113782 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:12:25.794695 113782 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 1073741824],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 41484 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:16:01.265985 113853 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:16:01.266978 113853 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 1073741824],"float32"),Tensor([4, 4],"float32"),], )
[torch error] paddle.concat(list[Tensor([4, 1073741824],"float32"),Tensor([4, 4],"float32"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 1073741824 but got size 4 for tensor number 1 in the list.

W0207 02:17:23.031539 113971 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:17:23.036237 113971 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 1073741824],"float32"),Tensor([4, 4],"float32"),Tensor([4, 4],"float32"),], )
[torch error] paddle.concat(list[Tensor([4, 1073741824],"float32"),Tensor([4, 4],"float32"),Tensor([4, 4],"float32"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 1073741824 but got size 4 for tensor number 1 in the list.

W0207 02:18:41.221266 114035 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:18:41.222543 114035 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 12, 32],"float64"),Tensor([4, 12, 44739243],"float64"),], -1, )
[paddle error] paddle.concat(list[Tensor([4, 12, 32],"float64"),Tensor([4, 12, 44739243],"float64"),], -1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 02:19:50.304790 114078 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:19:50.305696 114078 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 12, 32],"float64"),Tensor([4, 16777217, 32],"float64"),], -1, )
[torch error] paddle.concat(list[Tensor([4, 12, 32],"float64"),Tensor([4, 16777217, 32],"float64"),], -1, ) 
 Sizes of tensors must match except in dimension 2. Expected size 12 but got size 16777217 for tensor number 1 in the list.

W0207 02:20:38.139705 114120 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:20:38.140817 114120 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 12, 32],"float64"),Tensor([5592406, 12, 32],"float64"),], -1, )
[torch error] paddle.concat(list[Tensor([4, 12, 32],"float64"),Tensor([5592406, 12, 32],"float64"),], -1, ) 
 Sizes of tensors must match except in dimension 2. Expected size 4 but got size 5592406 for tensor number 1 in the list.

W0207 02:21:35.149865 114147 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:21:35.150972 114147 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 12, 44739243],"float64"),Tensor([4, 12, 32],"float64"),], -1, )
[paddle error] paddle.concat(list[Tensor([4, 12, 44739243],"float64"),Tensor([4, 12, 32],"float64"),], -1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 02:22:47.372385 114189 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:22:47.373278 114189 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 12, 44739243],"float64"),Tensor([4, 12, 44739243],"float64"),], -1, )
[torch error] paddle.concat(list[Tensor([4, 12, 44739243],"float64"),Tensor([4, 12, 44739243],"float64"),], -1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 110234 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:24:11.637568 114231 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:24:11.638687 114231 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 12, 44739243],"float64"),Tensor([4, 12, 8],"float64"),], -1, )
[paddle error] paddle.concat(list[Tensor([4, 12, 44739243],"float64"),Tensor([4, 12, 8],"float64"),], -1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 02:25:26.918934 114287 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:25:26.919873 114287 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 12, 8],"float64"),Tensor([22369622, 12, 8],"float64"),], -1, )
[torch error] paddle.concat(list[Tensor([4, 12, 8],"float64"),Tensor([22369622, 12, 8],"float64"),], -1, ) 
 Sizes of tensors must match except in dimension 2. Expected size 4 but got size 22369622 for tensor number 1 in the list.

W0207 02:26:17.345290 114330 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:26:17.346462 114330 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 12, 8],"float64"),Tensor([4, 12, 44739243],"float64"),], -1, )
[paddle error] paddle.concat(list[Tensor([4, 12, 8],"float64"),Tensor([4, 12, 44739243],"float64"),], -1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 02:27:23.706385 114371 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:27:23.707477 114371 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 12, 8],"float64"),Tensor([4, 67108865, 8],"float64"),], -1, )
[torch error] paddle.concat(list[Tensor([4, 12, 8],"float64"),Tensor([4, 67108865, 8],"float64"),], -1, ) 
 Sizes of tensors must match except in dimension 2. Expected size 12 but got size 67108865 for tensor number 1 in the list.

W0207 02:28:17.056595 114400 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:28:17.057730 114400 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 128, 110377, 76],"float32"),Tensor([4, 256, 110377, 76],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([4, 128, 110377, 76],"float32"),Tensor([4, 256, 110377, 76],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 29.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 15712 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 1.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:31:27.986140 114440 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:31:27.988925 114440 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 128, 110377, 76],"float32"),Tensor([4, 256, 76, 76],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([4, 128, 110377, 76],"float32"),Tensor([4, 256, 76, 76],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 110377 but got size 76 for tensor number 1 in the list.

W0207 02:32:46.270963 114509 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:32:46.272033 114509 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 128, 76, 110377],"float32"),Tensor([4, 256, 76, 110377],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([4, 128, 76, 110377],"float32"),Tensor([4, 256, 76, 110377],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 29.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 156838 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 1.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:36:12.646407 114552 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:36:12.647739 114552 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 128, 76, 110377],"float32"),Tensor([4, 256, 76, 76],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([4, 128, 76, 110377],"float32"),Tensor([4, 256, 76, 76],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 110377 but got size 76 for tensor number 1 in the list.

W0207 02:37:30.425683 114623 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:37:30.426990 114623 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 128, 76, 76],"float32"),Tensor([2905, 256, 76, 76],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([4, 128, 76, 76],"float32"),Tensor([2905, 256, 76, 76],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 4 but got size 2905 for tensor number 1 in the list.

W0207 02:38:52.309109 114652 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:38:52.313025 114652 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 128, 76, 76],"float32"),Tensor([4, 185898, 76, 76],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([4, 128, 76, 76],"float32"),Tensor([4, 185898, 76, 76],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000075GB memory on GPU 0, 66.612244GB memory has been allocated and available memory is only 12.572632GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 02:40:26.566272 114693 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:40:26.567101 114693 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 128, 76, 76],"float32"),Tensor([4, 256, 55189, 76],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([4, 128, 76, 76],"float32"),Tensor([4, 256, 55189, 76],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 76 but got size 55189 for tensor number 1 in the list.

W0207 02:41:43.022816 114750 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:41:43.023905 114750 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 128, 76, 76],"float32"),Tensor([4, 256, 76, 55189],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([4, 128, 76, 76],"float32"),Tensor([4, 256, 76, 55189],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 76 but got size 55189 for tensor number 1 in the list.

W0207 02:42:54.906684 114778 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:42:54.907872 114778 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 16777217, 32],"float64"),Tensor([4, 12, 32],"float64"),], -1, )
[torch error] paddle.concat(list[Tensor([4, 16777217, 32],"float64"),Tensor([4, 12, 32],"float64"),], -1, ) 
 Sizes of tensors must match except in dimension 2. Expected size 16777217 but got size 12 for tensor number 1 in the list.

W0207 02:43:49.464960 114806 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:43:49.466156 114806 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 16777217, 32],"float64"),Tensor([4, 16777217, 32],"float64"),], -1, )
[torch error] paddle.concat(list[Tensor([4, 16777217, 32],"float64"),Tensor([4, 16777217, 32],"float64"),], -1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 111501 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:45:26.669319 114834 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:45:26.670300 114834 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 185898, 76, 76],"float32"),Tensor([4, 185898, 76, 76],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([4, 185898, 76, 76],"float32"),Tensor([4, 185898, 76, 76],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 56357 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 02:47:41.216061 114875 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:47:41.217159 114875 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 185898, 76, 76],"float32"),Tensor([4, 256, 76, 76],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([4, 185898, 76, 76],"float32"),Tensor([4, 256, 76, 76],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000075GB memory on GPU 0, 66.623962GB memory has been allocated and available memory is only 12.560913GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 02:49:17.696651 114946 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:49:17.697539 114946 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 2],"float32"),Tensor([1, 4294967295],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([4, 2],"float32"),Tensor([1, 4294967295],"float32"),], axis=0, ) 
 Sizes of tensors must match except in dimension 0. Expected size 2 but got size 4294967295 for tensor number 1 in the list.

W0207 02:50:28.289361 115001 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:50:28.290648 115001 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 2],"float32"),Tensor([2147483648, 2],"float32"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([4, 2],"float32"),Tensor([2147483648, 2],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 02:52:04.135849 115043 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:52:04.136711 115043 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 20, 20],"float16"),Tensor([10737419, 20, 20],"float16"),], )
[Pass] paddle.concat(list[Tensor([4, 20, 20],"float16"),Tensor([10737419, 20, 20],"float16"),], )

W0207 02:53:42.165465 115105 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 02:53:42.166381 115105 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 20, 20],"float16"),Tensor([4, 20, 53687092],"float16"),], )
[torch error] paddle.concat(list[Tensor([4, 20, 20],"float16"),Tensor([4, 20, 53687092],"float16"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 20 but got size 53687092 for tensor number 1 in the list.

W0207 03:02:53.052624 115365 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:02:53.054126 115365 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 20, 20],"float16"),Tensor([4, 53687092, 20],"float16"),], )
[torch error] paddle.concat(list[Tensor([4, 20, 20],"float16"),Tensor([4, 53687092, 20],"float16"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 20 but got size 53687092 for tensor number 1 in the list.

W0207 03:04:21.179385 115420 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:04:21.180574 115420 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 20, 53687092],"float16"),Tensor([4, 20, 20],"float16"),], )
[torch error] paddle.concat(list[Tensor([4, 20, 53687092],"float16"),Tensor([4, 20, 20],"float16"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 53687092 but got size 20 for tensor number 1 in the list.

W0207 03:05:51.220363 115477 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:05:51.221593 115477 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 20, 53687092],"float16"),Tensor([4, 20, 53687092],"float16"),], )
[paddle error] paddle.concat(list[Tensor([4, 20, 53687092],"float16"),Tensor([4, 20, 53687092],"float16"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000000GB memory on GPU 0, 74.582947GB memory has been allocated and available memory is only 4.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 03:09:01.879114 115533 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:09:01.880038 115533 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 256, 110377, 38],"float32"),Tensor([4, 512, 110377, 38],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([4, 256, 110377, 38],"float32"),Tensor([4, 512, 110377, 38],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 29.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 69402 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 1.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:12:09.985960 115617 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:12:09.987497 115617 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 256, 110377, 38],"float32"),Tensor([4, 512, 38, 38],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([4, 256, 110377, 38],"float32"),Tensor([4, 512, 38, 38],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 110377 but got size 38 for tensor number 1 in the list.

W0207 03:13:23.883790 115729 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:13:23.884894 115729 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 256, 38, 110377],"float32"),Tensor([4, 512, 38, 110377],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([4, 256, 38, 110377],"float32"),Tensor([4, 512, 38, 110377],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 29.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 48461 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 1.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:16:35.039077 115771 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:16:35.040089 115771 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 256, 38, 110377],"float32"),Tensor([4, 512, 38, 38],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([4, 256, 38, 110377],"float32"),Tensor([4, 512, 38, 38],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 110377 but got size 38 for tensor number 1 in the list.

W0207 03:17:55.726253 115869 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:17:55.727327 115869 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 256, 38, 38],"float32"),Tensor([4, 512, 38, 55189],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([4, 256, 38, 38],"float32"),Tensor([4, 512, 38, 55189],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 38 but got size 55189 for tensor number 1 in the list.

W0207 03:19:08.728751 115911 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:19:08.729986 115911 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 256, 38, 38],"float32"),Tensor([4, 512, 55189, 38],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([4, 256, 38, 38],"float32"),Tensor([4, 512, 55189, 38],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 38 but got size 55189 for tensor number 1 in the list.

W0207 03:20:29.590806 115953 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:20:29.592065 115953 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 256, 38, 38],"float32"),Tensor([4, 743589, 38, 38],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([4, 256, 38, 38],"float32"),Tensor([4, 743589, 38, 38],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000010GB memory on GPU 0, 66.608337GB memory has been allocated and available memory is only 12.576538GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 03:21:59.901026 116008 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:21:59.902101 116008 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 256, 38, 38],"float32"),Tensor([5810, 512, 38, 38],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([4, 256, 38, 38],"float32"),Tensor([5810, 512, 38, 38],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 4 but got size 5810 for tensor number 1 in the list.

W0207 03:23:09.333030 116051 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:23:09.334246 116051 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 4],"float32"),Tensor([1073741824, 4],"float32"),], )
[paddle error] paddle.concat(list[Tensor([4, 4],"float32"),Tensor([1073741824, 4],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 03:24:43.067350 116093 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:24:43.068397 116093 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 4],"float32"),Tensor([1073741824, 4],"float32"),Tensor([4, 4],"float32"),], )
[paddle error] paddle.concat(list[Tensor([4, 4],"float32"),Tensor([1073741824, 4],"float32"),Tensor([4, 4],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 03:26:14.533054 116149 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:26:14.533893 116149 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 4],"float32"),Tensor([4, 1073741824],"float32"),], )
[torch error] paddle.concat(list[Tensor([4, 4],"float32"),Tensor([4, 1073741824],"float32"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 4 but got size 1073741824 for tensor number 1 in the list.

W0207 03:27:22.924520 116191 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:27:22.925712 116191 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 4],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 4],"float32"),], )
[torch error] paddle.concat(list[Tensor([4, 4],"float32"),Tensor([4, 1073741824],"float32"),Tensor([4, 4],"float32"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 4 but got size 1073741824 for tensor number 1 in the list.

W0207 03:28:44.867249 116233 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:28:44.868515 116233 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 4],"float32"),Tensor([4, 4],"float32"),Tensor([1073741824, 4],"float32"),], )
[paddle error] paddle.concat(list[Tensor([4, 4],"float32"),Tensor([4, 4],"float32"),Tensor([1073741824, 4],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 03:30:17.854769 116289 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:30:17.855679 116289 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 4],"float32"),Tensor([4, 4],"float32"),Tensor([4, 1073741824],"float32"),], )
[torch error] paddle.concat(list[Tensor([4, 4],"float32"),Tensor([4, 4],"float32"),Tensor([4, 1073741824],"float32"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 4 but got size 1073741824 for tensor number 2 in the list.

W0207 03:31:28.563300 116345 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:31:28.564376 116345 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 5, 20],"float32"),Tensor([4, 5, 214748365],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([4, 5, 20],"float32"),Tensor([4, 5, 214748365],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 20 but got size 214748365 for tensor number 1 in the list.

W0207 03:32:48.309545 116387 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:32:48.310729 116387 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 5, 20],"float32"),Tensor([4, 53687092, 20],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([4, 5, 20],"float32"),Tensor([4, 53687092, 20],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 03:34:19.514930 116442 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:34:19.516492 116442 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 5, 20],"float32"),Tensor([42949673, 5, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([4, 5, 20],"float32"),Tensor([42949673, 5, 20],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 4 but got size 42949673 for tensor number 1 in the list.

W0207 03:35:33.820168 116485 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:35:33.821259 116485 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 5, 214748365],"float32"),Tensor([4, 5, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([4, 5, 214748365],"float32"),Tensor([4, 5, 20],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 214748365 but got size 20 for tensor number 1 in the list.

W0207 03:36:49.333225 116527 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:36:49.334307 116527 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 5, 214748365],"float32"),Tensor([4, 5, 214748365],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([4, 5, 214748365],"float32"),Tensor([4, 5, 214748365],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 60741 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:39:12.762074 116582 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:39:12.763152 116582 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 536870913],"float64"),Tensor([4, 101],"float64"),], axis=-1, )
[paddle error] paddle.concat(list[Tensor([4, 536870913],"float64"),Tensor([4, 101],"float64"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 03:40:32.224555 116654 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:40:32.225450 116654 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([4, 536870913],"float64"),Tensor([4, 536870913],"float64"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 149316 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:42:12.540714 116722 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:42:12.541700 116722 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 53687092, 20],"float16"),Tensor([4, 20, 20],"float16"),], )
[torch error] paddle.concat(list[Tensor([4, 53687092, 20],"float16"),Tensor([4, 20, 20],"float16"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 53687092 but got size 20 for tensor number 1 in the list.

W0207 03:43:46.924702 116779 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:43:46.925977 116779 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 53687092, 20],"float16"),Tensor([4, 53687092, 20],"float16"),], )
[paddle error] paddle.concat(list[Tensor([4, 53687092, 20],"float16"),Tensor([4, 53687092, 20],"float16"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000000GB memory on GPU 0, 74.582947GB memory has been allocated and available memory is only 4.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 03:46:45.868950 116835 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:46:45.870754 116835 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 53687092, 20],"float32"),Tensor([4, 5, 20],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([4, 53687092, 20],"float32"),Tensor([4, 5, 20],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 03:48:21.311852 116919 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:48:21.313103 116919 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 53687092, 20],"float32"),Tensor([4, 53687092, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([4, 53687092, 20],"float32"),Tensor([4, 53687092, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 56096 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:50:38.313413 116974 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:50:38.314429 116974 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 67108865, 8],"float64"),Tensor([4, 12, 8],"float64"),], -1, )
[torch error] paddle.concat(list[Tensor([4, 67108865, 8],"float64"),Tensor([4, 12, 8],"float64"),], -1, ) 
 Sizes of tensors must match except in dimension 2. Expected size 67108865 but got size 12 for tensor number 1 in the list.

W0207 03:51:32.835789 117045 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:51:32.837512 117045 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 67108865, 8],"float64"),Tensor([4, 67108865, 8],"float64"),], -1, )
[torch error] paddle.concat(list[Tensor([4, 67108865, 8],"float64"),Tensor([4, 67108865, 8],"float64"),], -1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 115349 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:53:09.889175 117100 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:53:09.890398 117100 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 743589, 38, 38],"float32"),Tensor([4, 512, 38, 38],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([4, 743589, 38, 38],"float32"),Tensor([4, 512, 38, 38],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000010GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 03:54:39.938175 117143 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:54:39.939119 117143 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4, 743589, 38, 38],"float32"),Tensor([4, 743589, 38, 38],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([4, 743589, 38, 38],"float32"),Tensor([4, 743589, 38, 38],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 2431 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 03:56:59.699116 117212 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:56:59.700256 117212 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4],"float32"),Tensor([4],"float32"),Tensor([4],"float32"),Tensor([4294967295],"float32"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([4],"float32"),Tensor([4],"float32"),Tensor([4],"float32"),Tensor([4294967295],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 03:58:31.076035 117282 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 03:58:31.076910 117282 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4],"float32"),Tensor([4],"float32"),Tensor([4294967295],"float32"),Tensor([4],"float32"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([4],"float32"),Tensor([4],"float32"),Tensor([4294967295],"float32"),Tensor([4],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 04:00:03.713052 117339 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:00:03.713922 117339 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4],"float32"),Tensor([4294967295],"float32"),Tensor([4],"float32"),Tensor([4],"float32"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([4],"float32"),Tensor([4294967295],"float32"),Tensor([4],"float32"),Tensor([4],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 04:01:34.882793 117395 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:01:34.883690 117395 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4],"float64"),Tensor([2147483649],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([4],"float64"),Tensor([2147483649],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 04:02:43.256903 117437 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:02:43.257787 117437 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([40, 429497, 50, 5],"float32"),Tensor([60, 429497, 50, 5],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([40, 429497, 50, 5],"float32"),Tensor([60, 429497, 50, 5],"float32"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 40.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 77881 has 40.99 GiB memory in use. Of the allocated memory 40.00 GiB is allocated by PyTorch, and 3.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:05:29.845961 117492 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:05:29.847065 117492 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([40, 429497, 50, 5],"float32"),Tensor([60, 50, 50, 5],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([40, 429497, 50, 5],"float32"),Tensor([60, 50, 50, 5],"float32"),], axis=0, ) 
 Sizes of tensors must match except in dimension 0. Expected size 429497 but got size 50 for tensor number 1 in the list.

W0207 04:06:48.767709 117577 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:06:48.768926 117577 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([40, 50, 429497, 5],"float32"),Tensor([60, 50, 429497, 5],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([40, 50, 429497, 5],"float32"),Tensor([60, 50, 429497, 5],"float32"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 40.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 35156 has 40.99 GiB memory in use. Of the allocated memory 40.00 GiB is allocated by PyTorch, and 3.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:09:47.098085 117632 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:09:47.099193 117632 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([40, 50, 429497, 5],"float32"),Tensor([60, 50, 50, 5],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([40, 50, 429497, 5],"float32"),Tensor([60, 50, 50, 5],"float32"),], axis=0, ) 
 Sizes of tensors must match except in dimension 0. Expected size 429497 but got size 50 for tensor number 1 in the list.

W0207 04:11:13.129575 117730 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:11:13.130616 117730 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([40, 50, 50, 42950],"float32"),Tensor([60, 50, 50, 42950],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([40, 50, 50, 42950],"float32"),Tensor([60, 50, 50, 42950],"float32"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 40.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 23564 has 40.99 GiB memory in use. Of the allocated memory 40.00 GiB is allocated by PyTorch, and 3.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:14:14.731714 117773 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:14:14.732829 117773 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([40, 50, 50, 42950],"float32"),Tensor([60, 50, 50, 5],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([40, 50, 50, 42950],"float32"),Tensor([60, 50, 50, 5],"float32"),], axis=0, ) 
 Sizes of tensors must match except in dimension 0. Expected size 42950 but got size 5 for tensor number 1 in the list.

W0207 04:15:40.523877 117870 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:15:40.525285 117870 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([40, 50, 50, 5],"float32"),Tensor([343598, 50, 50, 5],"float32"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([40, 50, 50, 5],"float32"),Tensor([343598, 50, 50, 5],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000029GB memory on GPU 0, 66.600525GB memory has been allocated and available memory is only 12.584351GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 04:17:14.821501 117913 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:17:14.822463 117913 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([40, 50, 50, 5],"float32"),Tensor([60, 286332, 50, 5],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([40, 50, 50, 5],"float32"),Tensor([60, 286332, 50, 5],"float32"),], axis=0, ) 
 Sizes of tensors must match except in dimension 0. Expected size 50 but got size 286332 for tensor number 1 in the list.

W0207 04:18:24.893101 117961 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:18:24.894258 117961 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([40, 50, 50, 5],"float32"),Tensor([60, 50, 286332, 5],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([40, 50, 50, 5],"float32"),Tensor([60, 50, 286332, 5],"float32"),], axis=0, ) 
 Sizes of tensors must match except in dimension 0. Expected size 50 but got size 286332 for tensor number 1 in the list.

W0207 04:19:46.841447 118012 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:19:46.842762 118012 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([40, 50, 50, 5],"float32"),Tensor([60, 50, 50, 28634],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([40, 50, 50, 5],"float32"),Tensor([60, 50, 50, 28634],"float32"),], axis=0, ) 
 Sizes of tensors must match except in dimension 0. Expected size 5 but got size 28634 for tensor number 1 in the list.

W0207 04:21:06.546008 118081 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:21:06.547253 118081 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([40282, 2176, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([40282, 2176, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 40282 but got size 2 for tensor number 1 in the list.

W0207 04:22:23.962200 118123 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:22:23.963501 118123 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([40282, 2176, 7, 7],"float32"),Tensor([40282, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([40282, 2176, 7, 7],"float32"),Tensor([40282, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000226GB memory on GPU 0, 67.049744GB memory has been allocated and available memory is only 12.135132GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 04:23:55.731683 118179 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:23:55.732522 118179 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([40282, 544, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([40282, 544, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 40282 but got size 2 for tensor number 1 in the list.

W0207 04:25:06.884907 118221 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:25:06.885970 118221 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([40282, 544, 14, 14],"float32"),Tensor([40282, 32, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([40282, 544, 14, 14],"float32"),Tensor([40282, 32, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000226GB memory on GPU 0, 68.461853GB memory has been allocated and available memory is only 10.723022GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 04:26:40.382165 118276 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:26:40.383080 118276 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([40580, 2160, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([40580, 2160, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 40580 but got size 2 for tensor number 1 in the list.

W0207 04:27:55.843528 118333 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:27:55.844748 118333 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([40580, 2160, 7, 7],"float32"),Tensor([40580, 48, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([40580, 2160, 7, 7],"float32"),Tensor([40580, 48, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000074GB memory on GPU 0, 67.291931GB memory has been allocated and available memory is only 11.892944GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 04:29:38.851054 118375 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:29:38.851889 118375 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4077, 336, 56, 56],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([4077, 336, 56, 56],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 4077 but got size 2 for tensor number 1 in the list.

W0207 04:30:47.594413 118444 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:30:47.595664 118444 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4077, 336, 56, 56],"float32"),Tensor([4077, 48, 56, 56],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([4077, 336, 56, 56],"float32"),Tensor([4077, 48, 56, 56],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.003544GB memory on GPU 0, 71.157166GB memory has been allocated and available memory is only 8.027710GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 04:32:27.788853 118487 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:32:27.791438 118487 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([40883, 2144, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([40883, 2144, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 40883 but got size 2 for tensor number 1 in the list.

W0207 04:33:48.618530 118556 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:33:48.619877 118556 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([40883, 2144, 7, 7],"float32"),Tensor([40883, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([40883, 2144, 7, 7],"float32"),Tensor([40883, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000139GB memory on GPU 0, 67.057556GB memory has been allocated and available memory is only 12.127319GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 04:35:19.190306 118599 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:35:19.191154 118599 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4098, 1048065],"float32"),Tensor([4098, 1048065],"float32"),], )
[torch error] paddle.concat(list[Tensor([4098, 1048065],"float32"),Tensor([4098, 1048065],"float32"),], ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 62419 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 04:37:28.193920 118641 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:37:28.194878 118641 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4098, 1048065],"float32"),Tensor([4098, 4098],"float32"),], )
[torch error] paddle.concat(list[Tensor([4098, 1048065],"float32"),Tensor([4098, 4098],"float32"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 1048065 but got size 4098 for tensor number 1 in the list.

W0207 04:38:46.209745 118725 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:38:46.210939 118725 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4098, 4098],"float32"),Tensor([1048065, 4098],"float32"),], )
[paddle error] paddle.concat(list[Tensor([4098, 4098],"float32"),Tensor([1048065, 4098],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000012GB memory on GPU 0, 66.770447GB memory has been allocated and available memory is only 12.414429GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 04:40:14.136341 118767 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:40:14.137375 118767 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4098, 4098],"float32"),Tensor([4098, 1048065],"float32"),], )
[torch error] paddle.concat(list[Tensor([4098, 4098],"float32"),Tensor([4098, 1048065],"float32"),], ) 
 Sizes of tensors must match except in dimension 0. Expected size 4098 but got size 1048065 for tensor number 1 in the list.

W0207 04:41:32.140267 118822 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:41:32.141405 118822 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([412978, 416, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([412978, 416, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 412978 but got size 1 for tensor number 1 in the list.

W0207 04:42:48.207921 118866 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:42:48.209138 118866 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([412978, 416, 5, 5],"float32"),Tensor([412978, 32, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([412978, 416, 5, 5],"float32"),Tensor([412978, 32, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000015GB memory on GPU 0, 69.041931GB memory has been allocated and available memory is only 10.142944GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 04:44:23.243507 118913 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:44:23.244336 118913 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([41503, 2112, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([41503, 2112, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 41503 but got size 2 for tensor number 1 in the list.

W0207 04:45:42.386607 118977 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:45:42.388001 118977 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([41503, 2112, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([41503, 2112, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 41503 but got size 2 for tensor number 1 in the list.

W0207 04:47:03.805207 119032 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:47:03.806169 119032 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([41503, 2112, 7, 7],"float32"),Tensor([41503, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([41503, 2112, 7, 7],"float32"),Tensor([41503, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000355GB memory on GPU 0, 67.065369GB memory has been allocated and available memory is only 12.119507GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 04:48:41.626310 119074 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:48:41.627243 119074 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([41503, 2112, 7, 7],"float32"),Tensor([41503, 48, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([41503, 2112, 7, 7],"float32"),Tensor([41503, 48, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000355GB memory on GPU 0, 67.307556GB memory has been allocated and available memory is only 11.877319GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 04:50:11.900512 119117 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:50:11.901326 119117 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([41503, 528, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([41503, 528, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 41503 but got size 2 for tensor number 1 in the list.

W0207 04:51:23.023820 119172 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:51:23.025193 119172 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([41503, 528, 14, 14],"float32"),Tensor([41503, 48, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([41503, 528, 14, 14],"float32"),Tensor([41503, 48, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000355GB memory on GPU 0, 69.487244GB memory has been allocated and available memory is only 9.697632GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 04:53:06.136281 119215 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:53:06.138980 119215 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([42141, 2080, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([42141, 2080, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 42141 but got size 2 for tensor number 1 in the list.

W0207 04:54:17.407277 119257 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:54:17.408355 119257 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([42141, 2080, 7, 7],"float32"),Tensor([42141, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([42141, 2080, 7, 7],"float32"),Tensor([42141, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000162GB memory on GPU 0, 67.073181GB memory has been allocated and available memory is only 12.111694GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 04:55:57.956343 119312 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:55:57.957309 119312 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([42468, 2064, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([42468, 2064, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 42468 but got size 2 for tensor number 1 in the list.

W0207 04:57:16.444911 119368 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:57:16.446485 119368 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([42468, 2064, 7, 7],"float32"),Tensor([42468, 48, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([42468, 2064, 7, 7],"float32"),Tensor([42468, 48, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000284GB memory on GPU 0, 67.323181GB memory has been allocated and available memory is only 11.861694GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 04:58:48.649567 119397 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 04:58:48.650530 119397 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([42524429, 101],"float16"),Tensor([4, 101],"float16"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([42524429, 101],"float16"),Tensor([4, 101],"float16"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 42524429 but got size 4 for tensor number 1 in the list.

W0207 05:00:20.496397 119452 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:00:20.497895 119452 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([42524429, 101],"float16"),Tensor([42524429, 101],"float16"),], axis=-1, )
[paddle error] paddle.concat(list[Tensor([42524429, 101],"float16"),Tensor([42524429, 101],"float16"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000000GB memory on GPU 0, 74.582947GB memory has been allocated and available memory is only 4.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 05:03:35.635504 119509 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:03:35.636929 119509 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([42524429, 101],"float32"),Tensor([4, 101],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([42524429, 101],"float32"),Tensor([4, 101],"float32"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 42524429 but got size 4 for tensor number 1 in the list.

W0207 05:04:46.664945 119606 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:04:46.666175 119606 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([42524429, 101],"float32"),Tensor([42524429, 101],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([42524429, 101],"float32"),Tensor([42524429, 101],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 155834 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 05:06:59.748126 119648 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:06:59.749238 119648 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([42800, 128, 28, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([42800, 128, 28, 28],"float32"),Tensor([2, 32, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 42800 but got size 2 for tensor number 1 in the list.

W0207 05:08:22.061715 119718 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:08:22.062686 119718 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([42800, 128, 28, 28],"float32"),Tensor([42800, 32, 28, 28],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([42800, 128, 28, 28],"float32"),Tensor([42800, 32, 28, 28],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000366GB memory on GPU 0, 74.580994GB memory has been allocated and available memory is only 4.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 05:10:18.037618 119760 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:10:18.038440 119760 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([42800, 2048, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([42800, 2048, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 42800 but got size 2 for tensor number 1 in the list.

W0207 05:11:27.781636 119830 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:11:27.782680 119830 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([42800, 2048, 7, 7],"float32"),Tensor([42800, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([42800, 2048, 7, 7],"float32"),Tensor([42800, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000366GB memory on GPU 0, 67.080994GB memory has been allocated and available memory is only 12.103882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 05:12:59.613036 119859 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:12:59.613883 119859 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([42800, 512, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([42800, 512, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 42800 but got size 2 for tensor number 1 in the list.

W0207 05:14:10.449277 119913 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:14:10.450434 119913 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([42800, 512, 14, 14],"float32"),Tensor([42800, 32, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([42800, 512, 14, 14],"float32"),Tensor([42800, 32, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000366GB memory on GPU 0, 68.580994GB memory has been allocated and available memory is only 10.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 05:15:51.760113 119956 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:15:51.760973 119956 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295, 1, 1],"float16"),], axis=2, name=None, )
[Pass] paddle.concat(list[Tensor([4294967295, 1, 1],"float16"),], axis=2, name=None, )

W0207 05:17:22.535753 120012 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:17:22.536757 120012 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295, 1, 1],"float32"),], axis=2, name=None, )
[paddle error] paddle.concat(list[Tensor([4294967295, 1, 1],"float32"),], axis=2, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 05:26:24.369009 120209 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:26:24.371397 120209 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295, 1, 1],"int32"),], axis=2, name=None, )
[paddle error] paddle.concat(list[Tensor([4294967295, 1, 1],"int32"),], axis=2, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 05:27:51.877341 120250 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:27:51.878288 120250 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295, 1],"float16"),], axis=0, name=None, )
[Pass] paddle.concat(list[Tensor([4294967295, 1],"float16"),], axis=0, name=None, )

W0207 05:29:21.474682 120279 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:29:21.475534 120279 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295, 1],"float16"),], axis=1, name=None, )
[Pass] paddle.concat(list[Tensor([4294967295, 1],"float16"),], axis=1, name=None, )

W0207 05:38:29.199112 120557 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:38:29.200577 120557 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295, 1],"float32"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([4294967295, 1],"float32"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 05:47:40.236534 120782 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:47:40.237461 120782 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295, 1],"float32"),], axis=1, name=None, )
[paddle error] paddle.concat(list[Tensor([4294967295, 1],"float32"),], axis=1, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 05:49:13.832798 120824 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:49:13.833691 120824 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295, 1],"int32"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([4294967295, 1],"int32"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 05:50:43.162021 120868 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:50:43.163056 120868 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295, 1],"int32"),], axis=1, name=None, )
[paddle error] paddle.concat(list[Tensor([4294967295, 1],"int32"),], axis=1, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 05:52:09.123145 120923 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:52:09.124012 120923 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"bfloat16"),Tensor([100],"bfloat16"),], )
[paddle error] paddle.concat(list[Tensor([4294967295],"bfloat16"),Tensor([100],"bfloat16"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_cast(_object*, _object*, _object*)
1   cast_ad_func(paddle::Tensor const&, phi::DataType)
2   paddle::experimental::cast(paddle::Tensor const&, phi::DataType)
3   void phi::CastKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
4   void phi::CastCUDAKernelImpl<float, phi::dtype::bfloat16>(phi::GPUContext const&, phi::DenseTensor const&, phi::DataType, phi::DenseTensor*)
5   phi::dtype::bfloat16* phi::DeviceContext::Alloc<phi::dtype::bfloat16>(phi::TensorBase*, unsigned long, bool) const
6   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
7   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
8   paddle::memory::allocation::Allocator::Allocate(unsigned long)
9   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::Allocator::Allocate(unsigned long)
14  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
15  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
16  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000000GB memory on GPU 0, 74.577087GB memory has been allocated and available memory is only 4.607788GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 05:53:38.129390 120978 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:53:38.130339 120978 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"bfloat16"),Tensor([4294967295],"bfloat16"),], )
[paddle error] paddle.concat(list[Tensor([4294967295],"bfloat16"),Tensor([4294967295],"bfloat16"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 05:56:12.471101 121035 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:56:12.472555 121035 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float16"),], axis=0, name=None, )
[Pass] paddle.concat(list[Tensor([4294967295],"float16"),], axis=0, name=None, )

W0207 05:57:53.116228 121105 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 05:57:53.117324 121105 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float16"),Tensor([100],"float16"),], )
[Pass] paddle.concat(list[Tensor([4294967295],"float16"),Tensor([100],"float16"),], )

W0207 06:07:08.272297 121342 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:07:08.273173 121342 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float16"),Tensor([128],"float16"),Tensor([128],"float16"),], axis=-1, )
[Pass] paddle.concat(list[Tensor([4294967295],"float16"),Tensor([128],"float16"),Tensor([128],"float16"),], axis=-1, )

W0207 06:16:23.223927 121553 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:16:23.224758 121553 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),], )
[paddle error] paddle.concat(list[Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000000GB memory on GPU 0, 74.575134GB memory has been allocated and available memory is only 4.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 06:26:48.131547 121805 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:26:48.132412 121805 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),Tensor([4294967295],"float16"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 24.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 21.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 33173 has 24.99 GiB memory in use. Of the allocated memory 24.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 06:30:36.874003 121901 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:30:36.875089 121901 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float16"),Tensor([500],"float16"),], )
[Pass] paddle.concat(list[Tensor([4294967295],"float16"),Tensor([500],"float16"),], )

W0207 06:32:16.745509 121973 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:32:16.746388 121973 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float16"),Tensor([512],"float16"),Tensor([512],"float16"),], axis=-1, )
[Pass] paddle.concat(list[Tensor([4294967295],"float16"),Tensor([512],"float16"),Tensor([512],"float16"),], axis=-1, )

W0207 06:41:44.788110 122225 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:41:44.789142 122225 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float32"),], )
[paddle error] paddle.concat(list[Tensor([4294967295],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 06:51:09.877869 122408 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:51:09.878764 122408 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float32"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([4294967295],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 06:52:44.072386 122468 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:52:44.075369 122468 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float32"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([4294967295],"float32"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 06:54:12.524549 122520 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:54:12.525537 122520 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float32"),Tensor([1],"float32"),], )
[paddle error] paddle.concat(list[Tensor([4294967295],"float32"),Tensor([1],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.577087GB memory has been allocated and available memory is only 12.607788GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 06:55:43.696174 122587 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:55:43.697194 122587 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], )
[paddle error] paddle.concat(list[Tensor([4294967295],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),Tensor([1],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 06:57:08.415989 122631 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:57:08.416985 122631 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float32"),Tensor([100],"float32"),], )
[paddle error] paddle.concat(list[Tensor([4294967295],"float32"),Tensor([100],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 06:58:38.166096 122673 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 06:58:38.167028 122673 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),], )
[paddle error] paddle.concat(list[Tensor([4294967295],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 07:00:06.478268 122729 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:00:06.479157 122729 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([4294967295],"float32"),Tensor([128],"float32"),Tensor([128],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 07:01:39.123986 122771 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:01:39.124975 122771 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float32"),Tensor([2],"float32"),], )
[paddle error] paddle.concat(list[Tensor([4294967295],"float32"),Tensor([2],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 07:03:09.790372 122827 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:03:09.791327 122827 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float32"),Tensor([3],"float32"),Tensor([3],"float32"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([4294967295],"float32"),Tensor([3],"float32"),Tensor([3],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 07:04:41.452081 122870 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:04:41.453064 122870 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float32"),Tensor([36],"float32"),Tensor([10],"float32"),], )
[paddle error] paddle.concat(list[Tensor([4294967295],"float32"),Tensor([36],"float32"),Tensor([10],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 07:06:11.471136 122897 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:06:11.472384 122897 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float32"),Tensor([4],"float32"),Tensor([4],"float32"),Tensor([4],"float32"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([4294967295],"float32"),Tensor([4],"float32"),Tensor([4],"float32"),Tensor([4],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 07:07:44.252229 122959 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:07:44.255095 122959 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.concat(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 114045 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:10:00.104480 123022 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:10:00.105569 123022 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.concat(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 100303 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:13:17.006244 123080 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:13:17.008930 123080 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 16202 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:16:45.760545 123164 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:16:45.763418 123164 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 94445 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:20:05.910161 123261 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:20:05.911222 123261 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.concat(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 5171 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:23:35.769194 123372 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:23:35.771879 123372 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 83124 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:26:50.471679 123469 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:26:50.472688 123469 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.concat(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 136586 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:30:13.993261 123541 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:30:13.994287 123541 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], )
[torch error] paddle.concat(list[Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),Tensor([4294967295],"float32"),], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 56781 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:33:41.240523 123624 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:33:41.241674 123624 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float32"),Tensor([500],"float32"),], )
[paddle error] paddle.concat(list[Tensor([4294967295],"float32"),Tensor([500],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 07:35:20.078897 123737 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:35:20.081351 123737 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float32"),Tensor([512],"float32"),Tensor([512],"float32"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([4294967295],"float32"),Tensor([512],"float32"),Tensor([512],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 07:36:46.335264 123808 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:36:46.337764 123808 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float32"),Tensor([6],"float32"),], )
[paddle error] paddle.concat(list[Tensor([4294967295],"float32"),Tensor([6],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 07:38:10.109136 123864 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:38:10.110146 123864 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([4294967295],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),Tensor([8],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 07:39:35.992506 123932 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:39:35.993438 123932 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float32"),Tensor([8],"float32"),Tensor([80],"float32"),Tensor([10],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),Tensor([200],"float32"),], )
[paddle error] paddle.concat(list[Tensor([4294967295],"float32"),Tensor([8],"float32"),Tensor([80],"float32"),Tensor([10],"float32"),Tensor([100],"float32"),Tensor([10],"float32"),Tensor([200],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 07:41:01.997115 123975 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:41:01.998529 123975 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"float32"),Tensor([9],"float32"),], )
[paddle error] paddle.concat(list[Tensor([4294967295],"float32"),Tensor([9],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 07:42:31.259657 124030 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:42:31.260664 124030 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"int32"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([4294967295],"int32"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 07:44:04.098647 124087 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:44:04.099524 124087 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"int32"),Tensor([100],"int32"),], )
[paddle error] paddle.concat(list[Tensor([4294967295],"int32"),Tensor([100],"int32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 07:45:38.858913 124130 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:45:38.860055 124130 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"int32"),Tensor([4294967295],"int32"),], )
[torch error] paddle.concat(list[Tensor([4294967295],"int32"),Tensor([4294967295],"int32"),], ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 148503 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:47:48.355568 124176 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:47:48.356596 124176 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4294967295],"int32"),Tensor([500],"int32"),], )
[paddle error] paddle.concat(list[Tensor([4294967295],"int32"),Tensor([500],"int32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 07:49:20.560284 124241 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:49:20.561165 124241 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([42949673, 100],"float16"),Tensor([42949673, 100],"float16"),], axis=-1, )
[paddle error] paddle.concat(list[Tensor([42949673, 100],"float16"),Tensor([42949673, 100],"float16"),], axis=-1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000000GB memory on GPU 0, 74.582947GB memory has been allocated and available memory is only 4.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 07:52:13.413087 124309 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:52:13.414860 124309 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([42949673, 100],"float16"),Tensor([8, 100],"float16"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([42949673, 100],"float16"),Tensor([8, 100],"float16"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 42949673 but got size 8 for tensor number 1 in the list.

W0207 07:53:44.128644 124394 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:53:44.129659 124394 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([42949673, 100],"float32"),Tensor([42949673, 100],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([42949673, 100],"float32"),Tensor([42949673, 100],"float32"),], axis=-1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 62783 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 07:55:56.575984 124470 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:55:56.577093 124470 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([42949673, 100],"float32"),Tensor([8, 100],"float32"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([42949673, 100],"float32"),Tensor([8, 100],"float32"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 42949673 but got size 8 for tensor number 1 in the list.

W0207 07:57:12.676208 124535 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:57:12.677330 124535 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([42949673, 5, 20],"float32"),Tensor([4, 5, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([42949673, 5, 20],"float32"),Tensor([4, 5, 20],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 42949673 but got size 4 for tensor number 1 in the list.

W0207 07:58:39.588649 124604 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 07:58:39.590066 124604 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([42949673, 5, 20],"float32"),Tensor([42949673, 5, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([42949673, 5, 20],"float32"),Tensor([42949673, 5, 20],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 87337 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:00:59.412431 124646 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:00:59.413601 124646 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([429496730, 10],"float32"),], 1, )
[paddle error] paddle.concat(list[Tensor([429496730, 10],"float32"),], 1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 08:02:32.698202 124716 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:02:32.699131 124716 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([429496730, 10],"float32"),Tensor([10, 10],"float32"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([429496730, 10],"float32"),Tensor([10, 10],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 08:04:03.343288 124758 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:04:03.346062 124758 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([429496730, 10],"float32"),Tensor([4, 10],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([429496730, 10],"float32"),Tensor([4, 10],"float32"),], 1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 429496730 but got size 4 for tensor number 1 in the list.

W0207 08:05:13.157416 124813 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:05:13.158592 124813 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([429496730, 10],"float32"),Tensor([4, 10],"float32"),Tensor([4, 10],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([429496730, 10],"float32"),Tensor([4, 10],"float32"),Tensor([4, 10],"float32"),], 1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 429496730 but got size 4 for tensor number 1 in the list.

W0207 08:06:38.069535 124857 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:06:38.071292 124857 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([429496730, 10],"float32"),Tensor([429496730, 10],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([429496730, 10],"float32"),Tensor([429496730, 10],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 156622 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:08:50.236982 124904 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:08:50.238003 124904 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([429496730, 10],"float32"),Tensor([429496730, 10],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([429496730, 10],"float32"),Tensor([429496730, 10],"float32"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 136242 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:11:11.770023 124970 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:11:11.771138 124970 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([429496730, 10],"float32"),Tensor([429496730, 10],"float32"),Tensor([429496730, 10],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([429496730, 10],"float32"),Tensor([429496730, 10],"float32"),Tensor([429496730, 10],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 139783 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:14:36.479992 125039 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:14:36.481768 125039 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([429496730, 5, 1],"float64"),Tensor([1, 5, 1],"float64"),Tensor([1, 5, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([429496730, 5, 1],"float64"),Tensor([1, 5, 1],"float64"),Tensor([1, 5, 1],"float64"),], axis=2, name=None, ) 
 Sizes of tensors must match except in dimension 2. Expected size 429496730 but got size 1 for tensor number 1 in the list.

W0207 08:15:36.165458 125122 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:15:36.166558 125122 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([429496730, 5, 1],"float64"),Tensor([429496730, 5, 1],"float64"),Tensor([429496730, 5, 1],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([429496730, 5, 1],"float64"),Tensor([429496730, 5, 1],"float64"),Tensor([429496730, 5, 1],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 123710 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:17:49.378248 125165 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:17:49.379360 125165 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([429496730, 5],"float64"),Tensor([1, 5],"float64"),Tensor([1, 5],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([429496730, 5],"float64"),Tensor([1, 5],"float64"),Tensor([1, 5],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 08:18:59.261211 125235 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:18:59.263859 125235 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([429496730, 5],"float64"),Tensor([429496730, 5],"float64"),Tensor([429496730, 5],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([429496730, 5],"float64"),Tensor([429496730, 5],"float64"),Tensor([429496730, 5],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 20610 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:21:05.739007 125290 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:21:05.740209 125290 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([43479, 2016, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([43479, 2016, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 43479 but got size 2 for tensor number 1 in the list.

W0207 08:22:22.044405 125361 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:22:22.045671 125361 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([43479, 2016, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([43479, 2016, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 43479 but got size 2 for tensor number 1 in the list.

W0207 08:23:41.923614 125416 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:23:41.924783 125416 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([43479, 2016, 7, 7],"float32"),Tensor([43479, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([43479, 2016, 7, 7],"float32"),Tensor([43479, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000232GB memory on GPU 0, 67.088806GB memory has been allocated and available memory is only 12.096069GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 08:25:22.325191 125472 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:25:22.326125 125472 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([43479, 2016, 7, 7],"float32"),Tensor([43479, 48, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([43479, 2016, 7, 7],"float32"),Tensor([43479, 48, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000232GB memory on GPU 0, 67.342712GB memory has been allocated and available memory is only 11.842163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 08:26:59.130016 125528 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:26:59.132457 125528 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([44180, 1984, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([44180, 1984, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 44180 but got size 2 for tensor number 1 in the list.

W0207 08:28:10.171801 125585 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:28:10.173007 125585 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([44180, 1984, 7, 7],"float32"),Tensor([44180, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([44180, 1984, 7, 7],"float32"),Tensor([44180, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000133GB memory on GPU 0, 67.096619GB memory has been allocated and available memory is only 12.088257GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 08:29:50.681928 125640 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:29:50.682862 125640 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([44539, 1968, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([44539, 1968, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 44539 but got size 2 for tensor number 1 in the list.

W0207 08:31:00.777505 125683 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:31:00.778743 125683 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([44539, 1968, 7, 7],"float32"),Tensor([44539, 48, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([44539, 1968, 7, 7],"float32"),Tensor([44539, 48, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000066GB memory on GPU 0, 67.358337GB memory has been allocated and available memory is only 11.826538GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 08:32:33.453503 125726 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:32:33.454417 125726 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([44739243, 96],"float32"),Tensor([44739243, 96],"float32"),], 0, )
[torch error] paddle.concat(list[Tensor([44739243, 96],"float32"),Tensor([44739243, 96],"float32"),], 0, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 144682 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:34:47.755249 125781 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:34:47.756284 125781 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([44739243, 96],"float32"),Tensor([64, 96],"float32"),], 0, )
[paddle error] paddle.concat(list[Tensor([44739243, 96],"float32"),Tensor([64, 96],"float32"),], 0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 08:36:26.276566 125851 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:36:26.277488 125851 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([447393, 384, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([447393, 384, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 447393 but got size 1 for tensor number 1 in the list.

W0207 08:37:36.776046 125893 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:37:36.777601 125893 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([447393, 384, 5, 5],"float32"),Tensor([2, 384, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([447393, 384, 5, 5],"float32"),Tensor([2, 384, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 447393 but got size 2 for tensor number 1 in the list.

W0207 08:38:58.554606 125947 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:38:58.556154 125947 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([447393, 384, 5, 5],"float32"),Tensor([447393, 32, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([447393, 384, 5, 5],"float32"),Tensor([447393, 32, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000021GB memory on GPU 0, 69.245056GB memory has been allocated and available memory is only 9.939819GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 08:40:35.572889 125990 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:40:35.573912 125990 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([447393, 384, 5, 5],"float32"),Tensor([447393, 384, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([447393, 384, 5, 5],"float32"),Tensor([447393, 384, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 56441 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:43:00.097349 126032 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:43:00.098408 126032 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([44904, 1952, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([44904, 1952, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 44904 but got size 2 for tensor number 1 in the list.

W0207 08:44:15.126540 126116 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:44:15.127815 126116 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([44904, 1952, 7, 7],"float32"),Tensor([44904, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([44904, 1952, 7, 7],"float32"),Tensor([44904, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000039GB memory on GPU 0, 67.104431GB memory has been allocated and available memory is only 12.080444GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 08:45:46.808295 126159 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:45:46.809187 126159 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([456523, 12, 28, 28],"float32"),Tensor([2, 12, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([456523, 12, 28, 28],"float32"),Tensor([2, 12, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 456523 but got size 2 for tensor number 1 in the list.

W0207 08:47:00.605051 126227 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:47:00.606297 126227 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([456523, 12, 28, 28],"float32"),Tensor([456523, 12, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([456523, 12, 28, 28],"float32"),Tensor([456523, 12, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 17702 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:49:13.121512 126271 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:49:13.122537 126271 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([456523, 48, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([456523, 48, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 456523 but got size 2 for tensor number 1 in the list.

W0207 08:50:28.465159 126332 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:50:28.466626 126332 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([456523, 48, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([456523, 48, 14, 14],"float32"),Tensor([456523, 48, 14, 14],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 100832 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 08:52:52.207986 126382 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:52:52.209179 126382 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([45653, 1920, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([45653, 1920, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 45653 but got size 2 for tensor number 1 in the list.

W0207 08:54:09.187254 126452 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:54:09.188639 126452 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([45653, 1920, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([45653, 1920, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 45653 but got size 2 for tensor number 1 in the list.

W0207 08:55:34.718966 126508 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:55:34.720340 126508 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([45653, 1920, 7, 7],"float32"),Tensor([45653, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([45653, 1920, 7, 7],"float32"),Tensor([45653, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000249GB memory on GPU 0, 67.112244GB memory has been allocated and available memory is only 12.072632GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 08:57:07.539949 126564 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:57:07.542465 126564 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([45653, 1920, 7, 7],"float32"),Tensor([45653, 48, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([45653, 1920, 7, 7],"float32"),Tensor([45653, 48, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000249GB memory on GPU 0, 67.377869GB memory has been allocated and available memory is only 11.807007GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 08:58:45.151671 126606 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:58:45.152690 126606 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([45653, 480, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([45653, 480, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 45653 but got size 2 for tensor number 1 in the list.

W0207 08:59:59.900772 126663 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 08:59:59.901969 126663 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([45653, 480, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([45653, 480, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 45653 but got size 2 for tensor number 1 in the list.

W0207 09:01:24.684103 126691 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:01:24.685632 126691 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([45653, 480, 14, 14],"float32"),Tensor([45653, 32, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([45653, 480, 14, 14],"float32"),Tensor([45653, 32, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000249GB memory on GPU 0, 68.713806GB memory has been allocated and available memory is only 10.471069GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 09:03:25.752085 126746 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:03:25.752992 126746 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([45653, 480, 14, 14],"float32"),Tensor([45653, 48, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([45653, 480, 14, 14],"float32"),Tensor([45653, 48, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000249GB memory on GPU 0, 69.780212GB memory has been allocated and available memory is only 9.404663GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 09:04:57.237027 126789 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:04:57.239240 126789 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([46029, 128, 27, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([46029, 128, 27, 27],"float32"),Tensor([2, 128, 27, 27],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 46029 but got size 2 for tensor number 1 in the list.

W0207 09:06:13.314339 126832 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:06:13.315433 126832 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([46029, 128, 27, 27],"float32"),Tensor([2, 192, 27, 27],"float32"),Tensor([2, 96, 27, 27],"float32"),Tensor([2, 64, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([46029, 128, 27, 27],"float32"),Tensor([2, 192, 27, 27],"float32"),Tensor([2, 96, 27, 27],"float32"),Tensor([2, 64, 27, 27],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 46029 but got size 2 for tensor number 1 in the list.

W0207 09:07:37.251892 126873 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:07:37.253149 126873 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([46029, 128, 27, 27],"float32"),Tensor([46029, 128, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([46029, 128, 27, 27],"float32"),Tensor([46029, 128, 27, 27],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 4133 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:09:54.198545 126915 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:09:54.199657 126915 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([46029, 128, 27, 27],"float32"),Tensor([46029, 192, 27, 27],"float32"),Tensor([46029, 96, 27, 27],"float32"),Tensor([46029, 64, 27, 27],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([46029, 128, 27, 27],"float32"),Tensor([46029, 192, 27, 27],"float32"),Tensor([46029, 96, 27, 27],"float32"),Tensor([46029, 64, 27, 27],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 5.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 147427 has 40.99 GiB memory in use. Of the allocated memory 40.00 GiB is allocated by PyTorch, and 3.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:13:25.275254 126984 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:13:25.276366 126984 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([46427, 1888, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([46427, 1888, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 46427 but got size 2 for tensor number 1 in the list.

W0207 09:14:51.545379 127097 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:14:51.546484 127097 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([46427, 1888, 7, 7],"float32"),Tensor([46427, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([46427, 1888, 7, 7],"float32"),Tensor([46427, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000325GB memory on GPU 0, 67.122009GB memory has been allocated and available memory is only 12.062866GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 09:16:31.902670 127152 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:16:31.903713 127152 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([466034, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([466034, 256, 6, 6],"float32"),Tensor([2, 320, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),Tensor([2, 128, 6, 6],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 466034 but got size 2 for tensor number 1 in the list.

W0207 09:17:42.104624 127195 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:17:42.106102 127195 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([466034, 256, 6, 6],"float32"),Tensor([466034, 320, 6, 6],"float32"),Tensor([466034, 128, 6, 6],"float32"),Tensor([466034, 128, 6, 6],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([466034, 256, 6, 6],"float32"),Tensor([466034, 320, 6, 6],"float32"),Tensor([466034, 128, 6, 6],"float32"),Tensor([466034, 128, 6, 6],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 1.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 48092 has 45.00 GiB memory in use. Of the allocated memory 44.00 GiB is allocated by PyTorch, and 5.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:21:19.629422 127251 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:21:19.630561 127251 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([46823, 1872, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([46823, 1872, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 46823 but got size 2 for tensor number 1 in the list.

W0207 09:22:38.163384 127363 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:22:38.164726 127363 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([46823, 1872, 7, 7],"float32"),Tensor([46823, 48, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([46823, 1872, 7, 7],"float32"),Tensor([46823, 48, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000048GB memory on GPU 0, 67.401306GB memory has been allocated and available memory is only 11.783569GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 09:24:14.670255 127418 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:24:14.671207 127418 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([47227, 1856, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([47227, 1856, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 47227 but got size 2 for tensor number 1 in the list.

W0207 09:25:32.426740 127461 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:25:32.427809 127461 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([47227, 1856, 7, 7],"float32"),Tensor([47227, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([47227, 1856, 7, 7],"float32"),Tensor([47227, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000168GB memory on GPU 0, 67.131775GB memory has been allocated and available memory is only 12.053101GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 09:27:24.689371 127509 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:27:24.690304 127509 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4756, 288, 56, 56],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([4756, 288, 56, 56],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 4756 but got size 2 for tensor number 1 in the list.

W0207 09:28:44.082912 127587 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:28:44.084226 127587 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([4756, 288, 56, 56],"float32"),Tensor([4756, 48, 56, 56],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([4756, 288, 56, 56],"float32"),Tensor([4756, 48, 56, 56],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.001862GB memory on GPU 0, 71.914978GB memory has been allocated and available memory is only 7.269897GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 09:30:31.415649 127629 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:30:31.416483 127629 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([47935, 224, 20, 20],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([47935, 224, 20, 20],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 47935 but got size 1 for tensor number 1 in the list.

W0207 09:31:41.077848 127684 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:31:41.079562 127684 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([47935, 224, 20, 20],"float32"),Tensor([47935, 32, 20, 20],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([47935, 224, 20, 20],"float32"),Tensor([47935, 32, 20, 20],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000032GB memory on GPU 0, 71.151306GB memory has been allocated and available memory is only 8.033569GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 09:33:30.089514 127714 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:33:30.092113 127714 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([48056, 1824, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([48056, 1824, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 48056 but got size 2 for tensor number 1 in the list.

W0207 09:34:49.980433 127782 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:34:49.981438 127782 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([48056, 1824, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([48056, 1824, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 48056 but got size 2 for tensor number 1 in the list.

W0207 09:36:13.027962 128180 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:36:13.028963 128180 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([48056, 1824, 7, 7],"float32"),Tensor([48056, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([48056, 1824, 7, 7],"float32"),Tensor([48056, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000319GB memory on GPU 0, 67.139587GB memory has been allocated and available memory is only 12.045288GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 09:37:54.350512 128703 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:37:54.351394 128703 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([48056, 1824, 7, 7],"float32"),Tensor([48056, 48, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([48056, 1824, 7, 7],"float32"),Tensor([48056, 48, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000319GB memory on GPU 0, 67.420837GB memory has been allocated and available memory is only 11.764038GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 09:39:19.484963 129139 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:39:19.485869 129139 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([488065, 352, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([488065, 352, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 488065 but got size 1 for tensor number 1 in the list.

W0207 09:40:28.662497 129501 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:40:28.663618 129501 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([488065, 352, 5, 5],"float32"),Tensor([488065, 32, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([488065, 352, 5, 5],"float32"),Tensor([488065, 32, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000018GB memory on GPU 0, 69.487244GB memory has been allocated and available memory is only 9.697632GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 09:42:06.174461 129841 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:42:06.175369 129841 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([48914, 112, 28, 28],"float32"),Tensor([2, 112, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([48914, 112, 28, 28],"float32"),Tensor([2, 112, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 48914 but got size 2 for tensor number 1 in the list.

W0207 09:43:15.469198 130281 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:43:15.470329 130281 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([48914, 112, 28, 28],"float32"),Tensor([48914, 112, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([48914, 112, 28, 28],"float32"),Tensor([48914, 112, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 50708 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:45:30.415445 130681 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:45:30.416491 130681 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([48914, 1792, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([48914, 1792, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 48914 but got size 2 for tensor number 1 in the list.

W0207 09:46:55.482859 131132 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:46:55.483888 131132 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([48914, 1792, 7, 7],"float32"),Tensor([48914, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([48914, 1792, 7, 7],"float32"),Tensor([48914, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000273GB memory on GPU 0, 67.151306GB memory has been allocated and available memory is only 12.033569GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 09:48:26.073190 131535 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:48:26.074133 131535 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([48914, 448, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([48914, 448, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 48914 but got size 2 for tensor number 1 in the list.

W0207 09:49:45.155441 131951 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:49:45.156548 131951 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([48914, 448, 14, 14],"float32"),Tensor([48914, 32, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([48914, 448, 14, 14],"float32"),Tensor([48914, 32, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000273GB memory on GPU 0, 68.866150GB memory has been allocated and available memory is only 10.318726GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 09:51:21.136260 132321 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:51:21.137202 132321 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([49354, 1776, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([49354, 1776, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 49354 but got size 2 for tensor number 1 in the list.

W0207 09:52:39.357085 132721 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:52:39.358105 132721 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([49354, 1776, 7, 7],"float32"),Tensor([49354, 48, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([49354, 1776, 7, 7],"float32"),Tensor([49354, 48, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000057GB memory on GPU 0, 67.444275GB memory has been allocated and available memory is only 11.740601GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 09:54:11.650060 133032 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:54:11.650960 133032 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([49637, 128, 26, 26],"float32"),Tensor([2, 128, 26, 26],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([49637, 128, 26, 26],"float32"),Tensor([2, 128, 26, 26],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 49637 but got size 2 for tensor number 1 in the list.

W0207 09:55:21.040736 133451 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:55:21.041631 133451 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([49637, 128, 26, 26],"float32"),Tensor([49637, 128, 26, 26],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([49637, 128, 26, 26],"float32"),Tensor([49637, 128, 26, 26],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 95488 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 09:57:44.386399 133836 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:57:44.387549 133836 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([49803, 1760, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([49803, 1760, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 49803 but got size 2 for tensor number 1 in the list.

W0207 09:59:06.912729 134524 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 09:59:06.913834 134524 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([49803, 1760, 7, 7],"float32"),Tensor([49803, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([49803, 1760, 7, 7],"float32"),Tensor([49803, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000162GB memory on GPU 0, 67.161072GB memory has been allocated and available memory is only 12.023804GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 10:00:46.752807 134837 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:00:46.753705 134837 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 1],"float64"),Tensor([2147483649, 1],"float64"),Tensor([5, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([5, 1],"float64"),Tensor([2147483649, 1],"float64"),Tensor([5, 1],"float64"),], axis=1, name=None, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5 but got size 2147483649 for tensor number 1 in the list.

W0207 10:01:37.515023 135278 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:01:37.516137 135278 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 1],"float64"),Tensor([5, 1],"float64"),Tensor([2147483649, 1],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([5, 1],"float64"),Tensor([5, 1],"float64"),Tensor([2147483649, 1],"float64"),], axis=1, name=None, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5 but got size 2147483649 for tensor number 2 in the list.

W0207 10:02:36.493844 135544 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:02:36.495038 135544 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 1],"float64"),Tensor([5, 1],"float64"),Tensor([5, 429496730],"float64"),], axis=1, name=None, )
[paddle error] paddle.concat(list[Tensor([5, 1],"float64"),Tensor([5, 1],"float64"),Tensor([5, 429496730],"float64"),], axis=1, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 10:03:48.273190 135835 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:03:48.274209 135835 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 1],"float64"),Tensor([5, 429496730],"float64"),Tensor([5, 1],"float64"),], axis=1, name=None, )
[paddle error] paddle.concat(list[Tensor([5, 1],"float64"),Tensor([5, 429496730],"float64"),Tensor([5, 1],"float64"),], axis=1, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 10:04:57.818630 136232 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:04:57.819521 136232 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 17179870, 50],"float32"),Tensor([10, 17179870, 50],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([5, 17179870, 50],"float32"),Tensor([10, 17179870, 50],"float32"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 29.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 131975 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:08:17.056516 136532 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:08:17.057665 136532 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 17179870, 50],"float32"),Tensor([10, 50, 50],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([5, 17179870, 50],"float32"),Tensor([10, 50, 50],"float32"),], axis=0, ) 
 Sizes of tensors must match except in dimension 0. Expected size 17179870 but got size 50 for tensor number 1 in the list.

W0207 10:09:34.166015 137501 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:09:34.167340 137501 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 2, 2],"float32"),Tensor([1073741824, 2, 2],"float32"),], axis=2, )
[torch error] paddle.concat(list[Tensor([5, 2, 2],"float32"),Tensor([1073741824, 2, 2],"float32"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 5 but got size 1073741824 for tensor number 1 in the list.

W0207 10:10:55.647915 137807 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:10:55.649143 137807 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 2, 2],"float32"),Tensor([5, 2, 429496730],"float32"),], axis=2, )
[paddle error] paddle.concat(list[Tensor([5, 2, 2],"float32"),Tensor([5, 2, 429496730],"float32"),], axis=2, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 10:12:26.098642 138226 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:12:26.099687 138226 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 2, 2],"float32"),Tensor([5, 429496730, 2],"float32"),], axis=2, )
[torch error] paddle.concat(list[Tensor([5, 2, 2],"float32"),Tensor([5, 429496730, 2],"float32"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 2 but got size 429496730 for tensor number 1 in the list.

W0207 10:13:34.954535 138638 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:13:34.955751 138638 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 2, 4],"float32"),Tensor([5, 2, 429496730],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([5, 2, 4],"float32"),Tensor([5, 2, 429496730],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 4 but got size 429496730 for tensor number 1 in the list.

W0207 10:14:52.413147 138946 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:14:52.414494 138946 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 2, 4],"float32"),Tensor([5, 214748365, 4],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([5, 2, 4],"float32"),Tensor([5, 214748365, 4],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 10:16:20.717262 139365 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:16:20.718202 139365 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 2, 4],"float32"),Tensor([536870912, 2, 4],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([5, 2, 4],"float32"),Tensor([536870912, 2, 4],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5 but got size 536870912 for tensor number 1 in the list.

W0207 10:17:37.799432 139798 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:17:37.800750 139798 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 2, 429496730],"float32"),Tensor([5, 2, 2],"float32"),], axis=2, )
[paddle error] paddle.concat(list[Tensor([5, 2, 429496730],"float32"),Tensor([5, 2, 2],"float32"),], axis=2, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 10:19:17.659726 140129 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:19:17.661023 140129 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 2, 429496730],"float32"),Tensor([5, 2, 4],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([5, 2, 429496730],"float32"),Tensor([5, 2, 4],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 429496730 but got size 4 for tensor number 1 in the list.

W0207 10:20:27.819947 140642 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:20:27.821156 140642 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 2, 429496730],"float32"),Tensor([5, 2, 429496730],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([5, 2, 429496730],"float32"),Tensor([5, 2, 429496730],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 121899 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:22:49.667198 140942 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:22:49.668334 140942 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 2, 429496730],"float32"),Tensor([5, 2, 429496730],"float32"),], axis=2, )
[torch error] paddle.concat(list[Tensor([5, 2, 429496730],"float32"),Tensor([5, 2, 429496730],"float32"),], axis=2, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 129541 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:25:10.465548 141644 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:25:10.466576 141644 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 2],"float32"),Tensor([2147483648, 2],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([5, 2],"float32"),Tensor([2147483648, 2],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5 but got size 2147483648 for tensor number 1 in the list.

W0207 10:26:30.355435 142242 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:26:30.356524 142242 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 2],"float32"),Tensor([5, 858993459],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([5, 2],"float32"),Tensor([5, 858993459],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 10:28:01.581645 142634 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:28:01.582888 142634 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 214748365, 4],"float32"),Tensor([5, 2, 4],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([5, 214748365, 4],"float32"),Tensor([5, 2, 4],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 10:29:29.369410 143061 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:29:29.371927 143061 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 214748365, 4],"float32"),Tensor([5, 214748365, 4],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([5, 214748365, 4],"float32"),Tensor([5, 214748365, 4],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 116980 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:31:56.655970 143491 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:31:56.656973 143491 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 4],"float32"),Tensor([1073741824, 4],"float32"),Tensor([5, 4],"float32"),Tensor([5, 4],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([5, 4],"float32"),Tensor([1073741824, 4],"float32"),Tensor([5, 4],"float32"),Tensor([5, 4],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5 but got size 1073741824 for tensor number 1 in the list.

W0207 10:33:11.593930 144204 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:33:11.594986 144204 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 4],"float32"),Tensor([5, 4],"float32"),Tensor([1073741824, 4],"float32"),Tensor([5, 4],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([5, 4],"float32"),Tensor([5, 4],"float32"),Tensor([1073741824, 4],"float32"),Tensor([5, 4],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5 but got size 1073741824 for tensor number 2 in the list.

W0207 10:34:33.796762 144608 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:34:33.797982 144608 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 4],"float32"),Tensor([5, 4],"float32"),Tensor([5, 4],"float32"),Tensor([1073741824, 4],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([5, 4],"float32"),Tensor([5, 4],"float32"),Tensor([5, 4],"float32"),Tensor([1073741824, 4],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5 but got size 1073741824 for tensor number 3 in the list.

W0207 10:35:47.012954 144934 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:35:47.014166 144934 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 4],"float32"),Tensor([5, 4],"float32"),Tensor([5, 4],"float32"),Tensor([5, 858993459],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([5, 4],"float32"),Tensor([5, 4],"float32"),Tensor([5, 4],"float32"),Tensor([5, 858993459],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 10:37:24.202782 145342 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:37:24.203675 145342 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 4],"float32"),Tensor([5, 4],"float32"),Tensor([5, 858993459],"float32"),Tensor([5, 4],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([5, 4],"float32"),Tensor([5, 4],"float32"),Tensor([5, 858993459],"float32"),Tensor([5, 4],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 10:38:49.767912 145793 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:38:49.769340 145793 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 4],"float32"),Tensor([5, 858993459],"float32"),Tensor([5, 4],"float32"),Tensor([5, 4],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([5, 4],"float32"),Tensor([5, 858993459],"float32"),Tensor([5, 4],"float32"),Tensor([5, 4],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 10:40:18.396982 146211 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:40:18.397935 146211 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 429496730, 2],"float32"),Tensor([5, 2, 2],"float32"),], axis=2, )
[torch error] paddle.concat(list[Tensor([5, 429496730, 2],"float32"),Tensor([5, 2, 2],"float32"),], axis=2, ) 
 Sizes of tensors must match except in dimension 2. Expected size 429496730 but got size 2 for tensor number 1 in the list.

W0207 10:41:38.115428 146647 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:41:38.116505 146647 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 429496730, 2],"float32"),Tensor([5, 429496730, 2],"float32"),], axis=2, )
[torch error] paddle.concat(list[Tensor([5, 429496730, 2],"float32"),Tensor([5, 429496730, 2],"float32"),], axis=2, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 39978 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:43:50.738445 146975 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:43:50.739436 146975 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 429496730],"float64"),Tensor([5, 1],"float64"),Tensor([5, 1],"float64"),], axis=1, name=None, )
[paddle error] paddle.concat(list[Tensor([5, 429496730],"float64"),Tensor([5, 1],"float64"),Tensor([5, 1],"float64"),], axis=1, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 10:44:59.893527 147645 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:44:59.894495 147645 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 429496730],"float64"),Tensor([5, 429496730],"float64"),Tensor([5, 429496730],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([5, 429496730],"float64"),Tensor([5, 429496730],"float64"),Tensor([5, 429496730],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 96499 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:46:57.310469 147950 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:46:57.313378 147950 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 50, 17179870],"float32"),Tensor([10, 50, 17179870],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([5, 50, 17179870],"float32"),Tensor([10, 50, 17179870],"float32"),], axis=0, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 29.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 84368 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 10:50:10.147152 148522 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:50:10.150079 148522 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 50, 17179870],"float32"),Tensor([10, 50, 50],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([5, 50, 17179870],"float32"),Tensor([10, 50, 50],"float32"),], axis=0, ) 
 Sizes of tensors must match except in dimension 0. Expected size 17179870 but got size 50 for tensor number 1 in the list.

W0207 10:51:36.183990 149372 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:51:36.185276 149372 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 50, 50],"float32"),Tensor([10, 50, 8589935],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([5, 50, 50],"float32"),Tensor([10, 50, 8589935],"float32"),], axis=0, ) 
 Sizes of tensors must match except in dimension 0. Expected size 50 but got size 8589935 for tensor number 1 in the list.

W0207 10:52:56.670799 149794 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:52:56.672214 149794 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 50, 50],"float32"),Tensor([10, 8589935, 50],"float32"),], axis=0, )
[torch error] paddle.concat(list[Tensor([5, 50, 50],"float32"),Tensor([10, 8589935, 50],"float32"),], axis=0, ) 
 Sizes of tensors must match except in dimension 0. Expected size 50 but got size 8589935 for tensor number 1 in the list.

W0207 10:54:11.862686 150211 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:54:11.863742 150211 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 50, 50],"float32"),Tensor([1717987, 50, 50],"float32"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([5, 50, 50],"float32"),Tensor([1717987, 50, 50],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000001GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 10:55:41.484557 150609 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:55:41.485517 150609 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 858993459],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([5, 858993459],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.575134GB memory has been allocated and available memory is only 12.609741GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 10:57:14.979475 150951 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:57:14.980361 150951 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 858993459],"float32"),Tensor([5, 2],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([5, 858993459],"float32"),Tensor([5, 2],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 10:58:40.597609 151360 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 10:58:40.598506 151360 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 858993459],"float32"),Tensor([5, 4],"float32"),Tensor([5, 4],"float32"),Tensor([5, 4],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([5, 858993459],"float32"),Tensor([5, 4],"float32"),Tensor([5, 4],"float32"),Tensor([5, 4],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 11:00:08.379684 151722 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:00:08.380563 151722 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 858993459],"float32"),Tensor([5, 858993459],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([5, 858993459],"float32"),Tensor([5, 858993459],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 60125 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:02:47.858379 152147 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:02:47.859517 152147 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5, 858993459],"float32"),Tensor([5, 858993459],"float32"),Tensor([5, 858993459],"float32"),Tensor([5, 858993459],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([5, 858993459],"float32"),Tensor([5, 858993459],"float32"),Tensor([5, 858993459],"float32"),Tensor([5, 858993459],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 97922 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 11:06:06.134877 152970 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:06:06.137428 152970 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5],"float64"),Tensor([2147483649],"float64"),Tensor([5],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([5],"float64"),Tensor([2147483649],"float64"),Tensor([5],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 11:07:24.461016 153832 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:07:24.461930 153832 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5],"float64"),Tensor([5],"float64"),Tensor([2147483649],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([5],"float64"),Tensor([5],"float64"),Tensor([2147483649],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 11:08:33.008476 154238 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:08:33.009529 154238 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([50725, 1728, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([50725, 1728, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 50725 but got size 2 for tensor number 1 in the list.

W0207 11:09:55.317728 154559 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:09:55.319059 154559 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([50725, 1728, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([50725, 1728, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 50725 but got size 2 for tensor number 1 in the list.

W0207 11:11:10.610106 154964 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:11:10.611164 154964 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([50725, 1728, 7, 7],"float32"),Tensor([50725, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([50725, 1728, 7, 7],"float32"),Tensor([50725, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000074GB memory on GPU 0, 67.170837GB memory has been allocated and available memory is only 12.014038GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 11:12:52.141496 155287 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:12:52.142418 155287 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([50725, 1728, 7, 7],"float32"),Tensor([50725, 48, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([50725, 1728, 7, 7],"float32"),Tensor([50725, 48, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000074GB memory on GPU 0, 67.467712GB memory has been allocated and available memory is only 11.717163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 11:14:22.824635 155812 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:14:22.825528 155812 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([50725, 432, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([50725, 432, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 50725 but got size 2 for tensor number 1 in the list.

W0207 11:15:34.336592 156245 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:15:34.337657 156245 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([50725, 432, 14, 14],"float32"),Tensor([50725, 48, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([50725, 432, 14, 14],"float32"),Tensor([50725, 48, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000074GB memory on GPU 0, 70.135681GB memory has been allocated and available memory is only 9.049194GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 11:17:14.437927 156572 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:17:14.440531 156572 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([512],"float16"),Tensor([128],"float16"),Tensor([4294967295],"float16"),], axis=-1, )
[Pass] paddle.concat(list[Tensor([512],"float16"),Tensor([128],"float16"),Tensor([4294967295],"float16"),], axis=-1, )

W0207 11:18:43.301930 156996 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:18:43.302829 156996 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([512],"float16"),Tensor([4294967295],"float16"),Tensor([128],"float16"),], axis=-1, )
[Pass] paddle.concat(list[Tensor([512],"float16"),Tensor([4294967295],"float16"),Tensor([128],"float16"),], axis=-1, )

W0207 11:28:06.989959 159634 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:28:06.991006 159634 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([512],"float16"),Tensor([4294967295],"float16"),Tensor([512],"float16"),], axis=-1, )
[Pass] paddle.concat(list[Tensor([512],"float16"),Tensor([4294967295],"float16"),Tensor([512],"float16"),], axis=-1, )

W0207 11:37:29.869226 162174 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:37:29.870148 162174 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([512],"float16"),Tensor([512],"float16"),Tensor([4294967295],"float16"),], axis=-1, )
[Pass] paddle.concat(list[Tensor([512],"float16"),Tensor([512],"float16"),Tensor([4294967295],"float16"),], axis=-1, )

W0207 11:46:48.872852  1148 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:46:48.873859  1148 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([512],"float32"),Tensor([128],"float32"),Tensor([4294967295],"float32"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([512],"float32"),Tensor([128],"float32"),Tensor([4294967295],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 11:56:00.119557  3754 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:56:00.120489  3754 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([512],"float32"),Tensor([4294967295],"float32"),Tensor([128],"float32"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([512],"float32"),Tensor([4294967295],"float32"),Tensor([128],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 11:57:34.223436  4168 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:57:34.224365  4168 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([512],"float32"),Tensor([4294967295],"float32"),Tensor([512],"float32"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([512],"float32"),Tensor([4294967295],"float32"),Tensor([512],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 11:59:06.887217  4590 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 11:59:06.888201  4590 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([512],"float32"),Tensor([512],"float32"),Tensor([4294967295],"float32"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([512],"float32"),Tensor([512],"float32"),Tensor([4294967295],"float32"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 12:00:37.215260  5056 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:00:37.216181  5056 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([51682, 1696, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([51682, 1696, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 51682 but got size 2 for tensor number 1 in the list.

W0207 12:01:58.030467  5460 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:01:58.031656  5460 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([51682, 1696, 7, 7],"float32"),Tensor([51682, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([51682, 1696, 7, 7],"float32"),Tensor([51682, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000051GB memory on GPU 0, 67.182556GB memory has been allocated and available memory is only 12.002319GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 12:03:39.715057  5883 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:03:39.717552  5883 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([52175, 1680, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([52175, 1680, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 52175 but got size 2 for tensor number 1 in the list.

W0207 12:04:50.232002  6309 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:04:50.233440  6309 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([52175, 1680, 7, 7],"float32"),Tensor([52175, 48, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([52175, 1680, 7, 7],"float32"),Tensor([52175, 48, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000293GB memory on GPU 0, 67.495056GB memory has been allocated and available memory is only 11.689819GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 12:06:23.928823  6712 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:06:23.929802  6712 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([52676, 1664, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([52676, 1664, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 52676 but got size 2 for tensor number 1 in the list.

W0207 12:07:44.654762  7136 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:07:44.655947  7136 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([52676, 1664, 7, 7],"float32"),Tensor([52676, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([52676, 1664, 7, 7],"float32"),Tensor([52676, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000086GB memory on GPU 0, 67.194275GB memory has been allocated and available memory is only 11.990601GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 12:09:22.107939  7557 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:09:22.108958  7557 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([52676, 416, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([52676, 416, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 52676 but got size 2 for tensor number 1 in the list.

W0207 12:10:40.390947  7977 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:10:40.391932  7977 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([52676, 416, 14, 14],"float32"),Tensor([52676, 32, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([52676, 416, 14, 14],"float32"),Tensor([52676, 32, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000086GB memory on GPU 0, 69.041931GB memory has been allocated and available memory is only 10.142944GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 12:12:23.648250  8303 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:12:23.649304  8303 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([536870912, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([536870912, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),Tensor([2, 1, 8],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 536870912 but got size 2 for tensor number 1 in the list.

W0207 12:13:38.709458  8847 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:13:38.710572  8847 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([536870912, 1, 8],"float32"),Tensor([536870912, 1, 8],"float32"),Tensor([536870912, 1, 8],"float32"),Tensor([536870912, 1, 8],"float32"),Tensor([536870912, 1, 8],"float32"),Tensor([536870912, 1, 8],"float32"),Tensor([536870912, 1, 8],"float32"),Tensor([536870912, 1, 8],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([536870912, 1, 8],"float32"),Tensor([536870912, 1, 8],"float32"),Tensor([536870912, 1, 8],"float32"),Tensor([536870912, 1, 8],"float32"),Tensor([536870912, 1, 8],"float32"),Tensor([536870912, 1, 8],"float32"),Tensor([536870912, 1, 8],"float32"),Tensor([536870912, 1, 8],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 114254 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:16:56.449404  9178 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:16:56.450521  9178 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([536870912, 2, 4],"float32"),Tensor([5, 2, 4],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([536870912, 2, 4],"float32"),Tensor([5, 2, 4],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 536870912 but got size 5 for tensor number 1 in the list.

W0207 12:18:18.375974 10119 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:18:18.377018 10119 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([536870912, 2, 4],"float32"),Tensor([536870912, 2, 4],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([536870912, 2, 4],"float32"),Tensor([536870912, 2, 4],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 91625 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:20:37.970388 10511 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:20:37.971514 10511 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([536870912, 8],"float32"),Tensor([32, 8],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([536870912, 8],"float32"),Tensor([32, 8],"float32"),], 1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 536870912 but got size 32 for tensor number 1 in the list.

W0207 12:21:54.685154 11094 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:21:54.686349 11094 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([536870912, 8],"float32"),Tensor([536870912, 8],"float32"),], 1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 114299 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:24:09.876228 11493 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:24:09.877329 11493 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),], 1, )
[torch error] paddle.concat(list[Tensor([536870912, 8],"float32"),Tensor([8, 8],"float32"),], 1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 536870912 but got size 8 for tensor number 1 in the list.

W0207 12:25:26.374835 12061 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:25:26.376020 12061 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([53687092, 4, 2, 5],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([53687092, 4, 2, 5],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 12:26:36.368491 12455 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:26:36.369439 12455 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([53687092, 4, 2, 5],"float64"),], axis=1, name=None, )
[paddle error] paddle.concat(list[Tensor([53687092, 4, 2, 5],"float64"),], axis=1, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 12:27:39.021492 12752 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:27:39.023687 12752 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([53687092, 4, 2, 5],"float64"),], axis=2, name=None, )
[paddle error] paddle.concat(list[Tensor([53687092, 4, 2, 5],"float64"),], axis=2, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.579041GB memory has been allocated and available memory is only 12.605835GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 12:28:49.046038 13045 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:28:49.046926 13045 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=0, name=None, )
[paddle error] paddle.concat(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=0, name=None, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 12:29:53.835464 13424 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:29:53.836347 13424 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=1, name=None, ) 
 Sizes of tensors must match except in dimension 1. Expected size 53687092 but got size 3 for tensor number 1 in the list.

W0207 12:30:40.448019 13735 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:30:40.449193 13735 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),Tensor([3, 4, 2, 5],"float64"),], axis=2, name=None, ) 
 Sizes of tensors must match except in dimension 2. Expected size 53687092 but got size 3 for tensor number 1 in the list.

W0207 12:31:37.718382 13902 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:31:37.719568 13902 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], axis=0, name=None, )
[torch error] paddle.concat(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], axis=0, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 109639 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:33:43.456940 14195 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:33:43.458112 14195 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], axis=1, name=None, )
[torch error] paddle.concat(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], axis=1, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 161121 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:35:58.030361 14840 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:35:58.031432 14840 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], axis=2, name=None, )
[torch error] paddle.concat(list[Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),Tensor([53687092, 4, 2, 5],"float64"),], axis=2, name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 42149 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:38:15.696231 15432 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:38:15.698956 15432 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([536871, 320, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([536871, 320, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 536871 but got size 1 for tensor number 1 in the list.

W0207 12:39:35.628762 16089 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:39:35.629856 16089 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([536871, 320, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([536871, 320, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 536871 but got size 2 for tensor number 1 in the list.

W0207 12:40:49.039091 16403 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:40:49.040266 16403 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([536871, 320, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([536871, 320, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 768, 5, 5],"float32"),Tensor([2, 192, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 536871 but got size 2 for tensor number 1 in the list.

W0207 12:42:04.861991 16802 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:42:04.863094 16802 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([536871, 320, 5, 5],"float32"),Tensor([536871, 192, 5, 5],"float32"),Tensor([536871, 768, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([536871, 320, 5, 5],"float32"),Tensor([536871, 192, 5, 5],"float32"),Tensor([536871, 768, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 38.40 GiB. GPU 0 has a total capacity of 79.18 GiB of which 19.60 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 157842 has 26.59 GiB memory in use. Of the allocated memory 25.60 GiB is allocated by PyTorch, and 3.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:46:25.334365 17142 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:46:25.337296 17142 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([536871, 320, 5, 5],"float32"),Tensor([536871, 32, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([536871, 320, 5, 5],"float32"),Tensor([536871, 32, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000003GB memory on GPU 0, 69.780212GB memory has been allocated and available memory is only 9.404663GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 12:48:20.129036 18379 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:48:20.129925 18379 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([536871, 320, 5, 5],"float32"),Tensor([536871, 768, 5, 5],"float32"),Tensor([536871, 768, 5, 5],"float32"),Tensor([536871, 192, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([536871, 320, 5, 5],"float32"),Tensor([536871, 768, 5, 5],"float32"),Tensor([536871, 768, 5, 5],"float32"),Tensor([536871, 192, 5, 5],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 38.40 GiB. GPU 0 has a total capacity of 79.18 GiB of which 29.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 124904 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 12:51:51.368180 18896 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:51:51.369313 18896 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([53709, 1632, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([53709, 1632, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 53709 but got size 2 for tensor number 1 in the list.

W0207 12:53:11.950182 19876 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:53:11.951434 19876 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([53709, 1632, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([53709, 1632, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 53709 but got size 2 for tensor number 1 in the list.

W0207 12:54:27.417927 20194 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:54:27.419240 20194 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([53709, 1632, 7, 7],"float32"),Tensor([53709, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([53709, 1632, 7, 7],"float32"),Tensor([53709, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000127GB memory on GPU 0, 67.205994GB memory has been allocated and available memory is only 11.978882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 12:55:58.593083 20586 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:55:58.593966 20586 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([53709, 1632, 7, 7],"float32"),Tensor([53709, 48, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([53709, 1632, 7, 7],"float32"),Tensor([53709, 48, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000127GB memory on GPU 0, 67.520447GB memory has been allocated and available memory is only 11.664429GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 12:57:29.884663 20984 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:57:29.885505 20984 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([54783, 1600, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([54783, 1600, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 54783 but got size 2 for tensor number 1 in the list.

W0207 12:58:44.061630 21425 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 12:58:44.062713 21425 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([54783, 1600, 7, 7],"float32"),Tensor([54783, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([54783, 1600, 7, 7],"float32"),Tensor([54783, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000074GB memory on GPU 0, 67.217712GB memory has been allocated and available memory is only 11.967163GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 13:00:24.813922 21819 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:00:24.815155 21819 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([55337, 1584, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([55337, 1584, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 55337 but got size 2 for tensor number 1 in the list.

W0207 13:01:39.188758 22257 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:01:39.189795 22257 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([55337, 1584, 7, 7],"float32"),Tensor([55337, 48, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([55337, 1584, 7, 7],"float32"),Tensor([55337, 48, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000258GB memory on GPU 0, 67.549744GB memory has been allocated and available memory is only 11.635132GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 13:03:13.169487 22575 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:03:13.170428 22575 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([55901, 1568, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([55901, 1568, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 55901 but got size 2 for tensor number 1 in the list.

W0207 13:04:31.659158 22989 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:04:31.660442 22989 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([55901, 1568, 7, 7],"float32"),Tensor([55901, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([55901, 1568, 7, 7],"float32"),Tensor([55901, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000068GB memory on GPU 0, 67.233337GB memory has been allocated and available memory is only 11.951538GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 13:06:25.440308 23417 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:06:25.441251 23417 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5592406, 12, 32],"float64"),Tensor([4, 12, 32],"float64"),], -1, )
[torch error] paddle.concat(list[Tensor([5592406, 12, 32],"float64"),Tensor([4, 12, 32],"float64"),], -1, ) 
 Sizes of tensors must match except in dimension 2. Expected size 5592406 but got size 4 for tensor number 1 in the list.

W0207 13:07:21.118628 23947 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:07:21.120293 23947 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5592406, 12, 32],"float64"),Tensor([5592406, 12, 32],"float64"),], -1, )
[torch error] paddle.concat(list[Tensor([5592406, 12, 32],"float64"),Tensor([5592406, 12, 32],"float64"),], -1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 23509 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 4.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:08:50.621138 24225 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:08:50.622203 24225 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([55925, 192, 20, 20],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([55925, 192, 20, 20],"float32"),Tensor([1, 32, 20, 20],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 55925 but got size 1 for tensor number 1 in the list.

W0207 13:10:16.563691 24655 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:10:16.566753 24655 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([55925, 192, 20, 20],"float32"),Tensor([55925, 32, 20, 20],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([55925, 192, 20, 20],"float32"),Tensor([55925, 32, 20, 20],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000271GB memory on GPU 0, 71.913025GB memory has been allocated and available memory is only 7.271851GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 13:12:07.590198 25082 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:12:07.591199 25082 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([57066, 1536, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([57066, 1536, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 57066 but got size 2 for tensor number 1 in the list.

W0207 13:13:17.905930 25546 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:13:17.907338 25546 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([57066, 1536, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([57066, 1536, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 57066 but got size 2 for tensor number 1 in the list.

W0207 13:14:33.525283 25931 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:14:33.526355 25931 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([57066, 1536, 7, 7],"float32"),Tensor([57066, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([57066, 1536, 7, 7],"float32"),Tensor([57066, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000179GB memory on GPU 0, 67.245056GB memory has been allocated and available memory is only 11.939819GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 13:16:07.258512 26242 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:16:07.259471 26242 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([57066, 1536, 7, 7],"float32"),Tensor([57066, 48, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([57066, 1536, 7, 7],"float32"),Tensor([57066, 48, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000179GB memory on GPU 0, 67.580994GB memory has been allocated and available memory is only 11.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 13:17:39.363657 26671 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:17:39.364697 26671 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([57066, 384, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([57066, 384, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 57066 but got size 2 for tensor number 1 in the list.

W0207 13:18:50.823406 27104 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:18:50.824564 27104 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([57066, 384, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([57066, 384, 14, 14],"float32"),Tensor([2, 48, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 57066 but got size 2 for tensor number 1 in the list.

W0207 13:20:08.100450 27494 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:20:08.101470 27494 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([57066, 384, 14, 14],"float32"),Tensor([57066, 32, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([57066, 384, 14, 14],"float32"),Tensor([57066, 32, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000179GB memory on GPU 0, 69.245056GB memory has been allocated and available memory is only 9.939819GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 13:21:41.426326 27820 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:21:41.427228 27820 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([57066, 384, 14, 14],"float32"),Tensor([57066, 48, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([57066, 384, 14, 14],"float32"),Tensor([57066, 48, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000179GB memory on GPU 0, 70.580994GB memory has been allocated and available memory is only 8.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 13:23:23.644688 28233 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:23:23.645730 28233 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5707, 240, 56, 56],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([5707, 240, 56, 56],"float32"),Tensor([2, 48, 56, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5707 but got size 2 for tensor number 1 in the list.

W0207 13:24:34.724742 28795 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:24:34.726269 28795 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5707, 240, 56, 56],"float32"),Tensor([5707, 48, 56, 56],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([5707, 240, 56, 56],"float32"),Tensor([5707, 48, 56, 56],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.001301GB memory on GPU 0, 72.981384GB memory has been allocated and available memory is only 6.203491GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 13:26:15.844285 29101 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:26:15.845341 29101 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5810, 128, 76, 76],"float32"),Tensor([4, 256, 76, 76],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([5810, 128, 76, 76],"float32"),Tensor([4, 256, 76, 76],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 5810 but got size 4 for tensor number 1 in the list.

W0207 13:27:26.233228 29519 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:27:26.234512 29519 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([5810, 128, 76, 76],"float32"),Tensor([5810, 256, 76, 76],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([5810, 128, 76, 76],"float32"),Tensor([5810, 256, 76, 76],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.01 GiB. GPU 0 has a total capacity of 79.18 GiB of which 29.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 29251 has 16.99 GiB memory in use. Of the allocated memory 16.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 13:30:35.776252 29916 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:30:35.778977 29916 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([58280, 1504, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([58280, 1504, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 58280 but got size 2 for tensor number 1 in the list.

W0207 13:32:06.724332 30765 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:32:06.725637 30765 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([58280, 1504, 7, 7],"float32"),Tensor([58280, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([58280, 1504, 7, 7],"float32"),Tensor([58280, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000133GB memory on GPU 0, 67.260681GB memory has been allocated and available memory is only 11.924194GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 13:33:54.641414 31190 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:33:54.642398 31190 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([58907, 1488, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([58907, 1488, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 58907 but got size 2 for tensor number 1 in the list.

W0207 13:35:07.301883 31694 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:35:07.303100 31694 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([58907, 1488, 7, 7],"float32"),Tensor([58907, 48, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([58907, 1488, 7, 7],"float32"),Tensor([58907, 48, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000223GB memory on GPU 0, 67.612244GB memory has been allocated and available memory is only 11.572632GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 13:36:41.099026 32026 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:36:41.099936 32026 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([59547, 1472, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([59547, 1472, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 59547 but got size 2 for tensor number 1 in the list.

W0207 13:37:50.749861 32459 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:37:50.751044 32459 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([59547, 1472, 7, 7],"float32"),Tensor([59547, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([59547, 1472, 7, 7],"float32"),Tensor([59547, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000144GB memory on GPU 0, 67.276306GB memory has been allocated and available memory is only 11.908569GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 13:39:22.925498 32856 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:39:22.926456 32856 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([596524, 288, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([596524, 288, 5, 5],"float32"),Tensor([1, 32, 5, 5],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 596524 but got size 1 for tensor number 1 in the list.

W0207 13:40:32.004370 33267 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:40:32.005488 33267 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([596524, 288, 5, 5],"float32"),Tensor([596524, 32, 5, 5],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([596524, 288, 5, 5],"float32"),Tensor([596524, 32, 5, 5],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000021GB memory on GPU 0, 70.135681GB memory has been allocated and available memory is only 9.049194GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 13:42:21.324430 33565 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:42:21.325371 33565 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([6],"float32"),Tensor([36],"float32"),Tensor([4294967295],"float32"),], )
[paddle error] paddle.concat(list[Tensor([6],"float32"),Tensor([36],"float32"),Tensor([4294967295],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 13:43:44.960107 34087 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:43:44.961004 34087 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([6],"float32"),Tensor([4294967295],"float32"),], )
[paddle error] paddle.concat(list[Tensor([6],"float32"),Tensor([4294967295],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 13:45:12.776834 34411 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:45:12.777833 34411 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([6],"float32"),Tensor([4294967295],"float32"),Tensor([10],"float32"),], )
[paddle error] paddle.concat(list[Tensor([6],"float32"),Tensor([4294967295],"float32"),Tensor([10],"float32"),], ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.580994GB memory has been allocated and available memory is only 12.603882GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 13:46:46.247540 34829 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:46:46.248437 34829 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([6],"float64"),Tensor([2147483649],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([6],"float64"),Tensor([2147483649],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 13:47:50.536206 35354 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:47:50.537110 35354 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([6],"float64"),Tensor([2147483649],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([6],"float64"),Tensor([2147483649],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 13:48:57.323938 35649 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:48:57.325102 35649 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([6],"float64"),Tensor([6],"float64"),Tensor([2147483649],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([6],"float64"),Tensor([6],"float64"),Tensor([2147483649],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 13:49:59.348685 35947 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:49:59.349563 35947 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([6],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),Tensor([2147483649],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([6],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),Tensor([2147483649],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 13:51:12.593246 36217 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:51:12.594172 36217 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([6],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),Tensor([2147483649],"float64"),Tensor([6],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([6],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),Tensor([2147483649],"float64"),Tensor([6],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 13:52:24.765477 36540 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:52:24.766454 36540 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([6],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),Tensor([2147483649],"float64"),], axis=0, )
[paddle error] paddle.concat(list[Tensor([6],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),Tensor([6],"float64"),Tensor([2147483649],"float64"),], axis=0, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 66.582947GB memory has been allocated and available memory is only 12.601929GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 13:53:32.032634 36918 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:53:32.033690 36918 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([60870, 1440, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([60870, 1440, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 60870 but got size 2 for tensor number 1 in the list.

W0207 13:54:49.328697 37216 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:54:49.329702 37216 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([60870, 1440, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([60870, 1440, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 60870 but got size 2 for tensor number 1 in the list.

W0207 13:56:07.818961 37609 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:56:07.820102 37609 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([60870, 1440, 7, 7],"float32"),Tensor([60870, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([60870, 1440, 7, 7],"float32"),Tensor([60870, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000074GB memory on GPU 0, 67.291931GB memory has been allocated and available memory is only 11.892944GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 13:57:46.049741 37925 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:57:46.050668 37925 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([60870, 1440, 7, 7],"float32"),Tensor([60870, 48, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([60870, 1440, 7, 7],"float32"),Tensor([60870, 48, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000074GB memory on GPU 0, 67.647400GB memory has been allocated and available memory is only 11.537476GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 13:59:22.387285 38358 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 13:59:22.390377 38358 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([6115, 224, 56, 56],"float32"),Tensor([2, 32, 56, 56],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([6115, 224, 56, 56],"float32"),Tensor([2, 32, 56, 56],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 6115 but got size 2 for tensor number 1 in the list.

W0207 14:00:37.217824 38869 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:00:37.218688 38869 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([6115, 224, 56, 56],"float32"),Tensor([6115, 32, 56, 56],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([6115, 224, 56, 56],"float32"),Tensor([6115, 32, 56, 56],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.002235GB memory on GPU 0, 71.155212GB memory has been allocated and available memory is only 8.029663GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 14:02:22.392030 39186 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:02:22.393160 39186 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([62254, 1408, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([62254, 1408, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 62254 but got size 2 for tensor number 1 in the list.

W0207 14:03:36.296864 39729 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:03:36.297987 39729 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([62254, 1408, 7, 7],"float32"),Tensor([62254, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([62254, 1408, 7, 7],"float32"),Tensor([62254, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000226GB memory on GPU 0, 67.307556GB memory has been allocated and available memory is only 11.877319GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 14:05:16.824396 40030 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:05:16.825373 40030 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([62254, 352, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([62254, 352, 14, 14],"float32"),Tensor([2, 32, 14, 14],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 62254 but got size 2 for tensor number 1 in the list.

W0207 14:06:33.366529 40467 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:06:33.367637 40467 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([62254, 352, 14, 14],"float32"),Tensor([62254, 32, 14, 14],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([62254, 352, 14, 14],"float32"),Tensor([62254, 32, 14, 14],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000226GB memory on GPU 0, 69.487244GB memory has been allocated and available memory is only 9.697632GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 14:08:16.506987 40878 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:08:16.507973 40878 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([62254, 88, 28, 28],"float32"),Tensor([2, 88, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([62254, 88, 28, 28],"float32"),Tensor([2, 88, 28, 28],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 62254 but got size 2 for tensor number 1 in the list.

W0207 14:09:31.229703 41313 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:09:31.230798 41313 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([62254, 88, 28, 28],"float32"),Tensor([62254, 88, 28, 28],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([62254, 88, 28, 28],"float32"),Tensor([62254, 88, 28, 28],"float32"),], axis=1, ) 
 CUDA out of memory. Tried to allocate 32.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 13.20 GiB is free. Process 43748 has 32.99 GiB memory in use. Process 136207 has 32.99 GiB memory in use. Of the allocated memory 32.00 GiB is allocated by PyTorch, and 3.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0207 14:11:49.159487 41718 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:11:49.160648 41718 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([62969, 1392, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([62969, 1392, 7, 7],"float32"),Tensor([2, 48, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 62969 but got size 2 for tensor number 1 in the list.

W0207 14:13:08.112500 42369 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:13:08.113905 42369 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([62969, 1392, 7, 7],"float32"),Tensor([62969, 48, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([62969, 1392, 7, 7],"float32"),Tensor([62969, 48, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000083GB memory on GPU 0, 67.682556GB memory has been allocated and available memory is only 11.502319GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 14:14:49.567127 42694 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:14:49.567997 42694 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([63701, 1376, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, )
[torch error] paddle.concat(list[Tensor([63701, 1376, 7, 7],"float32"),Tensor([2, 32, 7, 7],"float32"),], axis=1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 63701 but got size 2 for tensor number 1 in the list.

W0207 14:16:02.418243 43208 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:16:02.419445 43208 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([63701, 1376, 7, 7],"float32"),Tensor([63701, 32, 7, 7],"float32"),], axis=1, )
[paddle error] paddle.concat(list[Tensor([63701, 1376, 7, 7],"float32"),Tensor([63701, 32, 7, 7],"float32"),], axis=1, ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000033GB memory on GPU 0, 67.323181GB memory has been allocated and available memory is only 11.861694GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0207 14:17:42.574957 43638 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:17:42.576153 43638 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([64, 32],"float16"),Tensor([134217728, 32],"float16"),], axis=-1, )
[torch error] paddle.concat(list[Tensor([64, 32],"float16"),Tensor([134217728, 32],"float16"),], axis=-1, ) 
 Sizes of tensors must match except in dimension 1. Expected size 64 but got size 134217728 for tensor number 1 in the list.

W0207 14:19:12.912336 44045 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:19:12.913460 44045 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.concat(list[Tensor([64, 32],"float16"),Tensor([64, 67108864],"float16"),], axis=-1, )
[Pass] paddle.concat(list[Tensor([64, 32],"float16"),Tensor([64, 67108864],"float16"),], axis=-1, )

W0207 14:20:47.742384 44537 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0207 14:20:47.743274 44537 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

Traceback (most recent call last):
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 70, in <module>
    main()
  File "/host_home/wanghuan29/PaddleAPITest/engine.py", line 65, in main
    print(str(res.stdout.read(), encoding="utf-8"), flush=True)
KeyboardInterrupt
