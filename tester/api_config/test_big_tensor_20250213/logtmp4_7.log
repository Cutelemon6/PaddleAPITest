test begin: paddle.trapezoid(y=Tensor([4, 1073741824],"float16"), x=Tensor([4, 1073741824],"float16"), )
[torch error] paddle.trapezoid(y=Tensor([4, 1073741824],"float16"), x=Tensor([4, 1073741824],"float16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 47055 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:31:23.149916 25707 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:31:23.151296 25707 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.trapezoid(y=Tensor([4, 1073741824],"float16"), x=Tensor([4, 4],"float16"), )
[torch error] paddle.trapezoid(y=Tensor([4, 1073741824],"float16"), x=Tensor([4, 4],"float16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 105054 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:32:54.801860 27860 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:32:54.802966 27860 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.trapezoid(y=Tensor([4, 4],"float16"), x=Tensor([1073741824, 4],"float16"), )
[torch error] paddle.trapezoid(y=Tensor([4, 4],"float16"), x=Tensor([1073741824, 4],"float16"), ) 
 CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 129280 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:34:21.792768 28920 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:34:21.793748 28920 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.trapezoid(y=Tensor([4, 4],"float16"), x=Tensor([4, 1073741824],"float16"), )
[torch error] paddle.trapezoid(y=Tensor([4, 4],"float16"), x=Tensor([4, 1073741824],"float16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 1022 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:35:54.282541 29951 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:35:54.283565 29951 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.trapezoid(y=Tensor([715827883, 3],"float64"), x=None, dx=None, axis=-1, )
[torch error] paddle.trapezoid(y=Tensor([715827883, 3],"float64"), x=None, dx=None, axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 28967 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:36:46.400089 30994 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:36:46.401124 30994 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.trapezoid(y=Tensor([715827883, 3],"float64"), x=Tensor([2, 3],"float64"), dx=None, axis=-1, )
[torch error] paddle.trapezoid(y=Tensor([715827883, 3],"float64"), x=Tensor([2, 3],"float64"), dx=None, axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 57969 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:37:34.922124 31361 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:37:34.923209 31361 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.trapezoid(y=Tensor([715827883, 3],"float64"), x=Tensor([715827883, 3],"float64"), dx=None, axis=-1, )
[torch error] paddle.trapezoid(y=Tensor([715827883, 3],"float64"), x=Tensor([715827883, 3],"float64"), dx=None, axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 80868 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:38:25.320508 32022 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:38:25.321504 32022 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.tril(Tensor([1, 4294967295],"float32"), diagonal=0, )
[torch error] paddle.tril(Tensor([1, 4294967295],"float32"), diagonal=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 101663 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:39:39.147909 32683 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:39:39.149026 32683 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.tril(Tensor([10, 20, 21474837],"float32"), 0, )
[torch error] paddle.tril(Tensor([10, 20, 21474837],"float32"), 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 126906 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:40:51.900170 33401 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:40:51.901278 33401 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.tril(Tensor([10, 429496730, 1],"float32"), 0, )
[torch error] paddle.tril(Tensor([10, 429496730, 1],"float32"), 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 152529 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:42:04.007360 34387 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:42:04.008375 34387 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.tril(Tensor([10, 429496730],"bool"), )
[paddle error] paddle.tril(Tensor([10, 429496730],"bool"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_tril(_object*, _object*, _object*)
1   tril_ad_func(paddle::Tensor const&, int)
2   paddle::experimental::tril(paddle::Tensor const&, int)
3   void phi::TrilTriuKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, int, bool, phi::DenseTensor*)
4   bool* phi::DeviceContext::Alloc<bool>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 79.174744GB memory has been allocated and available memory is only 10.375000MB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0213 09:43:19.491478 35075 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:43:19.492439 35075 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.tril(Tensor([2048, 2097152],"bool"), )
[paddle error] paddle.tril(Tensor([2048, 2097152],"bool"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_tril(_object*, _object*, _object*)
1   tril_ad_func(paddle::Tensor const&, int)
2   paddle::experimental::tril(paddle::Tensor const&, int)
3   void phi::TrilTriuKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, int, bool, phi::DenseTensor*)
4   bool* phi::DeviceContext::Alloc<bool>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 79.168884GB memory has been allocated and available memory is only 16.375000MB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0213 09:44:45.230401 36086 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:44:45.231405 36086 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.tril(Tensor([2097152, 2048],"bool"), )
[paddle error] paddle.tril(Tensor([2097152, 2048],"bool"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_tril(_object*, _object*, _object*)
1   tril_ad_func(paddle::Tensor const&, int)
2   paddle::experimental::tril(paddle::Tensor const&, int)
3   void phi::TrilTriuKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, int, bool, phi::DenseTensor*)
4   bool* phi::DeviceContext::Alloc<bool>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 79.168884GB memory has been allocated and available memory is only 16.375000MB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0213 09:46:05.977134 37096 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:46:05.978399 37096 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.tril(Tensor([214748365, 20, 1],"float32"), 0, )
[torch error] paddle.tril(Tensor([214748365, 20, 1],"float32"), 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 124948 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:47:21.469763 37826 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:47:21.470743 37826 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.tril(Tensor([4294967295, 1],"float32"), diagonal=0, )
[torch error] paddle.tril(Tensor([4294967295, 1],"float32"), diagonal=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 155824 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:48:31.819250 38798 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:48:31.821718 38798 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.tril(Tensor([429496730, 10],"bool"), )
[paddle error] paddle.tril(Tensor([429496730, 10],"bool"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_tril(_object*, _object*, _object*)
1   tril_ad_func(paddle::Tensor const&, int)
2   paddle::experimental::tril(paddle::Tensor const&, int)
3   void phi::TrilTriuKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, int, bool, phi::DenseTensor*)
4   bool* phi::DeviceContext::Alloc<bool>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 79.174744GB memory has been allocated and available memory is only 10.375000MB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0213 09:49:46.562294 39495 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:49:46.563352 39495 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.tril(Tensor([50, 85899346],"bool"), )
[paddle error] paddle.tril(Tensor([50, 85899346],"bool"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_tril(_object*, _object*, _object*)
1   tril_ad_func(paddle::Tensor const&, int)
2   paddle::experimental::tril(paddle::Tensor const&, int)
3   void phi::TrilTriuKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, int, bool, phi::DenseTensor*)
4   bool* phi::DeviceContext::Alloc<bool>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 79.174744GB memory has been allocated and available memory is only 10.375000MB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0213 09:51:06.123013 40486 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:51:06.124117 40486 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.tril(Tensor([64, 67108864],"float16"), )
[torch error] paddle.tril(Tensor([64, 67108864],"float16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 76528 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:52:41.035527 41236 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:52:41.036489 41236 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.tril(Tensor([64, 67108864],"float32"), )
[torch error] paddle.tril(Tensor([64, 67108864],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 109465 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:53:51.446525 42253 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:53:51.455526 42253 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.tril(Tensor([67108864, 64],"float16"), )
[torch error] paddle.tril(Tensor([67108864, 64],"float16"), ) 
 CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 4.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 136689 has 8.99 GiB memory in use. Of the allocated memory 8.00 GiB is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:55:18.465397 43240 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:55:18.466452 43240 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.tril(Tensor([67108864, 64],"float32"), )
[torch error] paddle.tril(Tensor([67108864, 64],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 11432 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:56:34.688653 44254 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:56:34.689769 44254 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.tril(Tensor([85899346, 50],"bool"), )
[paddle error] paddle.tril(Tensor([85899346, 50],"bool"), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::eager_api_tril(_object*, _object*, _object*)
1   tril_ad_func(paddle::Tensor const&, int)
2   paddle::experimental::tril(paddle::Tensor const&, int)
3   void phi::TrilTriuKernel<bool, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, int, bool, phi::DenseTensor*)
4   bool* phi::DeviceContext::Alloc<bool>(phi::TensorBase*, unsigned long, bool) const
5   phi::DeviceContext::Impl::Alloc(phi::TensorBase*, phi::Place const&, phi::DataType, unsigned long, bool, bool) const
6   phi::DenseTensor::AllocateFrom(phi::Allocator*, phi::DataType, unsigned long, bool)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 4.000000GB memory on GPU 0, 79.174744GB memory has been allocated and available memory is only 10.375000MB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0213 09:57:48.127395 44968 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:57:48.128278 44968 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.triu(Tensor([1, 128, 1048576, 32],"float32"), diagonal=1, )
[torch error] paddle.triu(Tensor([1, 128, 1048576, 32],"float32"), diagonal=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 68862 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 09:59:03.696449 45996 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 09:59:03.697501 45996 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.triu(Tensor([1, 128, 32, 1048576],"float32"), diagonal=1, )
[torch error] paddle.triu(Tensor([1, 128, 32, 1048576],"float32"), diagonal=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 94479 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:00:13.970757 46697 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:00:13.971849 46697 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.triu(Tensor([1, 4194304, 32, 32],"float32"), diagonal=1, )
[torch error] paddle.triu(Tensor([1, 4194304, 32, 32],"float32"), diagonal=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 128313 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:01:47.482673 47411 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:01:47.483872 47411 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.triu(Tensor([10, 20, 21474837],"float32"), 0, )
[torch error] paddle.triu(Tensor([10, 20, 21474837],"float32"), 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 163835 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:02:58.164530 48713 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:02:58.165539 48713 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.triu(Tensor([10, 429496730, 1],"float32"), 0, )
[torch error] paddle.triu(Tensor([10, 429496730, 1],"float32"), 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 24573 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:04:13.971190 49401 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:04:13.972144 49401 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.triu(Tensor([1073741824, 4],"float32"), diagonal=1, )
[torch error] paddle.triu(Tensor([1073741824, 4],"float32"), diagonal=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 59821 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:05:30.280436 50073 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:05:30.281530 50073 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.triu(Tensor([11, 390451573],"float32"), diagonal=1, )
[torch error] paddle.triu(Tensor([11, 390451573],"float32"), diagonal=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 87722 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:06:39.772709 51248 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:06:39.773792 51248 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.triu(Tensor([214748365, 20, 1],"float32"), 0, )
[torch error] paddle.triu(Tensor([214748365, 20, 1],"float32"), 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 119263 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:07:49.657711 51949 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:07:49.658851 51949 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.triu(Tensor([268435456, 16],"float32"), diagonal=1, )
[torch error] paddle.triu(Tensor([268435456, 16],"float32"), diagonal=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 144795 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:09:06.017287 53107 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:09:06.018272 53107 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.triu(Tensor([32768, 128, 32, 32],"float32"), diagonal=1, )
[torch error] paddle.triu(Tensor([32768, 128, 32, 32],"float32"), diagonal=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 5606 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:10:22.251999 53835 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:10:22.253103 53835 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.triu(Tensor([4, 1073741824],"float32"), diagonal=1, )
[torch error] paddle.triu(Tensor([4, 1073741824],"float32"), diagonal=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 42105 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:11:34.695156 54822 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:11:34.696177 54822 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.triu(Tensor([6, 715827883],"float32"), diagonal=1, )
[torch error] paddle.triu(Tensor([6, 715827883],"float32"), diagonal=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 68369 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:12:45.140971 55538 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:12:45.142083 55538 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.triu(Tensor([613566757, 7],"float32"), diagonal=1, )
[torch error] paddle.triu(Tensor([613566757, 7],"float32"), diagonal=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 94409 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:13:58.062837 56253 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:13:58.063858 56253 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.triu(Tensor([858993459, 5],"float32"), diagonal=1, )
[torch error] paddle.triu(Tensor([858993459, 5],"float32"), diagonal=1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 122980 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:15:17.515692 57240 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:15:17.516743 57240 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.trunc(Tensor([10, 20, 21474837],"float32"), )
[torch error] paddle.trunc(Tensor([10, 20, 21474837],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 159058 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:16:33.832877 58245 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:16:33.833873 58245 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.trunc(Tensor([10, 429496730, 1],"float32"), )
[torch error] paddle.trunc(Tensor([10, 429496730, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 28101 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:17:50.560985 58973 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:17:50.561969 58973 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.trunc(Tensor([20, 214748365],"float32"), )
[torch error] paddle.trunc(Tensor([20, 214748365],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 58670 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:19:06.871263 59967 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:19:06.872364 59967 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.trunc(Tensor([214748365, 20, 1],"float32"), )
[torch error] paddle.trunc(Tensor([214748365, 20, 1],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 84359 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:20:17.669632 60702 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:20:17.670642 60702 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.trunc(Tensor([214748365, 20],"float32"), )
[torch error] paddle.trunc(Tensor([214748365, 20],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 118011 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:21:35.320973 61665 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:21:35.321933 61665 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unbind(Tensor([1431655765, 3],"float32"), 0, )
[torch error] paddle.unbind(Tensor([1431655765, 3],"float32"), 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 145168 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:22:48.151670 62405 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:22:48.152892 62405 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unbind(Tensor([143165577, 5, 6],"float32"), )
[torch error] paddle.unbind(Tensor([143165577, 5, 6],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 9429 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:23:59.699715 63382 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:23:59.700788 63382 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unbind(Tensor([2, 2147483648],"bool"), axis=0, )
[accuracy error] paddle.unbind(Tensor([2, 2147483648],"bool"), axis=0, ) 
 'list' object has no attribute 'dtype'

W0213 10:25:16.333792 64098 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:25:16.334998 64098 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unbind(Tensor([2, 2147483648],"float32"), 0, )
[torch error] paddle.unbind(Tensor([2, 2147483648],"float32"), 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 63594 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:26:26.783156 64817 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:26:26.784193 64817 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unbind(Tensor([2, 3, 8, 89478486],"float32"), axis=0, )
[torch error] paddle.unbind(Tensor([2, 3, 8, 89478486],"float32"), axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 103416 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:27:39.769292 65815 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:27:39.770344 65815 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unbind(Tensor([2, 3, 89478486, 8],"float32"), axis=0, )
[torch error] paddle.unbind(Tensor([2, 3, 89478486, 8],"float32"), axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 128191 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:28:50.057857 66559 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:28:50.058971 66559 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unbind(Tensor([2, 33554432, 8, 8],"float32"), axis=0, )
[torch error] paddle.unbind(Tensor([2, 33554432, 8, 8],"float32"), axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 153405 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 10:30:02.297500 67570 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 10:30:02.298516 67570 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unbind(Tensor([2147483648, 2],"bool"), axis=0, )


test begin: paddle.unbind(Tensor([22369622, 3, 8, 8],"float32"), axis=0, )
[torch error] paddle.unbind(Tensor([22369622, 3, 8, 8],"float32"), axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 120480 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:42:02.137804 106987 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:42:02.142073 106987 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unbind(Tensor([3, 286331153, 5],"float32"), axis=0, )
[torch error] paddle.unbind(Tensor([3, 286331153, 5],"float32"), axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 147682 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:43:15.264065 107462 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:43:15.265147 107462 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unbind(Tensor([3, 9, 159072863],"float32"), axis=0, )
[torch error] paddle.unbind(Tensor([3, 9, 159072863],"float32"), axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 11528 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:44:25.629263 107937 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:44:25.631546 107937 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unbind(Tensor([4, 178956971, 6],"float32"), )
[torch error] paddle.unbind(Tensor([4, 178956971, 6],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 45062 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:45:35.772464 108640 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:45:35.773547 108640 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unbind(Tensor([4, 5, 214748365],"float32"), )
[torch error] paddle.unbind(Tensor([4, 5, 214748365],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 79054 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:46:46.974360 109115 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:46:46.975382 109115 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unbind(Tensor([4294967295],"float32"), 0, )
[torch error] paddle.unbind(Tensor([4294967295],"float32"), 0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 120427 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:47:59.775528 109590 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:47:59.776546 109590 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unbind(Tensor([95443718, 9, 5],"float32"), axis=0, )
[torch error] paddle.unbind(Tensor([95443718, 9, 5],"float32"), axis=0, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 147103 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:49:12.568315 110301 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:49:12.569344 110301 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(Tensor([3, 4, 4, 89478486],"float32"), axis=1, shape=list[2,2,], name=None, )
[torch error] paddle.unflatten(Tensor([3, 4, 4, 89478486],"float32"), axis=1, shape=list[2,2,], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 9142 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:50:23.233981 110776 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:50:23.234985 110776 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(Tensor([3, 4, 71582789, 5],"float32"), axis=1, shape=list[2,2,], name=None, )
[torch error] paddle.unflatten(Tensor([3, 4, 71582789, 5],"float32"), axis=1, shape=list[2,2,], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 39342 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:51:34.401504 111478 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:51:34.402562 111478 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(Tensor([3, 71582789, 4, 5],"float32"), axis=1, shape=list[2,2,], name=None, )
[torch error] paddle.unflatten(Tensor([3, 71582789, 4, 5],"float32"), axis=1, shape=list[2,2,], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 74288 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:52:48.140192 111953 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:52:48.141189 111953 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(Tensor([53687092, 4, 4, 5],"float32"), axis=1, shape=list[2,2,], name=None, )
[torch error] paddle.unflatten(Tensor([53687092, 4, 4, 5],"float32"), axis=1, shape=list[2,2,], name=None, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 110129 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:54:01.238901 112656 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:54:01.240002 112656 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([22369622, 6, 16],"float64"), axis=0, shape=tuple(2,2,), )
[torch error] paddle.unflatten(x=Tensor([22369622, 6, 16],"float64"), axis=0, shape=tuple(2,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 137217 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:54:53.201378 113131 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:54:53.202466 113131 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([22369622, 6, 16],"int64"), axis=0, shape=tuple(2,2,), )
[torch error] paddle.unflatten(x=Tensor([22369622, 6, 16],"int64"), axis=0, shape=tuple(2,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 156719 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:55:39.128216 113604 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:55:39.129319 113604 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 33554433, 16],"float64"), axis=0, shape=tuple(2,2,), )
[torch error] paddle.unflatten(x=Tensor([4, 33554433, 16],"float64"), axis=0, shape=tuple(2,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 11728 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:56:29.748770 113850 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:56:29.749758 113850 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 33554433, 16],"int64"), axis=0, shape=tuple(2,2,), )
[torch error] paddle.unflatten(x=Tensor([4, 33554433, 16],"int64"), axis=0, shape=tuple(2,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 34329 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:57:19.848641 114323 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:57:19.849643 114323 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 6, 16],"float32"), axis=0, shape=Tensor([2147483649],"int64"), )
[torch error] paddle.unflatten(x=Tensor([4, 6, 16],"float32"), axis=0, shape=Tensor([2147483649],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 49222 has 1016.00 MiB memory in use. Of the allocated memory 1.50 KiB is allocated by PyTorch, and 2.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 11:58:05.225785 114796 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:58:05.226861 114796 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 6, 178956971],"bool"), axis=0, shape=tuple(2,2,), )
[Pass] paddle.unflatten(x=Tensor([4, 6, 178956971],"bool"), axis=0, shape=tuple(2,2,), )

W0213 11:59:24.866626 115042 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 11:59:24.867624 115042 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 6, 178956971],"float16"), axis=0, shape=tuple(2,2,), )
[paddle error] paddle.unflatten(x=Tensor([4, 6, 178956971],"float16"), axis=0, shape=tuple(2,2,), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000000GB memory on GPU 0, 75.170837GB memory has been allocated and available memory is only 4.014038GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0213 12:02:13.463239 116204 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:02:13.464078 116204 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 6, 178956971],"float32"), axis=0, shape=list[-1,], )
[torch error] paddle.unflatten(x=Tensor([4, 6, 178956971],"float32"), axis=0, shape=list[-1,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 155920 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:03:20.668381 116910 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:03:20.669411 116910 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 6, 178956971],"float32"), axis=0, shape=list[2,2,], )
[torch error] paddle.unflatten(x=Tensor([4, 6, 178956971],"float32"), axis=0, shape=list[2,2,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 18163 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:04:37.829072 117612 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:04:37.830062 117612 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 6, 178956971],"float32"), axis=0, shape=Tensor([2],"int64"), )
[torch error] paddle.unflatten(x=Tensor([4, 6, 178956971],"float32"), axis=0, shape=Tensor([2],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 52858 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:05:54.552740 118088 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:05:54.553736 118088 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 6, 178956971],"float32"), axis=0, shape=tuple(-1,), )
[torch error] paddle.unflatten(x=Tensor([4, 6, 178956971],"float32"), axis=0, shape=tuple(-1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 84010 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:07:05.567747 118799 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:07:05.573222 118799 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 6, 178956971],"float32"), axis=0, shape=tuple(-1,2,), )
[torch error] paddle.unflatten(x=Tensor([4, 6, 178956971],"float32"), axis=0, shape=tuple(-1,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 110929 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:08:22.307358 119274 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:08:22.308382 119274 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 6, 178956971],"float32"), axis=0, shape=tuple(2,2,), )
[torch error] paddle.unflatten(x=Tensor([4, 6, 178956971],"float32"), axis=0, shape=tuple(2,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 141575 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:09:39.156689 119989 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:09:39.157859 119989 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 6, 178956971],"float32"), axis=-1, shape=list[-1,2,], )
[torch error] paddle.unflatten(x=Tensor([4, 6, 178956971],"float32"), axis=-1, shape=list[-1,2,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 11687 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:10:56.499857 120629 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:10:56.500967 120629 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 6, 178956971],"float32"), axis=1, shape=tuple(2,3,), )
[torch error] paddle.unflatten(x=Tensor([4, 6, 178956971],"float32"), axis=1, shape=tuple(2,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 38251 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:12:34.253232 121332 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:12:34.254383 121332 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 6, 178956971],"float32"), axis=-1, shape=tuple(2,8,), )
[torch error] paddle.unflatten(x=Tensor([4, 6, 178956971],"float32"), axis=-1, shape=tuple(2,8,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 77476 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:13:50.976457 122200 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:13:50.977447 122200 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 6, 178956971],"int16"), axis=0, shape=tuple(2,2,), )
[paddle error] paddle.unflatten(x=Tensor([4, 6, 178956971],"int16"), axis=0, shape=tuple(2,2,), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000000GB memory on GPU 0, 75.170837GB memory has been allocated and available memory is only 4.014038GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0213 12:15:14.969429 122903 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:15:14.971169 122903 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 6, 178956971],"int32"), axis=0, shape=tuple(2,2,), )
[torch error] paddle.unflatten(x=Tensor([4, 6, 178956971],"int32"), axis=0, shape=tuple(2,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 132778 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:16:20.525887 123379 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:16:20.526903 123379 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 6, 89478486],"float64"), axis=0, shape=tuple(2,2,), )
[torch error] paddle.unflatten(x=Tensor([4, 6, 89478486],"float64"), axis=0, shape=tuple(2,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 567 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:17:15.145816 124081 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:17:15.146802 124081 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 6, 89478486],"int64"), axis=0, shape=tuple(2,2,), )
[torch error] paddle.unflatten(x=Tensor([4, 6, 89478486],"int64"), axis=0, shape=tuple(2,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 19506 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:18:01.734112 124327 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:18:01.735662 124327 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 67108864, 16],"bool"), axis=0, shape=tuple(2,2,), )
[Pass] paddle.unflatten(x=Tensor([4, 67108864, 16],"bool"), axis=0, shape=tuple(2,2,), )

W0213 12:19:20.291291 124800 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:19:20.292273 124800 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 67108864, 16],"float16"), axis=0, shape=tuple(2,2,), )
[paddle error] paddle.unflatten(x=Tensor([4, 67108864, 16],"float16"), axis=0, shape=tuple(2,2,), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000000GB memory on GPU 0, 75.168884GB memory has been allocated and available memory is only 4.015991GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0213 12:21:57.588513 125735 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:21:57.589541 125735 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 67108864, 16],"float32"), axis=0, shape=list[-1,], )
[torch error] paddle.unflatten(x=Tensor([4, 67108864, 16],"float32"), axis=0, shape=list[-1,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 126320 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:23:02.778085 126667 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:23:02.779209 126667 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 67108864, 16],"float32"), axis=0, shape=list[2,2,], )
[torch error] paddle.unflatten(x=Tensor([4, 67108864, 16],"float32"), axis=0, shape=list[2,2,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 148477 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:24:19.424775 127142 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:24:19.425787 127142 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 67108864, 16],"float32"), axis=0, shape=Tensor([2],"int64"), )
[torch error] paddle.unflatten(x=Tensor([4, 67108864, 16],"float32"), axis=0, shape=Tensor([2],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 19349 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:25:29.287425 127845 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:25:29.289052 127845 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 67108864, 16],"float32"), axis=0, shape=tuple(-1,), )
[torch error] paddle.unflatten(x=Tensor([4, 67108864, 16],"float32"), axis=0, shape=tuple(-1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 48807 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:26:46.054756 128329 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:26:46.055779 128329 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 67108864, 16],"float32"), axis=0, shape=tuple(-1,2,), )
[torch error] paddle.unflatten(x=Tensor([4, 67108864, 16],"float32"), axis=0, shape=tuple(-1,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 84368 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:28:02.884207 128813 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:28:02.885329 128813 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 67108864, 16],"float32"), axis=0, shape=tuple(2,2,), )
[torch error] paddle.unflatten(x=Tensor([4, 67108864, 16],"float32"), axis=0, shape=tuple(2,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 109083 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:29:18.322304 129515 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:29:18.323374 129515 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 67108864, 16],"float32"), axis=-1, shape=list[-1,2,], )
[torch error] paddle.unflatten(x=Tensor([4, 67108864, 16],"float32"), axis=-1, shape=list[-1,2,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 135773 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:30:36.016624 130218 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:30:36.017616 130218 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 67108864, 16],"float32"), axis=1, shape=tuple(2,3,), )
[torch error] paddle.unflatten(x=Tensor([4, 67108864, 16],"float32"), axis=1, shape=tuple(2,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 6103 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:31:51.113525 130693 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:31:51.114590 130693 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 67108864, 16],"float32"), axis=-1, shape=tuple(2,8,), )
[torch error] paddle.unflatten(x=Tensor([4, 67108864, 16],"float32"), axis=-1, shape=tuple(2,8,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 31521 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:33:00.994397 131396 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:33:00.995489 131396 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 67108864, 16],"int16"), axis=0, shape=tuple(2,2,), )
[paddle error] paddle.unflatten(x=Tensor([4, 67108864, 16],"int16"), axis=0, shape=tuple(2,2,), ) 
 

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::pybind::TensorInit(_object*, _object*, _object*)
1   paddle::pybind::AutoInitTensorByPyArray(paddle::pybind::TensorObject*, std::unordered_map<std::string, _object*, std::hash<std::string >, std::equal_to<std::string >, std::allocator<std::pair<std::string const, _object*> > >, _object*, bool, long)
2   phi::DenseTensor::mutable_data(phi::Place const&, phi::DataType, unsigned long)
3   phi::memory_utils::AllocShared(phi::Place const&, unsigned long)
4   paddle::memory::AllocShared(phi::Place const&, unsigned long)
5   paddle::memory::allocation::AllocatorFacade::AllocShared(phi::Place const&, unsigned long)
6   paddle::memory::allocation::AllocatorFacade::Alloc(phi::Place const&, unsigned long)
7   paddle::memory::allocation::Allocator::Allocate(unsigned long)
8   paddle::memory::allocation::StatAllocator::AllocateImpl(unsigned long)
9   paddle::memory::allocation::Allocator::Allocate(unsigned long)
10  paddle::memory::allocation::Allocator::Allocate(unsigned long)
11  paddle::memory::allocation::Allocator::Allocate(unsigned long)
12  paddle::memory::allocation::Allocator::Allocate(unsigned long)
13  paddle::memory::allocation::CUDAAllocator::AllocateImpl(unsigned long)
14  std::string phi::enforce::GetCompleteTraceBackString<std::string >(std::string&&, char const*, int)
15  common::enforce::GetCurrentTraceBackString[abi:cxx11](bool)

----------------------
Error Message Summary:
----------------------
ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 8.000000GB memory on GPU 0, 75.168884GB memory has been allocated and available memory is only 4.015991GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
 (at ../paddle/phi/core/memory/allocation/cuda_allocator.cc:84)


W0213 12:34:30.328472 131871 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:34:30.329351 131871 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([4, 67108864, 16],"int32"), axis=0, shape=tuple(2,2,), )
[torch error] paddle.unflatten(x=Tensor([4, 67108864, 16],"int32"), axis=0, shape=tuple(2,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 84677 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:35:45.573076 132902 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:35:45.574162 132902 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([44739243, 6, 16],"bool"), axis=0, shape=tuple(2,2,), )
[torch error] paddle.unflatten(x=Tensor([44739243, 6, 16],"bool"), axis=0, shape=tuple(2,2,), ) 
 unflatten: Provided sizes [2, 2] don't multiply up to the size of dim 0 (44739243) in the input tensor

W0213 12:36:52.674145 133378 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:36:52.675294 133378 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([44739243, 6, 16],"float16"), axis=0, shape=tuple(2,2,), )
[torch error] paddle.unflatten(x=Tensor([44739243, 6, 16],"float16"), axis=0, shape=tuple(2,2,), ) 
 unflatten: Provided sizes [2, 2] don't multiply up to the size of dim 0 (44739243) in the input tensor

W0213 12:38:21.202157 134080 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:38:21.203413 134080 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([44739243, 6, 16],"float32"), axis=0, shape=list[-1,], )
[torch error] paddle.unflatten(x=Tensor([44739243, 6, 16],"float32"), axis=0, shape=list[-1,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 15043 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:39:38.250108 134784 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:39:38.251118 134784 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([44739243, 6, 16],"float32"), axis=0, shape=list[2,2,], )
[torch error] paddle.unflatten(x=Tensor([44739243, 6, 16],"float32"), axis=0, shape=list[2,2,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 48667 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:40:54.768688 135260 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:40:54.769671 135260 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([44739243, 6, 16],"float32"), axis=0, shape=Tensor([2],"int64"), )
[torch error] paddle.unflatten(x=Tensor([44739243, 6, 16],"float32"), axis=0, shape=Tensor([2],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 78952 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:42:11.300060 135962 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:42:11.301054 135962 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([44739243, 6, 16],"float32"), axis=0, shape=tuple(-1,), )
[torch error] paddle.unflatten(x=Tensor([44739243, 6, 16],"float32"), axis=0, shape=tuple(-1,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 105993 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:43:21.546532 136438 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:43:21.547660 136438 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([44739243, 6, 16],"float32"), axis=0, shape=tuple(-1,2,), )
[torch error] paddle.unflatten(x=Tensor([44739243, 6, 16],"float32"), axis=0, shape=tuple(-1,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 131152 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:44:32.073441 137140 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:44:32.074976 137140 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([44739243, 6, 16],"float32"), axis=0, shape=tuple(2,2,), )
[torch error] paddle.unflatten(x=Tensor([44739243, 6, 16],"float32"), axis=0, shape=tuple(2,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 2337 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:45:44.671921 137615 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:45:44.673000 137615 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([44739243, 6, 16],"float32"), axis=-1, shape=list[-1,2,], )
[torch error] paddle.unflatten(x=Tensor([44739243, 6, 16],"float32"), axis=-1, shape=list[-1,2,], ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 30189 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:46:54.382357 138090 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:46:54.383432 138090 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([44739243, 6, 16],"float32"), axis=1, shape=tuple(2,3,), )
[torch error] paddle.unflatten(x=Tensor([44739243, 6, 16],"float32"), axis=1, shape=tuple(2,3,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 57371 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:48:04.285270 138798 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:48:04.286433 138798 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([44739243, 6, 16],"float32"), axis=-1, shape=tuple(2,8,), )
[torch error] paddle.unflatten(x=Tensor([44739243, 6, 16],"float32"), axis=-1, shape=tuple(2,8,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 81633 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:49:13.979645 139273 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:49:13.980759 139273 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([44739243, 6, 16],"int16"), axis=0, shape=tuple(2,2,), )
[torch error] paddle.unflatten(x=Tensor([44739243, 6, 16],"int16"), axis=0, shape=tuple(2,2,), ) 
 unflatten: Provided sizes [2, 2] don't multiply up to the size of dim 0 (44739243) in the input tensor

W0213 12:50:31.289219 139748 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:50:31.290549 139748 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unflatten(x=Tensor([44739243, 6, 16],"int32"), axis=0, shape=tuple(2,2,), )
[torch error] paddle.unflatten(x=Tensor([44739243, 6, 16],"int32"), axis=0, shape=tuple(2,2,), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 138383 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:51:42.329677 140451 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:51:42.330685 140451 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unique(Tensor([171798692, 5, 5],"float32"), return_index=True, return_inverse=True, return_counts=True, axis=0, )
[paddle_to_torch] paddle.unique(Tensor([171798692, 5, 5],"float32"), return_index=True, return_inverse=True, return_counts=True, axis=0, ) 
  return_index not in paddle_to_torch_args_map, can not call torch

W0213 12:51:52.438175 140926 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:51:52.439131 140926 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unique(Tensor([2, 1073741825],"int64"), )
[torch error] paddle.unique(Tensor([2, 1073741825],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 4833 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:52:43.600450 141168 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:52:43.601425 141168 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unique(Tensor([2147483649, 1],"int64"), )
[torch error] paddle.unique(Tensor([2147483649, 1],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 22404 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:53:30.300344 141414 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:53:30.301592 141414 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unique(Tensor([2147483649],"int64"), )
[torch error] paddle.unique(Tensor([2147483649],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 39035 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:54:16.528568 141887 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:54:16.529973 141887 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unique(Tensor([2147483649],"int64"), return_index=True, return_inverse=True, return_counts=True, dtype="int32", )
[paddle_to_torch] paddle.unique(Tensor([2147483649],"int64"), return_index=True, return_inverse=True, return_counts=True, dtype="int32", ) 
  return_index not in paddle_to_torch_args_map, can not call torch

W0213 12:54:26.335711 142133 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:54:26.336685 142133 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unique(Tensor([3, 286331153, 5],"float32"), return_index=True, return_inverse=True, return_counts=True, axis=0, )
[paddle_to_torch] paddle.unique(Tensor([3, 286331153, 5],"float32"), return_index=True, return_inverse=True, return_counts=True, axis=0, ) 
  return_index not in paddle_to_torch_args_map, can not call torch

W0213 12:54:35.555351 142374 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:54:35.556295 142374 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unique(Tensor([3, 5, 286331153],"float32"), return_index=True, return_inverse=True, return_counts=True, axis=0, )
[paddle_to_torch] paddle.unique(Tensor([3, 5, 286331153],"float32"), return_index=True, return_inverse=True, return_counts=True, axis=0, ) 
  return_index not in paddle_to_torch_args_map, can not call torch

W0213 12:54:45.247494 142389 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:54:45.248464 142389 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unique(Tensor([3, 715827883],"int64"), )
[torch error] paddle.unique(Tensor([3, 715827883],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 68605 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:55:30.944324 142404 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:55:30.945371 142404 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unique(Tensor([4294967295],"float32"), )
[torch error] paddle.unique(Tensor([4294967295],"float32"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 87800 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:56:47.959399 142877 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:56:47.960491 142877 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unique(Tensor([4294967295],"float32"), return_counts=True, )
[torch error] paddle.unique(Tensor([4294967295],"float32"), return_counts=True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 128690 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:58:01.130798 143580 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:58:01.131872 143580 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unique(Tensor([715827883, 3],"int64"), )
[torch error] paddle.unique(Tensor([715827883, 3],"int64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 151064 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:58:50.046860 144055 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:58:50.047945 144055 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unique_consecutive(Tensor([2147483649],"float64"), )
[torch error] paddle.unique_consecutive(Tensor([2147483649],"float64"), ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 8938 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 12:59:39.084034 144528 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 12:59:39.096387 144528 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unique_consecutive(Tensor([2147483649],"float64"), return_inverse=True, return_counts=True, )
[torch error] paddle.unique_consecutive(Tensor([2147483649],"float64"), return_inverse=True, return_counts=True, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 26305 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 13:00:27.203967 144774 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 13:00:27.205063 144774 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

test begin: paddle.unique_consecutive(Tensor([2147483649],"float64"), return_inverse=True, return_counts=True, axis=-1, )
[torch error] paddle.unique_consecutive(Tensor([2147483649],"float64"), return_inverse=True, return_counts=True, axis=-1, ) 
 CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 12.61 GiB is free. Process 143471 has 65.58 GiB memory in use. Process 38637 has 1014.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

W0213 13:01:16.038492 145247 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.8
W0213 13:01:16.039606 145247 gpu_resources.cc:164] device: 0, cuDNN Version: 8.6.

